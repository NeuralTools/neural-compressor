Search.setIndex({"docnames": ["autoapi/block_mask/index", "autoapi/neural_compressor/adaptor/adaptor/index", "autoapi/neural_compressor/adaptor/index", "autoapi/neural_compressor/adaptor/keras/index", "autoapi/neural_compressor/adaptor/keras_utils/conv2d/index", "autoapi/neural_compressor/adaptor/keras_utils/dense/index", "autoapi/neural_compressor/adaptor/keras_utils/depthwise_conv2d/index", "autoapi/neural_compressor/adaptor/keras_utils/index", "autoapi/neural_compressor/adaptor/keras_utils/pool2d/index", "autoapi/neural_compressor/adaptor/keras_utils/quantizer/index", "autoapi/neural_compressor/adaptor/keras_utils/separable_conv2d/index", "autoapi/neural_compressor/adaptor/mxnet/index", "autoapi/neural_compressor/adaptor/mxnet_utils/index", "autoapi/neural_compressor/adaptor/mxnet_utils/util/index", "autoapi/neural_compressor/adaptor/onnxrt/index", "autoapi/neural_compressor/adaptor/ox_utils/calibration/index", "autoapi/neural_compressor/adaptor/ox_utils/calibrator/index", "autoapi/neural_compressor/adaptor/ox_utils/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/activation/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/argmax/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/attention/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/binary_op/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/concat/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/conv/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/direct_q8/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/embed_layernorm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/gather/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/gavgpool/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/gemm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/lstm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/matmul/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/maxpool/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/norm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/ops/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/pad/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/pooling/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/reduce/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/resize/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/split/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/unary_op/index", "autoapi/neural_compressor/adaptor/ox_utils/quantizer/index", "autoapi/neural_compressor/adaptor/ox_utils/smooth_quant/index", "autoapi/neural_compressor/adaptor/ox_utils/util/index", "autoapi/neural_compressor/adaptor/ox_utils/weight_only/index", "autoapi/neural_compressor/adaptor/pytorch/index", "autoapi/neural_compressor/adaptor/query/index", "autoapi/neural_compressor/adaptor/tensorflow/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter_without_calib/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/dequantize_cast_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_util/index", "autoapi/neural_compressor/adaptor/tf_utils/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph_common/index", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_calibration/index", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_scaler/index", "autoapi/neural_compressor/adaptor/tf_utils/tf2onnx_converter/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat/index", "autoapi/neural_compressor/adaptor/tf_utils/util/index", "autoapi/neural_compressor/adaptor/torch_utils/auto_round/index", "autoapi/neural_compressor/adaptor/torch_utils/awq/index", "autoapi/neural_compressor/adaptor/torch_utils/bf16_convert/index", "autoapi/neural_compressor/adaptor/torch_utils/gptq/index", "autoapi/neural_compressor/adaptor/torch_utils/hawq_metric/index", "autoapi/neural_compressor/adaptor/torch_utils/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/modified_pickle/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/quantize/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/torch_load/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/utils/index", "autoapi/neural_compressor/adaptor/torch_utils/mixed_precision/index", "autoapi/neural_compressor/adaptor/torch_utils/model_wrapper/index", "autoapi/neural_compressor/adaptor/torch_utils/pattern_detector/index", "autoapi/neural_compressor/adaptor/torch_utils/symbolic_trace/index", "autoapi/neural_compressor/adaptor/torch_utils/teq/index", "autoapi/neural_compressor/adaptor/torch_utils/util/index", "autoapi/neural_compressor/adaptor/torch_utils/waq/auto_alpha/index", "autoapi/neural_compressor/adaptor/torch_utils/waq/calibration/index", "autoapi/neural_compressor/adaptor/torch_utils/waq/graph_trace/index", "autoapi/neural_compressor/adaptor/torch_utils/waq/index", "autoapi/neural_compressor/adaptor/torch_utils/waq/smooth_quant/index", "autoapi/neural_compressor/adaptor/torch_utils/waq/utils/index", "autoapi/neural_compressor/adaptor/torch_utils/weight_only/index", "autoapi/neural_compressor/algorithm/algorithm/index", "autoapi/neural_compressor/algorithm/fast_bias_correction/index", "autoapi/neural_compressor/algorithm/index", "autoapi/neural_compressor/algorithm/smooth_quant/index", "autoapi/neural_compressor/algorithm/weight_correction/index", "autoapi/neural_compressor/benchmark/index", "autoapi/neural_compressor/common/base_config/index", "autoapi/neural_compressor/common/base_tuning/index", "autoapi/neural_compressor/common/index", "autoapi/neural_compressor/common/tuning_param/index", "autoapi/neural_compressor/common/utils/constants/index", "autoapi/neural_compressor/common/utils/index", "autoapi/neural_compressor/common/utils/logger/index", "autoapi/neural_compressor/common/utils/save_load/index", "autoapi/neural_compressor/common/utils/utility/index", "autoapi/neural_compressor/compression/callbacks/index", "autoapi/neural_compressor/compression/distillation/criterions/index", "autoapi/neural_compressor/compression/distillation/index", "autoapi/neural_compressor/compression/distillation/optimizers/index", "autoapi/neural_compressor/compression/distillation/utility/index", "autoapi/neural_compressor/compression/hpo/index", "autoapi/neural_compressor/compression/hpo/sa_optimizer/index", "autoapi/neural_compressor/compression/hpo/search_algorithms/index", "autoapi/neural_compressor/compression/hpo/search_space/index", "autoapi/neural_compressor/compression/index", "autoapi/neural_compressor/compression/pruner/criteria/index", "autoapi/neural_compressor/compression/pruner/dsnot/index", "autoapi/neural_compressor/compression/pruner/index", "autoapi/neural_compressor/compression/pruner/model_slim/auto_slim/index", "autoapi/neural_compressor/compression/pruner/model_slim/index", "autoapi/neural_compressor/compression/pruner/model_slim/pattern_analyzer/index", "autoapi/neural_compressor/compression/pruner/model_slim/weight_slim/index", "autoapi/neural_compressor/compression/pruner/patterns/base/index", "autoapi/neural_compressor/compression/pruner/patterns/index", "autoapi/neural_compressor/compression/pruner/patterns/mha/index", "autoapi/neural_compressor/compression/pruner/patterns/ninm/index", "autoapi/neural_compressor/compression/pruner/patterns/nxm/index", "autoapi/neural_compressor/compression/pruner/pruners/base/index", "autoapi/neural_compressor/compression/pruner/pruners/basic/index", "autoapi/neural_compressor/compression/pruner/pruners/block_mask/index", "autoapi/neural_compressor/compression/pruner/pruners/index", "autoapi/neural_compressor/compression/pruner/pruners/mha/index", "autoapi/neural_compressor/compression/pruner/pruners/pattern_lock/index", "autoapi/neural_compressor/compression/pruner/pruners/progressive/index", "autoapi/neural_compressor/compression/pruner/pruners/retrain_free/index", "autoapi/neural_compressor/compression/pruner/pruners/sparse_gpt/index", "autoapi/neural_compressor/compression/pruner/pruning/index", "autoapi/neural_compressor/compression/pruner/regs/index", "autoapi/neural_compressor/compression/pruner/schedulers/index", "autoapi/neural_compressor/compression/pruner/tf_criteria/index", "autoapi/neural_compressor/compression/pruner/utils/index", "autoapi/neural_compressor/compression/pruner/wanda/index", "autoapi/neural_compressor/compression/pruner/wanda/prune/index", "autoapi/neural_compressor/compression/pruner/wanda/utils/index", "autoapi/neural_compressor/compression/pruner/wanda/wrapper/index", "autoapi/neural_compressor/conf/config/index", "autoapi/neural_compressor/conf/dotdict/index", "autoapi/neural_compressor/conf/index", "autoapi/neural_compressor/conf/pythonic_config/index", "autoapi/neural_compressor/config/index", "autoapi/neural_compressor/contrib/index", "autoapi/neural_compressor/contrib/strategy/index", "autoapi/neural_compressor/contrib/strategy/sigopt/index", "autoapi/neural_compressor/contrib/strategy/tpe/index", "autoapi/neural_compressor/data/dataloaders/base_dataloader/index", "autoapi/neural_compressor/data/dataloaders/dataloader/index", "autoapi/neural_compressor/data/dataloaders/default_dataloader/index", "autoapi/neural_compressor/data/dataloaders/fetcher/index", "autoapi/neural_compressor/data/dataloaders/index", "autoapi/neural_compressor/data/dataloaders/mxnet_dataloader/index", "autoapi/neural_compressor/data/dataloaders/onnxrt_dataloader/index", "autoapi/neural_compressor/data/dataloaders/pytorch_dataloader/index", "autoapi/neural_compressor/data/dataloaders/sampler/index", "autoapi/neural_compressor/data/dataloaders/tensorflow_dataloader/index", "autoapi/neural_compressor/data/datasets/bert_dataset/index", "autoapi/neural_compressor/data/datasets/coco_dataset/index", "autoapi/neural_compressor/data/datasets/dataset/index", "autoapi/neural_compressor/data/datasets/dummy_dataset/index", "autoapi/neural_compressor/data/datasets/dummy_dataset_v2/index", "autoapi/neural_compressor/data/datasets/imagenet_dataset/index", "autoapi/neural_compressor/data/datasets/index", "autoapi/neural_compressor/data/datasets/style_transfer_dataset/index", "autoapi/neural_compressor/data/filters/coco_filter/index", "autoapi/neural_compressor/data/filters/filter/index", "autoapi/neural_compressor/data/filters/index", "autoapi/neural_compressor/data/index", "autoapi/neural_compressor/data/transforms/coco_transform/index", "autoapi/neural_compressor/data/transforms/imagenet_transform/index", "autoapi/neural_compressor/data/transforms/index", "autoapi/neural_compressor/data/transforms/postprocess/index", "autoapi/neural_compressor/data/transforms/tokenization/index", "autoapi/neural_compressor/data/transforms/transform/index", "autoapi/neural_compressor/experimental/benchmark/index", "autoapi/neural_compressor/experimental/common/criterion/index", "autoapi/neural_compressor/experimental/common/dataloader/index", "autoapi/neural_compressor/experimental/common/index", "autoapi/neural_compressor/experimental/common/metric/index", "autoapi/neural_compressor/experimental/common/model/index", "autoapi/neural_compressor/experimental/common/optimizer/index", "autoapi/neural_compressor/experimental/common/postprocess/index", "autoapi/neural_compressor/experimental/common/torch_utils/index", "autoapi/neural_compressor/experimental/component/index", "autoapi/neural_compressor/experimental/compression/index", "autoapi/neural_compressor/experimental/contrib/index", "autoapi/neural_compressor/experimental/contrib/strategy/index", "autoapi/neural_compressor/experimental/contrib/strategy/sigopt/index", "autoapi/neural_compressor/experimental/contrib/strategy/tpe/index", "autoapi/neural_compressor/experimental/data/dataloaders/base_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/default_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/fetcher/index", "autoapi/neural_compressor/experimental/data/dataloaders/index", "autoapi/neural_compressor/experimental/data/dataloaders/mxnet_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/pytorch_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/sampler/index", "autoapi/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader/index", "autoapi/neural_compressor/experimental/data/datasets/bert_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/coco_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/dataset/index", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset_v2/index", "autoapi/neural_compressor/experimental/data/datasets/imagenet_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/index", "autoapi/neural_compressor/experimental/data/datasets/style_transfer_dataset/index", "autoapi/neural_compressor/experimental/data/filters/coco_filter/index", "autoapi/neural_compressor/experimental/data/filters/filter/index", "autoapi/neural_compressor/experimental/data/filters/index", "autoapi/neural_compressor/experimental/data/index", "autoapi/neural_compressor/experimental/data/transforms/imagenet_transform/index", "autoapi/neural_compressor/experimental/data/transforms/index", "autoapi/neural_compressor/experimental/data/transforms/tokenization/index", "autoapi/neural_compressor/experimental/data/transforms/transform/index", "autoapi/neural_compressor/experimental/distillation/index", "autoapi/neural_compressor/experimental/export/index", "autoapi/neural_compressor/experimental/export/qlinear2qdq/index", "autoapi/neural_compressor/experimental/export/tf2onnx/index", "autoapi/neural_compressor/experimental/export/torch2onnx/index", "autoapi/neural_compressor/experimental/graph_optimization/index", "autoapi/neural_compressor/experimental/index", "autoapi/neural_compressor/experimental/metric/bleu/index", "autoapi/neural_compressor/experimental/metric/bleu_util/index", "autoapi/neural_compressor/experimental/metric/coco_label_map/index", "autoapi/neural_compressor/experimental/metric/coco_tools/index", "autoapi/neural_compressor/experimental/metric/evaluate_squad/index", "autoapi/neural_compressor/experimental/metric/f1/index", "autoapi/neural_compressor/experimental/metric/index", "autoapi/neural_compressor/experimental/metric/metric/index", "autoapi/neural_compressor/experimental/mixed_precision/index", "autoapi/neural_compressor/experimental/model_conversion/index", "autoapi/neural_compressor/experimental/nas/basic_nas/index", "autoapi/neural_compressor/experimental/nas/dynas/index", "autoapi/neural_compressor/experimental/nas/index", "autoapi/neural_compressor/experimental/nas/nas/index", "autoapi/neural_compressor/experimental/nas/nas_utils/index", "autoapi/neural_compressor/experimental/nas/search_algorithms/index", "autoapi/neural_compressor/experimental/pruner_legacy/gradient_sensitivity/index", "autoapi/neural_compressor/experimental/pruner_legacy/group_lasso/index", "autoapi/neural_compressor/experimental/pruner_legacy/index", "autoapi/neural_compressor/experimental/pruner_legacy/magnitude/index", "autoapi/neural_compressor/experimental/pruner_legacy/pattern_lock/index", "autoapi/neural_compressor/experimental/pruner_legacy/pruner/index", "autoapi/neural_compressor/experimental/pruning/index", "autoapi/neural_compressor/experimental/pruning_recipes/index", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/index", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/pattern/index", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern/index", "autoapi/neural_compressor/experimental/pruning_v2/index", "autoapi/neural_compressor/experimental/pytorch_pruner/index", "autoapi/neural_compressor/experimental/pytorch_pruner/logger/index", "autoapi/neural_compressor/experimental/pytorch_pruner/patterns/index", "autoapi/neural_compressor/experimental/pytorch_pruner/prune_utils/index", "autoapi/neural_compressor/experimental/pytorch_pruner/pruner/index", "autoapi/neural_compressor/experimental/pytorch_pruner/pruning/index", "autoapi/neural_compressor/experimental/pytorch_pruner/scheduler/index", "autoapi/neural_compressor/experimental/quantization/index", "autoapi/neural_compressor/experimental/scheduler/index", "autoapi/neural_compressor/experimental/strategy/auto_mixed_precision/index", "autoapi/neural_compressor/experimental/strategy/basic/index", "autoapi/neural_compressor/experimental/strategy/bayesian/index", "autoapi/neural_compressor/experimental/strategy/exhaustive/index", "autoapi/neural_compressor/experimental/strategy/index", "autoapi/neural_compressor/experimental/strategy/mse/index", "autoapi/neural_compressor/experimental/strategy/mse_v2/index", "autoapi/neural_compressor/experimental/strategy/random/index", "autoapi/neural_compressor/experimental/strategy/strategy/index", "autoapi/neural_compressor/experimental/strategy/utils/constant/index", "autoapi/neural_compressor/experimental/strategy/utils/index", "autoapi/neural_compressor/experimental/strategy/utils/tuning_sampler/index", "autoapi/neural_compressor/experimental/strategy/utils/tuning_space/index", "autoapi/neural_compressor/experimental/strategy/utils/tuning_structs/index", "autoapi/neural_compressor/experimental/strategy/utils/utility/index", "autoapi/neural_compressor/index", "autoapi/neural_compressor/metric/bleu/index", "autoapi/neural_compressor/metric/bleu_util/index", "autoapi/neural_compressor/metric/coco_label_map/index", "autoapi/neural_compressor/metric/coco_tools/index", "autoapi/neural_compressor/metric/evaluate_squad/index", "autoapi/neural_compressor/metric/f1/index", "autoapi/neural_compressor/metric/index", "autoapi/neural_compressor/metric/metric/index", "autoapi/neural_compressor/mix_precision/index", "autoapi/neural_compressor/model/base_model/index", "autoapi/neural_compressor/model/index", "autoapi/neural_compressor/model/keras_model/index", "autoapi/neural_compressor/model/model/index", "autoapi/neural_compressor/model/mxnet_model/index", "autoapi/neural_compressor/model/nets_factory/index", "autoapi/neural_compressor/model/onnx_model/index", "autoapi/neural_compressor/model/tensorflow_model/index", "autoapi/neural_compressor/model/torch_model/index", "autoapi/neural_compressor/objective/index", "autoapi/neural_compressor/onnxrt/algorithms/index", "autoapi/neural_compressor/onnxrt/algorithms/layer_wise/core/index", "autoapi/neural_compressor/onnxrt/algorithms/layer_wise/index", "autoapi/neural_compressor/onnxrt/algorithms/smoother/calibrator/index", "autoapi/neural_compressor/onnxrt/algorithms/smoother/core/index", "autoapi/neural_compressor/onnxrt/algorithms/smoother/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/awq/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/gptq/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/rtn/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/utility/index", "autoapi/neural_compressor/onnxrt/index", "autoapi/neural_compressor/onnxrt/quantization/algorithm_entry/index", "autoapi/neural_compressor/onnxrt/quantization/autotune/index", "autoapi/neural_compressor/onnxrt/quantization/calibrate/index", "autoapi/neural_compressor/onnxrt/quantization/config/index", "autoapi/neural_compressor/onnxrt/quantization/index", "autoapi/neural_compressor/onnxrt/quantization/quantize/index", "autoapi/neural_compressor/onnxrt/utils/index", "autoapi/neural_compressor/onnxrt/utils/onnx_model/index", "autoapi/neural_compressor/onnxrt/utils/utility/index", "autoapi/neural_compressor/profiling/index", "autoapi/neural_compressor/profiling/parser/factory/index", "autoapi/neural_compressor/profiling/parser/index", "autoapi/neural_compressor/profiling/parser/onnx_parser/factory/index", "autoapi/neural_compressor/profiling/parser/onnx_parser/index", "autoapi/neural_compressor/profiling/parser/onnx_parser/parser/index", "autoapi/neural_compressor/profiling/parser/parser/index", "autoapi/neural_compressor/profiling/parser/result/index", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/factory/index", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/index", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/parser/index", "autoapi/neural_compressor/profiling/profiler/factory/index", "autoapi/neural_compressor/profiling/profiler/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/factory/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/profiler/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/utils/index", "autoapi/neural_compressor/profiling/profiler/profiler/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/factory/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/profiler/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/utils/index", "autoapi/neural_compressor/quantization/index", "autoapi/neural_compressor/strategy/auto/index", "autoapi/neural_compressor/strategy/auto_mixed_precision/index", "autoapi/neural_compressor/strategy/basic/index", "autoapi/neural_compressor/strategy/bayesian/index", "autoapi/neural_compressor/strategy/conservative/index", "autoapi/neural_compressor/strategy/exhaustive/index", "autoapi/neural_compressor/strategy/hawq_v2/index", "autoapi/neural_compressor/strategy/index", "autoapi/neural_compressor/strategy/mse/index", "autoapi/neural_compressor/strategy/mse_v2/index", "autoapi/neural_compressor/strategy/random/index", "autoapi/neural_compressor/strategy/strategy/index", "autoapi/neural_compressor/strategy/utils/constant/index", "autoapi/neural_compressor/strategy/utils/index", "autoapi/neural_compressor/strategy/utils/tuning_sampler/index", "autoapi/neural_compressor/strategy/utils/tuning_space/index", "autoapi/neural_compressor/strategy/utils/tuning_structs/index", "autoapi/neural_compressor/strategy/utils/utility/index", "autoapi/neural_compressor/template/api_doc_example/index", "autoapi/neural_compressor/template/index", "autoapi/neural_compressor/tensorflow/algorithms/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/tensorflow/index", "autoapi/neural_compressor/tensorflow/index", "autoapi/neural_compressor/tensorflow/keras/index", "autoapi/neural_compressor/tensorflow/keras/layers/conv2d/index", "autoapi/neural_compressor/tensorflow/keras/layers/dense/index", "autoapi/neural_compressor/tensorflow/keras/layers/depthwise_conv2d/index", "autoapi/neural_compressor/tensorflow/keras/layers/index", "autoapi/neural_compressor/tensorflow/keras/layers/layer_initializer/index", "autoapi/neural_compressor/tensorflow/keras/layers/pool2d/index", "autoapi/neural_compressor/tensorflow/keras/layers/separable_conv2d/index", "autoapi/neural_compressor/tensorflow/keras/quantization/config/index", "autoapi/neural_compressor/tensorflow/keras/quantization/index", "autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index", "autoapi/neural_compressor/tensorflow/quantization/autotune/index", "autoapi/neural_compressor/tensorflow/quantization/config/index", "autoapi/neural_compressor/tensorflow/quantization/index", "autoapi/neural_compressor/tensorflow/quantization/quantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter_without_calib/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/bf16_convert/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/dequantize_cast_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_fake_quant/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value_without_calib/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_requantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_requantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/meta_op_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_hostconst_converter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_quantized_op_cse/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/rnn_convert/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/scale_propagation/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/insert_qdq_pattern/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/merge_duplicated_qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/share_qdq_y_pattern/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index", "autoapi/neural_compressor/tensorflow/quantization/utils/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/fake_quantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_config/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_helper/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/optimize_layer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/quantize_layer_add/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/quantize_layer_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/quantize_layer_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_wrapper/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_concatv2/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_deconv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_in/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_matmul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_pooling/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/optimize_qdq/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_concatv2/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_for_intel_cpu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_matmul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_pooling/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/bias_correction/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/graph_transform_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/insert_logging/index", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/rerange_quantized_concat/index", "autoapi/neural_compressor/tensorflow/quantization/utils/utility/index", "autoapi/neural_compressor/tensorflow/utils/constants/index", "autoapi/neural_compressor/tensorflow/utils/data/index", "autoapi/neural_compressor/tensorflow/utils/index", "autoapi/neural_compressor/tensorflow/utils/model/index", "autoapi/neural_compressor/tensorflow/utils/model_wrappers/index", "autoapi/neural_compressor/tensorflow/utils/nets_factory/index", "autoapi/neural_compressor/tensorflow/utils/utility/index", "autoapi/neural_compressor/torch/algorithms/base_algorithm/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/fp8_quant/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/modules/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/observer/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/save_load/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/scale/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/tensor/index", "autoapi/neural_compressor/torch/algorithms/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/load/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index", "autoapi/neural_compressor/torch/algorithms/mix_precision/half_precision_convert/index", "autoapi/neural_compressor/torch/algorithms/mix_precision/index", "autoapi/neural_compressor/torch/algorithms/mix_precision/module_wrappers/index", "autoapi/neural_compressor/torch/algorithms/mx_quant/index", "autoapi/neural_compressor/torch/algorithms/mx_quant/mx/index", "autoapi/neural_compressor/torch/algorithms/mx_quant/utils/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/core/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/half_precision_rewriter/index", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/save_load/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/smooth_quant/index", "autoapi/neural_compressor/torch/algorithms/smooth_quant/utility/index", "autoapi/neural_compressor/torch/algorithms/static_quant/index", "autoapi/neural_compressor/torch/algorithms/static_quant/save_load/index", "autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index", "autoapi/neural_compressor/torch/algorithms/static_quant/utility/index", "autoapi/neural_compressor/torch/algorithms/weight_only/autoround/index", "autoapi/neural_compressor/torch/algorithms/weight_only/awq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/utility/index", "autoapi/neural_compressor/torch/algorithms/weight_only/index", "autoapi/neural_compressor/torch/algorithms/weight_only/modules/index", "autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index", "autoapi/neural_compressor/torch/algorithms/weight_only/save_load/index", "autoapi/neural_compressor/torch/algorithms/weight_only/teq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/utility/index", "autoapi/neural_compressor/torch/amp/autocast/index", "autoapi/neural_compressor/torch/amp/fp8/functions/index", "autoapi/neural_compressor/torch/amp/fp8/index", "autoapi/neural_compressor/torch/amp/index", "autoapi/neural_compressor/torch/export/_export/index", "autoapi/neural_compressor/torch/export/index", "autoapi/neural_compressor/torch/index", "autoapi/neural_compressor/torch/quantization/algorithm_entry/index", "autoapi/neural_compressor/torch/quantization/autotune/index", "autoapi/neural_compressor/torch/quantization/config/index", "autoapi/neural_compressor/torch/quantization/index", "autoapi/neural_compressor/torch/quantization/load_entry/index", "autoapi/neural_compressor/torch/quantization/quantize/index", "autoapi/neural_compressor/torch/utils/auto_accelerator/index", "autoapi/neural_compressor/torch/utils/constants/index", "autoapi/neural_compressor/torch/utils/environ/index", "autoapi/neural_compressor/torch/utils/index", "autoapi/neural_compressor/torch/utils/utility/index", "autoapi/neural_compressor/training/index", "autoapi/neural_compressor/utils/collect_layer_histogram/index", "autoapi/neural_compressor/utils/constant/index", "autoapi/neural_compressor/utils/create_obj_from_config/index", "autoapi/neural_compressor/utils/index", "autoapi/neural_compressor/utils/kl_divergence/index", "autoapi/neural_compressor/utils/load_huggingface/index", "autoapi/neural_compressor/utils/logger/index", "autoapi/neural_compressor/utils/neural_insights_utils/index", "autoapi/neural_compressor/utils/options/index", "autoapi/neural_compressor/utils/pytorch/index", "autoapi/neural_compressor/utils/utility/index", "autoapi/neural_compressor/utils/weights_details/index", "autoapi/neural_compressor/version/index", "docs/build_docs/source/index", "docs/source/CODE_OF_CONDUCT", "docs/source/CONTRIBUTING", "docs/source/FX", "docs/source/NAS", "docs/source/SECURITY", "docs/source/Welcome", "docs/source/adaptor", "docs/source/add_new_adaptor", "docs/source/add_new_data_type", "docs/source/api-doc/adaptor", "docs/source/api-doc/adaptor/onnxrt", "docs/source/api-doc/adaptor/torch_utils", "docs/source/api-doc/api_doc_example", "docs/source/api-doc/apis", "docs/source/api-doc/benchmark", "docs/source/api-doc/compression", "docs/source/api-doc/config", "docs/source/api-doc/mix_precision", "docs/source/api-doc/model", "docs/source/api-doc/objective", "docs/source/api-doc/quantization", "docs/source/api-doc/strategy", "docs/source/api-doc/training", "docs/source/benchmark", "docs/source/calibration", "docs/source/coding_style", "docs/source/dataloader", "docs/source/dataset", "docs/source/design", "docs/source/diagnosis", "docs/source/distillation", "docs/source/distillation_quantization", "docs/source/distributed", "docs/source/examples_readme", "docs/source/export", "docs/source/faq", "docs/source/framework_yaml", "docs/source/get_started", "docs/source/incompatible_changes", "docs/source/infrastructure", "docs/source/installation_guide", "docs/source/legal_information", "docs/source/llm_recipes", "docs/source/metric", "docs/source/migration", "docs/source/mixed_precision", "docs/source/model", "docs/source/mx_quantization", "docs/source/neural_coder/README", "docs/source/neural_coder/docs/AWSSageMakerSupport", "docs/source/neural_coder/docs/BigDLNanoSupport", "docs/source/neural_coder/docs/IntelCPU_PerformanceSetting", "docs/source/neural_coder/docs/PythonAPI", "docs/source/neural_coder/docs/PythonLauncher", "docs/source/neural_coder/docs/Quantization", "docs/source/neural_coder/docs/SupportMatrix", "docs/source/neural_coder/docs/release_notes/v0.4", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/DEVELOP", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/README", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/RELEASE", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/CHANGELOG", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/README", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/vsc-extension-quickstart", "docs/source/neural_insights/README", "docs/source/neural_insights/docs/source/onnx_accuracy_debug", "docs/source/neural_insights/docs/source/pytorch_nlp_cli_mode", "docs/source/neural_insights/docs/source/tf_accuracy_debug", "docs/source/neural_insights/gui/README", "docs/source/neural_solution/README", "docs/source/neural_solution/docs/source/README", "docs/source/neural_solution/docs/source/description_api", "docs/source/neural_solution/docs/source/ns_design_doc", "docs/source/neural_solution/docs/source/template/task_request_description", "docs/source/neural_solution/examples/README", "docs/source/neural_solution/examples/custom_models_optimized/tf_example1/README", "docs/source/neural_solution/examples/hf_models/README", "docs/source/neural_solution/examples/hf_models_grpc/README", "docs/source/neural_solution/frontend/README", "docs/source/objective", "docs/source/orchestration", "docs/source/pruning", "docs/source/publication_list", "docs/source/pythonic_style", "docs/source/quantization", "docs/source/quantization_layer_wise", "docs/source/quantization_mixed_precision", "docs/source/quantization_weight_only", "docs/source/releases_info", "docs/source/sigopt_strategy", "docs/source/smooth_quant", "docs/source/tensorboard", "docs/source/transform", "docs/source/tuning_strategies", "docs/source/user_guide", "docs/source/user_yaml", "docs/source/validated_model_list", "index"], "filenames": ["autoapi/block_mask/index.rst", "autoapi/neural_compressor/adaptor/adaptor/index.rst", "autoapi/neural_compressor/adaptor/index.rst", "autoapi/neural_compressor/adaptor/keras/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/conv2d/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/dense/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/depthwise_conv2d/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/pool2d/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/quantizer/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/separable_conv2d/index.rst", "autoapi/neural_compressor/adaptor/mxnet/index.rst", "autoapi/neural_compressor/adaptor/mxnet_utils/index.rst", "autoapi/neural_compressor/adaptor/mxnet_utils/util/index.rst", "autoapi/neural_compressor/adaptor/onnxrt/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/calibration/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/calibrator/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/activation/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/argmax/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/attention/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/binary_op/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/concat/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/conv/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/direct_q8/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/embed_layernorm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/gather/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/gavgpool/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/gemm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/lstm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/matmul/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/maxpool/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/norm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/ops/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/pad/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/pooling/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/reduce/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/resize/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/split/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/unary_op/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/quantizer/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/smooth_quant/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/util/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/weight_only/index.rst", "autoapi/neural_compressor/adaptor/pytorch/index.rst", "autoapi/neural_compressor/adaptor/query/index.rst", "autoapi/neural_compressor/adaptor/tensorflow/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter_without_calib/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/dequantize_cast_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_util/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph_common/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_calibration/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_scaler/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/tf2onnx_converter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/util/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/auto_round/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/awq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/bf16_convert/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/gptq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/hawq_metric/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/modified_pickle/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/quantize/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/torch_load/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/utils/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/mixed_precision/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/model_wrapper/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/pattern_detector/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/symbolic_trace/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/teq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/util/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/waq/auto_alpha/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/waq/calibration/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/waq/graph_trace/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/waq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/waq/smooth_quant/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/waq/utils/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/weight_only/index.rst", "autoapi/neural_compressor/algorithm/algorithm/index.rst", "autoapi/neural_compressor/algorithm/fast_bias_correction/index.rst", "autoapi/neural_compressor/algorithm/index.rst", "autoapi/neural_compressor/algorithm/smooth_quant/index.rst", "autoapi/neural_compressor/algorithm/weight_correction/index.rst", "autoapi/neural_compressor/benchmark/index.rst", "autoapi/neural_compressor/common/base_config/index.rst", "autoapi/neural_compressor/common/base_tuning/index.rst", "autoapi/neural_compressor/common/index.rst", "autoapi/neural_compressor/common/tuning_param/index.rst", "autoapi/neural_compressor/common/utils/constants/index.rst", "autoapi/neural_compressor/common/utils/index.rst", "autoapi/neural_compressor/common/utils/logger/index.rst", "autoapi/neural_compressor/common/utils/save_load/index.rst", "autoapi/neural_compressor/common/utils/utility/index.rst", "autoapi/neural_compressor/compression/callbacks/index.rst", "autoapi/neural_compressor/compression/distillation/criterions/index.rst", "autoapi/neural_compressor/compression/distillation/index.rst", "autoapi/neural_compressor/compression/distillation/optimizers/index.rst", "autoapi/neural_compressor/compression/distillation/utility/index.rst", "autoapi/neural_compressor/compression/hpo/index.rst", "autoapi/neural_compressor/compression/hpo/sa_optimizer/index.rst", "autoapi/neural_compressor/compression/hpo/search_algorithms/index.rst", "autoapi/neural_compressor/compression/hpo/search_space/index.rst", "autoapi/neural_compressor/compression/index.rst", "autoapi/neural_compressor/compression/pruner/criteria/index.rst", "autoapi/neural_compressor/compression/pruner/dsnot/index.rst", "autoapi/neural_compressor/compression/pruner/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/auto_slim/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/pattern_analyzer/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/weight_slim/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/base/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/mha/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/ninm/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/nxm/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/base/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/basic/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/block_mask/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/mha/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/pattern_lock/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/progressive/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/retrain_free/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/sparse_gpt/index.rst", "autoapi/neural_compressor/compression/pruner/pruning/index.rst", "autoapi/neural_compressor/compression/pruner/regs/index.rst", "autoapi/neural_compressor/compression/pruner/schedulers/index.rst", "autoapi/neural_compressor/compression/pruner/tf_criteria/index.rst", "autoapi/neural_compressor/compression/pruner/utils/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/prune/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/utils/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/wrapper/index.rst", "autoapi/neural_compressor/conf/config/index.rst", "autoapi/neural_compressor/conf/dotdict/index.rst", "autoapi/neural_compressor/conf/index.rst", "autoapi/neural_compressor/conf/pythonic_config/index.rst", "autoapi/neural_compressor/config/index.rst", "autoapi/neural_compressor/contrib/index.rst", "autoapi/neural_compressor/contrib/strategy/index.rst", "autoapi/neural_compressor/contrib/strategy/sigopt/index.rst", "autoapi/neural_compressor/contrib/strategy/tpe/index.rst", "autoapi/neural_compressor/data/dataloaders/base_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/default_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/fetcher/index.rst", "autoapi/neural_compressor/data/dataloaders/index.rst", "autoapi/neural_compressor/data/dataloaders/mxnet_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/onnxrt_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/pytorch_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/sampler/index.rst", "autoapi/neural_compressor/data/dataloaders/tensorflow_dataloader/index.rst", "autoapi/neural_compressor/data/datasets/bert_dataset/index.rst", "autoapi/neural_compressor/data/datasets/coco_dataset/index.rst", "autoapi/neural_compressor/data/datasets/dataset/index.rst", "autoapi/neural_compressor/data/datasets/dummy_dataset/index.rst", "autoapi/neural_compressor/data/datasets/dummy_dataset_v2/index.rst", "autoapi/neural_compressor/data/datasets/imagenet_dataset/index.rst", "autoapi/neural_compressor/data/datasets/index.rst", "autoapi/neural_compressor/data/datasets/style_transfer_dataset/index.rst", "autoapi/neural_compressor/data/filters/coco_filter/index.rst", "autoapi/neural_compressor/data/filters/filter/index.rst", "autoapi/neural_compressor/data/filters/index.rst", "autoapi/neural_compressor/data/index.rst", "autoapi/neural_compressor/data/transforms/coco_transform/index.rst", "autoapi/neural_compressor/data/transforms/imagenet_transform/index.rst", "autoapi/neural_compressor/data/transforms/index.rst", "autoapi/neural_compressor/data/transforms/postprocess/index.rst", "autoapi/neural_compressor/data/transforms/tokenization/index.rst", "autoapi/neural_compressor/data/transforms/transform/index.rst", "autoapi/neural_compressor/experimental/benchmark/index.rst", "autoapi/neural_compressor/experimental/common/criterion/index.rst", "autoapi/neural_compressor/experimental/common/dataloader/index.rst", "autoapi/neural_compressor/experimental/common/index.rst", "autoapi/neural_compressor/experimental/common/metric/index.rst", "autoapi/neural_compressor/experimental/common/model/index.rst", "autoapi/neural_compressor/experimental/common/optimizer/index.rst", "autoapi/neural_compressor/experimental/common/postprocess/index.rst", "autoapi/neural_compressor/experimental/common/torch_utils/index.rst", "autoapi/neural_compressor/experimental/component/index.rst", "autoapi/neural_compressor/experimental/compression/index.rst", "autoapi/neural_compressor/experimental/contrib/index.rst", "autoapi/neural_compressor/experimental/contrib/strategy/index.rst", "autoapi/neural_compressor/experimental/contrib/strategy/sigopt/index.rst", "autoapi/neural_compressor/experimental/contrib/strategy/tpe/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/base_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/default_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/fetcher/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/mxnet_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/pytorch_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/sampler/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/datasets/bert_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/coco_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset_v2/index.rst", "autoapi/neural_compressor/experimental/data/datasets/imagenet_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/index.rst", "autoapi/neural_compressor/experimental/data/datasets/style_transfer_dataset/index.rst", "autoapi/neural_compressor/experimental/data/filters/coco_filter/index.rst", "autoapi/neural_compressor/experimental/data/filters/filter/index.rst", "autoapi/neural_compressor/experimental/data/filters/index.rst", "autoapi/neural_compressor/experimental/data/index.rst", "autoapi/neural_compressor/experimental/data/transforms/imagenet_transform/index.rst", "autoapi/neural_compressor/experimental/data/transforms/index.rst", "autoapi/neural_compressor/experimental/data/transforms/tokenization/index.rst", "autoapi/neural_compressor/experimental/data/transforms/transform/index.rst", "autoapi/neural_compressor/experimental/distillation/index.rst", "autoapi/neural_compressor/experimental/export/index.rst", "autoapi/neural_compressor/experimental/export/qlinear2qdq/index.rst", "autoapi/neural_compressor/experimental/export/tf2onnx/index.rst", "autoapi/neural_compressor/experimental/export/torch2onnx/index.rst", "autoapi/neural_compressor/experimental/graph_optimization/index.rst", "autoapi/neural_compressor/experimental/index.rst", "autoapi/neural_compressor/experimental/metric/bleu/index.rst", "autoapi/neural_compressor/experimental/metric/bleu_util/index.rst", "autoapi/neural_compressor/experimental/metric/coco_label_map/index.rst", "autoapi/neural_compressor/experimental/metric/coco_tools/index.rst", "autoapi/neural_compressor/experimental/metric/evaluate_squad/index.rst", "autoapi/neural_compressor/experimental/metric/f1/index.rst", "autoapi/neural_compressor/experimental/metric/index.rst", "autoapi/neural_compressor/experimental/metric/metric/index.rst", "autoapi/neural_compressor/experimental/mixed_precision/index.rst", "autoapi/neural_compressor/experimental/model_conversion/index.rst", "autoapi/neural_compressor/experimental/nas/basic_nas/index.rst", "autoapi/neural_compressor/experimental/nas/dynas/index.rst", "autoapi/neural_compressor/experimental/nas/index.rst", "autoapi/neural_compressor/experimental/nas/nas/index.rst", "autoapi/neural_compressor/experimental/nas/nas_utils/index.rst", "autoapi/neural_compressor/experimental/nas/search_algorithms/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/gradient_sensitivity/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/group_lasso/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/magnitude/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/pattern_lock/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/pruner/index.rst", "autoapi/neural_compressor/experimental/pruning/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/pattern/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern/index.rst", "autoapi/neural_compressor/experimental/pruning_v2/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/logger/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/patterns/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/prune_utils/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/pruner/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/pruning/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/scheduler/index.rst", "autoapi/neural_compressor/experimental/quantization/index.rst", "autoapi/neural_compressor/experimental/scheduler/index.rst", "autoapi/neural_compressor/experimental/strategy/auto_mixed_precision/index.rst", "autoapi/neural_compressor/experimental/strategy/basic/index.rst", "autoapi/neural_compressor/experimental/strategy/bayesian/index.rst", "autoapi/neural_compressor/experimental/strategy/exhaustive/index.rst", "autoapi/neural_compressor/experimental/strategy/index.rst", "autoapi/neural_compressor/experimental/strategy/mse/index.rst", "autoapi/neural_compressor/experimental/strategy/mse_v2/index.rst", "autoapi/neural_compressor/experimental/strategy/random/index.rst", "autoapi/neural_compressor/experimental/strategy/strategy/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/constant/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/tuning_sampler/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/tuning_space/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/tuning_structs/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/utility/index.rst", "autoapi/neural_compressor/index.rst", "autoapi/neural_compressor/metric/bleu/index.rst", "autoapi/neural_compressor/metric/bleu_util/index.rst", "autoapi/neural_compressor/metric/coco_label_map/index.rst", "autoapi/neural_compressor/metric/coco_tools/index.rst", "autoapi/neural_compressor/metric/evaluate_squad/index.rst", "autoapi/neural_compressor/metric/f1/index.rst", "autoapi/neural_compressor/metric/index.rst", "autoapi/neural_compressor/metric/metric/index.rst", "autoapi/neural_compressor/mix_precision/index.rst", "autoapi/neural_compressor/model/base_model/index.rst", "autoapi/neural_compressor/model/index.rst", "autoapi/neural_compressor/model/keras_model/index.rst", "autoapi/neural_compressor/model/model/index.rst", "autoapi/neural_compressor/model/mxnet_model/index.rst", "autoapi/neural_compressor/model/nets_factory/index.rst", "autoapi/neural_compressor/model/onnx_model/index.rst", "autoapi/neural_compressor/model/tensorflow_model/index.rst", "autoapi/neural_compressor/model/torch_model/index.rst", "autoapi/neural_compressor/objective/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/layer_wise/core/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/layer_wise/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/smoother/calibrator/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/smoother/core/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/smoother/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/awq/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/gptq/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/rtn/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/utility/index.rst", "autoapi/neural_compressor/onnxrt/index.rst", "autoapi/neural_compressor/onnxrt/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/onnxrt/quantization/autotune/index.rst", "autoapi/neural_compressor/onnxrt/quantization/calibrate/index.rst", "autoapi/neural_compressor/onnxrt/quantization/config/index.rst", "autoapi/neural_compressor/onnxrt/quantization/index.rst", "autoapi/neural_compressor/onnxrt/quantization/quantize/index.rst", "autoapi/neural_compressor/onnxrt/utils/index.rst", "autoapi/neural_compressor/onnxrt/utils/onnx_model/index.rst", "autoapi/neural_compressor/onnxrt/utils/utility/index.rst", "autoapi/neural_compressor/profiling/index.rst", "autoapi/neural_compressor/profiling/parser/factory/index.rst", "autoapi/neural_compressor/profiling/parser/index.rst", "autoapi/neural_compressor/profiling/parser/onnx_parser/factory/index.rst", "autoapi/neural_compressor/profiling/parser/onnx_parser/index.rst", "autoapi/neural_compressor/profiling/parser/onnx_parser/parser/index.rst", "autoapi/neural_compressor/profiling/parser/parser/index.rst", "autoapi/neural_compressor/profiling/parser/result/index.rst", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/factory/index.rst", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/index.rst", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/parser/index.rst", "autoapi/neural_compressor/profiling/profiler/factory/index.rst", "autoapi/neural_compressor/profiling/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/factory/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/utils/index.rst", "autoapi/neural_compressor/profiling/profiler/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/factory/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/utils/index.rst", "autoapi/neural_compressor/quantization/index.rst", "autoapi/neural_compressor/strategy/auto/index.rst", "autoapi/neural_compressor/strategy/auto_mixed_precision/index.rst", "autoapi/neural_compressor/strategy/basic/index.rst", "autoapi/neural_compressor/strategy/bayesian/index.rst", "autoapi/neural_compressor/strategy/conservative/index.rst", "autoapi/neural_compressor/strategy/exhaustive/index.rst", "autoapi/neural_compressor/strategy/hawq_v2/index.rst", "autoapi/neural_compressor/strategy/index.rst", "autoapi/neural_compressor/strategy/mse/index.rst", "autoapi/neural_compressor/strategy/mse_v2/index.rst", "autoapi/neural_compressor/strategy/random/index.rst", "autoapi/neural_compressor/strategy/strategy/index.rst", "autoapi/neural_compressor/strategy/utils/constant/index.rst", "autoapi/neural_compressor/strategy/utils/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_sampler/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_space/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_structs/index.rst", "autoapi/neural_compressor/strategy/utils/utility/index.rst", "autoapi/neural_compressor/template/api_doc_example/index.rst", "autoapi/neural_compressor/template/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/tensorflow/index.rst", "autoapi/neural_compressor/tensorflow/index.rst", "autoapi/neural_compressor/tensorflow/keras/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/conv2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/dense/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/depthwise_conv2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/layer_initializer/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/pool2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/layers/separable_conv2d/index.rst", "autoapi/neural_compressor/tensorflow/keras/quantization/config/index.rst", "autoapi/neural_compressor/tensorflow/keras/quantization/index.rst", "autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/tensorflow/quantization/autotune/index.rst", "autoapi/neural_compressor/tensorflow/quantization/config/index.rst", "autoapi/neural_compressor/tensorflow/quantization/index.rst", "autoapi/neural_compressor/tensorflow/quantization/quantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_converter_without_calib/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/bf16_convert/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/dequantize_cast_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/bf16/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_fake_quant/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/freeze_value_without_calib/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_conv_requantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/fuse_matmul_requantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/meta_op_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_hostconst_converter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/post_quantized_op_cse/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/rnn_convert/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/int8/scale_propagation/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/insert_qdq_pattern/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/merge_duplicated_qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/qdq/share_qdq_y_pattern/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/fake_quantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_config/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_helper/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/optimize_layer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/quantize_layer_add/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/quantize_layer_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_layers/quantize_layer_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qat/quantize_wrapper/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_concatv2/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_deconv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_in/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_matmul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/fuse_qdq_pooling/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/qdq/optimize_qdq/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_concatv2/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_for_intel_cpu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_matmul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph/quantize_graph_pooling/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/bias_correction/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/graph_transform_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/insert_logging/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/transform_graph/rerange_quantized_concat/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/utility/index.rst", "autoapi/neural_compressor/tensorflow/utils/constants/index.rst", "autoapi/neural_compressor/tensorflow/utils/data/index.rst", "autoapi/neural_compressor/tensorflow/utils/index.rst", "autoapi/neural_compressor/tensorflow/utils/model/index.rst", "autoapi/neural_compressor/tensorflow/utils/model_wrappers/index.rst", "autoapi/neural_compressor/tensorflow/utils/nets_factory/index.rst", "autoapi/neural_compressor/tensorflow/utils/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/base_algorithm/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/fp8_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/modules/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/observer/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/scale/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/tensor/index.rst", "autoapi/neural_compressor/torch/algorithms/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/load/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index.rst", "autoapi/neural_compressor/torch/algorithms/mix_precision/half_precision_convert/index.rst", "autoapi/neural_compressor/torch/algorithms/mix_precision/index.rst", "autoapi/neural_compressor/torch/algorithms/mix_precision/module_wrappers/index.rst", "autoapi/neural_compressor/torch/algorithms/mx_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/mx_quant/mx/index.rst", "autoapi/neural_compressor/torch/algorithms/mx_quant/utils/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/core/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/half_precision_rewriter/index.rst", "autoapi/neural_compressor/torch/algorithms/pt2e_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/smooth_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/smooth_quant/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/autoround/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/awq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/modules/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/save_load/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/teq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/utility/index.rst", "autoapi/neural_compressor/torch/amp/autocast/index.rst", "autoapi/neural_compressor/torch/amp/fp8/functions/index.rst", "autoapi/neural_compressor/torch/amp/fp8/index.rst", "autoapi/neural_compressor/torch/amp/index.rst", "autoapi/neural_compressor/torch/export/_export/index.rst", "autoapi/neural_compressor/torch/export/index.rst", "autoapi/neural_compressor/torch/index.rst", "autoapi/neural_compressor/torch/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/torch/quantization/autotune/index.rst", "autoapi/neural_compressor/torch/quantization/config/index.rst", "autoapi/neural_compressor/torch/quantization/index.rst", "autoapi/neural_compressor/torch/quantization/load_entry/index.rst", "autoapi/neural_compressor/torch/quantization/quantize/index.rst", "autoapi/neural_compressor/torch/utils/auto_accelerator/index.rst", "autoapi/neural_compressor/torch/utils/constants/index.rst", "autoapi/neural_compressor/torch/utils/environ/index.rst", "autoapi/neural_compressor/torch/utils/index.rst", "autoapi/neural_compressor/torch/utils/utility/index.rst", "autoapi/neural_compressor/training/index.rst", "autoapi/neural_compressor/utils/collect_layer_histogram/index.rst", "autoapi/neural_compressor/utils/constant/index.rst", "autoapi/neural_compressor/utils/create_obj_from_config/index.rst", "autoapi/neural_compressor/utils/index.rst", "autoapi/neural_compressor/utils/kl_divergence/index.rst", "autoapi/neural_compressor/utils/load_huggingface/index.rst", "autoapi/neural_compressor/utils/logger/index.rst", "autoapi/neural_compressor/utils/neural_insights_utils/index.rst", "autoapi/neural_compressor/utils/options/index.rst", "autoapi/neural_compressor/utils/pytorch/index.rst", "autoapi/neural_compressor/utils/utility/index.rst", "autoapi/neural_compressor/utils/weights_details/index.rst", "autoapi/neural_compressor/version/index.rst", "docs/build_docs/source/index.rst", "docs/source/CODE_OF_CONDUCT.md", "docs/source/CONTRIBUTING.md", "docs/source/FX.md", "docs/source/NAS.md", "docs/source/SECURITY.md", "docs/source/Welcome.md", "docs/source/adaptor.md", "docs/source/add_new_adaptor.md", "docs/source/add_new_data_type.md", "docs/source/api-doc/adaptor.rst", "docs/source/api-doc/adaptor/onnxrt.rst", "docs/source/api-doc/adaptor/torch_utils.rst", "docs/source/api-doc/api_doc_example.rst", "docs/source/api-doc/apis.rst", "docs/source/api-doc/benchmark.rst", "docs/source/api-doc/compression.rst", "docs/source/api-doc/config.rst", "docs/source/api-doc/mix_precision.rst", "docs/source/api-doc/model.rst", "docs/source/api-doc/objective.rst", "docs/source/api-doc/quantization.rst", "docs/source/api-doc/strategy.rst", "docs/source/api-doc/training.rst", "docs/source/benchmark.md", "docs/source/calibration.md", "docs/source/coding_style.md", "docs/source/dataloader.md", "docs/source/dataset.md", "docs/source/design.md", "docs/source/diagnosis.md", "docs/source/distillation.md", "docs/source/distillation_quantization.md", "docs/source/distributed.md", "docs/source/examples_readme.md", "docs/source/export.md", "docs/source/faq.md", "docs/source/framework_yaml.md", "docs/source/get_started.md", "docs/source/incompatible_changes.md", "docs/source/infrastructure.md", "docs/source/installation_guide.md", "docs/source/legal_information.md", "docs/source/llm_recipes.md", "docs/source/metric.md", "docs/source/migration.md", "docs/source/mixed_precision.md", "docs/source/model.md", "docs/source/mx_quantization.md", "docs/source/neural_coder/README.md", "docs/source/neural_coder/docs/AWSSageMakerSupport.md", "docs/source/neural_coder/docs/BigDLNanoSupport.md", "docs/source/neural_coder/docs/IntelCPU_PerformanceSetting.md", "docs/source/neural_coder/docs/PythonAPI.md", "docs/source/neural_coder/docs/PythonLauncher.md", "docs/source/neural_coder/docs/Quantization.md", "docs/source/neural_coder/docs/SupportMatrix.md", "docs/source/neural_coder/docs/release_notes/v0.4.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/DEVELOP.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/README.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/RELEASE.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE.md", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/CHANGELOG.md", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/README.md", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/vsc-extension-quickstart.md", "docs/source/neural_insights/README.md", "docs/source/neural_insights/docs/source/onnx_accuracy_debug.md", "docs/source/neural_insights/docs/source/pytorch_nlp_cli_mode.md", "docs/source/neural_insights/docs/source/tf_accuracy_debug.md", "docs/source/neural_insights/gui/README.md", "docs/source/neural_solution/README.md", "docs/source/neural_solution/docs/source/README.md", "docs/source/neural_solution/docs/source/description_api.md", "docs/source/neural_solution/docs/source/ns_design_doc.md", "docs/source/neural_solution/docs/source/template/task_request_description.md", "docs/source/neural_solution/examples/README.md", "docs/source/neural_solution/examples/custom_models_optimized/tf_example1/README.md", "docs/source/neural_solution/examples/hf_models/README.md", "docs/source/neural_solution/examples/hf_models_grpc/README.md", "docs/source/neural_solution/frontend/README.md", "docs/source/objective.md", "docs/source/orchestration.md", "docs/source/pruning.md", "docs/source/publication_list.md", "docs/source/pythonic_style.md", "docs/source/quantization.md", "docs/source/quantization_layer_wise.md", "docs/source/quantization_mixed_precision.md", "docs/source/quantization_weight_only.md", "docs/source/releases_info.md", "docs/source/sigopt_strategy.md", "docs/source/smooth_quant.md", "docs/source/tensorboard.md", "docs/source/transform.md", "docs/source/tuning_strategies.md", "docs/source/user_guide.md", "docs/source/user_yaml.md", "docs/source/validated_model_list.md", "index.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">block_mask</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.adaptor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.dense</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.depthwise_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.pool2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.separable_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.mxnet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.mxnet_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.mxnet_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.onnxrt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.calibrator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.activation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.argmax</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.binary_op</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.concat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.direct_q8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.embed_layernorm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.gather</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.gavgpool</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.gemm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.lstm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.maxpool</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.pad</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.reduce</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.resize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.split</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.unary_op</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.pytorch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.query</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tensorflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_converter_without_calib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.bf16</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph_common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.smooth_quant_calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.smooth_quant_scaler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.tf2onnx_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.bias_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.insert_logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.auto_round</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.awq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.bf16_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.gptq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.hawq_metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.model_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.pattern_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.symbolic_trace</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.teq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.waq.auto_alpha</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.waq.calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.waq.graph_trace</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.waq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.waq.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.waq.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.algorithm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.fast_bias_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.weight_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.benchmark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.base_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.base_tuning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.tuning_param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.logger</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.save_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.callbacks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation.criterions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation.optimizers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo.sa_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo.search_algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo.search_space</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.criteria</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.dsnot</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim.auto_slim</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim.pattern_analyzer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim.weight_slim</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.mha</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.ninm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.nxm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.basic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.block_mask</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.mha</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.pattern_lock</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.progressive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.retrain_free</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.sparse_gpt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.regs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.schedulers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.tf_criteria</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda.prune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda.wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf.dotdict</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf.pythonic_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib.strategy.sigopt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib.strategy.tpe</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.base_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.default_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.fetcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.mxnet_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.onnxrt_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.pytorch_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.tensorflow_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.bert_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.coco_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.dummy_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.dummy_dataset_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.imagenet_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.style_transfer_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.filters.coco_filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.filters.filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.filters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.coco_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.imagenet_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.postprocess</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.tokenization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.benchmark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.criterion</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.postprocess</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.torch_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.component</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.compression</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib.strategy.sigopt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib.strategy.tpe</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.base_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.default_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.fetcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.mxnet_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.onnxrt_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.pytorch_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.tensorflow_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.bert_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.coco_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.dummy_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.dummy_dataset_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.imagenet_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.style_transfer_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.filters.coco_filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.filters.filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.filters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms.imagenet_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms.tokenization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms.transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.distillation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export.qlinear2qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export.tf2onnx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export.torch2onnx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.graph_optimization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.bleu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.bleu_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.coco_label_map</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.coco_tools</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.evaluate_squad</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.f1</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.model_conversion</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.basic_nas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.dynas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.nas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.nas_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.search_algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.gradient_sensitivity</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.group_lasso</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.magnitude</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.pattern_lock</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes.patterns</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes.patterns.pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes.patterns.tile_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.logger</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.patterns</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.prune_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.pruning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.scheduler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.scheduler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.auto_mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.basic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.bayesian</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.exhaustive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.mse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.mse_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.tuning_sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.tuning_space</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.tuning_structs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.bleu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.bleu_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.coco_label_map</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.coco_tools</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.evaluate_squad</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.f1</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.mix_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.keras_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.mxnet_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.nets_factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.onnx_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.tensorflow_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.torch_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.objective</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.layer_wise.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.layer_wise</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.smoother.calibrator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.smoother.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.smoother</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.awq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.gptq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.rtn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.algorithm_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.autotune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.calibrate</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.utils.onnx_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.onnx_parser.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.onnx_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.onnx_parser.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.tensorflow_parser.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.tensorflow_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.tensorflow_parser.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.auto</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.auto_mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.basic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.bayesian</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.conservative</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.exhaustive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.hawq_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.mse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.mse_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.tuning_sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.tuning_space</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.tuning_structs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.template.api_doc_example</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.template</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother.calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother.scaler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.tensorflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers.conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers.dense</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers.depthwise_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers.layer_initializer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers.pool2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.layers.separable_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.keras.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.algorithm_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.autotune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph_common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.transform_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.data</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.model_wrappers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.nets_factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.base_algorithm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.fp8_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.modules</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.observer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.save_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.scale</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.tensor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise.load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise.modified_pickle</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.mix_precision.half_precision_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.mix_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.mix_precision.module_wrappers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.mx_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.mx_quant.mx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.mx_quant.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.pt2e_quant.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.pt2e_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.smooth_quant.save_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.smooth_quant.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.smooth_quant.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant.save_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant.static_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.autoround</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.awq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.gptq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.bitpack</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.qtensor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.modules</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.rtn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.save_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.teq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp.autocast</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp.fp8.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp.fp8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.export._export</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.export</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.algorithm_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.autotune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.load_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.auto_accelerator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.environ</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.collect_layer_histogram</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.create_obj_from_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.kl_divergence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.load_huggingface</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.logger</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.neural_insights_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.options</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.pytorch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.weights_details</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.version</span></code>", "Intel\u00ae Neural Compressor Documentation", "Contributor Covenant Code of Conduct", "Contribution Guidelines", "FX", "Neural Architecture Search", "Security Policy", "Intel\u00ae Neural Compressor", "Adaptor", "How to Add An Adaptor", "How to Support New Data Type, Like Int4, with a Few Line Changes", "Adaptor", "ONNX Runtime", "Torch Utils", "API Document Example", "APIs", "Benchmark", "Compression", "Config", "Mix Precision", "Model", "Objective", "Quantization", "Strategy", "Training", "Benchmarking", "Calibration Algorithms in Quantization", "INC Coding Conventions", "DataLoader", "Dataset", "Design", "Diagnosis", "Distillation", "Distillation for Quantization", "Distributed Training and Inference (Evaluation)", "Examples", "Export", "Frequently Asked Questions", "Framework YAML Configuration Files", "Getting Started", "Incompatible changes between v1.2 and v1.1", "Infrastructure of Intel\u00ae Neural Compressor", "Installation", "Legal Information", "LLMs Quantization Recipes", "Metrics", "Code Migration from Intel Neural Compressor 1.X to Intel Neural Compressor 2.X", "Mixed Precision", "Model", "Microscaling Quantization", "Neural Coder", "AWS Amazon SageMaker Support", "BigDL Nano Support", "Intel CPU Platforms: Best Performance Setting", "Neural Coder as Python API", "Python Launcher", "Neural Coder for Quantization", "Supported Optimization Features", "v0.4", "Changelog", "neural_compressor_ext_lab", "Intel\u00ae Neural Compressor as JupyterLab Extension", "Making a new release of neural_compressor_ext_lab", "Changelog", "neural_compressor_ext_lab_alibaba", "Making a new release of neural_compressor_ext_lab_alibaba", "Change Log", "Neural Coder", "Welcome to your VS Code Extension", "Neural Insights", "Step by step example how to debug accuracy with Neural Insights", "Step by step example how to dump weights data for PyTorch model with Neural Insights", "Step by step example how to debug accuracy with Neural Insights", "Getting Started with Create React App", "What\u2019s Neural Solution?", "Get started", "Neural Solution API", "Design Doc for Optimization as a Service [WIP]", "Task request description", "Examples List", "An end-to-end example: quantize a custom model with Neural Solution", "An end-to-end example: quantize a Hugging Face model with Neural Solution", "An end-to-end example: quantize a Hugging Face model with Neural Solution gRPC API", "Client", "Objective", "Optimization Orchestration", "Pruning", "Full Publications/Events (80)", "Pythonic Style Access for Configurations", "Quantization", "Layer Wise Quantization (LWQ)", "Turn OFF Auto Mixed Precision during Quantization", "Weight Only Quantization (WOQ)", "Release", "SigOpt Strategy", "Smooth Quant", "TensorBoard", "Transform", "Tuning Strategies", "User Guide", "User YAML Configuration Files", "Validated Models", "Intel\u00ae Neural Compressor Documentation"], "terms": {"block": [0, 44, 162, 165, 172, 198, 209, 212, 217, 223, 343, 384, 392, 395, 447, 602, 619, 692, 700, 735, 737, 743, 749], "mask": [0, 198, 205, 207, 210, 212, 216, 217, 247, 290, 316, 345, 369, 737, 752], "adaptor_registri": [1, 659], "cl": [1, 159, 173, 187, 189, 191, 195, 196, 205, 210, 219, 220, 221, 249, 256, 264, 266, 271, 292, 299, 305, 327, 334, 338, 343, 345, 347, 358, 373, 384, 440, 572, 585, 649, 678], "sourc": [1, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 188, 189, 191, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 232, 235, 236, 237, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 259, 260, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 278, 279, 280, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 302, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 332, 333, 334, 335, 338, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 361, 362, 363, 364, 365, 366, 367, 369, 370, 371, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 389, 391, 392, 394, 395, 397, 398, 399, 400, 404, 405, 407, 409, 411, 412, 413, 414, 416, 417, 419, 421, 422, 423, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 443, 444, 445, 446, 447, 450, 451, 453, 455, 456, 466, 468, 469, 470, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 527, 528, 529, 530, 533, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 564, 565, 567, 569, 570, 571, 572, 573, 583, 584, 585, 586, 588, 590, 591, 592, 593, 596, 597, 598, 601, 602, 603, 604, 605, 607, 612, 613, 615, 616, 618, 619, 620, 624, 627, 628, 629, 632, 633, 637, 638, 639, 641, 643, 644, 645, 646, 647, 648, 649, 650, 651, 655, 658, 694, 697, 711, 713, 715, 716, 718, 738], "The": [1, 3, 11, 14, 16, 34, 54, 74, 113, 119, 121, 140, 148, 158, 160, 165, 171, 172, 173, 178, 179, 180, 182, 187, 188, 189, 191, 195, 196, 198, 199, 203, 205, 207, 208, 210, 211, 212, 217, 218, 219, 220, 221, 222, 223, 228, 229, 231, 232, 235, 236, 237, 247, 248, 249, 250, 251, 255, 256, 264, 266, 269, 271, 274, 278, 279, 280, 290, 291, 292, 293, 294, 298, 299, 305, 306, 311, 313, 314, 315, 317, 318, 320, 322, 323, 324, 326, 327, 329, 330, 332, 333, 334, 335, 338, 340, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 355, 356, 357, 358, 362, 364, 366, 367, 368, 370, 371, 373, 374, 382, 384, 397, 398, 405, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 444, 446, 447, 450, 451, 455, 468, 469, 472, 479, 499, 533, 539, 541, 565, 567, 570, 572, 573, 583, 590, 592, 597, 598, 601, 602, 603, 604, 605, 612, 613, 616, 618, 620, 627, 628, 629, 632, 637, 638, 639, 641, 643, 644, 648, 649, 650, 653, 655, 656, 659, 660, 661, 662, 664, 668, 671, 674, 676, 677, 678, 679, 680, 682, 683, 685, 687, 689, 691, 692, 693, 695, 696, 697, 698, 699, 700, 703, 704, 706, 709, 711, 712, 713, 715, 716, 718, 719, 720, 721, 723, 724, 725, 726, 727, 728, 729, 731, 735, 736, 737, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752], "decor": [1, 16, 34, 67, 68, 70, 148, 171, 173, 179, 187, 191, 195, 196, 205, 210, 219, 221, 264, 271, 305, 320, 327, 334, 338, 343, 345, 347, 358, 361, 373, 384, 405, 440, 492, 493, 495, 572, 598, 613, 620, 637, 649, 655, 656, 659, 749], "us": [1, 13, 16, 34, 42, 43, 44, 48, 49, 70, 103, 105, 116, 141, 153, 158, 160, 165, 172, 178, 187, 189, 191, 195, 196, 198, 203, 205, 210, 214, 215, 219, 221, 222, 225, 229, 231, 232, 235, 236, 245, 246, 247, 248, 249, 250, 251, 254, 263, 264, 265, 266, 271, 278, 279, 288, 289, 290, 291, 292, 293, 294, 297, 304, 305, 309, 310, 311, 313, 314, 316, 320, 321, 322, 327, 334, 335, 338, 340, 343, 345, 346, 347, 348, 349, 352, 355, 358, 361, 362, 366, 367, 369, 373, 384, 391, 392, 394, 395, 405, 422, 427, 428, 432, 435, 437, 440, 444, 446, 447, 453, 455, 456, 472, 473, 474, 495, 536, 567, 572, 583, 591, 598, 602, 603, 619, 620, 632, 633, 637, 638, 639, 640, 641, 642, 644, 649, 653, 654, 655, 656, 658, 659, 660, 676, 677, 678, 680, 682, 683, 684, 685, 687, 689, 691, 693, 694, 697, 698, 699, 700, 701, 702, 703, 705, 706, 709, 711, 713, 715, 716, 718, 720, 721, 722, 723, 724, 731, 732, 733, 735, 737, 738, 739, 740, 741, 742, 743, 744, 745, 747, 748, 749, 751, 752], "regist": [1, 16, 34, 156, 158, 171, 173, 179, 189, 191, 195, 196, 198, 200, 205, 206, 210, 213, 219, 220, 221, 222, 249, 256, 264, 266, 271, 292, 299, 305, 320, 327, 334, 338, 343, 345, 347, 358, 361, 373, 384, 405, 440, 446, 466, 572, 583, 584, 598, 633, 637, 646, 656, 659, 678, 680, 685, 696, 697, 719, 735, 746, 749], "all": [1, 13, 16, 34, 44, 45, 63, 97, 152, 158, 159, 165, 172, 173, 175, 178, 179, 188, 191, 196, 200, 205, 213, 223, 231, 232, 237, 238, 245, 249, 256, 264, 265, 271, 274, 280, 288, 292, 299, 305, 310, 313, 316, 318, 320, 327, 334, 338, 339, 343, 349, 358, 361, 366, 369, 371, 373, 375, 384, 440, 446, 466, 488, 522, 567, 570, 572, 573, 583, 585, 590, 592, 597, 598, 601, 602, 603, 604, 605, 612, 616, 618, 629, 641, 649, 653, 654, 658, 659, 660, 661, 678, 679, 680, 685, 689, 693, 697, 701, 709, 712, 713, 716, 717, 718, 719, 720, 723, 724, 726, 727, 731, 732, 733, 736, 737, 738, 740, 742, 743, 746, 748, 749], "subclass": [1, 16, 34, 171, 173, 191, 195, 196, 205, 210, 219, 221, 242, 246, 249, 256, 264, 271, 285, 289, 292, 299, 305, 320, 327, 334, 338, 343, 345, 347, 358, 361, 373, 384, 440, 598, 659], "paramet": [1, 11, 13, 14, 16, 42, 43, 44, 45, 67, 68, 70, 86, 105, 116, 132, 140, 141, 148, 151, 152, 153, 158, 159, 163, 165, 171, 172, 173, 178, 179, 180, 182, 186, 187, 188, 189, 191, 193, 195, 196, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 228, 229, 231, 232, 235, 236, 246, 247, 249, 256, 260, 264, 266, 271, 278, 279, 289, 290, 292, 299, 302, 305, 306, 308, 309, 310, 311, 313, 314, 316, 317, 318, 320, 322, 323, 324, 326, 327, 328, 329, 330, 332, 333, 334, 335, 338, 340, 343, 344, 345, 346, 347, 348, 352, 358, 362, 364, 366, 367, 369, 370, 371, 373, 374, 378, 382, 384, 386, 391, 392, 394, 395, 398, 405, 422, 427, 428, 432, 440, 444, 446, 447, 450, 453, 468, 472, 492, 493, 495, 511, 536, 552, 565, 570, 572, 583, 585, 596, 598, 602, 603, 605, 613, 619, 620, 632, 633, 637, 638, 641, 644, 645, 646, 648, 649, 655, 660, 679, 680, 683, 685, 692, 696, 697, 700, 712, 718, 719, 720, 721, 726, 731, 732, 737, 740, 741, 743, 745, 746, 748, 749, 751], "framework_specific_info": [1, 3, 11, 14, 45, 47, 455, 456, 659], "base": [1, 13, 16, 34, 46, 47, 86, 105, 116, 120, 122, 132, 144, 153, 156, 162, 165, 173, 179, 188, 195, 196, 197, 198, 200, 206, 213, 220, 222, 232, 237, 240, 245, 247, 249, 256, 264, 274, 280, 283, 288, 290, 292, 299, 305, 320, 326, 328, 334, 335, 338, 340, 345, 355, 358, 362, 373, 375, 382, 383, 384, 391, 399, 437, 440, 444, 456, 511, 536, 540, 542, 552, 561, 567, 570, 573, 584, 590, 592, 597, 601, 602, 603, 604, 605, 612, 616, 618, 629, 656, 658, 659, 660, 661, 678, 680, 684, 685, 689, 697, 698, 706, 707, 709, 718, 721, 726, 729, 732, 733, 737, 738, 740, 743, 745, 746, 747, 749, 752], "framework": [1, 3, 11, 13, 14, 45, 178, 179, 189, 191, 200, 206, 210, 213, 217, 218, 219, 233, 234, 238, 239, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 258, 261, 264, 266, 267, 271, 276, 277, 281, 282, 284, 286, 289, 290, 291, 292, 293, 294, 295, 296, 297, 299, 301, 303, 305, 311, 320, 321, 348, 356, 362, 373, 374, 375, 376, 378, 438, 444, 455, 466, 641, 658, 659, 661, 677, 678, 682, 685, 686, 690, 691, 692, 693, 696, 697, 698, 720, 721, 737, 738, 740, 744, 747, 748, 749, 750, 751, 752], "layer": [1, 3, 11, 14, 46, 47, 116, 117, 118, 119, 121, 122, 152, 155, 157, 159, 170, 171, 172, 176, 189, 192, 201, 203, 204, 205, 209, 214, 223, 226, 227, 231, 232, 266, 273, 343, 344, 386, 392, 394, 455, 456, 536, 537, 538, 539, 541, 542, 572, 582, 585, 598, 605, 639, 641, 649, 658, 659, 660, 661, 684, 692, 721, 737, 743, 744, 750], "mxnet_util": 2, "util": [2, 12, 17, 105, 110, 111, 139, 142, 151, 153, 154, 155, 163, 179, 190, 197, 200, 224, 231, 232, 273, 312, 314, 344, 354, 365, 367, 386, 388, 389, 391, 392, 394, 400, 420, 425, 436, 468, 469, 472, 581, 582, 627, 629, 660, 661, 662, 677, 678, 685, 697, 701, 721, 737, 740, 749, 750], "ox_util": 2, "oper": [2, 17, 43, 104, 110, 140, 148, 203, 204, 209, 227, 231, 232, 260, 302, 343, 422, 427, 450, 530, 565, 655, 676, 679, 682, 687, 718, 724, 737, 740, 743, 746, 748, 749], "activ": [2, 17, 29, 44, 141, 150, 165, 172, 192, 231, 232, 273, 362, 391, 444, 446, 453, 598, 602, 659, 660, 661, 677, 682, 684, 689, 697, 719, 720, 723, 731, 732, 733, 739, 740, 743, 746, 747, 751], "argmax": [2, 17, 29], "attent": [2, 17, 29, 162, 201, 203, 214, 231, 232, 247, 290, 602, 653, 683, 737], "binary_op": [2, 17, 29], "concat": [2, 17, 29, 147, 564], "conv": [2, 17, 29, 58, 62, 66, 71, 72, 73, 92, 109, 176, 231, 232, 400, 483, 487, 491, 496, 497, 498, 517, 529, 655, 660, 661, 697, 737, 739, 740, 749], "direct_q8": [2, 17, 29], "embed_layernorm": [2, 17, 29], "gather": [2, 13, 17, 29, 231, 232, 343], "gavgpool": [2, 17, 29], "gemm": [2, 17, 29, 231, 232, 400], "lstm": [2, 17, 29], "matmul": [2, 17, 29, 44, 53, 59, 65, 73, 94, 109, 128, 137, 209, 231, 232, 343, 391, 392, 394, 395, 400, 470, 478, 484, 490, 498, 519, 529, 548, 557, 689, 721, 743, 749], "maxpool": [2, 17, 29, 129, 138, 549, 558, 689], "norm": [2, 17, 29], "op": [2, 13, 17, 29, 45, 51, 53, 65, 66, 67, 68, 69, 70, 71, 72, 74, 78, 81, 85, 88, 91, 92, 93, 94, 96, 105, 107, 109, 123, 124, 125, 131, 133, 134, 135, 136, 141, 143, 146, 148, 151, 153, 163, 165, 172, 176, 203, 231, 232, 310, 355, 362, 363, 422, 427, 433, 435, 437, 444, 445, 446, 453, 476, 478, 490, 491, 492, 493, 494, 495, 496, 497, 499, 503, 506, 510, 513, 516, 517, 518, 519, 521, 527, 529, 543, 544, 545, 551, 553, 554, 555, 556, 560, 563, 565, 598, 602, 619, 620, 637, 643, 649, 658, 659, 660, 661, 682, 689, 697, 698, 722, 723, 737, 740, 742, 744, 746, 747, 749, 751], "pad": [2, 17, 29, 44, 71, 72, 247, 264, 290, 305, 395, 496, 497, 680, 748], "pool": [2, 17, 29, 728], "reduc": [2, 17, 29, 231, 232, 659, 677, 684, 697, 698, 718, 719, 737, 738, 740, 741, 742, 743, 746, 749, 751], "resiz": [2, 17, 29, 247, 248, 260, 264, 290, 291, 302, 305, 680, 748], "split": [2, 17, 29, 43, 82, 172, 263, 264, 304, 305, 507, 655, 741, 743, 746, 748], "unary_op": [2, 17, 29], "calibr": [2, 11, 13, 14, 17, 44, 49, 89, 90, 140, 165, 172, 178, 231, 232, 235, 236, 278, 279, 311, 348, 386, 389, 390, 391, 392, 395, 397, 398, 428, 452, 468, 472, 474, 514, 515, 603, 619, 632, 643, 659, 661, 680, 691, 692, 737, 740, 743, 749, 750, 751], "quantiz": [2, 11, 13, 14, 16, 17, 42, 43, 44, 48, 49, 88, 92, 94, 96, 99, 107, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 150, 151, 152, 153, 154, 155, 159, 160, 161, 164, 165, 170, 172, 176, 178, 180, 185, 188, 231, 232, 235, 236, 260, 267, 274, 278, 279, 302, 310, 311, 312, 322, 349, 355, 361, 365, 386, 388, 389, 391, 392, 394, 395, 405, 433, 435, 437, 446, 450, 451, 453, 455, 456, 573, 582, 585, 590, 591, 592, 596, 597, 598, 601, 602, 603, 604, 605, 615, 616, 618, 619, 637, 638, 639, 643, 644, 648, 649, 659, 666, 678, 679, 680, 685, 686, 689, 691, 692, 696, 699, 701, 706, 708, 709, 712, 725, 727, 728, 730, 736, 738, 744, 747, 748, 749, 750, 751], "smooth_quant": [2, 17, 157, 165, 175, 231, 232, 365, 602, 678, 740, 746], "weight_onli": [2, 17, 232, 648, 658, 678, 700, 741, 743], "tf_util": 2, "graph_rewrit": [2, 111], "bf16": [2, 44, 87, 111, 151, 231, 232, 362, 391, 392, 394, 395, 444, 512, 586, 588, 659, 660, 689, 697, 703, 708, 712, 718, 742, 749, 752], "gener": [2, 13, 48, 49, 87, 111, 122, 148, 152, 165, 178, 182, 183, 203, 223, 235, 236, 237, 246, 249, 250, 251, 252, 264, 278, 279, 280, 289, 292, 293, 294, 295, 305, 313, 321, 352, 366, 374, 400, 423, 428, 432, 447, 466, 470, 473, 474, 512, 542, 565, 567, 591, 598, 602, 605, 629, 638, 654, 655, 659, 661, 679, 683, 696, 697, 698, 700, 701, 706, 711, 713, 715, 716, 718, 720, 721, 735, 737, 738, 740, 742, 743, 746, 747, 748, 749], "int8": [2, 18, 19, 43, 44, 87, 111, 123, 124, 125, 131, 133, 134, 135, 136, 143, 148, 172, 177, 178, 231, 232, 260, 302, 308, 309, 310, 362, 364, 391, 392, 394, 395, 405, 444, 446, 466, 470, 512, 543, 544, 545, 551, 553, 554, 555, 556, 560, 565, 619, 648, 649, 654, 655, 658, 659, 660, 661, 676, 680, 684, 689, 695, 697, 698, 700, 703, 706, 708, 709, 712, 718, 721, 723, 738, 739, 740, 742, 743, 744, 745, 746, 747, 748, 751], "onnx": [2, 14, 15, 16, 29, 41, 43, 44, 87, 111, 142, 176, 231, 232, 243, 286, 308, 309, 310, 374, 381, 386, 389, 391, 392, 394, 395, 397, 398, 404, 405, 422, 647, 654, 658, 659, 660, 662, 679, 682, 686, 687, 689, 690, 692, 698, 699, 700, 703, 708, 709, 721, 738, 739, 743, 744, 746, 749], "qdq": [2, 42, 87, 111, 112, 113, 142, 165, 172, 231, 232, 308, 309, 310, 455, 512, 531, 532, 533, 619, 659, 682, 687, 692, 708, 709, 740, 744, 746], "graph_bas": [2, 87, 111, 512], "quantize_graph": [2, 111, 531], "qat": [2, 111, 112, 163, 232, 322, 382, 531, 532, 570, 684, 685, 692, 697, 740], "quantize_graph_bas": [2, 111, 112, 531, 532], "quantize_graph_bn": [2, 111, 112, 531, 532], "quantize_graph_concatv2": [2, 111, 112, 531, 532], "quantize_graph_conv": [2, 111, 112, 531, 532], "quantize_graph_for_intel_cpu": [2, 111, 112, 531, 532], "quantize_graph_matmul": [2, 111, 112, 531, 532], "quantize_graph_pool": [2, 111, 112, 531, 532], "transform_graph": [2, 111, 531], "bias_correct": [2, 111, 145, 531, 562], "graph_transform_bas": [2, 111, 145, 531, 562], "insert_log": [2, 111, 145, 531, 562], "rerange_quantized_concat": [2, 111, 145, 531, 562], "graph_convert": [2, 111, 531], "graph_converter_without_calib": [2, 111, 531], "graph_util": [2, 111, 531], "quantize_graph_common": [2, 111, 531], "smooth_quant_calibr": [2, 111], "smooth_quant_scal": [2, 111], "tf2onnx_convert": [2, 111], "torch_util": [2, 268, 312, 365, 658, 741, 746], "layer_wise_qu": [2, 154, 232, 386, 400, 741], "modified_pickl": [2, 154, 155, 581, 582], "torch_load": [2, 154, 155], "bf16_convert": [2, 52, 87, 111, 154, 477, 512], "hawq_metr": [2, 154], "model_wrapp": [2, 15, 154, 568], "pattern_detector": [2, 154], "symbolic_trac": [2, 154], "tensorflow": [2, 52, 54, 75, 76, 77, 87, 95, 101, 102, 103, 104, 105, 106, 110, 111, 112, 114, 117, 130, 140, 141, 142, 145, 148, 189, 191, 222, 231, 232, 246, 247, 248, 249, 252, 254, 256, 264, 271, 289, 290, 291, 292, 295, 297, 299, 305, 309, 310, 311, 314, 316, 320, 321, 322, 348, 356, 367, 369, 373, 374, 382, 421, 422, 426, 427, 428, 438, 649, 654, 656, 658, 659, 660, 677, 678, 679, 682, 683, 684, 686, 689, 690, 692, 693, 697, 698, 699, 700, 708, 709, 720, 723, 737, 738, 739, 745, 746, 749, 751], "kerasadaptor": [3, 455], "mxnetadaptor": 11, "do": [11, 14, 152, 188, 219, 231, 232, 246, 247, 289, 290, 306, 310, 313, 316, 346, 366, 369, 596, 605, 648, 653, 660, 678, 680, 685, 689, 692, 696, 697, 713, 716, 737, 742, 744, 746, 749], "inspect": [11, 14, 744, 747], "tensor": [11, 13, 14, 15, 16, 43, 44, 70, 105, 140, 148, 153, 158, 159, 165, 172, 198, 200, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 222, 232, 264, 305, 308, 310, 343, 345, 355, 382, 395, 437, 450, 495, 565, 570, 572, 583, 585, 591, 593, 596, 598, 602, 619, 620, 632, 644, 648, 649, 655, 661, 678, 679, 680, 682, 700, 737, 740, 744, 747, 748, 749], "dict": [11, 13, 14, 44, 45, 116, 148, 151, 152, 153, 158, 165, 172, 173, 178, 186, 191, 195, 198, 200, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 226, 229, 231, 232, 235, 236, 246, 265, 271, 278, 279, 289, 308, 310, 315, 316, 317, 318, 320, 323, 326, 327, 328, 335, 338, 340, 343, 344, 345, 346, 347, 352, 355, 361, 364, 368, 369, 370, 371, 373, 374, 382, 386, 391, 392, 394, 400, 428, 443, 446, 447, 456, 466, 470, 536, 565, 570, 572, 583, 586, 596, 598, 602, 603, 605, 619, 624, 627, 637, 638, 639, 641, 648, 649, 655, 660, 678, 687, 696, 737, 739, 740, 746, 747, 749], "specif": [11, 14, 42, 46, 104, 116, 172, 178, 179, 191, 223, 227, 231, 232, 247, 248, 249, 250, 254, 256, 271, 290, 291, 292, 293, 297, 299, 329, 330, 332, 333, 334, 373, 428, 536, 567, 620, 637, 646, 653, 656, 659, 660, 677, 678, 679, 682, 683, 689, 691, 695, 696, 697, 698, 699, 700, 701, 705, 706, 708, 712, 718, 720, 726, 735, 737, 739, 743, 749, 751], "configur": [11, 13, 14, 45, 118, 151, 165, 172, 178, 179, 223, 228, 231, 232, 235, 236, 238, 249, 252, 265, 270, 278, 279, 292, 295, 306, 310, 311, 322, 323, 324, 326, 335, 340, 344, 348, 349, 355, 373, 374, 384, 428, 437, 446, 468, 472, 538, 596, 598, 602, 632, 638, 640, 641, 647, 648, 655, 656, 659, 660, 680, 682, 697, 705, 719, 726, 731, 732, 733, 735, 737, 740, 743, 744, 746, 748, 749, 752], "mxnet": [12, 13, 16, 232, 242, 246, 249, 252, 256, 264, 285, 289, 292, 295, 299, 305, 311, 320, 348, 373, 374, 379, 428, 654, 658, 659, 660, 677, 679, 686, 689, 692, 697, 698, 699, 739, 749, 751], "init": [12, 17, 42, 175, 190, 200, 202, 224, 680, 696, 749], "optyp": [13, 231, 232, 308, 660], "enum": [13, 591], "type": [13, 16, 42, 43, 44, 45, 74, 96, 105, 116, 122, 132, 140, 148, 151, 152, 153, 158, 165, 172, 173, 182, 186, 189, 191, 195, 196, 199, 203, 204, 205, 210, 219, 220, 221, 223, 226, 229, 231, 232, 245, 247, 249, 256, 264, 266, 271, 288, 290, 292, 299, 305, 310, 313, 314, 316, 320, 327, 334, 338, 343, 345, 347, 352, 358, 362, 364, 366, 367, 369, 373, 382, 384, 386, 391, 392, 394, 395, 405, 432, 433, 440, 444, 446, 447, 450, 468, 472, 499, 521, 536, 542, 552, 565, 570, 572, 583, 596, 598, 602, 605, 619, 620, 637, 648, 649, 659, 660, 680, 682, 685, 687, 689, 692, 697, 698, 700, 719, 721, 726, 727, 731, 732, 740, 741, 743, 745, 748, 749, 750, 751], "isiter": 13, "obj": [13, 105, 200, 223, 246, 289, 306, 311, 322, 323, 324, 326, 335, 340, 344, 348, 374, 384, 428, 638, 641, 649], "bool": [13, 42, 43, 44, 141, 148, 152, 158, 163, 165, 172, 187, 199, 205, 231, 232, 247, 249, 260, 264, 290, 292, 302, 305, 310, 314, 320, 343, 361, 367, 373, 391, 392, 394, 400, 405, 443, 447, 453, 466, 470, 565, 583, 598, 603, 605, 619, 620, 629, 632, 644, 648, 649, 679, 680, 696, 729, 739, 748], "check": [13, 44, 67, 68, 105, 148, 165, 172, 223, 238, 249, 292, 308, 344, 405, 492, 493, 565, 572, 598, 602, 648, 649, 658, 682, 685, 693, 702, 704, 706, 713, 716, 717, 721, 724, 727, 728, 744], "whether": [13, 43, 44, 105, 116, 148, 152, 158, 165, 172, 205, 231, 232, 245, 247, 260, 264, 288, 290, 302, 305, 314, 316, 320, 343, 367, 369, 373, 391, 392, 394, 405, 536, 565, 572, 583, 598, 605, 619, 620, 641, 644, 648, 649, 659, 680, 696, 740, 743, 746, 748], "object": [13, 42, 43, 44, 45, 74, 86, 105, 116, 132, 148, 151, 153, 156, 158, 163, 165, 178, 186, 188, 198, 200, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 228, 229, 231, 232, 235, 236, 237, 247, 248, 249, 264, 265, 267, 278, 279, 280, 290, 291, 292, 305, 306, 311, 316, 324, 326, 329, 330, 332, 333, 334, 335, 340, 343, 344, 345, 346, 347, 348, 352, 365, 369, 373, 374, 382, 383, 422, 427, 428, 432, 446, 499, 511, 536, 552, 565, 567, 570, 572, 583, 584, 586, 596, 598, 602, 607, 619, 637, 638, 641, 648, 649, 655, 656, 660, 666, 676, 678, 679, 680, 688, 696, 697, 699, 736, 737, 739, 740, 748, 749, 750, 752], "i": [13, 43, 44, 45, 48, 49, 51, 54, 55, 60, 64, 70, 82, 85, 105, 132, 143, 148, 152, 153, 156, 158, 160, 163, 165, 172, 177, 178, 180, 182, 188, 191, 192, 198, 199, 203, 204, 210, 215, 216, 217, 218, 219, 220, 222, 223, 231, 232, 235, 236, 237, 245, 246, 247, 248, 249, 250, 251, 254, 256, 260, 264, 265, 267, 271, 273, 274, 278, 279, 280, 288, 289, 290, 291, 292, 293, 294, 297, 299, 302, 305, 313, 316, 318, 320, 322, 327, 335, 340, 344, 345, 349, 356, 366, 369, 371, 373, 374, 384, 395, 398, 405, 411, 412, 416, 428, 433, 438, 446, 447, 473, 474, 476, 479, 480, 485, 489, 495, 507, 510, 552, 560, 565, 567, 572, 583, 584, 602, 603, 605, 607, 619, 620, 637, 638, 644, 648, 649, 653, 654, 655, 656, 658, 659, 660, 661, 662, 664, 668, 671, 674, 676, 677, 678, 679, 680, 682, 683, 684, 685, 687, 688, 689, 692, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 706, 707, 709, 711, 712, 713, 715, 716, 718, 719, 720, 721, 723, 724, 725, 726, 727, 728, 729, 731, 733, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752], "iter": [13, 15, 105, 140, 148, 165, 172, 178, 204, 210, 217, 221, 231, 232, 235, 236, 240, 245, 249, 250, 267, 278, 279, 283, 288, 292, 293, 345, 347, 374, 388, 428, 450, 468, 472, 565, 567, 602, 603, 607, 619, 638, 641, 655, 656, 659, 676, 679, 680, 697, 737, 739, 740, 746, 747, 749, 751], "return": [13, 16, 44, 45, 54, 67, 68, 70, 74, 105, 116, 148, 151, 152, 153, 158, 163, 165, 171, 172, 173, 178, 186, 189, 191, 195, 196, 199, 200, 203, 205, 206, 210, 213, 219, 220, 221, 223, 226, 229, 235, 236, 249, 256, 260, 264, 265, 266, 271, 278, 279, 292, 299, 302, 305, 310, 313, 314, 316, 317, 318, 320, 326, 327, 334, 338, 343, 344, 345, 347, 352, 358, 362, 364, 366, 367, 369, 370, 371, 373, 374, 378, 382, 384, 386, 391, 392, 394, 395, 400, 405, 422, 427, 428, 432, 440, 444, 446, 447, 466, 468, 470, 472, 479, 492, 493, 495, 499, 536, 565, 570, 572, 583, 591, 596, 598, 602, 605, 607, 619, 629, 632, 637, 638, 641, 646, 648, 649, 655, 656, 660, 661, 679, 680, 685, 696, 699, 731, 732, 733, 735, 737, 740, 743, 746, 747, 749], "true": [13, 43, 44, 85, 113, 146, 148, 152, 158, 172, 178, 195, 199, 231, 232, 245, 247, 249, 250, 263, 264, 265, 288, 290, 292, 293, 304, 305, 310, 314, 320, 338, 361, 367, 373, 384, 391, 392, 394, 400, 428, 443, 447, 466, 470, 510, 533, 563, 565, 567, 583, 598, 603, 605, 618, 619, 620, 629, 632, 641, 644, 648, 649, 658, 660, 679, 680, 682, 685, 689, 696, 697, 701, 704, 705, 720, 721, 722, 723, 729, 731, 739, 740, 741, 743, 746, 747, 748, 749, 751], "els": [13, 148, 172, 232, 245, 288, 384, 565, 619, 646, 706, 743, 747], "fals": [13, 15, 41, 42, 43, 44, 47, 48, 49, 71, 72, 89, 92, 99, 102, 103, 105, 113, 131, 136, 143, 146, 147, 148, 150, 152, 157, 158, 163, 165, 172, 178, 189, 192, 225, 231, 232, 237, 239, 243, 244, 246, 247, 249, 260, 264, 265, 266, 267, 273, 280, 282, 286, 287, 289, 290, 292, 302, 305, 316, 320, 369, 373, 384, 392, 394, 400, 405, 428, 447, 456, 470, 473, 474, 496, 497, 514, 517, 524, 533, 551, 556, 560, 563, 564, 565, 567, 583, 598, 602, 603, 605, 619, 629, 641, 644, 648, 649, 659, 660, 679, 680, 689, 696, 697, 711, 715, 721, 729, 732, 733, 739, 740, 743, 746, 747, 748, 749, 751], "boolean": 13, "ensure_list": 13, "x": [13, 55, 74, 152, 204, 231, 232, 246, 264, 289, 305, 352, 432, 447, 480, 499, 605, 677, 678, 682, 685, 698, 699, 726, 727, 731, 732, 734, 740, 741, 746, 747, 748, 750], "ensur": [13, 264, 305, 352, 432, 603, 685, 740, 748], "list": [13, 42, 43, 44, 54, 105, 140, 148, 151, 152, 153, 162, 165, 178, 179, 180, 182, 196, 203, 204, 209, 214, 219, 223, 226, 231, 232, 235, 236, 240, 247, 260, 264, 265, 278, 279, 283, 290, 302, 305, 309, 310, 313, 314, 316, 317, 318, 320, 327, 335, 340, 343, 346, 361, 366, 367, 369, 370, 371, 373, 374, 382, 388, 389, 391, 392, 394, 395, 398, 400, 405, 411, 412, 416, 428, 443, 447, 450, 466, 470, 472, 479, 565, 570, 593, 598, 602, 605, 619, 629, 638, 639, 649, 655, 658, 659, 680, 687, 689, 693, 695, 697, 701, 706, 708, 711, 712, 715, 723, 726, 728, 729, 735, 737, 739, 740, 742, 746, 747, 749], "input": [13, 15, 42, 43, 44, 45, 54, 60, 64, 67, 68, 70, 71, 72, 74, 82, 83, 85, 86, 105, 109, 110, 116, 122, 141, 148, 151, 161, 163, 164, 165, 170, 171, 172, 176, 203, 204, 223, 231, 232, 235, 236, 247, 248, 249, 251, 260, 263, 264, 269, 278, 279, 290, 291, 292, 294, 302, 304, 305, 308, 309, 310, 373, 374, 378, 382, 389, 395, 398, 428, 453, 479, 485, 489, 492, 493, 495, 496, 497, 499, 507, 508, 510, 511, 529, 530, 536, 542, 565, 567, 570, 572, 596, 598, 602, 615, 619, 620, 632, 637, 638, 644, 646, 648, 649, 656, 659, 660, 676, 677, 679, 680, 682, 683, 684, 685, 687, 689, 691, 696, 697, 698, 699, 701, 706, 737, 739, 740, 743, 746, 747, 748, 751], "check_mx_vers": 13, "version": [13, 54, 104, 161, 165, 203, 232, 309, 310, 365, 479, 615, 653, 655, 659, 678, 689, 693, 694, 697, 711, 713, 715, 716, 738, 746, 749, 750], "str": [13, 42, 43, 44, 140, 151, 153, 158, 159, 162, 163, 165, 171, 172, 173, 179, 182, 186, 187, 189, 191, 200, 203, 226, 231, 232, 247, 248, 249, 256, 260, 264, 266, 270, 271, 290, 291, 292, 299, 302, 305, 309, 310, 313, 314, 316, 318, 320, 327, 338, 361, 364, 366, 367, 369, 371, 373, 386, 388, 389, 391, 392, 394, 395, 397, 398, 400, 405, 413, 421, 423, 426, 427, 443, 446, 447, 450, 466, 469, 470, 472, 572, 583, 585, 586, 593, 598, 602, 603, 619, 620, 624, 627, 629, 633, 637, 641, 644, 646, 649, 650, 678, 679, 680, 696, 729, 739, 747, 748], "mx": [13, 700], "__version__": [13, 156, 584, 678], "combine_cap": 13, "current": [13, 70, 104, 170, 172, 198, 200, 203, 206, 210, 213, 231, 232, 322, 329, 330, 332, 333, 334, 343, 345, 352, 356, 432, 438, 495, 598, 619, 637, 649, 655, 656, 659, 661, 677, 678, 685, 689, 697, 701, 705, 718, 726, 735, 737, 740, 743, 746, 749], "new": [13, 16, 44, 148, 171, 178, 182, 183, 237, 249, 264, 265, 280, 292, 305, 344, 384, 395, 565, 567, 573, 590, 591, 592, 597, 598, 601, 603, 604, 605, 612, 616, 618, 619, 620, 633, 654, 660, 685, 697, 698, 712, 718, 719, 720, 721, 727, 728, 731, 732, 737, 738, 740, 743, 744, 745, 748, 750, 751], "combin": [13, 165, 231, 232, 235, 236, 260, 274, 278, 279, 302, 374, 428, 572, 602, 638, 649, 655, 659, 692, 697, 736, 738, 740, 742, 743, 748, 749], "capabl": [13, 47, 362, 444, 456, 660, 661, 676, 689, 697, 698, 709, 720, 725, 737, 739, 740, 749, 751], "contain": [13, 67, 68, 70, 74, 139, 148, 153, 158, 165, 172, 178, 188, 200, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 223, 231, 232, 235, 236, 247, 248, 249, 278, 279, 290, 291, 292, 306, 310, 311, 316, 317, 318, 322, 335, 338, 340, 343, 344, 345, 346, 347, 348, 369, 370, 371, 374, 428, 492, 493, 495, 499, 559, 565, 583, 598, 602, 638, 641, 648, 658, 677, 680, 683, 692, 696, 719, 726, 731, 732, 733, 737, 743, 747, 749, 750], "make_nc_model": 13, "target": [13, 42, 43, 102, 152, 165, 203, 221, 223, 232, 344, 347, 352, 432, 455, 605, 644, 680, 685, 697, 737, 747, 748, 749, 751], "sym_model": 13, "ctx": 13, "input_desc": 13, "convert": [13, 43, 48, 49, 50, 53, 54, 55, 56, 57, 66, 74, 86, 99, 100, 102, 103, 104, 105, 131, 136, 140, 142, 151, 165, 203, 231, 232, 247, 260, 263, 264, 290, 302, 304, 305, 309, 316, 322, 344, 362, 369, 444, 447, 450, 455, 456, 473, 474, 475, 478, 479, 480, 481, 482, 491, 499, 511, 524, 525, 551, 556, 573, 586, 590, 592, 593, 597, 601, 603, 604, 605, 612, 616, 618, 632, 637, 655, 660, 697, 698, 703, 740, 742, 743, 746, 748, 749], "symbol": [13, 43, 151, 163, 165, 313, 366, 374, 428, 655, 699], "model": [13, 15, 16, 29, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 116, 118, 140, 141, 142, 148, 150, 151, 152, 153, 157, 158, 159, 160, 162, 163, 164, 165, 170, 171, 172, 176, 178, 180, 188, 195, 200, 201, 203, 210, 211, 212, 215, 217, 218, 219, 221, 223, 225, 231, 232, 235, 236, 243, 246, 247, 249, 264, 265, 268, 269, 278, 279, 286, 289, 290, 292, 305, 306, 308, 309, 310, 311, 312, 320, 321, 322, 323, 326, 329, 330, 332, 333, 334, 335, 340, 344, 345, 346, 347, 348, 349, 350, 352, 355, 356, 358, 365, 373, 374, 384, 386, 388, 389, 391, 392, 394, 395, 397, 398, 404, 405, 421, 426, 427, 428, 429, 430, 432, 433, 437, 438, 440, 446, 447, 450, 453, 455, 468, 469, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 494, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 527, 528, 529, 536, 538, 565, 570, 572, 573, 583, 585, 590, 592, 596, 597, 598, 601, 602, 603, 604, 605, 612, 616, 618, 619, 620, 624, 627, 628, 632, 637, 638, 644, 646, 648, 649, 651, 654, 655, 656, 658, 659, 661, 666, 676, 677, 678, 679, 680, 682, 683, 684, 685, 686, 691, 692, 694, 696, 698, 701, 706, 708, 709, 712, 718, 720, 725, 727, 728, 729, 730, 735, 736, 738, 740, 744, 745, 747, 748, 749, 750, 751], "an": [13, 67, 68, 70, 105, 141, 143, 148, 153, 156, 158, 165, 172, 177, 192, 210, 231, 232, 240, 245, 249, 264, 268, 273, 283, 288, 292, 305, 312, 313, 317, 318, 326, 327, 349, 365, 366, 370, 371, 374, 422, 427, 428, 447, 453, 492, 493, 495, 560, 565, 583, 584, 603, 607, 619, 620, 633, 637, 638, 649, 651, 653, 655, 656, 658, 659, 661, 677, 679, 680, 681, 682, 687, 695, 696, 697, 698, 700, 701, 705, 706, 709, 718, 721, 722, 723, 726, 729, 735, 737, 738, 740, 743, 745, 746, 747, 748, 749], "neural": [13, 153, 178, 188, 191, 205, 206, 207, 208, 219, 231, 232, 259, 260, 261, 264, 265, 268, 271, 274, 302, 303, 305, 307, 312, 319, 320, 322, 335, 340, 343, 346, 348, 349, 354, 360, 365, 372, 373, 374, 378, 406, 428, 435, 436, 442, 569, 646, 651, 654, 659, 660, 661, 676, 677, 678, 680, 681, 683, 684, 685, 686, 687, 688, 689, 690, 691, 694, 695, 698, 699, 700, 702, 703, 706, 708, 709, 711, 713, 715, 716, 717, 729, 735, 736, 738, 740, 743, 744, 746, 747, 748, 749, 751, 752], "compressor": [13, 178, 188, 191, 207, 208, 219, 231, 232, 259, 260, 261, 264, 265, 268, 271, 274, 302, 303, 305, 307, 312, 319, 320, 322, 343, 346, 348, 349, 354, 360, 365, 372, 373, 374, 378, 406, 428, 436, 442, 569, 646, 651, 654, 656, 659, 660, 661, 676, 677, 678, 680, 681, 683, 684, 685, 686, 687, 688, 689, 690, 691, 694, 695, 698, 699, 700, 701, 702, 706, 708, 709, 711, 713, 715, 716, 717, 720, 721, 722, 723, 725, 726, 733, 735, 736, 737, 738, 740, 743, 744, 746, 747, 748, 749, 750, 751, 752], "tupl": [13, 105, 148, 165, 196, 232, 235, 236, 260, 264, 278, 279, 302, 305, 310, 361, 374, 395, 398, 428, 443, 469, 565, 586, 593, 596, 598, 602, 607, 624, 627, 638, 648, 660, 678, 680, 696, 697, 740, 748], "symnet": 13, "arg": [13, 54, 105, 165, 172, 247, 248, 249, 290, 291, 292, 343, 352, 386, 397, 432, 447, 479, 586, 605, 619, 627, 637, 644, 645, 680, 685, 697, 700, 707, 737, 740, 743, 746, 747, 748], "aux": 13, "data": [13, 42, 43, 44, 56, 105, 140, 148, 153, 158, 165, 170, 172, 176, 203, 231, 232, 235, 236, 265, 267, 278, 279, 310, 312, 352, 362, 364, 365, 374, 389, 395, 399, 405, 421, 426, 428, 432, 444, 446, 450, 468, 472, 481, 565, 568, 572, 583, 598, 602, 603, 619, 638, 641, 646, 649, 658, 659, 677, 679, 680, 685, 689, 690, 693, 696, 697, 698, 700, 720, 721, 723, 726, 731, 732, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750], "descript": [13, 132, 199, 447, 552, 655, 660, 661, 679, 726, 730, 746], "ncmodel": 13, "fuse": [13, 58, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 91, 92, 93, 94, 96, 131, 136, 163, 165, 176, 483, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 516, 517, 518, 519, 521, 551, 556, 602, 655, 746, 747], "suppli": 13, "get_framework_nam": 13, "get": [13, 42, 43, 44, 45, 67, 68, 70, 104, 105, 148, 152, 159, 165, 171, 178, 187, 191, 192, 196, 198, 200, 201, 203, 206, 213, 220, 221, 222, 223, 229, 232, 240, 264, 265, 271, 273, 283, 305, 310, 343, 345, 347, 355, 362, 364, 373, 382, 392, 399, 405, 428, 437, 444, 446, 466, 492, 493, 495, 565, 567, 570, 572, 585, 598, 602, 605, 613, 619, 637, 641, 644, 646, 649, 660, 677, 688, 692, 693, 695, 697, 704, 721, 723, 731, 732, 738, 743, 746, 749, 750, 753], "name": [13, 43, 45, 54, 67, 68, 70, 104, 105, 110, 116, 140, 148, 151, 152, 153, 158, 159, 163, 165, 171, 172, 173, 178, 179, 180, 182, 186, 192, 195, 196, 198, 203, 205, 210, 213, 214, 219, 220, 221, 222, 223, 226, 229, 231, 232, 247, 248, 249, 252, 256, 262, 264, 265, 269, 272, 273, 290, 291, 292, 295, 299, 305, 308, 309, 310, 315, 320, 338, 343, 345, 347, 362, 364, 368, 373, 378, 382, 384, 405, 428, 444, 446, 450, 479, 492, 493, 495, 530, 536, 565, 570, 572, 583, 585, 598, 602, 605, 619, 633, 637, 639, 641, 646, 649, 654, 655, 661, 678, 680, 682, 685, 687, 689, 694, 696, 697, 699, 700, 704, 711, 715, 719, 720, 726, 737, 740, 744, 745, 747, 749, 751, 752], "context": [13, 620, 649, 739, 743], "prepare_model_data": 13, "nc_model": [13, 335, 340], "data_x": 13, "prepar": [13, 44, 165, 395, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 632, 637, 655, 680, 685, 690, 720, 731, 732, 733, 737, 740], "dataload": [13, 15, 42, 44, 140, 141, 150, 152, 153, 165, 170, 172, 178, 200, 201, 203, 219, 223, 225, 235, 236, 247, 258, 268, 278, 279, 290, 301, 306, 312, 335, 340, 349, 365, 388, 389, 398, 421, 426, 428, 450, 453, 567, 598, 603, 605, 619, 638, 641, 655, 658, 659, 660, 682, 683, 684, 685, 690, 691, 697, 698, 720, 721, 736, 737, 740, 741, 742, 743, 746, 747, 748, 750, 751], "need": [13, 42, 105, 109, 170, 172, 178, 182, 203, 219, 232, 235, 236, 237, 245, 246, 249, 256, 264, 267, 269, 270, 278, 279, 280, 288, 289, 292, 299, 305, 310, 349, 355, 373, 374, 384, 389, 428, 437, 529, 567, 591, 596, 598, 638, 648, 649, 655, 659, 678, 679, 680, 682, 683, 685, 692, 697, 701, 703, 704, 707, 711, 712, 713, 715, 716, 718, 719, 720, 721, 722, 723, 725, 729, 731, 737, 739, 740, 741, 742, 743, 744, 746, 748, 749, 751], "run": [13, 140, 148, 158, 172, 178, 210, 223, 231, 232, 235, 236, 246, 263, 265, 278, 279, 289, 304, 344, 345, 352, 374, 428, 432, 450, 565, 583, 620, 638, 658, 659, 676, 685, 688, 689, 697, 701, 703, 705, 706, 707, 709, 711, 712, 713, 715, 716, 718, 726, 727, 728, 729, 731, 732, 733, 738, 740, 743, 744, 745, 747, 749, 751], "loader": [13, 140, 235, 236, 278, 279, 374, 428, 450, 468, 472, 638, 644, 679, 740], "dataloaderwrap": 13, "prepare_model": 13, "create_data_exampl": 13, "creat": [13, 16, 105, 156, 182, 231, 232, 237, 247, 249, 267, 280, 290, 292, 316, 326, 327, 362, 369, 398, 422, 427, 444, 446, 447, 567, 584, 593, 633, 641, 653, 656, 659, 680, 699, 711, 713, 715, 716, 719, 731, 732, 733, 737, 740, 745, 747, 749, 750], "exampl": [13, 44, 153, 158, 165, 172, 178, 179, 180, 182, 186, 196, 203, 204, 219, 231, 232, 247, 248, 249, 260, 264, 290, 291, 292, 302, 305, 316, 317, 318, 320, 346, 369, 370, 371, 373, 374, 384, 391, 392, 394, 405, 428, 446, 447, 572, 583, 596, 619, 633, 637, 638, 648, 649, 653, 658, 660, 661, 666, 691, 692, 701, 704, 705, 706, 709, 726, 729, 742, 744, 748, 749, 750, 753], "prepare_dataload": 13, "io": [13, 158, 583, 724], "ndarray_to_devic": 13, "ndarrai": [13, 42, 43, 67, 68, 70, 264, 305, 492, 493, 495, 639, 688, 748], "devic": [13, 79, 89, 90, 91, 92, 93, 94, 97, 107, 131, 136, 147, 152, 157, 158, 160, 165, 172, 200, 203, 204, 219, 223, 225, 231, 232, 504, 514, 515, 516, 517, 518, 519, 522, 527, 551, 556, 564, 583, 588, 603, 605, 620, 644, 658, 660, 679, 683, 697, 698, 701, 704, 709, 718, 737, 739, 741, 743], "is_model_quant": 13, "query_quantizable_nod": 13, "queri": [13, 47, 148, 165, 203, 214, 231, 232, 455, 456, 565, 602, 660, 661, 728, 740], "node": [13, 42, 43, 44, 50, 54, 55, 56, 57, 60, 62, 64, 67, 68, 70, 74, 77, 80, 82, 83, 84, 98, 102, 103, 105, 110, 132, 140, 148, 203, 308, 310, 382, 395, 405, 427, 450, 475, 479, 480, 481, 482, 485, 487, 489, 492, 493, 495, 499, 502, 505, 507, 508, 509, 523, 530, 552, 565, 570, 593, 659, 682, 685, 721, 725, 728, 731, 732, 733, 741, 747, 749, 752], "given": [13, 16, 43, 67, 68, 70, 104, 105, 116, 148, 159, 165, 226, 264, 305, 316, 369, 428, 492, 493, 495, 536, 565, 573, 585, 590, 592, 593, 597, 601, 603, 604, 605, 607, 612, 616, 618, 619, 632, 637, 656, 661, 737, 746, 748], "map": [13, 43, 105, 148, 158, 165, 186, 232, 264, 305, 308, 310, 311, 315, 317, 318, 320, 335, 340, 345, 348, 368, 370, 371, 373, 565, 583, 678, 680, 685, 696, 697, 711, 715, 723, 737, 740, 743], "quantize_sym_model": 13, "qconfig": [13, 165, 648, 743, 747], "accord": [13, 122, 165, 178, 231, 232, 247, 248, 249, 264, 290, 291, 292, 305, 355, 435, 437, 542, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 637, 641, 656, 659, 680, 685, 721, 726, 731, 732, 733, 737, 742, 746, 748, 749], "run_forward": 13, "b_filter": 13, "collector": [13, 153, 639], "none": [13, 41, 43, 44, 45, 47, 48, 49, 63, 89, 102, 104, 105, 110, 116, 142, 148, 150, 152, 153, 157, 158, 159, 160, 161, 164, 165, 170, 172, 178, 179, 180, 182, 187, 188, 189, 196, 198, 200, 201, 203, 207, 219, 223, 225, 227, 228, 229, 231, 232, 235, 236, 237, 239, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 260, 264, 265, 266, 267, 274, 278, 279, 280, 282, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 302, 305, 306, 309, 310, 311, 316, 320, 321, 322, 323, 326, 335, 340, 344, 348, 350, 352, 355, 356, 358, 362, 369, 373, 374, 384, 386, 398, 421, 426, 427, 428, 429, 430, 432, 433, 437, 438, 440, 444, 447, 455, 456, 466, 468, 469, 470, 472, 473, 474, 488, 514, 530, 536, 565, 567, 572, 573, 583, 585, 592, 598, 602, 603, 605, 613, 615, 618, 619, 620, 624, 628, 629, 632, 637, 638, 639, 641, 644, 646, 648, 649, 658, 659, 660, 679, 680, 696, 700, 721, 740, 743, 747, 748, 749], "pre_batch": 13, "post_batch": 13, "forward": [13, 165, 223, 619, 620, 660, 697, 720, 737, 739, 740, 743, 746, 747], "propag": [13, 100, 525], "filter": [13, 247, 248, 249, 250, 251, 252, 254, 258, 290, 291, 292, 293, 294, 295, 297, 301, 312, 365, 567, 572, 593, 649, 661, 680, 692, 737, 747], "which": [13, 42, 56, 83, 110, 152, 153, 158, 170, 172, 179, 198, 203, 204, 206, 210, 211, 212, 214, 217, 218, 219, 221, 223, 231, 232, 247, 248, 249, 260, 265, 290, 291, 292, 302, 313, 318, 327, 329, 330, 332, 333, 334, 338, 343, 344, 345, 347, 352, 366, 371, 373, 378, 384, 389, 392, 405, 428, 432, 481, 508, 530, 572, 583, 598, 605, 637, 649, 653, 655, 656, 658, 659, 660, 661, 677, 679, 680, 682, 683, 685, 688, 689, 692, 696, 697, 698, 699, 702, 706, 709, 712, 718, 719, 720, 723, 726, 731, 732, 733, 736, 737, 739, 740, 741, 742, 743, 744, 746, 747, 748, 749, 750, 751], "batch": [13, 165, 172, 237, 239, 240, 245, 246, 267, 280, 282, 283, 288, 289, 567, 638, 679, 683, 684, 697, 736, 737, 740, 746, 748, 749, 752], "infer": [13, 43, 105, 140, 165, 172, 203, 311, 348, 382, 384, 405, 428, 450, 570, 602, 619, 620, 638, 658, 659, 660, 677, 683, 684, 697, 698, 718, 735, 737, 738, 740, 743, 746, 747, 749], "collect": [13, 16, 43, 165, 180, 187, 262, 264, 267, 269, 270, 272, 305, 318, 320, 371, 373, 572, 590, 597, 601, 604, 616, 639, 649, 660, 740, 747, 749], "inform": [13, 153, 198, 200, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 232, 235, 236, 267, 269, 270, 278, 279, 343, 345, 346, 347, 349, 373, 388, 649, 653, 654, 657, 658, 659, 660, 661, 662, 664, 668, 671, 674, 677, 678, 683, 689, 697, 699, 700, 713, 716, 719, 720, 723, 724, 726, 727, 731, 732, 737, 742, 743, 744, 746, 747, 751, 752, 753], "dure": [13, 156, 158, 205, 209, 221, 231, 232, 343, 347, 384, 398, 583, 584, 632, 637, 649, 660, 682, 697, 699, 725, 735, 736, 737, 740, 746, 747, 751], "call": [13, 42, 158, 170, 173, 203, 211, 212, 217, 316, 345, 369, 389, 583, 598, 620, 655, 656, 659, 679, 691, 707, 709, 719, 737, 740, 746, 747, 748], "prior": [13, 88, 513, 749], "after": [13, 78, 148, 165, 201, 205, 210, 212, 217, 231, 232, 247, 260, 264, 267, 290, 302, 305, 345, 433, 447, 503, 565, 644, 649, 656, 658, 660, 680, 682, 683, 684, 687, 692, 696, 697, 711, 712, 715, 719, 723, 735, 736, 737, 740, 742, 743, 745, 746, 747, 748, 749], "count": [13, 656, 680, 743], "int": [13, 16, 42, 43, 44, 105, 140, 148, 150, 162, 165, 172, 179, 182, 187, 201, 231, 232, 246, 247, 248, 260, 264, 289, 290, 291, 302, 305, 309, 310, 314, 316, 320, 327, 367, 369, 373, 388, 391, 392, 394, 395, 400, 405, 413, 422, 427, 446, 447, 450, 451, 455, 468, 469, 472, 565, 591, 602, 603, 619, 629, 644, 649, 658, 678, 679, 680, 696, 697, 729, 739, 743, 748], "make_symbol_block": 13, "gluon": [13, 374, 428, 699], "symbolblock": 13, "make_modul": 13, "parse_tune_config": 13, "tune_cfg": [13, 148, 151, 165, 598, 602, 659, 661, 749], "quantizable_nod": 13, "strategi": [13, 165, 217, 231, 232, 233, 249, 276, 292, 312, 365, 658, 659, 660, 661, 666, 677, 678, 679, 685, 692, 697, 706, 718, 723, 738, 739, 740, 742, 743, 744, 750, 751], "config": [13, 44, 115, 116, 118, 122, 165, 178, 179, 180, 182, 186, 187, 198, 200, 201, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 231, 235, 236, 247, 278, 279, 290, 329, 330, 332, 333, 334, 335, 340, 343, 344, 345, 346, 347, 362, 363, 365, 374, 386, 391, 392, 394, 397, 398, 422, 427, 444, 445, 446, 447, 451, 455, 456, 472, 535, 536, 538, 542, 593, 598, 602, 612, 632, 638, 641, 648, 649, 656, 658, 660, 661, 666, 676, 678, 679, 682, 683, 684, 685, 687, 690, 692, 696, 697, 698, 699, 720, 721, 736, 737, 739, 740, 742, 743, 745, 747, 749], "tune": [13, 45, 171, 172, 178, 179, 180, 185, 231, 232, 235, 236, 247, 249, 278, 279, 290, 292, 311, 348, 350, 351, 352, 353, 355, 356, 357, 358, 361, 362, 363, 364, 374, 384, 398, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 443, 444, 445, 446, 469, 598, 628, 629, 638, 649, 659, 660, 677, 678, 679, 680, 682, 685, 692, 694, 697, 698, 718, 722, 725, 727, 728, 735, 737, 738, 742, 744, 745, 747, 751], "from": [13, 43, 45, 61, 67, 68, 70, 105, 148, 158, 159, 165, 171, 172, 178, 180, 182, 183, 186, 188, 189, 196, 198, 200, 206, 207, 208, 209, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 231, 232, 235, 236, 237, 240, 244, 247, 248, 249, 250, 251, 252, 254, 259, 260, 266, 267, 270, 278, 279, 280, 283, 287, 290, 291, 292, 293, 294, 295, 297, 302, 306, 308, 309, 310, 313, 316, 317, 318, 322, 327, 343, 344, 345, 347, 362, 364, 366, 369, 370, 371, 374, 382, 384, 391, 405, 428, 444, 446, 447, 455, 486, 492, 493, 495, 565, 567, 570, 572, 573, 583, 585, 590, 591, 592, 596, 597, 598, 601, 602, 603, 604, 605, 607, 612, 616, 618, 619, 637, 638, 641, 644, 648, 649, 653, 654, 655, 656, 659, 661, 676, 678, 679, 680, 682, 683, 684, 685, 686, 687, 688, 690, 692, 695, 696, 698, 699, 700, 701, 705, 706, 707, 709, 719, 721, 723, 724, 728, 731, 732, 733, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750], "distribute_calib_tensor": 13, "calib_tensor": 13, "calib_cfg": 13, "tensor_to_nod": 13, "distribut": [13, 16, 143, 177, 231, 232, 237, 239, 240, 243, 244, 245, 246, 267, 280, 282, 283, 286, 287, 288, 289, 391, 560, 567, 643, 658, 660, 679, 683, 693, 713, 716, 720, 723, 731, 738, 740, 743, 744, 746, 750, 752], "depend": [13, 235, 236, 265, 278, 279, 374, 428, 638, 654, 688, 689, 724, 739, 740, 749], "algorithm": [13, 44, 152, 165, 179, 182, 195, 228, 232, 313, 320, 328, 365, 366, 373, 398, 405, 572, 629, 637, 641, 643, 656, 658, 659, 660, 661, 678, 683, 684, 689, 692, 695, 707, 712, 737, 740, 747, 751], "set": [13, 43, 51, 96, 105, 115, 148, 158, 165, 171, 172, 178, 180, 187, 191, 223, 229, 231, 232, 235, 236, 237, 247, 249, 252, 264, 265, 270, 271, 278, 279, 280, 290, 292, 295, 305, 316, 322, 335, 340, 344, 349, 369, 373, 374, 382, 392, 394, 427, 428, 447, 455, 476, 521, 535, 565, 567, 570, 583, 598, 619, 629, 637, 638, 646, 649, 653, 656, 658, 660, 676, 679, 680, 683, 685, 687, 689, 691, 692, 693, 696, 697, 698, 701, 703, 705, 719, 720, 721, 722, 723, 724, 728, 731, 737, 739, 740, 743, 745, 746, 749, 751], "kl": [13, 16, 231, 232, 598, 639, 643, 660, 661, 677, 689, 697, 749, 751], "minmax": [13, 16, 470, 598, 660, 661, 677, 689, 740, 751], "calib_model": 13, "qsym_model": 13, "calib_data": [13, 157], "calibdata": 13, "threshold": [13, 174, 199, 639, 643, 696], "amp_convert": 13, "amp_cfg": 13, "support": [13, 42, 43, 44, 97, 104, 170, 172, 176, 179, 189, 191, 200, 206, 213, 217, 218, 231, 232, 235, 236, 246, 247, 249, 256, 260, 264, 266, 267, 268, 271, 278, 279, 289, 290, 292, 299, 302, 305, 312, 320, 322, 327, 343, 345, 349, 356, 362, 365, 373, 374, 378, 384, 389, 391, 392, 394, 395, 398, 405, 428, 438, 444, 447, 522, 598, 638, 641, 643, 644, 649, 651, 658, 660, 678, 695, 697, 701, 706, 709, 712, 718, 725, 726, 729, 738, 742, 745, 749, 750], "amp": [13, 172, 603, 701, 708, 727, 743], "wrap": [13, 105, 116, 189, 227, 266, 316, 369, 472, 536, 620, 655, 685, 713, 716], "dataiterload": 13, "data_it": [13, 203], "collectorbas": 13, "calibcollector": 13, "include_tensors_kl": 13, "include_tensors_minmax": 13, "num_bin": [13, 16, 639], "8001": [13, 639, 726, 731, 732, 733], "tensorcollector": 13, "include_nod": 13, "qtensor_to_tensor": 13, "build": [13, 42, 44, 115, 173, 174, 176, 177, 323, 326, 377, 379, 381, 382, 383, 395, 404, 535, 570, 659, 660, 661, 693, 699, 711, 713, 715, 716, 719, 738, 749], "up": [13, 100, 214, 264, 305, 344, 525, 602, 658, 685, 686, 689, 692, 709, 713, 716, 718, 737, 738, 739, 740, 745, 748, 749, 751], "namecollector": 13, "cache_kl": 13, "cache_minmax": 13, "tensors_kl": 13, "tensors_minmax": 13, "onnxruntimeadaptor": 14, "rt": 14, "onnxrt_weightonlyadaptor": 14, "onnxrt_qlinearopsadaptor": [14, 659], "onnxrt_integeropsadaptor": 14, "onnxrt_qdqadaptor": 14, "onnxrtaug": 15, "dump_op_typ": 15, "black_nod": 15, "white_nod": 15, "backend": [15, 41, 42, 46, 176, 191, 231, 232, 233, 234, 238, 239, 243, 247, 248, 250, 251, 252, 253, 254, 258, 261, 264, 270, 271, 276, 277, 281, 282, 284, 286, 290, 291, 293, 294, 295, 296, 297, 301, 303, 305, 321, 356, 374, 375, 376, 378, 438, 655, 661, 682, 685, 691, 692, 697, 698, 707, 726, 731, 732, 733, 739, 743, 748, 749, 751], "cpuexecutionprovid": [15, 41, 42, 44, 388, 389, 391, 392, 394, 400, 698, 740], "reduce_rang": [15, 41, 42, 231, 232, 405, 661, 739], "kwarg": [15, 43, 105, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 135, 137, 159, 165, 172, 201, 231, 232, 249, 262, 264, 269, 272, 292, 305, 361, 363, 373, 374, 375, 377, 379, 381, 382, 383, 386, 388, 397, 400, 404, 428, 443, 445, 447, 542, 543, 544, 545, 546, 547, 548, 549, 552, 553, 554, 555, 557, 570, 585, 586, 605, 619, 627, 637, 638, 644, 645, 648, 649, 679], "augment": 15, "dump": [15, 156, 165, 178, 310, 388, 572, 584, 602, 649, 654, 723, 740, 744, 747], "calib_registri": 16, "calib_method": 16, "calibratorbas": 16, "minmaxcalibr": 16, "percentilecalibr": 16, "2048": [16, 152, 172, 572, 603, 605, 629, 649, 658, 743], "percentil": [16, 44, 140, 172, 394, 395, 450, 470, 619, 677], "99": [16, 180, 470, 695, 752], "999": [16, 470, 751], "option": [16, 44, 105, 158, 165, 172, 182, 187, 205, 231, 232, 235, 236, 247, 264, 278, 279, 290, 305, 309, 310, 316, 322, 343, 349, 362, 365, 369, 373, 374, 386, 391, 392, 394, 395, 398, 405, 428, 444, 446, 447, 572, 573, 583, 590, 592, 597, 601, 603, 604, 605, 612, 613, 616, 618, 619, 620, 632, 637, 638, 642, 644, 649, 660, 661, 678, 679, 680, 689, 693, 697, 712, 726, 729, 731, 732, 733, 737, 740, 743, 745, 746, 748, 749, 751], "number": [16, 44, 67, 68, 105, 140, 165, 172, 179, 180, 196, 199, 201, 207, 208, 231, 232, 245, 248, 260, 264, 288, 291, 302, 305, 317, 318, 320, 343, 352, 370, 371, 373, 391, 392, 394, 395, 422, 427, 432, 447, 450, 492, 493, 567, 603, 619, 633, 641, 649, 676, 679, 680, 685, 696, 726, 728, 737, 740, 743, 745, 746, 748, 749], "bin": [16, 158, 159, 572, 583, 585, 649, 688], "histogram": [16, 572, 639, 649, 720, 747], "valu": [16, 43, 44, 56, 67, 68, 70, 89, 90, 105, 143, 148, 158, 165, 177, 178, 196, 198, 203, 204, 214, 222, 223, 229, 231, 232, 235, 236, 247, 250, 251, 260, 264, 265, 278, 279, 290, 293, 294, 302, 305, 316, 320, 344, 352, 355, 362, 369, 373, 374, 392, 405, 428, 432, 437, 444, 446, 447, 481, 492, 493, 495, 514, 515, 560, 565, 567, 583, 591, 602, 607, 620, 638, 639, 641, 649, 655, 660, 661, 677, 680, 682, 689, 696, 697, 698, 700, 704, 721, 723, 729, 735, 737, 739, 740, 743, 744, 746, 748, 749, 751], "default": [16, 44, 97, 148, 158, 165, 172, 179, 182, 187, 199, 223, 229, 231, 232, 235, 236, 239, 247, 248, 249, 260, 264, 278, 279, 282, 290, 291, 292, 302, 305, 309, 310, 313, 322, 344, 364, 366, 373, 382, 386, 391, 392, 394, 395, 400, 405, 446, 466, 470, 522, 565, 570, 572, 583, 598, 613, 619, 620, 629, 632, 637, 641, 644, 649, 655, 659, 678, 679, 680, 689, 692, 693, 696, 697, 698, 700, 706, 709, 711, 715, 723, 726, 731, 732, 733, 735, 737, 739, 740, 742, 743, 745, 746, 748, 749, 751], "float": [16, 43, 44, 140, 141, 153, 172, 179, 199, 205, 210, 220, 223, 231, 232, 247, 260, 290, 302, 314, 316, 317, 318, 345, 367, 369, 370, 371, 392, 395, 400, 443, 447, 450, 453, 470, 573, 590, 592, 597, 598, 601, 603, 604, 605, 612, 616, 618, 619, 629, 632, 633, 646, 649, 678, 680, 696, 700, 739, 740, 746, 748], "A": [16, 55, 74, 75, 103, 116, 140, 141, 148, 156, 165, 179, 185, 188, 195, 196, 198, 200, 203, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 231, 232, 249, 264, 267, 269, 270, 292, 305, 306, 313, 316, 317, 318, 320, 323, 326, 327, 328, 335, 338, 340, 343, 344, 345, 346, 347, 352, 366, 369, 370, 371, 373, 374, 378, 382, 432, 450, 453, 480, 499, 500, 536, 565, 569, 570, 572, 584, 591, 602, 619, 633, 638, 649, 654, 658, 660, 678, 679, 680, 686, 689, 696, 697, 699, 711, 712, 715, 718, 726, 737, 738, 740, 743, 746, 748, 749, 751], "between": [16, 42, 143, 177, 216, 231, 232, 264, 305, 317, 320, 370, 373, 422, 427, 560, 593, 649, 655, 659, 660, 661, 677, 682, 683, 692, 696, 697, 700, 709, 740, 743, 744, 745, 746, 748, 749], "0": [16, 43, 44, 54, 90, 105, 148, 157, 158, 165, 172, 174, 176, 179, 180, 189, 196, 198, 199, 201, 223, 225, 227, 231, 232, 237, 239, 243, 244, 246, 247, 250, 251, 254, 260, 264, 266, 267, 280, 282, 286, 287, 289, 290, 293, 294, 297, 302, 305, 310, 311, 320, 327, 335, 340, 348, 373, 384, 391, 392, 394, 395, 400, 405, 428, 433, 447, 470, 479, 515, 565, 567, 583, 602, 619, 629, 633, 644, 655, 658, 678, 679, 680, 683, 685, 687, 688, 689, 693, 694, 695, 696, 697, 698, 700, 704, 706, 711, 715, 721, 731, 732, 737, 739, 740, 741, 743, 744, 745, 746, 747, 748, 749, 751], "100": [16, 178, 179, 180, 196, 199, 231, 232, 249, 292, 400, 447, 468, 469, 472, 633, 676, 680, 685, 691, 693, 697, 723, 739, 740, 748, 749, 751, 752], "klcalibr": 16, "128": [16, 44, 150, 152, 165, 172, 225, 247, 250, 251, 264, 290, 293, 294, 305, 392, 400, 567, 605, 629, 680, 697, 740, 743, 748, 752], "num_quantized_bin": 16, "histogramcollector": 16, "collctor": 16, "smooth_distribut": 16, "p": [16, 658, 719, 720, 743], "ep": [16, 177, 698], "0001": [16, 196, 231, 232, 683, 697, 739], "smooth": [16, 140, 141, 148, 170, 176, 231, 232, 361, 388, 397, 400, 450, 451, 453, 470, 565, 598, 678, 737, 749], "discret": [16, 196, 749], "mai": [16, 148, 156, 158, 329, 330, 332, 333, 334, 447, 565, 583, 584, 620, 653, 654, 660, 677, 678, 682, 687, 688, 694, 698, 711, 715, 721, 724, 726, 738, 740, 743, 746, 749], "have": [16, 74, 83, 141, 148, 158, 200, 204, 206, 213, 245, 267, 288, 313, 316, 343, 345, 366, 369, 373, 428, 446, 447, 453, 499, 508, 565, 583, 602, 653, 654, 660, 661, 678, 679, 680, 682, 685, 689, 694, 696, 697, 698, 700, 701, 718, 721, 724, 726, 731, 732, 733, 735, 737, 740, 741, 743, 746, 749, 750], "been": [16, 158, 200, 206, 213, 313, 343, 345, 366, 405, 572, 583, 591, 602, 656, 661, 678, 683, 697, 698, 718, 743, 746], "normal": [16, 33, 264, 305, 318, 371, 697, 727, 735, 743, 746, 748], "1": [16, 42, 43, 44, 55, 74, 89, 105, 109, 113, 146, 148, 158, 161, 165, 170, 172, 174, 176, 177, 178, 180, 189, 196, 198, 199, 211, 212, 214, 231, 232, 237, 239, 243, 244, 246, 247, 248, 250, 251, 254, 255, 260, 264, 265, 266, 267, 280, 282, 286, 287, 289, 290, 291, 293, 294, 297, 298, 302, 305, 311, 316, 317, 318, 320, 335, 340, 345, 348, 349, 369, 370, 371, 373, 384, 389, 391, 392, 394, 395, 405, 428, 446, 447, 451, 480, 499, 514, 529, 533, 563, 565, 567, 572, 583, 598, 602, 603, 615, 619, 629, 641, 644, 649, 653, 655, 658, 659, 661, 677, 679, 680, 682, 683, 687, 689, 690, 693, 695, 696, 698, 700, 702, 704, 720, 721, 728, 729, 731, 732, 733, 735, 736, 737, 739, 740, 741, 743, 744, 745, 746, 747, 748, 749, 750, 751], "replac": [16, 159, 165, 171, 172, 318, 371, 585, 593, 598, 619, 678, 685, 697, 700, 709, 744], "zero": [16, 43, 44, 152, 172, 210, 223, 264, 305, 345, 392, 395, 405, 605, 619, 649, 658, 700, 723, 737, 740, 743, 746, 748, 749], "multipli": [16, 231, 232, 700, 743], "scale": [16, 43, 44, 100, 141, 143, 152, 161, 164, 165, 170, 171, 172, 176, 177, 260, 264, 302, 305, 391, 392, 395, 405, 453, 525, 560, 598, 605, 615, 619, 700, 740, 743, 745, 746, 748, 749], "factor": [16, 141, 453, 743, 746, 752], "take": [16, 205, 232, 235, 236, 240, 264, 269, 278, 279, 283, 305, 343, 352, 373, 374, 428, 432, 567, 638, 653, 655, 656, 679, 682, 683, 689, 697, 718, 737, 740, 742, 743, 748, 749, 751], "correspond": [16, 153, 203, 214, 231, 232, 247, 290, 313, 316, 320, 366, 369, 373, 602, 620, 641, 649, 659, 689, 697, 737, 739, 740, 745, 749], "amount": [16, 746], "off": [16, 67, 68, 70, 492, 493, 495, 654, 743], "non": [16, 344, 649, 655, 682, 743, 749], "ref": [16, 148, 565], "http": [16, 152, 153, 198, 199, 207, 208, 217, 218, 219, 225, 247, 249, 290, 292, 313, 314, 316, 317, 318, 343, 345, 346, 366, 367, 369, 370, 371, 373, 399, 428, 605, 629, 655, 680, 682, 690, 693, 694, 697, 707, 713, 716, 720, 722, 723, 724, 725, 726, 729, 731, 732, 733, 737, 744], "hanj": 16, "c": [16, 74, 249, 292, 499, 649, 680, 688, 693, 743, 749], "illinoi": 16, "edu": [16, 249, 292, 680], "cs412": 16, "bk3": 16, "diverg": [16, 639, 643, 661, 677, 683, 749], "pdf": [16, 199, 225], "github": [16, 153, 207, 208, 219, 247, 290, 313, 314, 317, 318, 343, 346, 366, 367, 370, 371, 373, 399, 428, 654, 658, 680, 682, 686, 693, 694, 697, 707, 713, 716, 720, 722, 723, 724, 725, 726, 729, 732, 733, 744], "com": [16, 153, 207, 208, 219, 247, 290, 313, 314, 317, 318, 343, 346, 366, 367, 370, 371, 373, 399, 428, 653, 678, 680, 682, 690, 693, 694, 697, 701, 707, 720, 722, 723, 725, 726, 729, 732, 733, 744, 745, 752], "apach": [16, 694], "incub": 16, "blob": [16, 153, 207, 208, 313, 314, 317, 318, 343, 366, 367, 370, 371, 373, 399, 428, 697, 707, 729, 732, 733], "master": [16, 207, 208, 219, 313, 314, 317, 318, 343, 346, 366, 367, 370, 371, 373, 428, 697, 749], "python": [16, 75, 148, 156, 158, 187, 249, 268, 292, 312, 365, 399, 447, 500, 565, 572, 583, 584, 649, 651, 655, 658, 678, 680, 682, 685, 688, 693, 697, 703, 709, 712, 718, 722, 723, 725, 726, 728, 731, 733, 737, 738, 748], "contrib": [16, 312, 365], "py": [16, 148, 153, 178, 210, 231, 232, 314, 316, 317, 318, 345, 367, 369, 370, 371, 399, 447, 565, 655, 659, 678, 682, 685, 693, 697, 703, 705, 706, 707, 713, 716, 720, 722, 723, 725, 726, 728, 729, 731, 732, 733, 740, 744, 747], "microsoft": [16, 399, 658, 659, 700], "onnxruntim": [16, 231, 232, 243, 249, 256, 286, 292, 299, 321, 399, 422, 659, 677, 679, 692, 693, 698, 721, 739], "main": [16, 152, 191, 196, 214, 219, 271, 346, 397, 398, 399, 468, 469, 472, 605, 627, 628, 632, 655, 679, 682, 685, 697, 705, 707, 719, 728, 737, 740, 743], "tool": [16, 148, 309, 399, 565, 649, 658, 659, 697, 711, 715, 721, 724, 725, 726, 737, 738, 740], "arrai": [16, 43, 44, 148, 158, 264, 305, 316, 327, 369, 395, 405, 565, 583, 649, 748], "small": [16, 67, 68, 69, 70, 435, 492, 493, 494, 495, 656, 723, 724, 737, 743, 749, 752], "probabl": [16, 231, 232, 643, 743], "activationoper": 18, "onnx_quant": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "onnx_nod": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 87, 101, 111], "removableactivationoper": 18, "remov": [18, 43, 51, 57, 60, 74, 80, 83, 84, 85, 96, 98, 140, 201, 214, 318, 371, 450, 476, 482, 485, 499, 505, 508, 509, 510, 521, 523, 637, 653, 697, 711, 715, 724, 731, 732, 737, 747], "qactivationoper": 18, "children": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 35, 36, 38, 39, 159, 585], "initi": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 35, 36, 38, 39, 42, 43, 44, 105, 116, 148, 158, 189, 210, 235, 236, 244, 247, 266, 278, 279, 287, 290, 344, 345, 362, 395, 428, 444, 536, 565, 583, 607, 637, 638, 656, 661, 680, 696, 717, 737, 740, 746, 749], "qoper": [18, 34, 231, 232, 687, 721], "format": [18, 43, 54, 148, 165, 231, 232, 247, 248, 249, 290, 291, 292, 310, 316, 322, 362, 369, 444, 447, 455, 456, 479, 565, 603, 644, 658, 660, 661, 678, 680, 685, 687, 696, 697, 698, 699, 700, 701, 723, 726, 738, 740, 743, 744], "float16activationoper": 18, "float16": [18, 21, 43, 588, 593, 620, 644, 680, 743], "argmaxoper": 19, "qargmaxoper": 19, "attentionoper": 20, "qattentionoper": 20, "qattent": 20, "binari": [21, 148, 320, 373, 565, 688, 696, 713, 716, 744], "binaryoper": 21, "binarydirect8bitoper": 21, "qbinaryoper": 21, "qbinari": 21, "float16binaryoper": 21, "concatoper": 22, "qconcatoper": 22, "qconcat": 22, "convoper": 23, "qconvoper": 23, "qlinearconv": 23, "direct8bit": 24, "direct8bitoper": 24, "qdirectoper": 24, "qdirect": 24, "embedlayernorm": 25, "embedlayernormalizationoper": 25, "qembedlayernormalizationoper": 25, "qembedlayernorm": 25, "gatheroper": 26, "qgatheroper": 26, "qgather": 26, "globalaveragepool": 27, "globalaveragepooloper": 27, "qglobalaveragepooloper": 27, "qlinearglobalaveragepool": 27, "gemmoper": 28, "qgemmoper": 28, "qgemm": 28, "lstmoper": 30, "matmuloper": 31, "qmatmuloper": 31, "qlinearmatmul": 31, "fusedmatmuloper": 31, "fusedmatmul": 31, "maxpooloper": 32, "qmaxpooloper": 32, "qmaxpool": 32, "batchnormalizationoper": 33, "batchnorm": [33, 62, 67, 121, 487, 492, 541, 655, 746], "normalizationoper": 33, "op_registri": 34, "op_typ": [34, 140, 141, 148, 226, 363, 400, 445, 450, 453, 470, 565, 598, 602], "qop_registri": 34, "padoper": 35, "qpadoper": 35, "qpad": 35, "averagepool": 36, "pooloper": 36, "qpooloper": 36, "qlinearaveragepool": 36, "reduceoper": 37, "reduceminmaxoper": 37, "reducemin": 37, "reducemax": 37, "resizeoper": 38, "qresizeoper": 38, "qresiz": 38, "splitoper": 39, "qsplitoper": 39, "qsplit": 39, "unari": 40, "unaryoper": 40, "unarydirect8bitoper": 40, "q_config": [41, 165, 310, 659], "mode": [41, 42, 43, 45, 110, 158, 170, 183, 256, 299, 316, 362, 369, 382, 389, 405, 444, 530, 570, 583, 598, 627, 632, 637, 646, 648, 649, 659, 660, 682, 692, 711, 715, 723, 724, 740, 742, 743, 749], "static": [41, 42, 47, 170, 176, 203, 232, 310, 362, 389, 428, 444, 455, 456, 466, 468, 470, 598, 632, 659, 660, 661, 682, 687, 692, 697, 701, 706, 707, 708, 709, 712, 718, 721, 729, 731, 732, 733, 741, 746, 749, 752], "quantization_param": 41, "op_types_to_quant": 41, "fallback_list": 41, "fp32": [41, 42, 44, 79, 131, 136, 143, 165, 172, 177, 231, 232, 235, 236, 278, 279, 309, 310, 320, 355, 362, 373, 391, 392, 394, 395, 400, 433, 437, 444, 468, 472, 504, 551, 556, 560, 572, 596, 603, 619, 641, 644, 648, 649, 654, 659, 661, 682, 689, 690, 695, 696, 697, 698, 708, 720, 721, 722, 723, 739, 740, 742, 743, 744, 745, 746, 747, 749, 751, 752], "add_qdq_pair_to_weight": [41, 231, 232, 740], "optypes_to_exclude_output_qu": [41, 231, 232, 740], "dedicated_qdq_pair": [41, 231, 232, 740], "smoothquant": [42, 165, 170, 171, 176, 389, 451, 598, 658, 695, 738, 743, 750], "onnxrt": [42, 43, 44, 247, 249, 256, 264, 290, 292, 299, 305, 320, 373, 421, 647, 659, 682, 698, 720, 740, 752], "get_quant_dequant_output": 42, "input_data": [42, 679], "output_data": 42, "loss": [42, 180, 189, 231, 232, 266, 311, 320, 335, 340, 348, 373, 620, 638, 677, 682, 683, 684, 685, 686, 695, 696, 697, 698, 709, 721, 723, 736, 737, 738, 740, 743, 746, 749, 751], "output": [42, 43, 44, 51, 54, 59, 74, 98, 105, 110, 148, 165, 171, 172, 192, 203, 204, 209, 223, 229, 231, 232, 235, 236, 269, 273, 278, 279, 309, 310, 313, 343, 366, 373, 374, 382, 395, 428, 476, 479, 484, 499, 523, 530, 565, 570, 572, 598, 602, 619, 620, 632, 638, 644, 645, 649, 655, 659, 660, 683, 684, 685, 687, 689, 691, 696, 697, 699, 709, 718, 719, 721, 726, 727, 731, 732, 733, 736, 737, 739, 740, 743, 744, 746, 747, 748, 749, 751], "numpi": [42, 43, 67, 68, 70, 105, 148, 264, 305, 316, 327, 369, 395, 492, 493, 495, 565, 688, 746, 748], "7": [42, 172, 178, 199, 231, 232, 384, 400, 405, 619, 661, 676, 688, 689, 697, 737, 740, 744, 746, 749, 752], "bit": [42, 44, 150, 165, 172, 231, 232, 391, 392, 394, 395, 405, 446, 619, 629, 658, 661, 677, 684, 698, 700, 738, 740, 743, 746], "execut": [42, 43, 54, 152, 158, 178, 210, 211, 212, 231, 232, 345, 349, 351, 392, 427, 428, 429, 431, 479, 573, 583, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 638, 641, 648, 649, 682, 683, 684, 697, 698, 703, 704, 711, 712, 718, 719, 720, 721, 725, 728, 736, 737, 740, 743, 745, 749, 752], "provid": [42, 43, 44, 102, 105, 110, 203, 235, 236, 264, 278, 279, 305, 311, 316, 335, 340, 348, 349, 369, 374, 388, 389, 391, 392, 394, 395, 400, 428, 530, 633, 638, 642, 644, 656, 658, 659, 660, 661, 676, 679, 682, 684, 685, 686, 692, 693, 695, 696, 697, 698, 699, 701, 705, 709, 712, 718, 719, 720, 726, 727, 737, 739, 740, 743, 746, 747, 749, 750, 751, 752], "make_sub_graph": 42, "opset": [42, 102, 104, 105, 232, 309, 310, 687], "ir_vers": 42, "thi": [42, 45, 86, 110, 132, 139, 143, 147, 153, 156, 158, 165, 172, 177, 180, 182, 183, 188, 192, 195, 201, 203, 205, 207, 208, 209, 210, 214, 215, 216, 217, 219, 220, 221, 227, 231, 232, 235, 236, 246, 247, 248, 249, 250, 251, 252, 254, 264, 267, 273, 274, 278, 279, 289, 290, 291, 292, 293, 294, 295, 297, 305, 313, 316, 317, 318, 320, 329, 330, 332, 333, 334, 335, 340, 343, 345, 347, 348, 349, 352, 355, 366, 369, 370, 371, 373, 374, 384, 428, 432, 437, 446, 447, 511, 530, 552, 559, 560, 564, 567, 583, 584, 591, 602, 603, 620, 638, 648, 649, 653, 654, 655, 656, 659, 660, 661, 677, 678, 679, 680, 683, 684, 685, 687, 688, 689, 692, 694, 695, 696, 697, 698, 699, 701, 703, 704, 706, 707, 709, 711, 713, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 726, 727, 731, 732, 733, 737, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750], "quant_dequant_data": 42, "qtype": [42, 43, 405, 659], "3": [42, 44, 148, 158, 180, 199, 212, 232, 249, 264, 292, 305, 316, 369, 391, 392, 394, 395, 400, 447, 565, 583, 649, 655, 656, 658, 677, 678, 679, 680, 683, 685, 687, 689, 690, 693, 696, 697, 698, 700, 701, 705, 709, 711, 715, 720, 725, 726, 728, 729, 731, 735, 737, 738, 739, 740, 743, 744, 745, 746, 748, 749, 752], "scheme": [42, 43, 44, 150, 161, 165, 172, 391, 392, 394, 395, 405, 602, 615, 619, 659, 660, 661, 679, 689, 709, 743, 749, 751], "sym": [42, 43, 44, 172, 405, 619, 660, 661, 689, 740, 743, 751], "dequant": [42, 43, 44, 51, 88, 91, 92, 93, 94, 96, 153, 165, 172, 395, 476, 513, 516, 517, 518, 519, 521, 572, 619, 649, 655, 660, 746, 747], "asym": [42, 43, 44, 150, 161, 165, 172, 391, 392, 394, 395, 405, 615, 619, 661, 689, 743, 751], "ortsmoothqu": 42, "fake": [42, 44, 113, 161, 170, 172, 176, 182, 389, 446, 533, 598, 615, 619, 697, 740, 743, 746], "channel": [42, 43, 44, 143, 170, 171, 172, 176, 177, 201, 204, 209, 231, 232, 260, 264, 302, 305, 343, 389, 392, 560, 598, 619, 644, 658, 659, 661, 692, 693, 700, 701, 703, 708, 723, 737, 743, 748, 752], "For": [42, 44, 165, 172, 176, 180, 182, 186, 199, 203, 204, 207, 208, 219, 232, 249, 264, 292, 305, 317, 318, 320, 343, 346, 370, 371, 373, 374, 389, 391, 392, 394, 428, 619, 653, 655, 657, 659, 661, 683, 684, 685, 687, 689, 692, 701, 703, 704, 706, 709, 720, 721, 726, 737, 742, 743, 746, 747, 749, 751, 752], "more": [42, 148, 170, 176, 182, 207, 208, 264, 305, 343, 389, 565, 598, 620, 656, 657, 658, 660, 677, 678, 680, 683, 685, 687, 690, 692, 693, 695, 697, 698, 700, 701, 709, 713, 716, 721, 726, 735, 736, 737, 742, 743, 746, 749, 750, 752], "detail": [42, 170, 176, 179, 203, 264, 305, 389, 598, 649, 650, 653, 658, 660, 661, 677, 678, 683, 689, 690, 691, 695, 696, 697, 698, 701, 709, 718, 726, 727, 737, 743, 744, 745, 746, 747, 749, 750], "pleas": [42, 152, 153, 170, 176, 198, 207, 208, 209, 217, 218, 219, 231, 232, 247, 248, 249, 252, 290, 291, 292, 295, 343, 345, 346, 373, 389, 428, 447, 598, 605, 655, 656, 657, 658, 659, 676, 677, 680, 684, 685, 687, 693, 695, 696, 698, 701, 702, 706, 709, 725, 726, 727, 737, 740, 742, 743, 744, 745, 746, 749, 750], "refer": [42, 152, 153, 170, 176, 198, 207, 208, 209, 217, 218, 219, 223, 231, 232, 247, 290, 313, 314, 320, 343, 345, 346, 366, 367, 373, 389, 428, 447, 598, 605, 655, 658, 659, 660, 676, 679, 680, 682, 684, 685, 687, 691, 693, 694, 696, 697, 698, 701, 706, 709, 720, 721, 723, 725, 726, 727, 735, 739, 741, 744, 748, 749], "accur": [42, 152, 170, 176, 218, 389, 598, 605, 629, 737, 743, 746], "effici": [42, 170, 176, 389, 598, 656, 658, 677, 679, 683, 701, 726, 736, 737, 738, 743, 746, 749], "post": [42, 97, 98, 152, 170, 176, 217, 232, 235, 236, 278, 279, 389, 428, 522, 523, 598, 605, 629, 653, 658, 659, 660, 682, 684, 685, 687, 692, 693, 700, 701, 707, 718, 728, 737, 738, 741, 743, 746, 747, 749], "train": [42, 57, 80, 152, 170, 172, 176, 188, 211, 212, 215, 217, 218, 231, 232, 235, 236, 247, 249, 264, 274, 278, 279, 290, 292, 305, 306, 322, 345, 365, 389, 428, 482, 505, 598, 603, 605, 629, 641, 656, 658, 659, 660, 666, 680, 682, 683, 684, 687, 692, 698, 700, 701, 707, 718, 723, 731, 736, 738, 741, 743, 745, 746, 749, 751], "larg": [42, 43, 170, 176, 218, 389, 598, 658, 679, 683, 697, 700, 738, 741, 743, 746, 752], "languag": [42, 170, 176, 218, 313, 366, 389, 598, 653, 658, 687, 700, 722, 738, 741, 743, 746], "2": [42, 43, 44, 54, 74, 105, 109, 158, 170, 172, 174, 176, 178, 180, 199, 205, 211, 212, 225, 231, 232, 248, 265, 291, 316, 318, 320, 345, 352, 369, 371, 373, 384, 389, 391, 392, 394, 395, 405, 432, 447, 479, 499, 529, 583, 598, 619, 649, 655, 658, 659, 677, 679, 680, 682, 683, 689, 692, 693, 694, 695, 696, 698, 700, 722, 728, 729, 731, 732, 733, 735, 737, 738, 740, 741, 743, 744, 745, 746, 748, 749, 750], "spiq": [42, 170, 176, 389, 598, 746], "free": [42, 170, 176, 217, 235, 236, 278, 279, 389, 428, 598, 653, 707, 712, 720, 728, 735, 745, 746], "per": [42, 43, 44, 170, 172, 176, 178, 231, 232, 265, 389, 392, 395, 598, 619, 620, 643, 659, 661, 679, 700, 726, 737, 742, 743, 752], "we": [42, 43, 67, 68, 70, 74, 86, 143, 158, 170, 176, 177, 178, 180, 203, 207, 214, 231, 232, 246, 265, 267, 289, 313, 316, 366, 369, 389, 399, 405, 435, 492, 493, 495, 499, 511, 560, 583, 598, 653, 655, 659, 660, 661, 678, 679, 682, 685, 687, 689, 695, 696, 697, 705, 706, 709, 713, 716, 718, 719, 721, 724, 731, 732, 733, 735, 736, 737, 739, 740, 741, 743, 744, 745, 746, 747, 749, 750], "onli": [42, 44, 54, 63, 70, 86, 109, 115, 143, 158, 164, 170, 172, 176, 177, 178, 191, 196, 200, 206, 213, 231, 232, 247, 265, 267, 271, 290, 310, 322, 343, 345, 356, 389, 395, 398, 400, 428, 438, 446, 447, 479, 488, 495, 511, 529, 535, 560, 583, 598, 618, 620, 629, 649, 659, 660, 661, 676, 677, 678, 679, 682, 683, 685, 688, 689, 695, 697, 698, 706, 719, 737, 738, 739, 740, 741, 746, 747, 749, 750, 751], "inplac": [42, 170, 389, 598, 632], "mean": [42, 44, 170, 172, 205, 214, 231, 232, 260, 264, 302, 305, 318, 320, 343, 355, 371, 373, 389, 437, 598, 655, 660, 661, 679, 682, 685, 689, 696, 697, 704, 723, 737, 740, 741, 743, 746, 748, 749, 751, 752], "weight": [42, 43, 44, 60, 61, 122, 140, 141, 143, 148, 150, 153, 164, 165, 170, 171, 172, 177, 180, 198, 200, 204, 207, 208, 209, 210, 211, 212, 213, 215, 216, 217, 218, 220, 222, 231, 232, 310, 343, 345, 362, 373, 389, 391, 392, 394, 395, 400, 405, 428, 435, 444, 446, 450, 453, 485, 486, 542, 560, 565, 572, 598, 618, 619, 620, 629, 649, 650, 659, 660, 661, 677, 682, 684, 689, 691, 695, 697, 720, 731, 735, 737, 738, 739, 740, 741, 746, 747, 749, 750, 751], "chang": [42, 96, 143, 170, 177, 211, 212, 214, 215, 217, 218, 221, 231, 232, 345, 347, 389, 435, 521, 560, 598, 632, 649, 654, 660, 679, 685, 688, 694, 697, 701, 711, 712, 715, 718, 724, 737, 747, 748, 749], "you": [42, 158, 170, 231, 232, 245, 247, 288, 290, 345, 373, 389, 428, 583, 598, 620, 654, 655, 660, 678, 679, 680, 682, 685, 693, 694, 696, 698, 701, 703, 704, 706, 711, 715, 718, 719, 720, 721, 722, 723, 724, 726, 737, 740, 743, 744, 745, 746, 747, 750], "can": [42, 43, 44, 143, 153, 158, 170, 177, 195, 203, 204, 205, 210, 218, 219, 221, 231, 232, 235, 236, 246, 249, 264, 265, 267, 278, 279, 289, 292, 305, 316, 318, 320, 343, 345, 347, 369, 371, 373, 374, 384, 389, 395, 405, 428, 560, 583, 598, 620, 632, 638, 649, 655, 656, 658, 659, 660, 661, 676, 678, 679, 680, 682, 683, 684, 685, 687, 689, 692, 693, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 707, 709, 711, 712, 713, 715, 716, 718, 719, 721, 723, 724, 725, 726, 728, 735, 736, 737, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 751, 752], "recov": [42, 170, 389, 596, 598, 619, 648, 649, 659, 684], "helper": [43, 45, 110, 116, 148, 165, 247, 248, 249, 263, 290, 291, 292, 304, 308, 309, 310, 382, 405, 530, 536, 565, 570, 602, 633, 647], "get_node_original_nam": 43, "origin": [43, 44, 140, 148, 159, 165, 171, 199, 203, 215, 223, 225, 232, 247, 264, 265, 290, 305, 329, 330, 332, 333, 334, 344, 345, 364, 395, 405, 433, 446, 450, 565, 585, 598, 619, 632, 644, 649, 654, 680, 706, 737, 740, 748, 749, 751], "simple_progress_bar": [43, 405], "total": [43, 210, 264, 305, 320, 345, 373, 405, 680, 682, 737, 743, 748, 752], "progress": [43, 197, 200, 213, 249, 292, 405, 712, 718, 720, 737, 740], "bar": [43, 249, 292, 405, 718, 738], "case": [43, 70, 74, 158, 172, 178, 232, 246, 263, 264, 265, 289, 304, 305, 311, 335, 340, 348, 384, 405, 495, 499, 583, 661, 678, 679, 683, 684, 685, 689, 691, 696, 702, 706, 718, 719, 720, 723, 729, 732, 733, 735, 737, 738, 740, 743, 744, 746, 748, 750, 751, 752], "where": [43, 158, 231, 232, 316, 320, 369, 373, 405, 446, 583, 591, 649, 661, 677, 682, 683, 711, 715, 719, 746, 747], "tqdm": [43, 405, 697], "t": [43, 67, 68, 70, 143, 158, 177, 205, 231, 232, 264, 267, 305, 318, 371, 405, 492, 493, 495, 560, 583, 655, 659, 678, 682, 683, 685, 697, 698, 719, 724, 737, 740, 743, 749, 751], "dtype_to_nam": 43, "dtype_map": 43, "dtype": [43, 44, 102, 105, 231, 232, 250, 251, 260, 264, 293, 294, 302, 305, 395, 567, 588, 593, 619, 620, 629, 644, 658, 660, 661, 680, 682, 687, 689, 701, 723, 739, 740, 743, 746, 747, 748, 751], "its": [43, 60, 96, 148, 153, 203, 212, 215, 217, 223, 232, 243, 249, 264, 286, 292, 305, 308, 314, 315, 345, 352, 367, 368, 432, 485, 521, 565, 593, 653, 680, 683, 694, 696, 698, 709, 711, 715, 718, 719, 737, 743, 745, 748, 749], "string": [43, 45, 116, 148, 152, 156, 158, 178, 187, 189, 191, 195, 196, 203, 205, 210, 219, 220, 221, 223, 228, 231, 232, 249, 266, 271, 292, 306, 311, 313, 316, 322, 323, 324, 326, 327, 335, 340, 343, 344, 345, 346, 347, 348, 366, 369, 378, 382, 405, 536, 565, 570, 572, 583, 584, 605, 613, 641, 646, 649, 696, 748], "represent": [43, 156, 584, 653, 655, 677, 684, 700, 737, 740], "quanttyp": [43, 446], "repres": [43, 205, 209, 210, 219, 220, 223, 249, 254, 292, 297, 316, 318, 320, 369, 371, 373, 391, 392, 394, 395, 653, 661, 677, 680, 687, 726, 737, 740, 741, 749], "make_quant_nod": 43, "axi": [43, 232], "make": [43, 105, 143, 177, 195, 205, 210, 219, 221, 245, 288, 343, 345, 347, 560, 649, 653, 659, 660, 676, 678, 679, 689, 696, 697, 706, 711, 715, 718, 720, 737, 740, 741, 742, 743, 745, 746, 749], "quantizelinear": 43, "make_dquant_nod": 43, "dequantizelinear": 43, "is_b_transpos": [43, 405], "inuput": [43, 405], "b": [43, 74, 172, 247, 290, 405, 499, 603, 649, 654, 677, 680, 696, 737, 743, 746, 749], "transpos": [43, 73, 209, 260, 264, 305, 309, 343, 405, 498, 743, 748], "split_shared_bia": 43, "share": [43, 44, 82, 98, 109, 141, 172, 395, 453, 507, 523, 529, 619, 688, 689, 743, 746, 749], "float_to_float16": 43, "float_to_bfloat16": 43, "bfloat16": [43, 620, 698, 701, 709, 742], "cast_tensor": 43, "is_large_model": 43, "tensorproto": [43, 105], "raw": [43, 178, 248, 252, 255, 291, 295, 298, 355, 437, 696, 722, 749], "remove_init_from_model_input": 43, "collate_pr": 43, "result": [43, 148, 153, 165, 260, 264, 302, 305, 313, 316, 317, 318, 320, 366, 369, 370, 371, 373, 408, 428, 435, 565, 602, 638, 648, 649, 653, 656, 658, 679, 682, 683, 685, 692, 694, 696, 697, 706, 707, 718, 719, 722, 726, 727, 728, 729, 735, 737, 738, 740, 743, 745, 746, 747, 748, 749, 750, 752], "quantize_data_with_scale_zero": 43, "zero_point": [43, 44, 395], "point": [43, 44, 172, 260, 302, 317, 318, 327, 352, 370, 371, 392, 395, 405, 432, 619, 649, 696, 700, 718, 723, 724, 740, 743, 746, 748, 749], "To": [43, 316, 369, 384, 405, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 654, 658, 660, 661, 678, 680, 682, 685, 698, 700, 702, 705, 711, 713, 715, 716, 720, 724, 737, 739, 742, 743, 744, 746, 749, 751], "pack": [43, 61, 405, 486], "comput": [43, 44, 105, 153, 165, 313, 314, 317, 318, 320, 366, 367, 370, 371, 373, 391, 392, 394, 395, 405, 602, 620, 638, 649, 677, 679, 684, 687, 696, 697, 698, 700, 701, 712, 721, 737, 738, 740, 743, 746, 749], "linear": [43, 152, 161, 164, 165, 172, 176, 201, 203, 204, 209, 214, 223, 226, 231, 232, 343, 405, 615, 619, 655, 683, 687, 697, 737, 743, 746, 749], "transform": [43, 50, 143, 145, 146, 147, 152, 162, 164, 217, 247, 248, 249, 250, 251, 252, 254, 256, 258, 290, 291, 292, 293, 294, 295, 297, 299, 301, 312, 365, 405, 475, 560, 562, 563, 564, 567, 593, 598, 602, 605, 618, 629, 655, 656, 658, 677, 680, 683, 684, 685, 686, 690, 695, 697, 701, 706, 707, 708, 709, 721, 729, 732, 733, 737, 738, 742, 743, 746, 747, 749, 751], "when": [43, 54, 64, 70, 148, 156, 158, 180, 204, 210, 215, 223, 231, 232, 247, 248, 256, 264, 290, 291, 299, 305, 314, 344, 345, 367, 405, 428, 479, 489, 495, 565, 583, 584, 620, 638, 653, 656, 660, 678, 679, 680, 697, 709, 711, 712, 715, 719, 720, 723, 724, 725, 727, 731, 737, 740, 743, 746, 748, 749], "uint8": [43, 172, 260, 302, 316, 364, 369, 405, 446, 619, 659, 680, 689, 739, 740, 748, 751], "rmin": [43, 405, 700, 740], "rmax": [43, 405, 740], "m": [43, 153, 172, 207, 208, 231, 232, 343, 405, 619, 654, 683, 693, 701, 703, 706, 709, 713, 716, 726, 737, 752], "max": [43, 104, 143, 172, 177, 196, 199, 231, 232, 264, 305, 317, 318, 352, 370, 371, 405, 432, 560, 572, 619, 649, 658, 682, 693, 697, 700, 721, 723, 737, 740, 743, 746, 748, 749], "ab": [43, 152, 172, 198, 217, 218, 345, 405, 605, 619, 629, 737, 740, 746], "np": [43, 264, 305, 352, 395, 432, 685, 728, 746, 748, 749], "calculate_scale_zp": 43, "quantize_rang": [43, 405], "calcul": [43, 60, 165, 180, 198, 207, 223, 232, 250, 251, 293, 294, 317, 318, 343, 345, 355, 370, 371, 437, 485, 567, 639, 649, 677, 680, 696, 697, 709, 721, 735, 737, 740, 743, 745, 746, 749, 751], "quantize_data": [43, 405], "add": [43, 53, 64, 109, 119, 148, 191, 223, 231, 232, 247, 249, 271, 290, 292, 344, 362, 405, 444, 478, 489, 529, 539, 565, 649, 654, 655, 658, 661, 679, 680, 685, 687, 689, 696, 697, 713, 716, 720, 721, 728, 731, 732, 745, 746, 747, 749, 750], "necessari": [43, 219, 405, 653, 656, 660, 699, 719, 737, 745, 749], "intermedi": [43, 153, 189, 231, 232, 266, 405, 655, 692, 740], "full": [43, 172, 247, 248, 249, 290, 291, 292, 405, 644, 649, 658, 677, 680, 682, 688, 694, 719, 724, 737, 743, 744], "equat": [43, 318, 320, 371, 373, 405, 740, 746], "r": [43, 143, 177, 405, 560, 682, 693, 719, 720, 722, 723, 725, 726, 740, 752], "": [43, 44, 105, 143, 148, 158, 177, 203, 204, 205, 209, 210, 211, 212, 215, 217, 218, 223, 226, 228, 229, 231, 232, 246, 249, 263, 264, 265, 267, 269, 289, 292, 304, 305, 318, 343, 345, 371, 373, 374, 378, 392, 405, 428, 560, 565, 572, 583, 607, 619, 620, 646, 649, 653, 654, 656, 660, 661, 678, 682, 683, 685, 687, 689, 692, 697, 698, 706, 709, 711, 715, 718, 721, 723, 726, 736, 737, 738, 739, 740, 743, 744, 745, 746, 749, 750, 751, 752], "q": [43, 44, 107, 109, 131, 405, 527, 529, 551, 743, 746], "z": [43, 405, 602, 677, 678, 683, 746], "real": [43, 250, 267, 293, 405, 567, 660, 677, 685, 720, 727, 738, 740], "quantize_data_per_channel": 43, "dequantize_data_with_scale_zero": 43, "tensor_valu": 43, "scale_valu": 43, "zo_valu": 43, "dequantize_data": 43, "valueinfo": 43, "tensor_nam": [43, 148, 158, 159, 565, 583, 585], "new_dtyp": 43, "cast": [43, 51, 476, 742, 748], "info": [43, 165, 172, 187, 207, 208, 223, 262, 267, 272, 343, 378, 572, 598, 602, 644, 645, 649, 655, 678, 682, 699, 728, 733], "quantizedvalu": 43, "new_quantized_nam": 43, "scale_nam": 43, "zero_point_nam": 43, "quantized_value_typ": 43, "quint8": 43, "linearli": 43, "quantizediniti": 43, "quantized_data": 43, "quantizationmod": 43, "quantizedvaluetyp": 43, "quantformat": 43, "quantize_nparrai": 43, "arr": [43, 572, 649], "low": [43, 172, 235, 236, 250, 251, 278, 279, 293, 294, 311, 321, 348, 374, 567, 659, 660, 676, 677, 680, 685, 697, 698, 723, 738, 740, 743, 746, 749], "high": [43, 250, 251, 293, 294, 567, 680, 682, 693, 723, 738, 749], "attribute_to_kwarg": 43, "attribut": [43, 83, 104, 105, 148, 165, 203, 214, 229, 232, 508, 565, 620, 637, 649, 659, 679, 689, 691, 697, 739, 751], "make_nod": 43, "find_by_nam": [43, 405], "item_list": [43, 405], "find": [43, 67, 68, 70, 105, 148, 226, 320, 327, 352, 373, 405, 432, 492, 493, 495, 565, 649, 659, 682, 695, 704, 711, 715, 718, 719, 721, 723, 737, 743, 745, 746, 747, 749], "item": [43, 223, 229, 231, 232, 263, 304, 344, 362, 405, 444, 572, 607, 677, 685, 737, 746, 749], "trt_env_setup": 43, "environ": [43, 178, 265, 653, 658, 676, 711, 715, 718, 726, 729, 731, 732, 733, 749], "variabl": [43, 156, 178, 220, 231, 232, 249, 265, 292, 352, 432, 446, 584, 693, 737, 749], "tensorrt": [43, 677, 698, 740], "to_numpi": 43, "infer_shap": 43, "in_mp": 43, "int_max": 43, "31": [43, 695, 752], "auto_merg": 43, "guess_output_rank": 43, "verbos": [43, 310, 352, 432], "base_dir": 43, "shape": [43, 44, 105, 148, 205, 250, 251, 260, 264, 293, 294, 302, 305, 316, 369, 395, 405, 565, 567, 658, 680, 689, 690, 697, 720, 721, 743, 746, 748], "weightonli": 44, "get_blob_s": 44, "group_siz": [44, 150, 161, 165, 172, 391, 392, 394, 395, 446, 615, 619, 629, 743], "has_zp": 44, "blob_siz": 44, "how": [44, 158, 172, 188, 198, 205, 211, 212, 217, 218, 231, 232, 264, 305, 306, 343, 395, 583, 619, 637, 654, 655, 657, 659, 679, 680, 683, 684, 685, 691, 696, 697, 712, 713, 716, 717, 718, 720, 731, 732, 733, 737, 738, 740, 746, 748, 749, 750, 751], "mani": [44, 172, 373, 395, 428, 619, 678, 679, 693, 743, 749, 751], "element": [44, 172, 180, 207, 208, 223, 245, 288, 316, 343, 369, 395, 567, 591, 619, 649, 680, 692, 696, 700, 737, 743, 746], "one": [44, 109, 110, 115, 158, 165, 172, 178, 205, 209, 214, 217, 218, 219, 221, 264, 274, 305, 313, 316, 320, 322, 343, 346, 347, 366, 369, 373, 395, 529, 530, 535, 583, 602, 619, 620, 656, 659, 677, 683, 684, 685, 689, 692, 693, 696, 697, 698, 701, 702, 706, 707, 709, 711, 712, 715, 718, 719, 720, 723, 724, 725, 726, 728, 735, 736, 737, 739, 740, 741, 743, 744, 746, 748, 749], "zp": [44, 172, 395, 619, 746], "make_matmul_weight_only_nod": [44, 395], "weight_shap": [44, 395], "num_bit": [44, 113, 161, 165, 172, 391, 392, 394, 395, 533, 615, 746], "k_block": [44, 395], "q_weight": [44, 395], "accuracy_level": [44, 391, 392, 394, 395, 400], "matmulfpq4": [44, 395], "accuraci": [44, 178, 180, 223, 231, 232, 235, 236, 278, 279, 306, 311, 320, 335, 340, 348, 373, 374, 384, 391, 392, 394, 395, 428, 433, 447, 620, 638, 646, 655, 658, 660, 661, 677, 679, 680, 682, 684, 685, 686, 687, 696, 697, 700, 709, 718, 720, 727, 728, 731, 732, 735, 736, 737, 738, 739, 743, 744, 745, 746, 747, 750, 751, 752], "level": [44, 182, 203, 391, 392, 394, 395, 433, 447, 645, 653, 700, 728, 746, 749], "unset": [44, 391, 392, 394, 395], "jbla": [44, 391, 392, 394, 395], "kernel": [44, 176, 231, 232, 391, 392, 394, 395, 659, 660, 749], "fp16": [44, 172, 232, 362, 391, 392, 394, 395, 444, 586, 588, 740], "4": [44, 54, 150, 161, 165, 172, 178, 199, 205, 214, 231, 232, 256, 259, 260, 264, 299, 302, 305, 313, 314, 316, 366, 367, 369, 391, 392, 394, 395, 398, 400, 446, 447, 479, 615, 619, 629, 653, 658, 659, 661, 676, 685, 686, 689, 692, 693, 696, 697, 700, 706, 726, 728, 732, 737, 740, 743, 746, 748, 749, 752], "matmulnbit": [44, 395], "new_init": [44, 395], "matmul_weight_only_nod": [44, 395], "quant_tensor": [44, 395, 619], "32": [44, 150, 172, 201, 391, 392, 394, 395, 400, 446, 619, 629, 685, 691, 700, 743, 752], "ratio": [44, 143, 177, 205, 210, 223, 231, 232, 260, 264, 302, 305, 345, 394, 395, 560, 680, 695, 697, 721, 737, 748, 752], "group": [44, 172, 220, 330, 391, 392, 394, 395, 619, 658, 692, 737, 743, 747, 748, 749, 752], "clip": [44, 172, 391, 394, 395, 619, 743, 746], "qdq_tensor": [44, 395], "quant": [44, 148, 165, 172, 231, 232, 362, 388, 391, 392, 394, 395, 397, 400, 444, 455, 456, 466, 470, 565, 619, 629, 655, 678, 695, 697, 740], "pad_tensor": [44, 395], "rowi": [44, 395], "so": [44, 105, 180, 264, 305, 395, 446, 632, 655, 659, 682, 688, 692, 698, 700, 704, 706, 722, 723, 724, 740, 742, 743, 746, 747, 748, 750], "divis": [44, 395], "pade": [44, 395], "rtn_quantiz": [44, 172, 394], "weight_config": [44, 150, 152, 164, 172, 386, 391, 392, 394, 605, 618], "round": [44, 143, 172, 177, 394, 400, 560, 629, 658, 738, 740, 743, 746], "nearst": [44, 172, 394], "method": [44, 141, 143, 156, 158, 165, 172, 195, 220, 231, 232, 240, 245, 246, 247, 249, 256, 264, 267, 283, 288, 289, 290, 292, 299, 305, 326, 327, 328, 362, 391, 392, 394, 444, 446, 453, 560, 573, 583, 584, 590, 592, 597, 601, 602, 603, 604, 605, 612, 616, 618, 620, 641, 642, 644, 645, 655, 656, 658, 677, 678, 679, 680, 682, 683, 684, 696, 697, 736, 737, 740, 742, 743, 746, 748, 749], "modelproto": [44, 308, 374, 386, 389, 391, 392, 394, 395, 397, 398, 405, 699], "onnxmodel": [44, 381, 386, 388, 389, 391, 392, 394, 395, 404, 421], "fc2": [44, 165, 172, 391, 392, 394, 619], "rtn": [44, 165, 397, 400, 470, 573, 590, 592, 597, 601, 603, 604, 605, 612, 618, 627, 629, 678, 741, 743], "get_weight_scal": 44, "apply_awq_scal": 44, "absorb_pair": 44, "output_dict": 44, "appli": [44, 113, 126, 127, 128, 131, 133, 137, 148, 161, 164, 188, 214, 216, 274, 314, 367, 391, 392, 394, 397, 468, 533, 546, 547, 548, 551, 553, 557, 565, 573, 590, 592, 597, 601, 603, 604, 605, 612, 615, 616, 618, 627, 637, 653, 660, 661, 697, 700, 701, 703, 709, 718, 722, 723, 728, 736, 737, 740, 742, 745, 746, 749, 750, 751], "salient": [44, 172, 737, 743], "apply_awq_clip": 44, "mse": [44, 165, 172, 231, 232, 312, 320, 354, 365, 373, 392, 400, 428, 436, 649, 682, 696, 723, 739, 743, 744], "prepare_input": [44, 395], "n_sampl": [44, 150, 165, 172, 603], "sampl": [44, 77, 165, 172, 180, 231, 232, 240, 245, 247, 248, 249, 260, 264, 283, 288, 290, 291, 292, 302, 305, 320, 327, 352, 373, 432, 502, 567, 603, 656, 679, 680, 686, 692, 719, 740, 743, 746, 748, 749, 751, 752], "session": [44, 148, 246, 289, 382, 395, 565, 570, 697, 747], "awq_quant": [44, 172, 391], "enable_auto_scal": [44, 172, 391, 400, 743], "enable_mse_search": [44, 172, 391, 400, 743], "awar": [44, 150, 153, 172, 188, 232, 274, 322, 343, 391, 435, 638, 659, 660, 661, 677, 684, 685, 687, 692, 718, 728, 736, 738, 743, 749], "awq": [44, 172, 397, 400, 619, 741, 743], "enabl": [44, 109, 153, 172, 210, 231, 232, 345, 529, 620, 660, 661, 685, 693, 698, 701, 703, 706, 707, 709, 720, 722, 723, 725, 728, 737, 738, 746, 749], "gptq": [44, 172, 397, 400, 573, 590, 592, 597, 601, 603, 604, 612, 616, 618, 629, 678, 695, 741, 743], "w": [44, 152, 264, 305, 605, 737, 746, 748], "h": [44, 231, 232, 264, 305, 685, 726, 727, 731, 732, 733, 748], "blocksiz": [44, 392, 400, 700], "percdamp": [44, 392, 400, 629, 743], "01": [44, 180, 231, 232, 391, 392, 400, 629, 695, 697, 739, 743, 749, 751, 752], "actord": [44, 392, 400, 743], "perchannel": [44, 392, 400], "hessian": [44, 153, 392, 435, 743, 749], "matrix": [44, 373, 428, 658, 709, 750], "percent": 44, "averag": [44, 317, 318, 320, 370, 371, 373, 392, 696, 697, 743, 749, 752], "diagon": [44, 392, 743], "dampen": 44, "rearrang": [44, 217, 392, 737, 743], "consid": [44, 148, 320, 373, 565, 653, 677, 678, 683, 719, 749], "diag": 44, "error": [44, 105, 153, 158, 172, 320, 355, 373, 392, 437, 583, 603, 645, 682, 696, 702, 723, 724, 727, 743, 746, 749], "gptq_quantiz": [44, 172, 392], "get_ops_recurs": 45, "prefix": [45, 148, 151, 158, 159, 163, 165, 178, 565, 583, 585, 619, 701, 706, 747], "graph_info": 45, "templateadaptor": 45, "tampl": 45, "dictionari": [45, 67, 68, 70, 148, 151, 153, 158, 165, 172, 195, 226, 229, 231, 232, 263, 304, 316, 323, 326, 328, 369, 405, 492, 493, 495, 565, 572, 583, 591, 598, 602, 637, 649], "yaml": [45, 223, 229, 232, 235, 236, 247, 249, 265, 278, 279, 290, 292, 306, 311, 322, 323, 324, 326, 335, 340, 348, 349, 455, 648, 649, 659, 661, 691, 696, 697, 735, 739, 747, 748], "file": [45, 105, 148, 156, 158, 159, 165, 175, 186, 192, 219, 223, 228, 231, 232, 235, 236, 247, 248, 249, 252, 263, 264, 270, 273, 278, 279, 290, 291, 292, 295, 304, 305, 306, 311, 316, 322, 323, 324, 326, 335, 340, 344, 346, 348, 349, 369, 374, 384, 411, 412, 416, 428, 565, 572, 583, 584, 585, 596, 598, 648, 649, 654, 656, 659, 660, 661, 685, 688, 691, 694, 696, 697, 699, 704, 713, 716, 717, 718, 719, 721, 722, 723, 724, 726, 727, 731, 732, 733, 735, 739, 740, 743, 747, 748], "pytorchadaptor": 45, "api": [45, 70, 75, 110, 152, 275, 311, 316, 348, 361, 362, 369, 373, 428, 443, 444, 447, 495, 500, 530, 572, 605, 649, 655, 658, 662, 664, 668, 671, 674, 682, 687, 692, 693, 697, 703, 707, 708, 709, 725, 726, 730, 744, 745, 749, 753], "pytorch_ipexadaptor": 45, "intel": [45, 191, 207, 208, 219, 268, 271, 307, 312, 319, 320, 343, 346, 354, 360, 365, 372, 373, 406, 428, 436, 442, 572, 651, 653, 654, 656, 657, 659, 660, 661, 677, 680, 681, 683, 684, 686, 687, 689, 690, 694, 695, 698, 699, 701, 706, 708, 709, 720, 721, 722, 723, 725, 726, 735, 736, 737, 738, 740, 742, 743, 744, 746, 747, 749, 750, 751, 752], "extens": [45, 156, 158, 572, 583, 584, 649, 656, 658, 659, 678, 689, 692, 693, 695, 697, 698, 699, 702, 707, 708, 709, 713, 716, 717, 721, 737, 738, 740, 743, 746, 749, 750, 751], "ipex": [45, 160, 165, 231, 232, 596, 602, 648, 692, 695, 697, 698, 703, 707, 708, 746], "pytorch_fxadaptor": 45, "fx": [45, 165, 231, 356, 438, 593, 624, 692, 698, 707, 708, 722, 738, 740, 742], "graph": [45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 117, 130, 132, 136, 139, 142, 143, 145, 146, 147, 148, 203, 246, 289, 311, 375, 382, 427, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 532, 533, 534, 537, 550, 552, 556, 559, 560, 562, 563, 564, 565, 570, 655, 659, 680, 683, 685, 691, 699, 701, 720, 723, 740, 741, 742, 747], "pytorchweightonlyadaptor": 45, "querybackendcap": [46, 659, 660], "defin": [46, 86, 153, 182, 183, 195, 196, 203, 205, 210, 211, 212, 217, 218, 219, 220, 221, 231, 232, 235, 236, 278, 279, 323, 324, 326, 327, 328, 335, 340, 343, 344, 345, 347, 374, 399, 428, 511, 591, 638, 648, 653, 656, 659, 660, 679, 680, 683, 684, 689, 692, 696, 697, 719, 736, 737, 740, 743, 745, 746, 747, 749, 751], "interfac": [46, 86, 113, 228, 311, 335, 340, 348, 349, 511, 533, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 641, 692, 697, 709, 727, 740, 744], "each": [46, 141, 148, 153, 158, 165, 172, 223, 231, 232, 245, 249, 252, 260, 264, 288, 292, 295, 302, 305, 314, 316, 317, 318, 355, 367, 369, 370, 371, 437, 453, 565, 567, 583, 602, 619, 649, 654, 659, 660, 661, 678, 680, 682, 683, 684, 689, 697, 703, 709, 712, 718, 726, 728, 735, 737, 741, 743, 745, 747, 748, 749, 750], "adapt": [46, 653, 660, 680, 700, 709, 738], "should": [46, 55, 115, 116, 158, 188, 201, 203, 214, 231, 232, 235, 236, 245, 247, 249, 264, 269, 278, 279, 288, 290, 292, 305, 310, 314, 367, 373, 374, 428, 447, 480, 535, 536, 583, 620, 638, 649, 655, 656, 659, 660, 661, 680, 683, 685, 696, 697, 704, 713, 716, 718, 720, 721, 735, 737, 740, 743, 748, 749, 751], "implement": [46, 110, 143, 147, 150, 158, 235, 236, 242, 245, 246, 247, 249, 278, 279, 285, 288, 289, 290, 292, 313, 366, 374, 384, 428, 435, 530, 560, 564, 573, 583, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 638, 661, 679, 680, 696, 697, 709, 719, 737, 740, 743, 744, 747, 749, 751], "inherit": [46, 188, 189, 215, 216, 221, 231, 244, 264, 266, 274, 287, 305, 345, 347, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 633, 656, 659, 660, 680], "own": [46, 74, 158, 245, 264, 288, 305, 384, 499, 583, 656, 660, 679, 680, 692, 696, 720, 724, 735, 743, 745, 750], "tensorflowadaptor": [47, 456], "stock": [47, 456, 707, 746], "spr": [47, 456], "tensorflow_itexadaptor": [47, 456], "itex": [47, 109, 231, 232, 309, 456, 529, 698, 740, 746], "tensorflowqueri": [47, 456, 659], "local_config_fil": [47, 455, 456], "performance_onli": [47, 48, 49, 107, 131, 136, 147, 231, 456, 473, 474, 527, 551, 556, 564, 697], "itex_mod": [47, 48, 89, 107, 131, 136, 456, 473, 514, 527, 551, 556], "quant_mod": [47, 362, 444, 456, 660, 661], "graphconvert": [48, 473], "qt_config": [48, 473], "recip": [48, 203, 231, 232, 311, 348, 473, 658, 697, 700, 741, 743, 746, 749], "int8_sequ": [48, 473], "fp32_op": [48, 50, 107, 473, 475, 527], "bf16_op": [48, 50, 107, 473, 475, 527, 660, 742], "data_load": [48, 49, 473, 474, 659], "calib_func": [48, 150, 165, 172, 428, 473, 619, 742], "fake_qu": [48, 88, 107, 131, 136, 473, 513, 527, 551, 556], "qdq_enabl": [48, 473], "new_api": [48, 49, 71, 72, 77, 79, 92, 99, 131, 136, 143, 473, 474, 496, 497, 502, 504, 517, 524, 551, 556, 560], "use_bf16": [48, 49, 231, 473, 474, 739], "without": [49, 90, 148, 199, 215, 264, 305, 345, 364, 446, 474, 515, 565, 653, 683, 685, 697, 700, 709, 720, 723, 737, 738, 739, 749, 750], "graphconverterwithoutcalib": [49, 474], "recover_config": [49, 474], "rewrit": [50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 106, 107, 108, 109, 200, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529], "bf16convert": [50, 475, 742], "rerewrit": [51, 476], "dequantizecastoptim": [51, 476], "b16": [51, 476], "dequantize_cast_optim": [52, 87, 111, 477, 512], "biasadd": [53, 59, 64, 66, 109, 478, 484, 489, 491, 529, 689], "convertaddtobiasaddoptim": [53, 478], "conv2d": [53, 59, 60, 61, 65, 66, 71, 125, 135, 143, 152, 470, 478, 484, 485, 486, 490, 491, 496, 545, 555, 560, 660, 661, 682, 687, 689, 723, 746, 747, 749], "addv2": [53, 69, 478, 494, 689], "layout": [54, 479], "convertlayoutoptim": [54, 479], "convers": [54, 55, 232, 322, 479, 480, 654, 659, 660, 697, 698, 740, 742, 746], "optim": [54, 74, 75, 79, 80, 116, 118, 148, 190, 193, 194, 195, 197, 200, 203, 212, 217, 228, 231, 232, 268, 274, 311, 312, 328, 348, 352, 365, 432, 479, 499, 500, 504, 505, 536, 538, 565, 638, 639, 646, 649, 656, 658, 676, 678, 682, 683, 684, 685, 689, 690, 692, 693, 695, 697, 699, 701, 703, 705, 706, 709, 712, 720, 723, 724, 725, 727, 729, 738, 739, 740, 742, 743, 745, 746, 747, 749, 751], "nchw": [54, 260, 479], "nhwc": [54, 260, 479], "It": [54, 158, 172, 185, 188, 192, 205, 235, 236, 273, 278, 279, 318, 320, 327, 343, 348, 355, 371, 373, 374, 428, 433, 437, 479, 583, 603, 619, 632, 638, 659, 660, 661, 677, 682, 683, 697, 700, 704, 707, 712, 718, 719, 720, 721, 723, 724, 726, 737, 740, 743, 744, 745, 749, 751], "exist": [54, 178, 229, 265, 382, 479, 570, 572, 649, 687, 696, 705, 749], "abov": [54, 479, 659, 660, 661, 683, 720, 721, 723, 726, 737, 740, 746, 749], "graph_def": [54, 140, 141, 148, 309, 374, 382, 427, 428, 450, 453, 479, 565, 570], "leakyrelu": [55, 480, 746], "convertleakyreluoptim": [55, 480], "below": [55, 66, 74, 231, 232, 349, 373, 399, 428, 480, 491, 499, 654, 655, 658, 659, 660, 661, 679, 682, 683, 685, 691, 696, 700, 701, 703, 711, 712, 715, 718, 721, 726, 735, 736, 737, 739, 740, 743, 745, 746, 747, 749, 750], "subgraph": [55, 66, 105, 163, 480, 491, 741, 749], "mul": [55, 65, 66, 69, 172, 176, 480, 490, 491, 494, 687, 743, 746], "maximum": [55, 172, 180, 205, 210, 231, 232, 247, 264, 290, 305, 314, 345, 352, 367, 382, 432, 480, 570, 661, 677, 680, 682, 697, 737, 740, 746, 748], "note": [55, 156, 180, 209, 316, 356, 369, 438, 480, 573, 584, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 656, 658, 660, 661, 678, 679, 682, 685, 687, 689, 693, 695, 697, 703, 706, 711, 715, 718, 720, 724, 726, 728, 737, 740, 743, 746, 747, 749, 750, 751], "coeffici": [55, 220, 480, 737], "less": [55, 148, 165, 231, 232, 480, 572, 603, 619, 649, 676, 683, 697, 725, 737], "than": [55, 148, 247, 264, 290, 305, 480, 572, 603, 620, 649, 656, 658, 676, 680, 691, 700, 723, 731, 735, 736, 737, 740, 743, 745, 748, 749], "valid": [55, 67, 68, 105, 185, 210, 213, 223, 231, 232, 249, 292, 316, 344, 345, 369, 382, 480, 492, 493, 570, 656, 658, 659, 680, 682, 683, 686, 689, 692, 694, 697, 709, 723, 737, 740, 743, 744], "nan": [56, 481], "random": [56, 148, 172, 187, 195, 231, 232, 260, 264, 302, 305, 312, 328, 352, 354, 365, 432, 436, 481, 572, 649, 656, 697, 737, 739, 748, 751], "convertnantorandom": [56, 481], "const": [56, 57, 63, 64, 67, 68, 70, 82, 98, 481, 482, 488, 489, 492, 493, 495, 507, 523], "consist": [56, 63, 481, 488, 654, 655, 678, 726, 746, 749], "placehold": [57, 245, 288, 482, 567, 678], "convertplaceholdertoconst": [57, 482], "dilat": [58, 483], "contract": [58, 483], "dilatedcontract": [58, 483], "spacetobatchnd": [58, 483], "batchtospacend": [58, 483], "pattern": [58, 59, 61, 78, 96, 107, 108, 109, 131, 136, 165, 195, 196, 197, 198, 200, 203, 204, 210, 211, 212, 213, 215, 217, 218, 220, 228, 231, 232, 249, 292, 312, 333, 334, 336, 341, 345, 362, 365, 444, 483, 484, 486, 503, 521, 527, 528, 529, 551, 556, 593, 659, 678, 680, 689, 692, 697, 719, 736, 739, 746, 749, 752], "inject": [59, 484, 697], "dummi": [59, 203, 250, 251, 293, 294, 320, 373, 484, 567, 658, 680, 690, 696, 697, 720], "injectdummybiasaddoptim": [59, 484], "fusion": [59, 61, 70, 78, 109, 126, 127, 128, 131, 132, 133, 137, 484, 486, 495, 503, 529, 546, 547, 548, 551, 552, 553, 557, 655, 659, 689], "expanddim": [60, 485], "expanddimsoptim": [60, 485], "next": [60, 240, 283, 447, 485, 567, 656, 660, 661, 679, 739, 743, 749], "fetch": [61, 165, 175, 240, 283, 486, 567, 660, 680, 731, 732, 733], "reshap": [61, 67, 68, 73, 171, 486, 492, 493, 498, 598, 746], "fetchweightfromreshapeoptim": [61, 486], "handl": [61, 148, 170, 176, 185, 486, 565, 598, 645, 655, 657, 678, 679, 726, 746], "fold": [62, 63, 165, 172, 310, 400, 470, 487, 488, 618, 619, 689, 743, 746], "foldbatchnormnodesoptim": [62, 487], "graphfoldconstantoptim": [63, 488], "sequenc": [63, 105, 172, 204, 207, 208, 231, 232, 247, 263, 264, 290, 304, 305, 314, 318, 343, 367, 371, 488, 607, 659, 680, 689, 737, 743, 748], "self": [63, 165, 172, 203, 231, 232, 384, 488, 619, 620, 659, 660, 679, 680, 692, 696, 720, 745, 747, 749], "supported_op_typ": [63, 488], "fusebiasaddandaddoptim": [64, 489], "second": [64, 158, 204, 231, 232, 247, 290, 433, 489, 583, 649, 682, 697, 711, 715, 719, 731, 732, 743, 746, 749, 751], "columnwis": [65, 490], "fusecolumnwisemuloptim": [65, 490], "depthwiseconv2dn": [65, 71, 125, 135, 490, 496, 545, 555, 689], "math": [66, 491, 740], "fuseconvwithmathoptim": [66, 491], "elimin": [66, 491, 725], "sub": [66, 165, 178, 203, 265, 491, 602, 656, 678, 749], "realdiv": [66, 69, 491, 494], "decompos": [67, 68, 492, 493], "fusedecomposedbnoptim": [67, 492], "input_graph_def": [67, 68, 70, 492, 493, 495], "node_name_from_input": [67, 68, 70, 492, 493, 495], "node_nam": [67, 68, 70, 148, 382, 413, 492, 493, 495, 565, 570, 660], "strip": [67, 68, 70, 83, 84, 148, 492, 493, 495, 508, 509, 565, 747], "port": [67, 68, 70, 492, 493, 495, 720, 727], "other": [67, 68, 70, 156, 170, 176, 246, 289, 318, 371, 382, 492, 493, 495, 570, 584, 598, 653, 655, 660, 661, 678, 682, 689, 692, 694, 697, 699, 700, 721, 735, 737, 740, 746, 748, 749, 752], "underli": [67, 68, 70, 158, 492, 493, 495, 583], "node_from_map": [67, 68, 70, 492, 493, 495], "node_map": [67, 68, 70, 492, 493, 495], "pull": [67, 68, 70, 492, 493, 495], "def": [67, 68, 70, 180, 235, 236, 278, 279, 405, 428, 447, 492, 493, 495, 572, 620, 637, 638, 655, 659, 678, 679, 680, 683, 684, 685, 696, 697, 740, 746, 747, 749], "entri": [67, 68, 70, 153, 191, 271, 311, 349, 397, 398, 468, 469, 472, 492, 493, 495, 627, 628, 632, 649, 678, 694], "index": [67, 68, 70, 105, 178, 223, 232, 240, 245, 249, 283, 288, 292, 327, 492, 493, 495, 567, 649, 680, 696, 719, 723, 743, 746], "everi": [67, 68, 70, 205, 208, 210, 231, 232, 343, 345, 492, 493, 495, 659, 679, 706, 711, 715, 741, 743, 749], "identifi": [67, 68, 70, 158, 316, 369, 382, 492, 493, 495, 570, 583, 726, 737, 743], "want": [67, 68, 70, 203, 231, 232, 245, 247, 288, 290, 345, 433, 492, 493, 495, 620, 638, 655, 659, 679, 680, 685, 697, 706, 718, 719, 726, 735, 740, 743, 745, 747, 749], "nodedef": [67, 68, 70, 492, 493, 495], "rais": [67, 68, 70, 105, 156, 158, 165, 200, 206, 213, 223, 316, 343, 344, 345, 369, 374, 447, 492, 493, 495, 583, 584, 619, 658, 678, 720, 737, 738], "valueerror": [67, 68, 70, 165, 316, 369, 447, 492, 493, 495, 619, 688], "If": [67, 68, 70, 74, 158, 172, 178, 180, 182, 231, 232, 235, 236, 249, 264, 278, 279, 292, 305, 344, 374, 428, 447, 492, 493, 495, 499, 583, 603, 607, 619, 620, 638, 654, 655, 660, 676, 678, 679, 680, 685, 693, 694, 696, 697, 704, 712, 713, 716, 718, 724, 729, 735, 737, 740, 743, 745, 746, 747, 748, 749], "isn": [67, 68, 70, 492, 493, 495], "present": [67, 68, 70, 492, 493, 495, 682, 726, 738, 746], "values_from_const": [67, 68, 70, 492, 493, 495], "node_def": [67, 68, 70, 492, 493, 495], "extract": [67, 68, 70, 148, 203, 249, 292, 364, 446, 492, 493, 495, 565, 680], "ha": [67, 68, 70, 74, 152, 158, 209, 210, 265, 313, 343, 345, 366, 405, 447, 492, 493, 495, 499, 572, 583, 591, 605, 654, 656, 659, 660, 661, 679, 687, 692, 697, 698, 704, 718, 723, 724, 726, 729, 737, 739, 740, 742, 745, 746, 749], "access": [67, 68, 70, 229, 232, 492, 493, 495, 644, 649, 713, 716, 720], "valid_reshape_input": [67, 68, 492, 493], "reshape_in0_ndef": [67, 68, 492, 493], "reshape_in1_ndef": [67, 68, 492, 493], "ar": [67, 68, 105, 158, 165, 205, 210, 211, 212, 217, 218, 231, 232, 247, 264, 290, 305, 316, 320, 327, 343, 344, 345, 349, 351, 352, 369, 373, 391, 392, 394, 398, 429, 431, 432, 446, 447, 492, 493, 573, 583, 590, 591, 592, 597, 601, 602, 603, 604, 605, 612, 616, 618, 620, 641, 648, 649, 653, 654, 655, 656, 659, 660, 678, 679, 680, 682, 683, 684, 685, 686, 687, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 700, 701, 704, 706, 709, 712, 718, 720, 721, 723, 724, 725, 726, 729, 735, 736, 737, 738, 740, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751], "bypass_reshap": [67, 68, 492, 493], "input_node_map": [67, 68, 492, 493], "input_nam": [67, 68, 102, 142, 232, 309, 310, 382, 492, 493, 570, 687], "get_const_dim_count": [67, 68, 492, 493], "dimens": [67, 68, 105, 239, 264, 282, 305, 492, 493, 567, 680, 683, 743, 748], "instancenorm": [68, 493, 746], "fusedecomposedinoptim": [68, 493], "gelu": [69, 494], "fusegeluoptim": [69, 494], "sqrt": [69, 494, 682], "erf": [69, 494], "layernorm": [70, 495, 746], "fuselayernormoptim": [70, 495], "remap": [70, 158, 495, 583], "smaller": [70, 264, 305, 495, 683, 697, 700, 737, 748], "fusedbatcnormv3": [70, 495], "And": [70, 495, 654, 655, 676, 678, 697, 704, 746], "further": [70, 232, 495, 653, 658, 698, 699, 701, 703, 712, 718, 740], "restrict": [70, 158, 231, 232, 495, 583, 737, 745], "2d": [70, 495, 746], "3d": [70, 495, 738, 746], "kera": [70, 116, 191, 203, 223, 232, 249, 256, 271, 292, 299, 377, 382, 469, 472, 495, 536, 570, 572, 660, 679, 685, 699, 708, 709], "fusepadwithconv2doptim": [71, 496], "excluded_op_nam": [71, 72, 228, 231, 232, 496, 497, 697, 737], "cfg": [71, 72, 165, 228, 362, 444, 496, 497, 598, 602, 641, 660, 661], "itex_qdq_mod": [71, 72, 496, 497], "conv3d": [71, 125, 496, 545], "fusepadwithfp32conv2doptim": [72, 497], "fusetransposereshapeoptim": [73, 498], "cse": [74, 98, 499, 523], "graphcseoptim": [74, 499], "introduc": [74, 499, 659, 660, 661, 689, 697, 740, 743, 744, 746, 750], "ident": [74, 80, 204, 499, 505, 653, 683], "three": [74, 223, 247, 290, 351, 429, 431, 499, 655, 659, 660, 677, 693, 698, 712, 726, 736, 740, 742, 745, 746, 747], "d": [74, 165, 499, 602, 683, 691, 719, 721, 727, 737], "those": [74, 158, 355, 437, 499, 583, 649, 682, 683, 684, 691, 697, 698, 736, 737, 740, 749], "child": [74, 152, 159, 499, 585, 605, 747], "b1": [74, 499], "c1c2": [74, 499], "d1": [74, 499, 649], "c1": [74, 499], "c2": [74, 499], "memori": [74, 165, 172, 311, 335, 340, 348, 384, 386, 499, 619, 649, 677, 679, 684, 697, 698, 700, 701, 735, 737, 740, 741, 743, 746, 749, 752], "bound": [74, 178, 196, 264, 305, 316, 352, 369, 432, 499, 696, 748], "like": [74, 96, 98, 148, 158, 182, 203, 223, 232, 235, 236, 237, 249, 278, 279, 280, 292, 311, 320, 345, 348, 349, 373, 382, 398, 428, 499, 521, 523, 565, 567, 570, 583, 638, 654, 655, 656, 659, 660, 682, 683, 684, 692, 706, 721, 723, 736, 737, 740, 743, 744, 746, 749], "relu": [74, 78, 109, 499, 503, 529, 655, 689, 746, 747], "relu6": [74, 499, 689], "updat": [74, 159, 165, 198, 199, 205, 223, 345, 373, 428, 499, 585, 598, 602, 646, 688, 695, 696, 697, 704, 709, 712, 728, 737, 743, 746, 749, 750], "graphdef": [74, 148, 382, 427, 499, 565, 570, 699], "grappler": [75, 500, 689], "grappleroptim": [75, 500], "input_output_nam": [75, 500], "opt_cfg": [75, 500], "wrapper": [75, 102, 103, 104, 105, 122, 140, 151, 161, 164, 189, 200, 246, 264, 266, 267, 269, 270, 289, 305, 316, 320, 369, 373, 378, 382, 450, 500, 542, 569, 570, 588, 615, 742], "leverag": [75, 500, 644, 656, 658, 683, 687, 701, 718, 736, 740, 743, 749], "built": [75, 191, 214, 233, 234, 238, 243, 247, 248, 253, 255, 257, 258, 260, 261, 264, 269, 271, 276, 277, 281, 284, 286, 290, 291, 296, 298, 300, 301, 302, 303, 305, 349, 373, 376, 384, 428, 500, 607, 638, 656, 659, 680, 685, 697, 711, 715, 735, 740, 745, 748, 749, 751], "convert_add_to_biasadd": [76, 87, 111, 501, 512], "convert_layout": [76, 87, 111, 501, 512], "convert_leakyrelu": [76, 87, 111, 501, 512], "convert_nan_to_random": [76, 87, 111, 501, 512], "convert_placeholder_to_const": [76, 87, 111, 501, 512], "dilated_contract": [76, 87, 111, 501, 512], "dummy_biasadd": [76, 87, 111, 501, 512], "expanddims_optim": [76, 87, 111, 501, 512], "fetch_weight_from_reshap": [76, 87, 111, 501, 512], "fold_batch_norm": [76, 87, 111, 501, 512], "fold_const": [76, 87, 111, 501, 512], "fuse_biasadd_add": [76, 87, 111, 501, 512], "fuse_column_wise_mul": [76, 87, 111, 501, 512], "fuse_conv_with_math": [76, 87, 111, 501, 512], "fuse_decomposed_bn": [76, 87, 111, 501, 512], "fuse_decomposed_in": [76, 87, 111, 501, 512], "fuse_gelu": [76, 87, 111, 501, 512], "fuse_layer_norm": [76, 87, 111, 501, 512], "fuse_pad_with_conv": [76, 87, 111, 501, 512], "fuse_pad_with_fp32_conv": [76, 87, 111, 501, 512], "fuse_reshape_transpos": [76, 87, 111, 501, 512], "graph_cse_optim": [76, 87, 111, 501, 512], "grappler_pass": [76, 87, 111, 501, 512], "insert_print_nod": [76, 87, 111, 501, 512], "move_squeeze_after_relu": [76, 87, 111, 501, 512], "pre_optim": [76, 87, 111, 501, 512], "remove_training_nod": [76, 87, 111, 501, 512], "rename_batch_norm": [76, 87, 111, 501, 512], "split_shared_input": [76, 87, 111, 501, 512], "strip_equivalent_nod": [76, 87, 111, 148, 501, 512, 565], "strip_unused_nod": [76, 87, 111, 148, 501, 512, 565], "switch_optim": [76, 87, 111, 501, 512], "insert": [77, 105, 107, 109, 113, 146, 171, 176, 455, 502, 527, 529, 533, 563, 598, 619, 632, 655, 660, 679, 692, 697, 701, 737, 740, 742, 743, 746, 747], "print": [77, 152, 153, 203, 320, 373, 447, 502, 605, 649, 685, 696, 697, 720, 721, 737, 746, 749], "insertprintminmaxnod": [77, 502], "pre_node_nam": [77, 502], "post_node_nam": [77, 502], "pass": [77, 148, 156, 158, 178, 187, 373, 398, 428, 502, 565, 572, 583, 584, 596, 613, 620, 648, 649, 654, 655, 659, 676, 680, 683, 684, 685, 691, 696, 697, 719, 726, 737, 739, 740, 742, 746, 751], "move": [78, 158, 171, 503, 583, 598, 655, 724, 739, 743, 744], "squeez": [78, 503, 655], "movesqueezeafterreluoptim": [78, 503], "match": [78, 102, 158, 203, 316, 317, 369, 370, 503, 583, 658, 683, 719, 743], "pre": [79, 116, 159, 203, 235, 236, 247, 278, 279, 290, 374, 428, 504, 536, 585, 629, 638, 678, 680, 683, 684, 697, 706, 723, 737, 738, 740, 743, 747, 749], "entranc": [79, 196, 238, 504], "preoptim": [79, 504], "removetrainingnodesoptim": [80, 505], "protected_nod": [80, 505], "types_to_splic": [80, 505], "checknumer": [80, 505], "stopgradi": [80, 505], "renam": [81, 506, 744], "fusedbatchnorm": [81, 506], "fusedbatchnormv2": [81, 506], "renamebatchnormoptim": [81, 506], "splitsharedinputoptim": [82, 507], "equival": [83, 164, 508, 618, 658, 700, 738, 743, 746], "stripequivalentnodesoptim": [83, 508], "output_node_nam": [83, 84, 131, 132, 136, 148, 508, 509, 551, 552, 556, 565], "same": [83, 141, 148, 172, 180, 199, 217, 232, 247, 264, 290, 305, 316, 369, 453, 508, 565, 607, 620, 649, 659, 661, 676, 679, 680, 683, 685, 689, 697, 700, 702, 706, 711, 715, 737, 739, 740, 743, 746, 747, 748, 749], "unus": [84, 148, 509, 565, 637], "stripunusednodesoptim": [84, 509], "input_node_nam": [84, 131, 136, 148, 509, 551, 556, 565], "switch": [85, 510, 701, 747], "switchoptim": [85, 510], "condit": [85, 180, 247, 248, 249, 264, 290, 291, 292, 305, 351, 429, 431, 510, 680, 694, 748, 749], "graphrewriterbas": [86, 511], "abstract": [86, 188, 196, 264, 305, 306, 311, 348, 511, 659, 661, 691], "freeze_fake_qu": [87, 95, 111, 512, 520], "freeze_valu": [87, 95, 111, 512, 520], "freeze_value_without_calib": [87, 95, 111, 512, 520], "fuse_conv_redundant_dequant": [87, 95, 111, 512, 520], "fuse_conv_requant": [87, 95, 111, 512, 520], "fuse_matmul_redundant_dequant": [87, 95, 111, 512, 520], "fuse_matmul_requant": [87, 95, 111, 512, 520], "meta_op_optim": [87, 95, 111, 512, 520], "post_hostconst_convert": [87, 95, 111, 512, 520], "post_quantized_op_cs": [87, 95, 111, 512, 520], "rnn_convert": [87, 95, 111, 512, 520], "scale_propag": [87, 95, 111, 512, 520], "onnx_graph": [87, 101, 111], "onnx_schema": [87, 101, 111], "tf2onnx_util": [87, 101, 111], "insert_qdq_pattern": [87, 106, 111, 512, 526], "merge_duplicated_qdq": [87, 106, 111, 512, 526], "share_qdq_y_pattern": [87, 106, 111, 512, 526], "freez": [88, 89, 90, 148, 513, 514, 515, 565, 701, 737], "fakequ": [88, 455, 513], "freezefakequantopoptim": [88, 513], "follow": [88, 110, 180, 204, 249, 292, 313, 316, 366, 369, 513, 530, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 653, 654, 655, 656, 658, 659, 660, 661, 678, 679, 680, 683, 684, 685, 689, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 711, 715, 720, 722, 723, 726, 731, 736, 737, 739, 740, 743, 746, 747, 749], "freezevaluetransform": [89, 514], "max_min_data": [89, 90, 514, 515], "postfix": [89, 90, 514, 515], "tensor_data": [89, 514, 572, 649, 650], "th": [89, 90, 514, 515], "gpu": [89, 90, 97, 158, 172, 231, 232, 514, 515, 522, 583, 620, 658, 676, 692, 697, 698, 703, 709, 718, 739, 740, 741], "freezevaluewithoutcalibtransform": [90, 515], "95": [90, 320, 373, 515, 696, 752], "quantizedconv": [91, 92, 516, 517], "quantizeddeconv": [91, 516], "redund": [91, 93, 516, 518, 637], "fuseconvredundantdequantizetransform": [91, 516], "cpu": [91, 92, 93, 94, 152, 157, 158, 160, 165, 187, 231, 232, 516, 517, 518, 519, 572, 583, 588, 605, 620, 644, 649, 658, 660, 676, 677, 692, 697, 698, 701, 703, 709, 718, 726, 738, 739, 740, 741, 742, 743, 747], "_quantizedconv": [91, 516], "_quantizeddeconv": [91, 516], "successor": [91, 92, 93, 94, 516, 517, 518, 519], "requant": [92, 94, 517, 519, 747], "fuseconvrequantizetransform": [92, 517], "quantizedmatmul": [93, 94, 518, 519], "fusematmulredundantdequantizetransform": [93, 518], "_quantizedmatmul": [93, 94, 518, 519], "fusematmulrequantizedequantizetransform": [94, 519], "quantizedmatmulwithbiasanddequant": [94, 519], "fusematmulrequantizetransform": [94, 519], "fusematmulrequantizedequantizenewapitransform": [94, 519], "fusematmulrequantizenewapitransform": [94, 519], "newapi": [94, 519], "meta": [96, 521, 658, 695, 738, 752], "metainfochangingmemopoptim": [96, 521], "metaop": [96, 521], "With": [96, 384, 521, 655, 659, 661, 679, 697, 706, 711, 715, 719, 725, 735, 737, 738, 745, 746, 749, 752], "better": [96, 231, 232, 235, 236, 278, 279, 327, 374, 428, 521, 638, 678, 684, 696, 698, 737, 738, 740, 743, 745, 746, 749], "perform": [96, 140, 178, 220, 231, 232, 247, 259, 260, 265, 290, 302, 311, 335, 340, 348, 355, 373, 384, 428, 433, 437, 450, 451, 521, 603, 620, 654, 655, 656, 659, 660, 676, 680, 681, 682, 684, 686, 687, 692, 693, 696, 697, 698, 699, 701, 703, 707, 709, 712, 718, 724, 735, 736, 737, 738, 739, 740, 741, 742, 743, 746, 747, 749, 751, 752], "hostconst": [97, 522], "posthostconstconvert": [97, 522], "just": [97, 237, 262, 264, 267, 269, 270, 272, 280, 305, 384, 522, 567, 656, 697, 708, 712, 718, 726, 736, 740, 746, 748, 749], "postcseoptim": [98, 523], "duplic": [98, 108, 352, 432, 523, 528], "quantizev2": [98, 523], "decreas": [98, 523, 723, 737], "size": [98, 172, 180, 207, 208, 239, 240, 246, 249, 255, 260, 264, 282, 283, 289, 292, 298, 302, 305, 343, 382, 384, 391, 392, 394, 523, 567, 570, 619, 649, 653, 660, 679, 680, 685, 688, 697, 700, 718, 719, 735, 737, 740, 741, 743, 746, 748, 751, 752], "rnn": [99, 524], "quantizedrnnconvert": [99, 524], "calibration_data": [99, 107, 524, 527], "rnn_detail": [99, 524], "scalepropagationtransform": [100, 525], "direct": [100, 209, 343, 525, 737], "export": [101, 232, 312, 316, 365, 369, 658, 690, 704, 719, 721, 747, 750], "onnxgraph": 102, "output_shap": 102, "extra_opset": 102, "output_nam": [102, 142, 232, 309, 310, 382, 570, 687], "is_subgraph": 102, "graph_nam": 102, "manipul": [102, 103], "onnxnod": 103, "skip_convers": 103, "schema": [104, 172, 619], "onnxopschema": 104, "domain": [104, 105, 231, 232, 737, 749], "since_vers": 104, "get_schema": 104, "max_inclusive_opset_vers": 104, "within": [104, 179, 180, 211, 212, 217, 218, 226, 311, 316, 348, 369, 382, 422, 427, 570, 653, 655, 661, 677, 698, 711, 715, 718, 726, 737, 738, 746, 749], "get_max_supported_opset_vers": 104, "packag": [104, 658, 659, 678, 688, 693, 718, 719, 738, 744, 749], "set_nam": 105, "find_opset": 105, "assert_error": 105, "bool_val": 105, "error_msg": 105, "messag": [105, 146, 563, 654, 726, 727, 731, 732, 733, 749], "map_numpy_to_onnx_dtyp": 105, "np_dtype": 105, "map_onnx_to_numpy_typ": 105, "onnx_typ": 105, "add_port_to_nam": 105, "nr": 105, "get_tensorflow_node_attr": 105, "pars": [105, 148, 165, 247, 248, 260, 264, 290, 291, 302, 305, 411, 412, 416, 565, 602, 660, 661, 748], "get_tensorflow_tensor_shap": 105, "get_tensorflow_node_shape_attr": 105, "attr": [105, 148, 203, 565], "map_tensorflow_dtyp": 105, "get_tensorflow_tensor_data": 105, "convert_tensorflow_tensor_to_onnx": 105, "read_tensorflow_node_attr": 105, "read": [105, 148, 158, 252, 264, 295, 305, 344, 565, 583, 680, 742, 745], "infer_onnx_shape_dtyp": 105, "opset_vers": [105, 142, 232, 309, 310, 687], "input_shap": [105, 251, 294, 567, 680], "input_dtyp": 105, "sometim": [105, 655, 682, 740], "make_onnx_shap": 105, "seqtyp": 105, "tensor_dtyp": 105, "around": 105, "signifi": 105, "make_onnx_inputs_output": 105, "elem_typ": 105, "text": [105, 219, 263, 264, 304, 305, 313, 318, 346, 366, 371, 687, 694, 700, 707, 729, 732, 733, 737, 738, 743, 746, 748, 752], "datatyp": [105, 165, 742, 749, 752], "save_protobuf": 105, "path": [105, 140, 148, 159, 165, 186, 203, 219, 223, 228, 247, 248, 249, 264, 290, 291, 292, 305, 306, 309, 310, 311, 322, 323, 324, 326, 335, 340, 344, 346, 348, 349, 362, 374, 382, 386, 389, 391, 392, 394, 397, 398, 405, 427, 428, 444, 450, 565, 570, 572, 585, 598, 602, 632, 644, 646, 649, 655, 656, 659, 680, 682, 685, 691, 696, 697, 698, 699, 704, 707, 718, 721, 723, 726, 731, 732, 733, 736, 743, 748, 751], "as_text": 105, "save": [105, 148, 157, 158, 186, 200, 223, 231, 232, 249, 292, 309, 310, 349, 382, 386, 428, 565, 570, 572, 583, 638, 639, 644, 649, 655, 659, 691, 697, 698, 699, 702, 706, 711, 715, 721, 726, 731, 732, 733, 736, 740, 741, 743, 746], "protobuf": [105, 382, 570, 721], "is_onnx_domain": 105, "is_list_or_tupl": 105, "are_shapes_equ": 105, "src": [105, 719], "dest": 105, "equal": [105, 143, 148, 177, 447, 560, 572, 649, 700, 737, 743], "get_subgraphs_from_onnx": 105, "model_proto": 105, "over": [105, 158, 249, 292, 320, 373, 583, 660, 686, 690, 692, 696, 709, 718, 724, 728, 737, 739, 746, 749], "df": 105, "initialize_name_count": 105, "avoid": [105, 158, 165, 172, 247, 290, 583, 619, 637, 655, 678, 747], "conflict": [105, 678, 688], "counter": 105, "make_nam": 105, "get_index_from_strided_slice_of_shap": 105, "outputs_to_valu": 105, "stride": [105, 264, 305, 748], "slice": 105, "compute_const_folding_using_tf": 105, "g": [105, 158, 205, 231, 232, 583, 620, 654, 683, 686, 690, 701, 706, 737, 743, 744, 746, 749], "const_node_valu": 105, "graph_output": 105, "constant": [105, 310, 312, 352, 354, 360, 365, 432, 436, 442, 642, 678, 679, 689, 721, 748], "tf": [105, 116, 141, 148, 203, 223, 246, 247, 248, 249, 264, 289, 290, 291, 292, 305, 380, 382, 453, 470, 472, 536, 565, 567, 569, 570, 571, 572, 678, 685, 693, 699, 738, 742, 748], "generategraphwithqdqpattern": [107, 527], "op_wise_config": [107, 131, 136, 527, 551, 556, 660], "quantized_nod": [107, 527], "llm_weight_minmax": [107, 527], "dq": [107, 109, 131, 527, 529, 551, 746], "pair": [107, 231, 232, 527, 660, 679, 697, 698, 744], "befor": [107, 109, 152, 176, 195, 205, 210, 212, 217, 219, 221, 231, 232, 247, 290, 343, 345, 347, 455, 527, 529, 605, 654, 661, 679, 680, 683, 684, 685, 688, 689, 693, 697, 713, 716, 722, 723, 740, 743, 745, 747, 749], "merg": [108, 239, 282, 362, 444, 528, 567, 713, 716, 747, 749], "mergeduplicatedqdqoptim": [108, 528], "y": [109, 231, 232, 264, 305, 352, 432, 529, 678, 682, 688, 704, 746, 748], "shareqdqforitexypatternoptim": [109, 529], "break": [109, 529, 685, 697], "graphanalyz": [110, 530], "extend_engin": [110, 530], "analyz": [110, 203, 382, 530, 570, 745, 746, 747], "under": [110, 231, 232, 249, 292, 405, 530, 572, 620, 637, 644, 648, 654, 656, 658, 680, 694, 696, 697, 701, 706, 707, 718, 726, 736, 737, 738, 741, 743, 747, 749], "singleton": [110, 187, 530, 572, 649], "specifi": [110, 158, 165, 178, 182, 223, 231, 232, 235, 236, 264, 265, 278, 279, 305, 311, 316, 320, 322, 323, 326, 335, 340, 348, 349, 369, 373, 374, 428, 447, 530, 583, 591, 602, 603, 607, 637, 638, 648, 649, 660, 661, 685, 689, 696, 697, 706, 720, 726, 730, 731, 732, 733, 735, 737, 739, 743, 748, 749, 751], "graphrewriterhelp": [110, 530], "encapsul": [110, 235, 236, 278, 279, 374, 428, 530, 638, 699], "quantize_lay": [111, 112, 114, 531, 532, 534], "fake_quant": [111, 112, 114, 531, 532, 534], "quantize_config": [111, 112, 114, 531, 532, 534, 660], "quantize_help": [111, 112, 114, 531, 532, 534], "quantize_wrapp": [111, 112, 114, 531, 532, 534], "fuse_qdq_bn": [111, 112, 130, 531, 532, 550], "fuse_qdq_concatv2": [111, 112, 130, 531, 532, 550], "fuse_qdq_conv": [111, 112, 130, 531, 532, 550], "fuse_qdq_deconv": [111, 112, 130, 531, 532, 550], "fuse_qdq_in": [111, 112, 130, 531, 532, 550], "fuse_qdq_matmul": [111, 112, 130, 531, 532, 550], "fuse_qdq_pool": [111, 112, 130, 531, 532, 550], "optimize_qdq": [111, 112, 130, 531, 532, 550], "optimize_lay": [112, 114, 117, 532, 534, 537], "quantize_layer_add": [112, 114, 117, 532, 534, 537], "quantize_layer_bas": [112, 114, 117, 532, 534, 537], "quantize_layer_bn": [112, 114, 117, 532, 534, 537], "fakequantizebas": [113, 533], "abc": [113, 318, 371, 533, 633, 659, 747, 749], "fakequant": [113, 533], "per_channel": [113, 533, 660, 661, 689, 740, 751], "8": [113, 158, 172, 231, 232, 263, 304, 398, 533, 583, 603, 619, 629, 655, 660, 677, 678, 689, 693, 700, 725, 726, 737, 738, 743, 746, 749, 752], "channel_axi": [113, 174, 177, 533], "symmetr": [113, 172, 391, 392, 394, 533, 644, 661, 740, 743, 748, 749], "narrow_rang": [113, 533], "quantizeconfig": [115, 116, 535, 536], "custom": [115, 156, 165, 172, 178, 232, 349, 373, 384, 535, 584, 619, 648, 676, 683, 684, 701, 724, 725, 726, 730, 732, 733, 737, 738, 743, 745], "There": [115, 349, 351, 429, 431, 535, 678, 682, 683, 689, 692, 697, 701, 723, 725, 726, 743, 746, 749, 751], "instanc": [115, 116, 178, 199, 231, 232, 235, 236, 265, 278, 279, 317, 318, 320, 323, 326, 329, 330, 332, 333, 334, 352, 364, 370, 371, 373, 374, 428, 432, 446, 535, 536, 620, 638, 646, 649, 653, 654, 655, 659, 676, 697, 703, 709, 743, 749, 751, 752], "global": [115, 205, 231, 232, 329, 330, 332, 333, 334, 343, 446, 535, 649, 655, 697, 737, 739, 749], "class": [116, 156, 165, 171, 200, 206, 213, 327, 374, 428, 472, 536, 584, 637, 655, 656, 660, 678, 679, 680, 683, 696, 697, 709, 735, 736, 740, 744, 747, 749, 751], "init_quantize_config": [116, 536], "quantize_recip": [116, 536], "begin": [116, 211, 212, 217, 345, 536, 678, 679, 683, 684, 697, 737, 749], "process": [116, 140, 153, 172, 178, 180, 185, 205, 210, 211, 212, 219, 221, 223, 231, 232, 235, 236, 247, 248, 249, 260, 264, 265, 278, 279, 290, 291, 292, 302, 305, 343, 345, 347, 351, 352, 374, 428, 429, 431, 432, 450, 536, 603, 620, 637, 638, 648, 649, 656, 659, 660, 661, 677, 679, 680, 683, 684, 685, 687, 697, 700, 702, 723, 725, 726, 728, 736, 737, 740, 741, 743, 746, 747, 748, 751], "model_nam": [116, 231, 232, 536, 658], "special": [116, 158, 203, 384, 536, 583, 655, 679, 696, 697, 735, 737, 743, 750], "decid": [116, 231, 232, 314, 345, 367, 536, 659, 660, 697, 740, 744, 749], "qat_clone_funct": [116, 536], "leav": [116, 536, 712], "quantizewrapp": [116, 122, 536, 542], "wrapped_lay": [116, 199, 536], "config_quantizable_lay": [118, 538], "quantizelayeradd": [119, 539], "quantizelay": [120, 540], "quantizelayerbas": [120, 540], "quantizelayerbatchnorm": [121, 541], "quantizewrapperbas": [122, 542], "fusedbatchnormv3": [123, 133, 543, 553], "fusenodestartwithfusedbatchnormv3": [123, 133, 543, 553], "_quantizedfusedbatchnorm": [123, 543], "concatv2": [124, 134, 147, 544, 554, 564, 689], "fusenodestartwithconcatv2": [124, 134, 544, 554], "quantizedconcatv2": [124, 134, 544, 554], "fusenodestartwithconv2d": [125, 135, 545, 555], "conv2dbackpropinput": [126, 546], "conv3dbackpropinputv2": [126, 546], "fusenodestartwithdeconv2d": [126, 546], "fusedinstancenorm": [127, 547], "fusenodestartwithfusedinstancenorm": [127, 547], "batchmatmul": [128, 548], "batchmatmulv2": [128, 548], "fusenodestartwithmatmul": [128, 137, 548, 557], "avgpool": [129, 138, 549, 558, 689], "fusenodestartwithpool": [129, 138, 549, 558], "optimizeqdqgraph": [131, 551], "input_graph": [131, 136, 143, 423, 427, 551, 556, 560, 659], "op_wise_sequ": [131, 136, 551, 556], "quantizegraph": [132, 552], "quantizegraphbas": [132, 552], "quantizenodebas": [132, 552], "quantizegraphforintel": [136, 556], "common": [139, 156, 158, 195, 232, 262, 312, 322, 326, 327, 328, 365, 398, 400, 466, 468, 469, 470, 472, 559, 583, 584, 627, 628, 629, 632, 641, 653, 678, 680, 684, 685, 687, 691, 693, 697, 740, 746], "herlper": [139, 559], "quantizegraphhelp": [139, 559], "sever": [139, 221, 264, 305, 347, 349, 559, 656, 682, 683, 684, 692, 697, 698, 700, 711, 715, 726, 737, 739, 741, 746, 748, 749, 751], "staticmethod": [139, 559], "function": [139, 140, 156, 170, 185, 211, 212, 217, 231, 232, 235, 236, 248, 278, 279, 291, 323, 326, 335, 340, 389, 450, 559, 584, 654, 655, 656, 659, 660, 661, 676, 679, 683, 684, 687, 691, 692, 693, 695, 696, 697, 698, 709, 719, 725, 726, 737, 740, 743, 744, 745, 746, 747, 749, 750], "smoothquantcalibr": [140, 450], "dataset": [140, 141, 165, 172, 219, 235, 236, 237, 239, 240, 243, 244, 245, 246, 258, 267, 278, 279, 280, 282, 283, 286, 287, 288, 289, 301, 312, 316, 317, 318, 320, 349, 365, 369, 370, 371, 373, 374, 428, 450, 453, 567, 603, 619, 638, 641, 656, 658, 659, 660, 679, 685, 690, 696, 697, 706, 720, 721, 731, 737, 740, 743, 744, 746, 749, 751, 752], "outlier": [140, 450, 660, 677, 682, 723, 743, 746], "smoothquantcalibrationllm": [140, 450], "model_path": [140, 148, 172, 450, 565, 605, 629, 682, 731], "temp_path": [140, 450], "weight_name_map": [140, 450], "llm": [140, 141, 152, 218, 450, 453, 605, 700, 737, 738, 741, 743, 746], "eval_func": [140, 235, 236, 278, 279, 349, 350, 352, 355, 356, 358, 374, 428, 429, 430, 432, 433, 437, 438, 440, 447, 450, 638, 655, 679, 680, 682, 683, 684, 685, 697, 721, 740, 741, 742, 743, 749, 751], "temporari": [140, 165, 450, 598, 649, 653], "store": [140, 196, 198, 200, 203, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 222, 231, 232, 249, 292, 338, 345, 450, 691], "median": [140, 450], "autotrack": [140, 148, 450, 565], "smoothquantscal": [141, 453], "alpha": [141, 157, 161, 176, 198, 220, 400, 453, 470, 598, 615, 678, 740, 749], "scales_per_op": [141, 400, 453, 470], "individu": [141, 205, 343, 422, 427, 453, 653, 726, 737, 746], "smoothquantscalerllm": [141, 453], "tensorflowqdqtoonnxqdqconvert": 142, "shape_overrid": 142, "inputs_as_nchw": [142, 309], "default_opset_vers": 142, "bia": [143, 231, 232, 560, 743, 747], "correct": [143, 177, 223, 231, 232, 316, 317, 318, 320, 344, 369, 370, 371, 373, 560, 653, 701], "biascorrect": [143, 560], "fp32_graph": [143, 560], "weight_empir": [143, 560], "Will": [143, 560, 683, 692], "our": [143, 165, 231, 232, 399, 560, 598, 656, 658, 687, 697, 700, 719, 720, 723, 745, 750], "task": [143, 247, 254, 290, 297, 320, 373, 560, 680, 683, 684, 687, 692, 696, 697, 721, 725, 728, 737, 741, 743, 746, 752], "close": [143, 177, 560, 677, 727], "w_int8": [143, 177, 560], "u": [143, 177, 560, 701, 720, 725], "w_fp32": [143, 177, 560], "varianc": [143, 177, 199, 560, 682], "differ": [143, 173, 177, 179, 182, 189, 195, 214, 231, 232, 240, 249, 264, 266, 283, 292, 305, 311, 320, 326, 328, 337, 348, 373, 382, 384, 560, 570, 643, 653, 655, 656, 660, 679, 680, 682, 683, 685, 686, 691, 692, 696, 697, 699, 711, 715, 720, 723, 726, 735, 737, 740, 743, 746, 747, 748, 749], "wise": [143, 155, 157, 159, 172, 177, 231, 232, 352, 355, 392, 394, 432, 433, 437, 560, 582, 585, 591, 658, 660, 692, 723, 737, 743, 746, 747, 749, 750, 751], "minim": [143, 177, 352, 432, 560, 660, 661, 677, 683, 686, 696, 697, 711, 715, 737, 740, 749], "scale_c": [143, 177, 560], "shift": [143, 177, 260, 302, 560, 719, 748], "notic": [143, 177, 265, 560, 694, 698, 721, 744], "first": [143, 158, 165, 177, 179, 204, 229, 231, 232, 247, 290, 316, 362, 369, 433, 444, 560, 572, 583, 619, 649, 655, 656, 658, 659, 660, 661, 680, 682, 693, 698, 700, 703, 712, 713, 716, 719, 721, 722, 723, 739, 740, 742, 743, 745, 746, 747, 749, 751], "empir": [143, 177, 560], "solut": [143, 177, 560, 658, 659, 660, 688, 703, 707, 712, 738, 743, 744, 746, 749, 750], "don": [143, 177, 205, 231, 232, 560, 655, 724, 737, 749], "min": [143, 172, 177, 196, 232, 400, 560, 572, 619, 649, 682, 700, 721, 723, 737, 740, 743, 746, 748, 749], "graphtransform": [144, 561], "graphtransformbas": [144, 561], "input_pb": [144, 146, 147, 561, 563, 564], "log": [146, 178, 185, 203, 411, 412, 416, 563, 603, 645, 655, 709, 731, 732, 733, 745, 747, 749], "insertlog": [146, 563], "node_name_list": [146, 563], "show_nam": [146, 563], "show_op": [146, 563], "first_n": [146, 563], "summar": [146, 563, 678, 683], "1024": [146, 249, 292, 563, 704], "dump_fp32": [146, 563], "rerang": [147, 564], "rerangequantizedconcat": [147, 564], "rerange_quant": [147, 564], "version1_lt_version2": [148, 572, 649], "version1": [148, 572, 649], "version2": [148, 572, 649], "version1_gt_version2": [148, 572, 649], "greater": [148, 572, 649, 731, 737, 749], "version1_eq_version2": [148, 572, 649], "version1_gte_version2": [148, 572, 649], "version1_lte_version2": [148, 572, 649], "disable_random": [148, 572], "seed": [148, 172, 187, 195, 231, 232, 328, 572, 603, 649, 697, 751], "disabl": [148, 231, 232, 572, 653, 718, 723, 742, 743, 746], "read_graph": [148, 565], "in_graph": [148, 565], "in_graph_is_binari": [148, 565], "write_graph": [148, 565], "out_graph_def": [148, 565], "out_graph_fil": [148, 565], "write": [148, 256, 299, 565, 649, 685, 691, 697, 701, 747], "is_ckpt_format": [148, 565], "ckpt": [148, 374, 382, 428, 565, 570, 752], "folder": [148, 249, 254, 292, 297, 374, 428, 565, 648, 680, 706, 711, 715, 724, 731, 732, 733, 743, 747], "is_saved_model_format": [148, 565], "saved_model": [148, 322, 565, 741], "get_estimator_graph": [148, 565], "estim": [148, 320, 373, 382, 565, 570, 749], "input_fn": [148, 382, 565, 570], "get_tensor_by_nam": [148, 565], "try_cnt": [148, 565], "import": [148, 178, 180, 187, 196, 231, 232, 322, 374, 384, 428, 447, 565, 572, 638, 649, 655, 656, 658, 661, 676, 679, 680, 682, 683, 684, 685, 687, 690, 696, 697, 698, 699, 700, 701, 705, 707, 720, 721, 729, 735, 736, 737, 739, 740, 741, 742, 744, 745, 746, 747, 748, 749, 750], "scope": [148, 565, 654, 660, 697], "onc": [148, 158, 191, 221, 271, 347, 351, 429, 431, 565, 583, 660, 661, 679, 718, 724, 737, 738, 749, 752], "both": [148, 232, 565, 653, 656, 659, 684, 697, 702, 721, 723, 725, 737, 739, 740, 743, 746, 749], "compat": [148, 382, 565, 570, 654, 685, 699, 713, 716, 718, 737, 744], "v1": [148, 259, 260, 302, 317, 318, 320, 370, 371, 373, 382, 565, 570, 685, 687, 688, 696, 699, 722, 737, 744, 745, 746, 752], "suffix": [148, 565], "time": [148, 158, 187, 199, 231, 232, 264, 305, 320, 352, 373, 384, 432, 565, 572, 583, 613, 649, 660, 679, 682, 685, 688, 697, 706, 708, 711, 715, 718, 719, 724, 727, 731, 732, 735, 737, 738, 740, 743, 745, 746, 747, 748, 749], "got": [148, 565, 660, 688, 747], "iterator_sess_run": [148, 565], "sess": [148, 382, 565, 570], "iter_op": [148, 565], "feed_dict": [148, 246, 289, 565], "output_tensor": [148, 382, 565, 570], "measur": [148, 265, 374, 565, 643, 656, 659, 676, 682, 683, 696, 697, 743, 747, 749], "integr": [148, 189, 266, 565, 659, 697, 719, 720, 725, 743], "makeiter": [148, 565], "feed": [148, 246, 289, 565, 603, 683, 737], "end": [148, 210, 211, 212, 217, 231, 232, 247, 263, 264, 290, 304, 305, 345, 351, 429, 431, 565, 659, 660, 661, 683, 684, 689, 693, 697, 712, 728, 735, 737, 747, 748, 749], "predict": [148, 264, 269, 305, 313, 317, 318, 320, 366, 370, 371, 373, 428, 565, 656, 683, 696, 709, 743, 746, 747, 748], "pred": [148, 320, 373, 565, 696], "collate_tf_pr": [148, 565], "collat": [148, 165, 565], "get_input_output_node_nam": [148, 565], "fix_ref_type_of_graph_def": [148, 565], "fix": [148, 215, 217, 247, 290, 345, 565, 679, 680, 705, 737, 740, 743, 749], "strip_unused_lib": [148, 565], "offici": [148, 313, 317, 318, 366, 370, 371, 565, 653, 746], "r1": [148, 565], "15": [148, 565, 689, 693, 732], "branch": [148, 565, 654], "get_graph_def": [148, 565], "auto_input_output": [148, 565], "get_model_input_shap": [148, 565], "get_tensor_val_from_graph_nod": [148, 565], "graph_node_name_map": [148, 565], "kei": [148, 153, 158, 159, 171, 203, 214, 223, 229, 231, 232, 327, 344, 382, 447, 565, 570, 572, 583, 585, 598, 619, 639, 641, 649, 658, 660, 720, 721, 727, 738, 743, 747, 749], "val": [148, 223, 249, 252, 292, 295, 344, 565, 682, 697, 723], "tensor_v": [148, 565], "int8_node_name_revers": [148, 565], "revers": [148, 565, 721], "tf_diagnosis_help": 148, "fp32_model": [148, 153, 165, 310, 649, 659, 741, 743], "quan_model": 148, "save_path": [148, 309, 310, 659, 699], "diagnosi": [148, 231, 232, 697, 721, 722, 723, 738, 744, 750], "generate_feed_dict": [148, 565], "input_tensor": [148, 199, 382, 565, 570], "get_weight_from_input_tensor": [148, 565], "input_tensor_nam": [148, 382, 565, 570], "associ": [148, 158, 316, 369, 565, 583], "search": [148, 152, 172, 195, 196, 203, 217, 228, 232, 235, 236, 278, 279, 311, 313, 323, 326, 327, 328, 348, 352, 366, 391, 432, 565, 593, 605, 619, 649, 658, 678, 692, 696, 701, 702, 712, 737, 738, 743, 746, 747, 749, 750], "look": [148, 214, 565, 659, 661, 689, 696, 720, 721, 723, 746, 751], "sq_weight_tensor": [148, 565], "sq_weights_nod": [148, 565], "two": [148, 153, 158, 178, 204, 209, 216, 221, 249, 254, 265, 292, 297, 316, 343, 347, 349, 356, 369, 438, 565, 583, 649, 654, 655, 656, 678, 679, 680, 683, 685, 687, 689, 697, 698, 700, 725, 726, 728, 737, 740, 742, 743, 745, 746, 749, 751], "apply_inlin": [148, 565], "func": [148, 165, 565, 649, 740, 751], "inlin": [148, 565, 701, 706, 709], "definit": [148, 161, 240, 245, 283, 288, 565, 615], "concret": [148, 565, 749], "new_graph_def": [148, 565], "construct_function_from_graph_def": [148, 565], "frozen_func": [148, 565], "rebuild": [148, 565, 702, 711, 715], "reconstruct": [148, 565, 738], "new_func": [148, 565], "parse_saved_model": [148, 565], "output_tensor_nam": [148, 382, 565, 570], "_saved_model": [148, 565], "load": [148, 156, 158, 159, 247, 263, 264, 290, 304, 305, 374, 382, 428, 565, 570, 572, 581, 582, 584, 585, 602, 648, 649, 660, 679, 711, 715, 719, 721, 739, 740, 741, 746], "reconstruct_saved_model": [148, 565], "trackabl": [148, 565], "destin": [148, 308, 322, 565], "actawareweightqu": 150, "example_input": [150, 160, 164, 165, 170, 172, 231, 232, 310, 596, 598, 602, 618, 619, 624, 628, 632, 648, 687], "data_typ": [150, 172, 364, 446], "enable_full_rang": [150, 172, 603, 619, 644, 741, 743], "algo": [150, 182, 386, 455, 456, 641], "torch": [151, 152, 153, 154, 155, 158, 159, 161, 162, 163, 165, 171, 172, 176, 180, 186, 200, 203, 204, 206, 214, 228, 231, 232, 310, 374, 428, 644, 648, 655, 658, 661, 662, 683, 685, 687, 697, 698, 699, 700, 701, 706, 709, 721, 740, 743, 746, 747], "bf16modulewrapp": 151, "bf16modul": 151, "mix": [151, 160, 172, 231, 232, 350, 362, 374, 430, 444, 620, 658, 659, 666, 692, 701, 707, 708, 709, 750], "precis": [151, 160, 172, 231, 232, 235, 236, 278, 279, 311, 318, 320, 321, 348, 350, 362, 371, 373, 374, 384, 430, 433, 444, 456, 586, 588, 620, 649, 658, 659, 660, 666, 676, 677, 684, 685, 689, 692, 700, 701, 707, 708, 709, 738, 739, 740, 743, 746, 749, 750], "mixed_precision_model": 151, "bf16_symbolic_trac": 151, "fx_sub_module_list": 151, "trace": [151, 153, 163, 165, 203, 231, 232, 310, 435, 598, 602, 632, 655, 708, 749], "_description_": [151, 386], "is_leaf": [152, 605], "judg": [152, 605], "nn": [152, 159, 161, 165, 171, 172, 203, 204, 214, 226, 231, 232, 310, 374, 428, 585, 598, 602, 605, 615, 619, 620, 624, 627, 628, 632, 637, 644, 648, 655, 683, 697, 699, 743, 746, 747], "trace_gptq_target_block": [152, 605], "module_typ": [152, 605], "modulelist": [152, 605], "sequenti": [152, 180, 245, 288, 349, 351, 429, 431, 567, 572, 605, 749], "stack": [152, 605, 658], "structur": [152, 204, 215, 216, 231, 232, 345, 363, 445, 605, 649, 692, 717, 719, 722, 731, 737, 738, 740, 747, 750, 752], "critic": [152, 214, 605, 653], "gptq_related_block": [152, 605], "embed": [152, 165, 605, 677, 737], "transformers_pr": [152, 605], "todo": [152, 182, 247, 250, 290, 293, 316, 362, 369, 444, 567, 605], "transformers_nam": [152, 605], "find_lay": [152, 226, 605], "conv1d": [152, 226, 661], "find_layers_nam": [152, 605], "log_quantizable_layers_per_transform": [152, 605], "transformer_block": [152, 605], "maxq": [152, 605], "gptquantiz": [152, 605], "nsampl": [152, 172, 225, 605, 743], "use_max_length": [152, 172, 605, 743], "pad_max_length": [152, 172, 743], "layer_wis": [152, 172, 581, 648, 741], "compress": [152, 312, 335, 340, 365, 384, 605, 638, 644, 651, 658, 666, 683, 692, 697, 718, 720, 735, 736, 737, 738, 740, 746, 750, 752], "pretrain": [152, 605, 644, 701, 707], "url": [152, 249, 292, 605, 654, 694, 729, 730, 737], "arxiv": [152, 198, 199, 217, 218, 225, 345, 605, 629, 658, 677, 700, 737, 738, 743, 746], "org": [152, 198, 199, 217, 218, 225, 316, 345, 369, 605, 629, 655, 682, 693, 713, 716, 737], "2210": [152, 605, 629, 743], "17323": [152, 605, 629, 743], "node_collector": 153, "hook": [153, 188, 192, 214, 273, 274, 335, 340, 641, 683, 684, 697, 737, 746, 747], "record": [153, 165, 189, 192, 247, 248, 249, 255, 266, 273, 290, 291, 292, 298, 619, 649, 680, 723, 743, 745, 747, 749], "hessiantrac": 153, "q_model": [153, 157, 232, 322, 428, 468, 472, 602, 655, 679, 680, 682, 685, 687, 690, 691, 696, 697, 699, 720, 721, 740, 741, 742, 743], "criterion": [153, 188, 190, 191, 197, 198, 205, 210, 211, 212, 214, 217, 218, 222, 231, 232, 268, 271, 312, 365, 683, 684, 697, 737, 740, 746, 749, 751], "yao": 153, "zhewei": 153, "et": [153, 677, 700, 743, 746], "al": [153, 677, 700, 743, 746], "pyhessian": 153, "network": [153, 198, 205, 206, 345, 435, 620, 656, 677, 683, 684, 687, 697, 700, 720, 738, 740, 746, 749], "through": [153, 235, 236, 278, 279, 373, 374, 428, 658, 676, 689, 691, 692, 696, 704, 725, 735, 736, 737, 739, 740, 743], "len": [153, 232, 264, 305, 680, 685, 748], "2020": [153, 700], "ieee": [153, 698, 746], "intern": [153, 245, 288, 362, 444, 567, 679, 680, 696, 737], "confer": [153, 737, 746], "big": [153, 682, 743], "dong": 153, "zhen": 153, "hawq": [153, 435, 749], "v2": [153, 435, 679, 685, 687, 688, 693, 695, 707, 744, 746, 749, 750, 752], "advanc": [153, 231, 232, 653, 658, 660, 666, 695, 700, 737, 740, 743, 751], "system": [153, 158, 178, 265, 583, 649, 676, 700, 704, 737, 752], "33": [153, 695, 700, 752], "18518": 153, "18529": 153, "openvinotoolkit": 153, "nncf": 153, "develop": [153, 182, 384, 654, 655, 678, 693, 697, 698, 700, 701, 707, 718, 724, 737, 738, 742, 745], "hessian_trac": 153, "compare_weight": 153, "float_dict": 153, "ani": [153, 158, 182, 316, 318, 361, 369, 371, 398, 422, 427, 443, 447, 469, 573, 583, 620, 624, 632, 633, 646, 649, 653, 658, 661, 678, 685, 701, 706, 719, 720, 724, 725, 737, 745, 749], "quantized_dict": 153, "compar": [153, 320, 373, 649, 684, 696, 700, 721, 737, 740, 743, 745, 747, 749], "being": [153, 316, 369, 661, 726], "wt_compare_dict": 153, "float_model": [153, 658], "state_dict": [153, 685, 743, 747], "qmodel": 153, "compute_error": 153, "state": [153, 204, 620, 661, 704, 737], "weight_dict": 153, "hawq_top": 153, "enable_act": 153, "modul": [154, 155, 200, 206, 213, 325, 331, 341, 342, 582, 614, 655, 678, 679, 683, 692, 696, 697, 699, 737, 739, 742, 743, 747, 750], "portabl": [156, 584], "serial": [156, 158, 583, 584], "see": [156, 199, 225, 264, 305, 313, 366, 584, 620, 653, 654, 655, 657, 678, 694, 697, 711, 712, 715, 718, 719, 723, 724, 743, 746, 747, 749], "copyreg": [156, 584], "mechan": [156, 198, 584, 737, 745, 750], "pickler": [156, 584], "pickletool": [156, 584], "comment": [156, 584, 653, 660, 680, 696, 697, 743, 748], "unpickl": [156, 158, 583, 584], "misc": [156, 584, 694], "format_vers": [156, 584], "compatible_format": [156, 584], "except": [156, 158, 447, 583, 584, 649, 678, 724, 740, 741], "pickleerror": [156, 584], "pickl": [156, 158, 583, 584], "picklingerror": [156, 584], "unpicklingerror": [156, 584], "problem": [156, 247, 290, 320, 373, 584, 696, 698, 719], "secur": [156, 584, 658, 720, 738, 753], "violat": [156, 584], "also": [156, 204, 246, 249, 264, 289, 292, 305, 313, 366, 373, 384, 428, 584, 591, 620, 654, 656, 659, 660, 661, 679, 682, 686, 690, 692, 696, 697, 701, 706, 711, 712, 715, 718, 719, 720, 723, 724, 735, 737, 738, 740, 742, 743, 746, 749], "includ": [156, 189, 198, 203, 205, 220, 222, 231, 232, 247, 249, 256, 264, 266, 290, 292, 299, 305, 311, 321, 343, 348, 447, 573, 584, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 620, 637, 649, 653, 659, 660, 661, 679, 680, 682, 693, 694, 695, 696, 697, 701, 704, 707, 712, 724, 728, 731, 732, 733, 737, 740, 742, 743, 747, 749], "necessarili": [156, 584], "limit": [156, 196, 352, 432, 584, 649, 658, 682, 683, 695, 700, 740, 743, 744, 747], "attributeerror": [156, 447, 584], "eoferror": [156, 584], "importerror": [156, 584, 688], "indexerror": [156, 584], "layerwisequ": 157, "pretrained_model_name_or_path": [157, 159, 585], "op_cfg": 157, "output_dir": [157, 644, 697, 706, 707, 722, 723, 729, 732, 733], "5": [157, 176, 180, 189, 199, 231, 232, 251, 260, 266, 294, 302, 320, 373, 400, 428, 470, 659, 680, 687, 689, 693, 696, 697, 723, 728, 731, 732, 737, 739, 740, 743, 746, 748, 749, 751, 752], "order": [157, 165, 180, 199, 313, 314, 349, 352, 355, 364, 366, 367, 392, 432, 437, 446, 655, 682, 696, 721, 739, 743, 746, 747, 749], "memomeri": 157, "f": [158, 200, 583, 678, 683, 685, 740, 743, 746], "file_lik": [158, 583], "map_loc": [158, 583], "pickle_modul": [158, 200, 583], "weights_onli": [158, 583], "pickle_load_arg": [158, 583], "facil": [158, 583], "treat": [158, 583, 679], "storag": [158, 583, 690, 696, 720, 723, 743, 746], "thei": [158, 265, 447, 583, 653, 678, 683, 689, 697, 706, 721, 724, 735], "deseri": [158, 583], "were": [158, 320, 373, 583, 704, 737], "fail": [158, 583, 655, 679, 687, 727], "e": [158, 205, 231, 232, 583, 620, 653, 654, 658, 683, 686, 690, 701, 706, 707, 711, 715, 737, 743, 746, 749], "becaus": [158, 209, 214, 264, 305, 343, 583, 655, 723, 740, 746, 748, 749], "doesn": [158, 264, 305, 583, 659, 685, 697, 698, 719, 751], "certain": [158, 226, 583, 745], "howev": [158, 583, 724, 737, 743, 746], "dynam": [158, 172, 232, 237, 280, 310, 362, 444, 567, 583, 659, 679, 683, 687, 692, 697, 701, 706, 707, 708, 709, 712, 718, 738, 749, 752], "altern": [158, 231, 232, 428, 583], "argument": [158, 172, 232, 398, 447, 583, 593, 607, 632, 656, 682, 722, 723, 726, 729, 731, 732, 733, 743], "callabl": [158, 231, 232, 318, 371, 386, 398, 451, 468, 469, 472, 583, 627, 628, 632, 633, 638, 678, 679], "locat": [158, 173, 223, 264, 305, 583, 685, 704, 711, 715, 718, 726, 740, 744, 748, 751], "resid": [158, 583], "tag": [158, 382, 570, 583, 746, 747], "wa": [158, 231, 232, 583, 659, 697, 700, 723, 724, 727, 738, 749], "builtin": [158, 583, 685], "cuda": [158, 223, 583, 620, 633, 698, 701, 703, 737, 740], "device_id": [158, 583], "either": [158, 180, 232, 316, 369, 583, 702, 706, 726, 736, 739, 740], "final": [158, 203, 210, 223, 345, 583, 660, 697, 704, 735, 737, 740, 744, 749], "alreadi": [158, 178, 249, 263, 265, 292, 304, 583, 659, 680, 692, 713, 716, 720, 729, 749], "right": [158, 260, 302, 316, 369, 583, 653, 654, 655, 718, 724, 746, 748], "otherwis": [158, 249, 264, 292, 305, 583, 649, 653, 660, 680, 713, 716, 739, 743, 748], "fall": [158, 165, 583, 700], "back": [158, 165, 264, 270, 305, 583, 682, 718, 724], "behavior": [158, 583, 653, 659, 660, 661, 689, 699, 743, 747, 749, 751], "wasn": [158, 583], "indic": [158, 179, 188, 199, 231, 232, 240, 245, 247, 283, 288, 290, 306, 316, 327, 369, 391, 392, 394, 567, 583, 633, 655, 679, 688, 721, 726, 747], "appear": [158, 583, 653, 712, 718, 720], "ones": [158, 316, 369, 583, 737], "put": [158, 249, 292, 583, 680, 683], "user": [158, 178, 191, 203, 215, 223, 231, 232, 235, 236, 249, 252, 256, 264, 265, 271, 278, 279, 292, 295, 299, 305, 311, 335, 340, 346, 348, 349, 373, 374, 384, 428, 433, 446, 583, 602, 638, 649, 655, 656, 658, 659, 660, 661, 666, 676, 678, 679, 683, 684, 687, 689, 692, 695, 696, 697, 698, 699, 700, 701, 702, 703, 705, 706, 707, 709, 712, 718, 725, 726, 727, 728, 731, 732, 733, 735, 736, 737, 738, 740, 741, 742, 744, 746, 747, 748, 749, 753], "register_packag": [158, 583], "readlin": [158, 583], "tell": [158, 373, 428, 583, 739], "seek": [158, 583, 743], "o": [158, 447, 583, 678, 693, 703, 721], "pathlik": [158, 583], "metadata": [158, 583], "primit": [158, 583], "keyword": [158, 172, 232, 583], "unless": [158, 583, 689], "implicitli": [158, 182, 583], "known": [158, 267, 352, 432, 583, 697, 700, 737, 740, 747, 749], "insecur": [158, 583, 720], "possibl": [158, 265, 583, 593, 620, 682, 720, 736, 737, 741, 742, 749], "construct": [158, 247, 250, 251, 254, 262, 267, 269, 270, 272, 290, 293, 294, 297, 373, 378, 382, 446, 567, 569, 570, 583, 641, 653, 660, 661, 680, 685, 737, 749], "malici": [158, 583], "arbitrari": [158, 583, 697, 736], "code": [158, 203, 235, 236, 265, 278, 279, 322, 346, 349, 428, 583, 638, 655, 658, 659, 660, 661, 680, 683, 684, 685, 691, 692, 694, 696, 701, 703, 705, 706, 707, 709, 712, 718, 722, 723, 725, 726, 727, 735, 736, 737, 738, 739, 740, 745, 746, 747, 748], "never": [158, 583, 749], "could": [158, 170, 176, 205, 235, 236, 249, 278, 279, 292, 349, 374, 428, 583, 598, 638, 653, 655, 684, 697, 736, 737, 740, 743, 746, 750], "come": [158, 583, 695, 700, 749], "untrust": [158, 583], "unsaf": [158, 583], "tamper": [158, 583], "trust": [158, 583, 682, 720], "load_state_dict": [158, 583], "ram": [158, 583], "surg": [158, 583], "checkpoint": [158, 382, 570, 583, 648, 699], "By": [158, 203, 231, 232, 313, 366, 583, 660, 661, 696, 699, 711, 712, 715, 737, 738, 743, 749], "decod": [158, 259, 260, 302, 313, 366, 583, 696, 748], "byte": [158, 583], "utf": [158, 263, 304, 583], "unicodedecodeerror": [158, 583], "ascii": [158, 583], "codec": [158, 583], "0x": [158, 583], "incorrect": [158, 583], "extra": [158, 318, 371, 583, 697, 743], "encod": [158, 316, 369, 583, 721, 748], "latin1": [158, 583], "them": [158, 203, 247, 290, 583, 655, 661, 679, 682, 687, 689, 691, 721, 724, 736, 737, 743, 749], "keep": [158, 214, 223, 344, 433, 583, 655, 659, 678, 717, 718, 744], "later": [158, 170, 176, 583, 598, 678, 725, 726, 747], "byte_arrai": [158, 583], "xdoctest": [158, 583], "skip": [158, 583, 747, 749], "undefin": [158, 223, 344, 583], "filepath": [158, 583, 649, 678], "pt": [158, 583, 648, 693, 699, 722, 738, 740, 742, 743], "onto": [158, 583], "lambda": [158, 583, 741], "loc": [158, 583], "bytesio": [158, 583], "open": [158, 268, 312, 365, 583, 641, 651, 653, 658, 687, 688, 697, 713, 716, 719, 720, 724, 725, 726, 738], "rb": [158, 583], "buffer": [158, 583], "get_modul": [159, 171, 585, 598, 619], "get_children": [159, 585], "get_named_children": [159, 585], "dowload_hf_model": [159, 585], "repo_id": [159, 585], "cache_dir": [159, 585], "repo_typ": [159, 585], "revis": [159, 585], "download": [159, 249, 292, 585, 680, 682, 693, 723, 729, 744], "hug": [159, 585, 658, 725, 738], "face": [159, 585, 653, 658, 666, 701, 705, 725, 727, 738, 744, 752], "hf": [159, 585, 695, 746, 752], "hub": [159, 585, 658, 686, 690, 709], "load_empty_model": [159, 585, 741], "automodelforcausallm": [159, 585], "empti": [159, 172, 231, 232, 585, 607, 704, 741], "get_super_module_by_nam": [159, 585], "module_nam": [159, 187, 198, 200, 210, 211, 212, 213, 215, 216, 217, 218, 220, 222, 345, 572, 585, 649], "father": [159, 203, 585], "update_modul": [159, 585], "new_modul": [159, 165, 171, 585, 598, 619, 637], "load_layer_wise_quantized_model": [159, 585], "load_tensor_from_shard": [159, 585], "shard": [159, 585], "load_tensor": [159, 585], "ipex_mixed_precis": 160, "fakeaffinetensorquantfunct": [161, 615], "affin": [161, 615, 740], "teqlinearfakequ": [161, 615], "orig_lay": [161, 615], "mullinear": [161, 172, 615], "input_scal": [161, 615], "detector": 162, "transformerbasedmodelblockpatterndetector": [162, 602], "pattern_lst": [162, 602], "block_pattern": [162, 602], "detect": [162, 165, 172, 203, 231, 232, 316, 320, 369, 373, 378, 602, 654, 655, 701, 708, 709, 737, 749], "ffn": [162, 214, 602], "trace_and_fuse_sub_graph": 163, "is_qat": 163, "traced_model": [163, 170, 598], "tequant": [164, 618], "absorb_to_lay": [164, 165, 172, 618, 619], "extra_config": [164, 172], "trainabl": [164, 618, 658, 738, 743], "move_input_devic": 165, "auto": [165, 171, 179, 180, 201, 203, 231, 232, 350, 365, 398, 430, 436, 469, 598, 628, 649, 655, 677, 701, 704, 706, 708, 709, 737, 740, 743], "kind": [165, 697], "forward_wrapp": 165, "get_embedding_contigu": 165, "contigu": 165, "is_fused_modul": 165, "_propagate_qconfig_help": 165, "collate_torch_pr": 165, "collate_result": 165, "input2tupl": 165, "append_attr": 165, "fx_model": 165, "fx_white_list": 165, "append": [165, 349, 352, 432, 655, 684, 697, 736], "graphmodul": [165, 593, 624, 655, 742], "addit": [165, 172, 232, 638, 660, 661, 683, 712, 720, 726, 743, 744, 749], "dir": [165, 247, 290, 644, 648, 680, 688, 691], "generate_activation_observ": [165, 602], "smooth_quant_en": [165, 602], "observ": [165, 602, 632, 661, 743, 745, 747, 749], "what": [165, 210, 245, 288, 373, 428, 602, 638, 653, 738], "check_cfg_and_qconfig": [165, 598, 602], "op_infos_from_cfg": [165, 598, 602], "output_tensor_ids_op_nam": [165, 598, 602], "paser_cfg": 165, "ops_nam": [165, 602], "get_quantizable_ops_from_cfg": [165, 602], "input_tensor_ids_op_nam": [165, 602], "update_sq_scal": [165, 598], "ipex_config_path": [165, 598], "smoothquant_scale_info": [165, 598], "ipex_config": [165, 598], "json": [165, 186, 248, 264, 291, 305, 596, 598, 648, 680, 699, 719, 726, 727, 731, 732, 733, 743, 748], "auto_copi": 165, "fetch_modul": [165, 619, 637], "op_nam": [165, 228, 231, 232, 363, 445, 598, 602, 619, 637, 649, 650, 660, 697, 737, 747], "set_modul": [165, 171, 598, 619, 637], "simple_infer": [165, 602], "get_example_input": [165, 619], "example_inp": [165, 619], "get_fallback_ord": 165, "confidence_batch": [165, 749], "fallback": [165, 232, 355, 356, 435, 437, 438, 687, 698, 721, 742, 749], "requantize_cfg": 165, "confid": 165, "ordered_op": 165, "get_mse_order_per_fp32": 165, "influenc": [165, 737], "last": [165, 171, 198, 223, 231, 232, 598, 679, 698, 701, 703, 708, 712, 740, 743, 746], "fallback_ord": 165, "get_mse_order_per_int8": 165, "get_torch_vers": 165, "match_datatype_pattern": 165, "calculate_quant_min_max": 165, "unsign": [165, 364, 446, 661, 743], "qmin": 165, "qmax": 165, "get_depth": [165, 602], "depth": [165, 602, 683, 742], "get_dict_at_depth": [165, 602], "target_depth": [165, 602], "nest": [165, 229, 572, 602], "get_element_under_depth": [165, 602], "ops_lst": [165, 602], "get_op_type_by_nam": 165, "quantizable_op": [165, 598, 602], "collect_weight_info": 165, "fc": [165, 232, 737], "param": [165, 171, 178, 182, 191, 237, 265, 271, 280, 320, 352, 373, 432, 567, 591, 598, 649, 659, 699, 749], "_type_": [165, 386, 644], "get_module_input_output": [165, 619], "module_hook_config": [165, 619], "input_func": [165, 619], "output_func": [165, 619], "help": [165, 192, 273, 322, 619, 678, 695, 699, 701, 707, 718, 726, 731, 732, 733, 743, 749, 750], "module_name_list": [165, 619], "requir": [165, 172, 231, 232, 238, 349, 382, 427, 570, 619, 620, 655, 659, 660, 676, 677, 679, 682, 684, 685, 689, 697, 698, 699, 702, 712, 718, 720, 725, 726, 729, 732, 733, 737, 740, 743, 744, 745, 746, 747, 749, 751], "fc1": [165, 172, 619], "preprocess": [165, 231, 232, 247, 264, 290, 305, 446, 619, 641, 685, 748], "usag": [165, 179, 180, 182, 246, 289, 316, 322, 349, 369, 405, 447, 572, 619, 633, 637, 660, 680, 685, 686, 701, 709, 720, 726, 731, 732, 733, 735, 739, 743, 748], "input_valu": [165, 619], "output_valu": [165, 619], "total_valu": [165, 619], "get_absorb_lay": [165, 619], "supported_lay": [165, 605, 619], "no_absorb_lay": [165, 619], "allow": [165, 352, 432, 619, 620, 683, 685, 696, 697, 698, 720, 725, 737, 739, 743, 746, 749, 751], "absorpt": [165, 619], "eg": [165, 229, 249, 292, 572, 619, 680, 739], "absorb": [165, 170, 172, 176, 598, 619, 743], "absorbed_1": [165, 619], "xx": [165, 619], "get_block_prefix": [165, 619], "block_list": [165, 619], "block_num": [165, 619], "block_prefix": [165, 619], "get_hidden_st": 165, "calib": [165, 660], "rest": [165, 619, 725, 726, 731, 732, 733], "part": [165, 201, 210, 343, 345, 619, 655, 693, 698, 713, 716, 726, 728, 737, 741, 746, 750], "total_block_kwarg": 165, "total_block_arg": 165, "torchsmoothqu": [170, 598, 746], "q_func": [170, 235, 236, 278, 279, 350, 352, 355, 356, 358, 429, 430, 432, 433, 437, 438, 440, 598, 659, 660, 697, 749], "whose": [170, 176, 205, 344, 382, 570, 598, 691, 746, 749], "reshape_in_channel_to_last": [171, 598], "layer_nam": [171, 172, 227, 232, 598, 737], "dim": [171, 264, 305, 598, 746, 748], "reshape_scale_as_input": [171, 598], "featur": [171, 231, 232, 247, 248, 260, 264, 290, 291, 302, 305, 598, 654, 658, 676, 679, 681, 683, 697, 698, 699, 701, 705, 706, 709, 718, 720, 724, 737, 738, 744, 748], "reshape_scale_as_weight": [171, 598], "depthwis": [171, 598], "orig": [171, 598], "register_autotun": [171, 598], "quantize_4bit": [172, 619], "quantil": [172, 619, 749], "nf4": [172, 619, 658, 743], "return_int": [172, 619, 743], "fp4": [172, 619, 658, 700, 743], "q_tensor": [172, 619], "qdq_weight_asym": [172, 619], "choos": [172, 249, 292, 619, 644, 692, 706, 738, 744, 746, 749, 751], "qdq_weight_sym": [172, 619], "full_rang": [172, 619], "rang": [172, 250, 251, 264, 293, 294, 305, 391, 405, 447, 567, 619, 638, 644, 658, 659, 661, 677, 680, 682, 683, 684, 685, 697, 700, 721, 723, 736, 737, 740, 743, 746, 748], "amax": [172, 619, 700], "qdq_weight_actor": [172, 619], "select": [172, 220, 223, 232, 247, 290, 619, 644, 655, 656, 677, 692, 693, 718, 737, 740, 743, 747, 749], "quant_weight": 172, "place": [172, 598, 619, 632, 684, 693, 731, 737, 747, 749], "search_clip": [172, 619], "best": [172, 188, 264, 305, 306, 311, 348, 355, 391, 437, 619, 653, 656, 658, 678, 693, 701, 707, 718, 724, 735, 740, 743, 746, 748, 749], "num": [172, 619, 649], "best_clip_ratio": [172, 619], "group_dim": [172, 629, 743], "gptq_perm": 172, "perm": [172, 264, 305, 748], "int32": [172, 644, 680, 743], "absorb_lay": 172, "absorb_dict": 172, "absorbed_lay": 172, "fc3": 172, "n_block": [172, 603, 743], "oom": 172, "teq_quant": 172, "quant_weight_w_scal": [172, 619], "autoround_quant": 172, "token": [172, 247, 258, 261, 264, 290, 301, 303, 305, 312, 313, 314, 365, 366, 367, 603, 644, 658, 680, 696, 697, 720, 721, 743, 745, 746, 748, 749], "batch_siz": [172, 232, 237, 239, 243, 244, 245, 246, 247, 248, 267, 280, 282, 286, 287, 288, 289, 290, 291, 310, 567, 603, 656, 679, 680, 685, 687, 691, 697, 701, 740], "lr_schedul": [172, 603, 697, 737], "dataset_nam": [172, 603, 722], "neelnanda": [172, 603], "pile": [172, 603], "10k": [172, 603, 686, 690], "dataset_split": [172, 603], "use_quant_input": [172, 603], "enable_minmax_tun": [172, 603], "lr": [172, 231, 232, 603, 683, 685, 697], "minmax_lr": [172, 603], "low_gpu_mem_usag": [172, 603], "200": [172, 263, 304, 603, 655, 727, 749], "seqlen": [172, 603, 658], "512": [172, 603], "sampler": [172, 180, 237, 239, 241, 243, 244, 246, 267, 280, 282, 284, 286, 287, 289, 301, 312, 361, 443, 567, 603, 679, 685], "rand": [172, 603, 701, 746], "42": [172, 195, 232, 328, 603, 695, 752], "gradient_accumulate_step": [172, 603], "not_use_best_ms": [172, 603], "dynamic_max_gap": [172, 603], "scale_dtyp": [172, 603, 644, 743], "autoround": [172, 658, 695], "pytorch": [172, 189, 191, 192, 200, 203, 206, 209, 210, 213, 218, 219, 226, 231, 232, 246, 247, 249, 252, 256, 264, 266, 271, 273, 289, 290, 292, 295, 299, 305, 310, 311, 320, 321, 341, 343, 346, 348, 356, 365, 373, 374, 383, 428, 438, 591, 637, 642, 649, 654, 655, 656, 658, 659, 660, 661, 677, 678, 679, 683, 684, 686, 689, 692, 693, 695, 697, 698, 699, 700, 701, 703, 706, 707, 708, 709, 718, 720, 729, 732, 733, 737, 738, 739, 743, 744, 746, 749, 751], "temporarili": [172, 653], "mandatori": [172, 235, 236, 278, 279, 428, 697, 751], "layer1": [172, 203, 231, 232, 697, 737, 740], "automat": [172, 201, 203, 204, 231, 232, 249, 252, 259, 260, 292, 295, 302, 311, 321, 348, 655, 658, 676, 680, 692, 697, 698, 701, 703, 706, 707, 709, 711, 712, 713, 715, 716, 718, 725, 728, 736, 737, 740, 746, 748, 749], "learn": [172, 658, 659, 660, 679, 680, 687, 691, 692, 693, 697, 698, 700, 701, 703, 706, 707, 709, 712, 713, 716, 718, 737, 738, 740, 746, 747, 749, 750], "rate": [172, 697, 737, 740], "schedul": [172, 197, 200, 210, 211, 212, 217, 218, 220, 231, 232, 312, 341, 345, 365, 697, 725, 726, 728, 736], "futur": [172, 176, 180, 235, 236, 267, 278, 279, 692, 695, 697, 709, 731, 732, 733, 750], "005": [172, 743], "length": [172, 214, 231, 232, 247, 264, 290, 305, 316, 369, 680, 696, 738, 740, 743, 748], "gradient": [172, 198, 329, 658, 692, 697, 737, 738, 752], "accumul": [172, 361, 443, 700, 749], "step": [172, 198, 209, 210, 211, 212, 216, 217, 221, 231, 232, 343, 345, 347, 638, 660, 661, 682, 683, 684, 685, 697, 713, 716, 718, 731, 732, 733, 736, 737, 739, 742, 743, 745, 746, 747, 749], "squar": [172, 320, 355, 373, 437, 682, 696, 723, 749], "gap": [172, 682, 699], "algorithm_registri": 173, "algorithm_typ": 173, "registr": [173, 249, 256, 264, 292, 299, 305, 338], "algorithmschedul": 173, "conf": [173, 178, 188, 232, 235, 236, 265, 278, 279, 322, 329, 330, 332, 333, 334, 335, 340, 350, 352, 355, 356, 358, 362, 374, 384, 428, 429, 430, 432, 433, 437, 438, 440, 444, 447, 638, 655, 656, 658, 661, 676, 683, 690, 691, 697, 698, 699, 720, 722, 723, 736, 740, 741, 742, 743, 745, 746, 749], "control": [173, 231, 232, 655, 697, 724, 737, 749], "phase": [173, 637, 656, 697, 737, 740, 742, 749], "fastbiascorrect": [174, 177], "fast_bias_correct": [175, 231, 232, 365, 740], "weight_correct": [175, 231, 232, 365, 740], "weightcorrect": 177, "1e": [177, 746, 751], "05": [177, 232, 320, 373, 400, 696, 746, 752], "evalu": [178, 180, 188, 205, 231, 235, 236, 247, 265, 278, 279, 290, 306, 313, 316, 317, 318, 320, 322, 366, 369, 370, 371, 373, 374, 384, 398, 428, 638, 641, 656, 659, 660, 678, 680, 683, 684, 691, 692, 695, 696, 697, 698, 701, 707, 709, 712, 718, 735, 737, 740, 745, 746, 747, 749, 751], "set_env_var": [178, 265], "env_var": [178, 265], "overwrite_exist": [178, 265], "env": [178, 265, 688, 731, 732, 733], "set_all_env_var": [178, 265], "physic": [178, 265, 653, 676, 726], "core": [178, 231, 232, 265, 390, 654, 676, 694, 711, 715, 726, 752], "get_architectur": [178, 265], "architectur": [178, 265, 323, 326, 658, 676, 683, 697, 725, 737, 738, 743, 750], "get_threads_per_cor": [178, 265], "thread": [178, 231, 232, 265, 422, 427, 620, 679, 728], "get_thread": [178, 265], "get_physical_id": [178, 265], "socket": [178, 265, 649, 726, 728, 752], "get_core_id": [178, 265], "id": [178, 263, 265, 304, 313, 315, 316, 317, 318, 366, 368, 369, 370, 371, 658, 696, 726, 727, 731, 732, 733, 745, 749], "get_bounded_thread": [178, 265], "core_id": [178, 265], "bind": [178, 265], "run_inst": 178, "b_dataload": [178, 231, 232, 676, 697], "b_func": [178, 676], "benchmarkconfig": [178, 231, 232, 676, 682, 697], "goal": [178, 306, 311, 335, 340, 348, 374, 428, 660, 679, 736, 740, 749], "prefer": [178, 311, 348, 428, 737, 743], "space": [178, 195, 196, 211, 212, 217, 218, 231, 232, 235, 236, 278, 279, 311, 318, 323, 326, 327, 328, 348, 352, 355, 362, 371, 374, 428, 432, 437, 444, 653, 654, 656, 659, 660, 661, 678, 737, 740, 746, 751], "etc": [178, 188, 263, 304, 306, 311, 318, 335, 340, 348, 371, 374, 428, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 648, 658, 683, 692, 720, 724, 737, 745, 749], "generate_prefix": 178, "core_list": 178, "command": [178, 265, 638, 682, 685, 701, 703, 706, 711, 715, 719, 720, 722, 723, 724, 726], "numactl": [178, 688, 704, 712], "call_on": 178, "cmd": 178, "log_fil": [178, 421, 426], "window": [178, 676, 693, 718, 719], "config_inst": 178, "raw_cmd": 178, "multi": [178, 201, 203, 214, 316, 369, 373, 428, 656, 679, 680, 692, 697, 735, 737, 740, 749], "trigger": [178, 210, 345], "summary_benchmark": 178, "summari": [178, 638, 682, 713, 716, 747, 752], "profil": [178, 232, 365], "benchmark_with_raw_cmd": 178, "fit_with_raw_cmd": 178, "cores_per_inst": [178, 231, 232, 676, 697, 739], "num_of_inst": [178, 231, 232, 676, 697, 739], "test": [178, 231, 232, 264, 305, 654, 658, 682, 693, 726, 731, 752], "fit": [178, 205, 231, 232, 352, 374, 428, 432, 447, 638, 655, 658, 676, 679, 680, 682, 685, 690, 691, 696, 697, 698, 699, 720, 721, 737, 740, 741, 742, 743], "pb": [178, 231, 232, 374, 382, 428, 570, 676, 685, 690, 697, 699, 720, 723, 731, 747, 752], "eval_dataload": [178, 231, 232, 235, 236, 278, 279, 349, 350, 352, 355, 356, 358, 374, 428, 429, 430, 432, 433, 437, 438, 440, 638, 676, 691, 696, 697, 720, 740, 741, 749], "register_config": [179, 678], "framework_nam": [179, 678], "algo_nam": [179, 678], "prioriti": [179, 633, 678, 729], "examplealgorithm": 179, "examplealgorithmconfig": 179, "larger": [179, 633, 660, 737, 743, 746], "higher": [179, 231, 232, 235, 236, 278, 279, 327, 374, 428, 633, 638, 655, 682, 683, 687, 696, 721, 737, 740, 745], "tri": [179, 232, 678, 749], "stage": [179, 351, 356, 429, 431, 438, 683, 737, 747, 749], "baseconfig": [179, 180, 182, 466, 468, 472, 632, 678], "white_list": [179, 400, 466, 470, 629], "op_name_or_module_typ": [179, 400, 466, 470, 629], "default_white_list": [179, 400, 466, 470, 629], "composableconfig": [179, 678], "register_supported_configs_for_fwk": 179, "fwk_name": [179, 678], "deprec": [180, 678, 713, 716, 744, 748], "eval_acc": 180, "eval_perf": 180, "mold": 180, "user_eval_fns1": 180, "user_eval_fns2": 180, "eval_fn": [180, 398, 469, 628], "user_eval_fns3": 180, "user_eval_fns4": 180, "sequentialsampl": [180, 245, 288, 567], "config_sourc": 180, "alwai": [180, 269, 316, 369, 373, 428, 682, 696, 697, 723, 743], "_configset": 180, "tuningconfig": [180, 398, 469, 628], "config_set": [180, 398], "base_config": [180, 466, 468, 470, 472, 632], "default_sampl": 180, "tolerable_loss": [180, 231, 232, 697, 749], "max_trial": [180, 231, 232, 697, 749], "pipelin": [180, 188, 306, 323, 324, 349, 654, 684, 697, 736], "tune_config": [180, 398, 469, 628, 660], "config1": 180, "config2": 180, "stop": [180, 231, 232, 697, 749, 750, 751], "met": [180, 656, 689, 740, 747], "trial": [180, 749], "reach": [180, 205, 221, 231, 232, 347, 654, 679, 720, 737, 749], "metric": [180, 188, 231, 232, 235, 236, 268, 278, 279, 306, 311, 312, 327, 335, 340, 348, 349, 365, 374, 428, 638, 641, 656, 659, 660, 680, 682, 685, 697, 698, 720, 740, 745, 746, 747, 749, 750, 751, 752], "toler": [180, 723], "relative_loss": 180, "fp32_baselin": [180, 641, 659], "eval_result_of_q_model": 180, "paramlevel": 182, "enumer": [182, 183, 327, 591, 638, 659, 683, 684, 685, 697, 700, 736, 737, 747], "deriv": [182, 183, 188, 198, 207, 208, 209, 215, 216, 217, 218, 219, 220, 221, 222, 306, 343, 345, 347, 591], "tuningparam": 182, "default_v": 182, "tunable_typ": 182, "op_level": 182, "tunabl": 182, "fakealgoconfig": 182, "params_list": [182, 398], "simpl": [182, 264, 305, 693, 697, 737, 745, 746, 749], "give": [182, 660, 718, 749], "enough": [182, 740], "simple_attr": 182, "complex": [182, 678, 697, 698, 737], "explicitli": [182, 231, 232, 691, 737], "complex_attr": 182, "model_attr": 182, "model_level": 182, "explain": [182, 661, 682, 746], "logger": [184, 312, 341, 365, 572, 602, 639, 642, 649], "tuninglogg": 185, "unifi": [185, 311, 348, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 659, 660, 661, 679, 691, 692, 696, 697, 699], "assist": [185, 744], "team": [185, 318, 371, 653, 742], "retriev": [185, 245, 288, 567, 737], "save_config_map": 186, "config_map": 186, "qconfig_file_path": 186, "load_config_map": 186, "config_name_map": 186, "reload": [186, 702, 719, 721, 724], "configregistri": 186, "get_all_config": 186, "lazyimport": [187, 572, 649], "lazi": [187, 572, 649], "till": [187, 572, 649, 749], "cpuinfo": [187, 572, 649], "dump_elapsed_tim": [187, 572, 613, 649, 659], "customized_msg": [187, 572, 613, 649], "elaps": [187, 572, 613, 649], "set_random_se": [187, 231, 232, 649], "set_workspac": [187, 231, 232, 649], "workspac": [187, 231, 232, 648, 649, 699, 726, 731, 732, 733], "set_resume_from": [187, 231, 232, 649], "resume_from": [187, 231, 232, 649], "set_tensorboard": [187, 231, 232, 649], "tensorboard": [187, 231, 232, 641, 649, 659, 697, 721], "compon": [188, 306, 312, 349, 365, 655, 678, 682, 685, 693, 694, 701, 718, 726, 736, 737], "quantizationawaretrainingcallback": 188, "pruningcallback": 188, "distillationcallback": 188, "basecallback": 188, "design": [188, 246, 269, 274, 289, 373, 433, 656, 658, 697, 706, 709, 737, 740, 750], "mainli": [188, 221, 274, 347, 658, 697, 737, 740], "prune": [188, 197, 198, 200, 201, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 220, 221, 222, 223, 231, 232, 274, 275, 312, 329, 330, 332, 333, 334, 338, 340, 341, 343, 344, 345, 347, 349, 365, 649, 658, 685, 686, 689, 690, 692, 736, 738, 750, 751], "distil": [188, 197, 231, 232, 266, 273, 274, 312, 365, 658, 686, 690, 692, 736, 750, 751], "In": [188, 207, 208, 209, 214, 215, 216, 220, 232, 246, 274, 289, 316, 343, 345, 369, 384, 620, 637, 653, 655, 656, 658, 659, 660, 679, 680, 682, 683, 684, 685, 696, 697, 708, 711, 712, 715, 721, 722, 723, 724, 731, 732, 733, 735, 736, 737, 740, 742, 743, 745, 746, 747, 748, 749, 750], "adaptor": [188, 231, 232, 364, 446, 455, 456, 641, 658, 661, 692, 741, 742, 744, 746, 747, 750], "knowledg": [188, 189, 231, 232, 266, 306, 684, 686, 690, 692, 697, 699, 751], "transfer": [188, 254, 297, 306, 680, 683, 684, 697, 746], "teacher": [188, 231, 232, 306, 683, 684, 697, 752], "student": [188, 192, 231, 232, 247, 273, 290, 306, 680, 683, 684, 752], "distillation_conf": [188, 228, 306], "_epoch_ran": [188, 306], "integ": [188, 209, 210, 231, 232, 306, 316, 320, 327, 343, 345, 369, 373, 447, 659, 661, 677, 740, 743, 746, 749], "much": [188, 198, 231, 232, 264, 305, 306, 683, 712, 746, 748], "epoch": [188, 211, 212, 217, 306, 345, 638, 679, 683, 684, 685, 697, 736, 737, 751], "ran": [188, 306], "eval_frequ": [188, 306], "frequenc": [188, 210, 231, 232, 306, 345, 697, 737, 751], "term": [188, 211, 212, 217, 218, 220, 306, 654, 677, 683, 694, 696, 735, 736, 749], "best_scor": [188, 306], "best_model": [188, 306, 648, 743], "found": [188, 306, 658, 678, 683, 695, 698, 706, 723, 727, 746, 749, 752], "critet": [189, 266], "tensorflowcrossentropyloss": [189, 266], "pytorchcrossentropyloss": [189, 266], "tensorflowsparsecategoricalcrossentropi": 189, "tensorflowknowledgedistillationloss": [189, 266], "pytorchknowledgedistillationloss": [189, 266, 697], "pytorchintermediatelayersknowledgedistillationloss": [189, 266], "tensorflowcriterion": [189, 266], "pytorchcriterion": [189, 266], "criterion_registri": [189, 266], "criterion_typ": [189, 266], "registry_criterion": [189, 266], "param_dict": [189, 191, 266, 271], "crossentropyloss": [189, 231, 232, 683, 697], "sparsecategoricalcrossentropyloss": 189, "knowledgedistillationframework": [189, 266], "student_model": [189, 232, 266, 697], "teacher_model": [189, 231, 232, 266, 683, 684, 697], "knowledgedistillationloss": [189, 266, 697, 751], "temperatur": [189, 231, 232, 266, 697, 751], "loss_typ": [189, 195, 231, 232, 266, 697, 751], "ce": [189, 231, 232, 266, 697, 751], "loss_weight": [189, 231, 232, 266, 697, 751], "pytorchknowledgedistillationlosswrapp": [189, 266], "tensorflowknowledgedistillationlosswrapp": 189, "tensorflowknowledgedistillationlossextern": [189, 266], "intermediatelayersknowledgedistillationloss": [189, 266], "layer_map": [189, 232, 266, 683], "add_origin_loss": [189, 232, 266], "pytorchintermediatelayersknowledgedistillationlosswrapp": [189, 266], "selfknowledgedistillationloss": [189, 266], "selfknowledg": [189, 266], "pytorchselfknowledgedistillationloss": 189, "pytorchselfknowledgedistillationlosswrapp": 189, "multipl": [191, 201, 233, 234, 238, 239, 247, 248, 250, 251, 252, 253, 254, 258, 261, 264, 271, 276, 277, 281, 282, 284, 290, 291, 293, 294, 295, 296, 297, 301, 303, 305, 321, 374, 375, 376, 378, 384, 620, 676, 680, 687, 697, 725, 728, 736, 737, 745, 746, 749], "tensorflowoptim": [191, 271], "pytorchoptim": [191, 271], "optimizer_registri": [191, 271], "optimizer_typ": [191, 271], "cross": [191, 271, 320, 373, 691, 749], "tensorflowsgd": [191, 271], "sgd": [191, 231, 232, 271, 683, 697, 739, 751], "tensorflowadamw": [191, 271], "tensorflow_addon": [191, 271], "adamw": [191, 271], "tensorflowadam": 191, "adam": [191, 751], "pytorchsgd": [191, 271], "record_output": [192, 273], "output_process": [192, 273], "get_activ": [192, 273], "hyper": [193, 751], "sa_optim": [193, 197], "simul": [194, 661], "anneal": 194, "register_search": 195, "searcher": [195, 203, 232, 328], "registri": [195, 196, 198, 205, 210, 219, 220, 221, 222, 343, 345, 347, 656], "sure": [195, 205, 210, 219, 221, 343, 345, 347, 676, 720], "search_spac": [195, 228, 232, 323, 326, 327, 328], "gridsearch": [195, 328], "grid": [195, 232, 328, 656, 737], "whole": [195, 328, 661, 720, 740, 752], "exhaust": [195, 232, 312, 328, 354, 365, 436, 739], "randomsearch": [195, 328], "randomli": [195, 264, 305, 328, 352, 432, 656, 746, 748, 749], "bayesianoptimizationsearch": [195, 328], "bayesian": [195, 232, 312, 328, 354, 365, 436, 656, 737, 739], "xgbsearcher": 195, "higher_is_bett": [195, 231, 232, 373, 428, 749, 751], "reg": [195, 197, 200, 211, 212, 217, 218, 232], "min_train_sampl": [195, 232], "10": [195, 231, 232, 249, 292, 352, 432, 658, 676, 680, 687, 693, 695, 697, 720, 721, 737, 739, 748, 749, 752], "xgboost": [195, 737], "searchspac": 196, "factori": [196, 380, 408, 410, 415, 418, 420, 425, 571], "actual": [196, 320, 373, 685], "interv": [196, 216, 737], "continu": [196, 208, 316, 343, 369, 656, 695, 697, 719, 737, 750], "learning_r": [196, 231, 232, 697, 739, 751], "001": [196, 249, 292, 680, 685, 746, 751], "num_train_epoch": [196, 697, 737], "20": [196, 264, 305, 723, 726, 731, 732, 733, 737, 748, 751, 752], "weight_decai": [196, 697, 751], "register_searchspac": 196, "pruner": [196, 197, 312, 329, 330, 331, 332, 333, 335, 340, 341, 343, 346, 365, 697, 737, 751], "basesearchspac": 196, "discretesearchspac": 196, "continuoussearchspac": 196, "hpo": [197, 235, 278, 737], "model_slim": [197, 200, 214], "auto_slim": [197, 200, 202], "pattern_analyz": [197, 200, 202], "weight_slim": [197, 200, 202, 214], "mha": [197, 200, 206, 213, 737], "ninm": [197, 200, 206], "nxm": [197, 200, 206, 216, 231, 232, 339, 343, 737], "basic": [197, 200, 203, 205, 213, 231, 232, 263, 304, 312, 323, 343, 354, 358, 361, 365, 436, 440, 443, 638, 692, 693, 697, 700, 720, 739, 745], "block_mask": [197, 198, 200, 213], "pattern_lock": [197, 200, 213, 231, 232, 312, 331, 365], "retrain_fre": [197, 198, 200, 213, 737], "wanda": [197, 200], "criteria": [197, 200, 231, 232, 311, 335, 340, 343, 345, 348, 655, 718, 746], "tf_criteria": [197, 200], "callback": [197, 335, 340, 638, 641, 655, 697, 736, 737, 740], "register_criterion": [198, 222], "get_criterion": 198, "pruningcriterion": [198, 222], "about": [198, 222, 649, 653, 678, 679, 697, 723, 724, 737, 742, 749, 750, 752], "score": [198, 205, 210, 214, 222, 231, 232, 313, 314, 316, 317, 318, 320, 345, 366, 367, 369, 370, 371, 373, 435, 641, 655, 696, 721, 735, 737, 745, 749], "magnitudecriterion": [198, 222], "magnitud": [198, 222, 231, 232, 312, 320, 331, 365, 373, 692, 737], "criterion_class": [198, 222], "determin": [198, 205, 210, 222, 231, 232, 643, 653, 655, 677, 737, 740], "gradientcriterion": 198, "absolut": [198, 231, 232, 320, 373, 696, 697, 700, 737, 740, 749], "snipcriterion": 198, "snip": [198, 231, 232, 345, 692, 737, 752], "product": [198, 658, 692, 698, 701, 702, 718, 724, 738, 740, 745, 749], "singl": [198, 221, 231, 232, 240, 247, 264, 283, 290, 305, 316, 345, 347, 369, 373, 428, 472, 567, 655, 680, 682, 693, 724, 737, 741, 746], "shot": [198, 217, 218, 221, 274, 345, 347, 656, 692, 697, 737, 738, 743], "connect": [198, 345, 718, 720, 727, 737, 745], "sensit": [198, 329, 345, 692, 737], "1810": [198, 345], "02340": [198, 345], "snipmomentumcriterion": 198, "snip_momentum": [198, 231, 232, 697, 737], "momentum": [198, 345, 692, 697, 737, 751], "preserv": [198, 677, 700, 737, 743], "beta": 198, "blockmaskcriterion": 198, "9": [198, 231, 232, 655, 693, 697, 737, 739, 746, 749, 751, 752], "retrainfreecriterion": 198, "return_reorder_indic": 199, "6": [199, 231, 232, 689, 700, 740, 746, 749, 752], "rel": [199, 231, 232, 384, 697, 721, 739, 749, 751, 752], "posit": [199, 264, 305, 398, 632, 653, 696, 701, 726, 731, 732, 733], "remain": [199, 706], "unchang": 199, "neg": 199, "flip": [199, 260, 264, 302, 305, 748], "initial_metr": 199, "sparsity_ratio": [199, 225], "prune_n": [199, 225], "prune_m": [199, 225], "pow_of_var_regrow": 199, "max_cycle_tim": 199, "without_same_sign": 199, "update_threshold": 199, "power": [199, 683, 697, 700, 712, 738], "cycl": [199, 656], "sign": [199, 364, 446, 654, 658, 661, 677, 720, 738, 740, 743, 745], "paper": [199, 225, 683, 737, 743, 746], "2310": [199, 700], "08915": 199, "pickle_protocol": 200, "_use_new_zipfile_seri": 200, "prepare_prun": [200, 737], "loss_func": [200, 219], "assertionerror": [200, 206, 213, 223, 343, 344, 345, 374], "slim": [201, 202, 203, 316, 369, 380, 382, 570, 571, 699, 737], "round_multipli": 201, "spars": [201, 215, 345, 680, 738], "model_slim_ffn2": 201, "some": [201, 203, 231, 232, 247, 290, 344, 660, 661, 678, 680, 682, 687, 693, 696, 697, 720, 721, 722, 723, 726, 735, 737, 740, 742, 743, 746, 747, 749, 750], "perman": [201, 653, 737], "obtain": [201, 203, 212, 217, 220, 223, 344, 620, 655, 660, 726, 737, 745, 746, 749], "acceler": [201, 633, 658, 683, 697, 701, 709, 718, 721, 725, 737, 738, 742, 743, 746, 749], "directli": [201, 231, 232, 246, 289, 316, 320, 344, 369, 373, 658, 696, 697, 705, 737, 739, 740, 747], "sprase": 201, "model_slim_mha": 201, "parse_auto_slim_config": [201, 737], "ffn2_sparsiti": [201, 737], "mha_spars": [201, 737], "generate_ffn2_pruning_config": 201, "consecut": [201, 203, 204, 737], "generate_mha_pruning_config": 201, "head": [201, 203, 207, 214, 223, 737], "get_attribut": 203, "descent": [203, 658, 738], "get_common_modul": 203, "layer2": [203, 697, 737, 740], "nearest": [203, 264, 305, 400, 629, 743, 748], "print_iter": 203, "recipesearch": 203, "root": [203, 247, 248, 249, 252, 290, 291, 292, 295, 320, 373, 680, 685, 696, 697, 751], "levelwis": 203, "wai": [203, 248, 249, 252, 291, 292, 295, 382, 570, 633, 656, 661, 679, 680, 682, 696, 697, 701, 704, 719, 720, 724, 725, 726, 736, 737, 740, 743, 746, 749, 751], "huggingfac": [203, 214, 247, 290, 644, 680, 686, 690, 700, 706, 707, 708, 709, 729, 730, 732, 733, 746, 752], "bert": [203, 232, 243, 246, 247, 264, 286, 289, 290, 305, 658, 680, 683, 696, 698, 706, 729, 732, 733, 737, 748, 752], "recipe_sampl": 203, "bertattent": 203, "dens": [203, 221, 231, 232, 347, 721, 737, 752], "searching_result": 203, "jitbasicsearch": 203, "placeholder_shap": 203, "placeholder_dtyp": 203, "jit": [203, 231, 701, 703, 708, 746, 747], "script": [203, 313, 314, 317, 318, 366, 367, 370, 371, 620, 654, 658, 685, 692, 701, 705, 708, 709, 712, 729, 731, 738], "static_graph": 203, "flatten_static_graph": 203, "target_lay": 203, "linear2linearsearch": 203, "target_op_lut": 203, "lookup": 203, "tabl": [203, 214, 649, 661, 682, 687, 700, 721, 723, 752], "current_pattern": 203, "statu": [203, 646, 653, 679, 700, 728, 731, 732, 733, 735, 737], "selfmhasearch": 203, "classifierheadsearch": 203, "classifi": [203, 223, 247, 290, 320, 373, 680, 683], "classifierheadsearchertf": 203, "squeezer": 204, "postcompressionutil": 204, "librari": [204, 268, 312, 365, 422, 651, 658, 693, 697, 698, 703, 712, 718, 738, 740], "relat": [204, 220, 306, 316, 335, 340, 343, 369, 446, 641, 661, 701, 725, 726, 737, 751], "linearcompress": 204, "root_linear": 204, "target_linear": 204, "while": [204, 215, 223, 345, 352, 432, 620, 659, 660, 680, 686, 692, 698, 701, 706, 718, 720, 737, 739, 740, 743, 746], "hidden": [204, 209, 343, 659], "layer_1": 204, "act_fn": 204, "layer_2": 204, "linearcompressioniter": 204, "linear_pattern": 204, "register_pattern": [205, 343], "basepattern": [205, 207, 209], "unit": [205, 343, 654, 726, 737], "4x1": [205, 231, 232, 339, 697, 737, 752], "is_glob": [205, 343], "local": [205, 231, 232, 343, 572, 620, 649, 711, 715, 720, 727, 728, 737, 745], "contrast": [205, 343, 748], "keep_mask_lay": 205, "invalid_lay": 205, "max_sparsity_ratio_per_op": [205, 210, 228, 231, 232, 697, 737], "sparsiti": [205, 207, 208, 210, 211, 212, 215, 217, 218, 221, 223, 231, 232, 345, 347, 649, 658, 680, 692, 697, 750, 752], "min_sparsity_ratio_per_op": [205, 228, 231, 232, 697, 737], "minimum": [205, 231, 232, 661, 677, 682, 697, 700, 709, 737, 746, 749], "target_spars": [205, 228, 231, 232, 697, 737, 739, 751], "pytorchbasepattern": [205, 220], "kerasbasepattern": 205, "get_pattern": [206, 343], "patternmha": 207, "doc": [207, 208, 231, 232, 343, 361, 362, 373, 428, 443, 444, 447, 572, 649, 696, 697, 713, 716, 724], "md": [207, 208, 231, 232, 343, 373, 428], "n": [207, 208, 231, 232, 248, 264, 291, 305, 314, 343, 367, 447, 661, 678, 680, 682, 683, 726, 737, 740, 746, 748], "pytorchpatternninm": 208, "out": [208, 231, 232, 247, 248, 249, 290, 291, 292, 311, 343, 348, 598, 654, 655, 658, 680, 701, 706, 711, 712, 713, 715, 716, 718, 724, 737, 739, 740, 743], "pytorchpatternnxm": 209, "kept": [209, 343], "block_siz": [209, 343, 629, 743], "height": [209, 260, 264, 302, 305, 343, 685, 748, 751], "width": [209, 260, 264, 302, 305, 343, 677, 685, 737, 740, 748, 751], "vertic": [209, 264, 305, 343, 748], "keraspatternnxm": 209, "register_prun": [210, 219, 345], "baseprun": [210, 215, 217, 219], "current_sparsity_ratio": [210, 345], "global_step": [210, 345], "start_step": [210, 228, 231, 232, 345, 697, 737, 739], "end_step": [210, 228, 231, 232, 345, 697, 737, 739], "pruning_frequ": [210, 228, 231, 232, 697, 737], "target_sparsity_ratio": [210, 345], "show": [210, 649, 653, 683, 685, 697, 700, 704, 719, 720, 721, 723, 726, 731, 732, 733, 746, 749, 750], "pytorchbaseprun": [210, 218], "kerasbaseprun": 210, "pytorchbasicprun": 211, "arrang": [211, 212, 217, 218, 248, 249, 252, 291, 292, 295, 680, 737], "proce": [211, 212, 217, 218], "regul": [211, 212, 217, 218], "kerasbasicprun": 211, "pytorchblockmaskprun": 212, "grad": [212, 217], "parse_valid_pruner_typ": 213, "get_prun": [213, 345], "pythonmultiheadattentionprun": 214, "mha_modul": 214, "partial": [214, 737, 740], "qkv": 214, "feedward": 214, "simultan": [214, 701, 725, 736, 739], "qkv_name": 214, "query_layer_nam": 214, "key_layer_nam": 214, "value_layer_nam": 214, "ffn_name": 214, "attention_ffn_nam": 214, "mha_nam": 214, "qkv_modul": 214, "ffn_modul": 214, "mha_compress": 214, "mhacompress": 214, "modifi": [214, 249, 292, 427, 446, 655, 661, 685, 689, 722, 723, 737, 751], "linear_lay": 214, "independ": [214, 422, 427, 661], "4x": [214, 656, 740], "subsequ": [214, 660, 701, 718], "head_mask": 214, "mha_head_s": 214, "similar": [214, 228, 697, 722, 739, 746, 749, 751], "mha_scor": 214, "lock": [215, 333, 334, 692, 736, 737], "pytorchpatternlockprun": 215, "parent": [215, 216, 221, 339, 345, 347, 747], "pytorchprogressiveprun": 216, "basicprun": [216, 219], "interpol": [216, 264, 305, 696, 737, 748], "fine": [216, 247, 290, 678, 680, 704, 737, 738, 740], "grain": [216, 737, 738, 749], "improv": [216, 620, 654, 677, 678, 697, 701, 718, 719, 721, 737, 738, 740, 742, 743, 749, 750, 752], "ad": [216, 247, 290, 313, 352, 366, 392, 432, 660, 661, 682, 698, 701, 706, 709, 713, 716, 726, 737, 743, 747], "retrain": [217, 684], "pytorchretrainfreeprun": 217, "pruner_class": [217, 218], "fast": [217, 231, 232, 737, 738, 743], "retrainfreeprun": [217, 219], "effect": [217, 658, 659, 737, 738], "2204": 217, "09656": 217, "sparsegptprun": [218, 219], "most": [218, 231, 232, 320, 373, 682, 697, 698, 737, 740, 743, 746, 749, 752], "sparsegpt": [218, 219, 737], "massiv": [218, 737], "One": [218, 661, 678, 680, 685, 692, 723, 737, 738, 749], "2301": [218, 737], "00774": [218, 737], "opt": [219, 658, 695, 706, 737, 746, 749, 752], "least": [219, 346, 654, 697, 737, 749], "templat": [219, 346, 697, 737], "tree": [219, 346, 362, 444, 726], "nlp": [219, 231, 232, 346, 706, 722, 737, 740], "huggingface_model": [219, 346, 722], "classif": [219, 247, 264, 290, 305, 320, 346, 373, 683, 687, 696, 707, 721, 729, 732, 733, 737, 738], "pytorch_prun": [219, 312, 365], "eager": [219, 346, 427, 624, 658, 685, 692, 740, 742, 747], "config_file_path": [219, 346], "pruner_info": [219, 346], "pruning_class": 219, "avail": [219, 231, 232, 378, 658, 662, 664, 668, 671, 674, 678, 686, 688, 690, 692, 711, 715, 720, 725, 726, 727, 731, 732, 733, 737, 749, 752], "regular": [220, 313, 344, 366], "register_reg": 220, "regulariz": 220, "get_reg_typ": 220, "get_reg": 220, "basereg": 220, "grouplasso": 220, "coeff": 220, "lasso": [220, 330, 692, 737], "reg_term": 220, "register_schedul": [221, 347], "get_schedul": [221, 347], "pruningschedul": 221, "gradual": [221, 347, 737], "oneshotschedul": [221, 347], "iterativeschedul": [221, 347], "get_tf_criterion": 222, "get_sparsity_ratio": 223, "elementwise_over_matmul_gemm_conv": 223, "elementwise_over_al": 223, "blockwise_over_matmul_gemm_conv": 223, "get_sparsity_ratio_tf": 223, "check_config": [223, 344], "prune_config": [223, 344], "everyth": [223, 344, 706], "reset_none_to_default": 223, "update_param": 223, "process_weight_config": 223, "global_config": [223, 329, 330, 332, 333, 334], "local_config": [223, 231, 232, 329, 330, 332, 333, 334], "default_config": 223, "pruners_info": 223, "process_yaml_config": 223, "check_key_valid": 223, "template_config": 223, "user_config": 223, "process_and_check_config": [223, 344], "process_config": [223, 344], "parse_last_linear": 223, "often": [223, 679, 683, 723, 736, 737], "act": [223, 245, 288, 567, 653], "might": [223, 655, 678, 720, 749], "caus": [223, 660, 679, 702, 721, 723, 737, 743], "drop": [223, 316, 344, 369, 654, 697, 698, 712, 737, 743, 746, 752], "parse_last_linear_tf": 223, "parse_to_prun": [223, 344], "parse_to_prune_tf": 223, "generate_pruner_config": 223, "dotdict": [223, 228, 232, 384, 649], "get_lay": 223, "collect_layer_input": 223, "layer_idx": 223, "layer_input": 223, "previou": [223, 660, 661, 697, 737, 744, 746, 747, 749, 750, 752], "prune_wanda": 225, "use_vari": 225, "low_mem_usag": 225, "dsnot": 225, "sij": 225, "wij": 225, "xj": 225, "2306": [225, 743], "11695": 225, "recurs": [226, 649], "wrappedgpt": 227, "layer_id": 227, "gpt": [227, 658, 695, 722, 737, 746, 752], "prunerv2": 228, "pruning_typ": [228, 231, 232, 697, 737], "pruning_scop": [228, 231, 232, 697, 737], "sparsity_decay_typ": [228, 231, 232, 697, 737], "pruning_op_typ": [228, 231, 232, 697, 737], "reg_typ": 228, "criterion_reduce_typ": 228, "resume_from_pruned_checkpoint": 228, "cfg_fname": 228, "parser": 228, "quantization_conf": 228, "pruning_conf": 228, "graph_optimization_conf": [228, 311], "mixedprecision_conf": 228, "benchmark_conf": 228, "nasconfig": [228, 232, 324, 326, 656], "approach": [228, 231, 232, 323, 324, 326, 655, 656, 658, 677, 680, 683, 692, 697, 706, 718, 721, 729, 731, 732, 733, 737, 738, 739, 741, 743, 749, 751], "search_algorithm": [228, 232, 312, 325, 365, 656], "na": [228, 232, 312, 365, 378, 692, 695, 752], "procedur": [228, 656, 737, 749], "deep_get": [229, 384, 572], "dot": [229, 572, 698, 740], "person": [229, 572, 653, 738], "john": [229, 572], "deep": [229, 572, 658, 659, 660, 679, 692, 693, 697, 698, 700, 701, 703, 706, 707, 709, 712, 718, 738, 740, 749, 750], "deep_set": [229, 384], "sex": [229, 653], "male": 229, "instead": [229, 232, 246, 289, 649, 704, 706, 709, 724, 737, 743], "notat": [229, 232, 649], "pythonic_config": 230, "random_se": [231, 232, 352, 432, 697, 751], "1978": [231, 232], "default_workspac": [231, 232], "directori": [231, 232, 248, 249, 291, 292, 382, 570, 572, 644, 646, 648, 649, 680, 685, 688, 711, 713, 715, 716, 722, 724, 747], "histori": [231, 232, 648, 649, 718, 722, 749], "nc_workspac": [231, 232, 721, 722], "datetim": [231, 232], "now": [231, 232, 264, 305, 655, 656, 661, 680, 685, 709, 739, 748, 749], "strftime": [231, 232], "d_": [231, 232], "resum": [231, 232, 235, 236, 278, 279, 350, 356, 358, 429, 430, 432, 433, 437, 438, 440], "flag": [231, 232, 314, 367, 682], "visual": [231, 232, 658, 709, 718, 745, 747, 749, 750], "displai": [231, 232, 361, 362, 443, 444, 572, 649, 718, 721], "2022": [231, 232, 694, 737, 743, 746], "workspace_path": [231, 232], "accuracycriterion": [231, 232, 697, 749], "accept": [231, 232, 447, 653, 676, 678, 679, 720, 743], "accuracy_criterion": [231, 232, 384, 697, 722, 735, 739, 749, 751], "warmup": [231, 232, 676, 697, 739], "inter_num_of_thread": [231, 232, 422, 427, 697, 739], "intra_num_of_thread": [231, 232, 422, 427, 697, 739], "benchmark": [231, 232, 267, 312, 349, 365, 384, 649, 658, 666, 699, 701, 705, 709, 712, 718, 721, 749, 750, 751, 752], "onnxrt_trt_ep": [231, 232, 698, 740], "onnxrt_cuda_ep": [231, 232, 698, 740], "inter": [231, 232], "intra": [231, 232], "quantizationconfig": 231, "post_training_static_qu": [231, 680, 697, 739, 749], "calibration_sampling_s": [231, 232, 697, 723], "op_type_dict": [231, 232, 658, 661, 739, 740, 743, 749], "op_name_dict": [231, 232, 682, 697, 721, 723, 740, 749], "strategy_kwarg": [231, 232, 745, 749], "timeout": [231, 232, 697, 739, 749, 751], "quant_level": [231, 232, 721, 743, 746, 749], "posttrainingquantconfig": [231, 232, 428, 655, 658, 661, 679, 682, 687, 690, 696, 697, 699, 720, 721, 722, 723, 740, 741, 742, 743, 745, 746, 749], "quantizationawaretrainingconfig": [231, 232, 638, 655, 684, 687, 697, 740, 742, 749], "cv": [231, 232, 737], "object_detect": [231, 232, 316, 369], "recommendation_system": [231, 232], "overrid": [231, 232, 649, 678], "quantiztaion": [231, 232], "smooth_quant_arg": [231, 232, 740, 746], "gemm_to_matmul": [231, 232, 740], "graph_optimization_level": [231, 232, 739, 740], "disable_al": [231, 232, 739], "enable_bas": [231, 232], "enable_extend": [231, 232], "enable_al": [231, 232], "first_conv_or_matmul_quant": [231, 232, 740], "last_conv_or_matmul_quant": [231, 232, 740], "pre_post_process_quant": [231, 232, 740], "postprocess": [231, 232, 258, 261, 264, 268, 305, 312, 365, 373, 428, 641, 659, 697, 747, 748], "dedic": [231, 232], "quant_format": [231, 232, 310, 687, 721], "constraint": [231, 232, 311, 348, 697, 737, 745, 749, 751], "conv1": [231, 232, 740, 751], "tuning_strategi": [231, 232], "guarante": [231, 232, 697], "models": [231, 232, 384, 697, 735, 739], "footprint": [231, 232, 311, 335, 340, 348, 384, 684, 697, 735, 737, 739, 741], "earli": [231, 232, 697, 740, 749, 751], "field": [231, 232, 249, 292, 316, 369, 655, 659, 661, 685, 697, 700, 745, 749, 751], "exit": [231, 232, 351, 429, 431, 603, 697, 726, 731, 732, 733, 751], "excluded_precis": [231, 232, 742], "exclud": [231, 232, 659, 677, 742], "conserv": [231, 232, 365, 436], "use_distributed_tun": 231, "weightpruningconfig": [231, 232, 697, 736, 737], "pruning_config": [231, 232, 697, 737], "98": [231, 232, 697, 737, 739, 752], "exp": [231, 232, 697, 700, 737], "link": [231, 232, 247, 290, 373, 399, 428, 677, 680, 687, 711, 715, 718, 743, 752], "90": [231, 232, 695, 741, 751, 752], "magnitude_progress": [231, 232], "snip_progress": [231, 232], "snip_momentum_progress": [231, 232], "feasibl": [231, 232], "situat": [231, 232, 685, 737], "unstructur": [231, 232, 339, 692, 737, 752], "8x1": [231, 232], "channelx1": [231, 232, 737], "1xchannel": [231, 232, 737], "itrex": [231, 232, 746], "start": [231, 232, 264, 305, 316, 369, 433, 693, 723, 738, 748, 749, 750, 753], "togeth": [231, 232, 264, 305, 683, 693, 705, 738, 747, 748], "sort": [231, 232, 355, 392, 437, 682, 721, 743, 749], "sinc": [231, 232, 311, 313, 335, 340, 348, 366, 683, 687, 693, 696, 712, 718, 723, 736, 743, 744], "lead": [231, 232, 678, 683, 697, 698, 723, 737, 743, 746], "increas": [231, 232, 392, 681, 692, 700, 701, 718, 723, 743, 749], "cube": [231, 232, 737], "update_config": [231, 232], "knowledgedistillationlossconfig": [231, 232, 683, 684, 697, 736], "hyperparamet": [231, 232, 361, 745, 746, 749], "entropi": [231, 232, 677, 749], "groundtruth": [231, 232, 316, 369], "label": [231, 232, 235, 236, 247, 249, 250, 251, 252, 255, 260, 264, 269, 278, 279, 290, 292, 293, 294, 295, 298, 302, 305, 313, 315, 320, 366, 368, 373, 374, 428, 567, 638, 655, 679, 680, 682, 696, 697, 740, 748], "sum": [231, 232, 320, 373, 682, 683], "distillationconfig": [231, 232, 638, 683, 684, 697, 736], "prepare_compress": [231, 232, 638, 655, 683, 684, 697, 736, 737, 740], "criterion_conf": [231, 232], "d_conf": [231, 232, 684, 697, 736], "compression_manag": [231, 232, 638, 655, 683, 684, 697, 736, 737, 740], "distil_loss": [231, 232, 697], "ni_workload_nam": 232, "onnxrt_dnnl_ep": [232, 698, 740], "onnxrt_dml_ep": [232, 740], "tuningcriterion": [232, 697, 735, 745, 749], "tuning_criterion": [232, 697, 735, 745, 749], "npu": [232, 740], "xpu": [232, 620, 709, 740], "ptq": [232, 428, 655, 682, 685, 692, 697, 723, 740, 746, 747, 749], "meet": [232, 238, 349, 351, 429, 431, 655, 660, 735, 738, 739, 740, 743, 747, 749], "mse_v2": [232, 312, 354, 365, 436], "hawq_v2": [232, 365, 436], "docstr": [232, 447], "workload": [232, 646, 649, 720, 738], "insight": [232, 646, 658, 682, 738, 744, 749, 750], "copi": [232, 344, 649, 679, 724], "deepcopi": 232, "model_origin": [232, 428, 742], "qat_op_name_dict": 232, "low_memory_usag": 232, "hpoconfig": 232, "xgb": 232, "bo": 232, "intermediatelayersknowledgedistillationlossconfig": [232, 683], "relationship": [232, 720], "student_layer_nam": 232, "student_layer_output_process": 232, "teacher_layer_nam": 232, "teacher_layer_output_process": 232, "desir": [232, 260, 264, 302, 305, 660, 661, 737, 746, 748], "serv": [232, 382, 570, 620, 726, 731, 732, 733], "numer": [232, 320, 373, 392, 661, 698, 700, 738, 740, 743], "abbrevi": 232, "l1": 232, "selfknowledgedistillationlossconfig": [232, 683, 697], "student1_layer_name1": 232, "teacher_layer_name1": 232, "student2_layer_name1": 232, "student1_layer_name2": 232, "teacher_layer_name2": 232, "student2_layer_name2": 232, "soft": 232, "l2": [232, 737], "hard": [232, 679, 682], "resblock": 232, "deepst": 232, "02": [232, 752], "mixedprecisionconfig": [232, 374, 447, 697, 698], "mixedprecis": [232, 321, 697], "won": [232, 740, 743], "work": [232, 311, 348, 620, 657, 660, 678, 679, 683, 713, 716, 724, 742, 743, 744, 746, 747], "mix_precis": [232, 365, 447, 697, 698], "converted_model": [232, 374, 697, 698], "exportconfig": 232, "14": [232, 309, 310, 658, 687, 693, 733, 752], "dynamic_ax": [232, 310, 687], "qlinear": [232, 249, 256, 292, 299, 320, 373, 659, 708], "ax": [232, 310], "onnxqlinear2qdqconfig": 232, "onnxqlinear2qdq": 232, "torch2onnxconfig": [232, 687], "torch2onnx": [232, 307, 312, 365], "qdq_op_fp32_bia": 232, "qdq_op_int32_bia": 232, "qdq_op_fp32_bias_qdq": 232, "resnet50": [232, 658, 682, 685, 687, 698, 701, 705, 737, 740, 745, 752], "int8_onnx_config": [232, 687], "randn": [232, 687], "224": [232, 260, 302, 658, 680, 685, 687, 690, 697, 701, 720, 748, 751], "tf2onnxconfig": [232, 687], "tf2onnx": [232, 307, 312, 365], "output_graph": 232, "dyna": [232, 312, 325, 365, 656, 692, 739], "sigopt": [233, 234, 276, 277, 312, 365, 738], "tpe": [233, 234, 276, 277, 312, 365], "sigopttunestrategi": [235, 278], "q_dataload": [235, 236, 278, 279, 350, 352, 355, 356, 358, 429, 430, 432, 433, 437, 438, 440, 691, 749], "eval_metr": [235, 236, 374, 428, 429, 430, 432, 433, 437, 438, 440, 638, 696, 720, 740], "q_hook": [235, 236, 278, 279, 350, 352, 355, 356, 358, 429, 430, 432, 433, 437, 438, 440], "yield": [235, 236, 245, 267, 278, 279, 288, 352, 374, 428, 432, 447, 567, 638, 679, 740, 749], "_": [235, 236, 278, 279, 428, 655, 656, 658, 659, 660, 677, 682, 683, 685, 687, 689, 697, 698, 699, 701, 707, 711, 713, 715, 716, 723, 726, 727, 735, 737, 740, 743, 744, 745, 746, 747, 749, 751], "well": [235, 236, 278, 279, 374, 428, 638, 656, 658, 678, 680, 700, 737, 740, 744, 746, 751], "taken": [235, 236, 278, 279, 374, 428, 638, 740], "reserv": [235, 236, 278, 279], "abl": [235, 236, 278, 279, 374, 428, 638, 709, 718, 740], "tuner": [235, 236, 278, 279, 311, 348, 374, 428, 638, 740], "scalar": [235, 236, 278, 279, 374, 428, 638, 696, 740, 749], "pseudo": [235, 236, 278, 279, 428, 638, 743, 747], "someth": [235, 236, 249, 278, 279, 292, 428, 638], "fefin": [236, 279], "tpetunestrategi": [236, 279], "basedatalod": [237, 280, 567], "basedataload": [237, 242, 244, 280, 285, 287, 567], "last_batch": [237, 239, 243, 244, 246, 267, 280, 282, 286, 287, 289, 567, 679], "rollov": [237, 239, 243, 244, 246, 267, 280, 282, 286, 287, 289, 567, 679], "collate_fn": [237, 239, 240, 243, 244, 246, 267, 280, 282, 283, 286, 287, 289, 567, 679, 680], "batch_sampl": [237, 239, 243, 244, 246, 267, 280, 282, 286, 287, 289, 567, 679], "num_work": [237, 239, 243, 244, 246, 267, 280, 282, 286, 287, 289, 567, 679, 697, 740], "pin_memori": [237, 239, 243, 244, 246, 267, 280, 282, 286, 287, 289, 567, 679], "shuffl": [237, 239, 243, 244, 246, 267, 280, 282, 286, 287, 289, 567, 679, 697, 740], "_generate_dataload": [237, 280, 567], "check_dataload": 238, "default_col": [239, 282, 567], "outer": [239, 282, 567], "defaultdataload": [239, 246, 282, 289], "style": [240, 254, 283, 297, 447, 678, 680, 691], "drop_last": [240, 245, 283, 288, 567], "iterablefetch": [240, 283, 567], "indexfetch": [240, 283, 567], "base_dataload": [241, 284, 301, 312], "default_dataload": [241, 284, 301, 312], "fetcher": [241, 284, 301, 312], "mxnet_dataload": [241, 284, 301, 312], "onnxrt_dataload": [241, 284, 301, 312, 421], "pytorch_dataload": [241, 284, 301, 312], "tensorflow_dataload": [241, 284, 301, 312, 426], "mxnetdataload": [242, 285], "onnxrtbertdataload": [243, 286], "variant": [243, 286], "onnxrtdataload": [243, 286, 421], "pytorchdataload": [244, 287], "data_sourc": [245, 288, 641], "__iter__": [245, 249, 288, 292, 679, 680, 697], "matter": [245, 288, 742], "iterablesampl": [245, 288, 567], "squential": [245, 288], "your": [245, 247, 288, 290, 620, 654, 658, 678, 679, 680, 682, 685, 694, 697, 701, 704, 705, 706, 711, 712, 713, 715, 716, 718, 720, 724, 726, 731, 732, 733, 737, 738, 745, 747, 749, 750], "clear": [245, 288, 659, 689, 696, 697], "iterabledataset": [245, 249, 288, 292], "try": [245, 288, 382, 570, 655, 658, 682, 721, 737, 740, 746, 749], "indexdataset": [245, 288], "__getitem__": [245, 249, 264, 288, 292, 305, 679, 680, 697], "__len__": [245, 249, 288, 292, 680], "batchsampl": [245, 288, 567], "tfdatadataload": [246, 289], "tensorflow1": [246, 289], "coupl": [246, 289], "satisfi": [246, 289, 682, 693, 724], "tf1": [246, 289, 699], "although": [246, 289, 745], "tensorflowbertdataload": [246, 289], "tensorflowmodelzoobertdataload": [246, 289], "zoo": [246, 264, 289, 305, 658, 686, 690, 752], "tensorflowdataload": [246, 289, 426], "pytorchbertdataset": [247, 290], "model_typ": [247, 290, 649, 680], "tensordataset": [247, 290, 680], "repo": [247, 290, 652, 654, 680, 686, 711, 713, 715, 716, 753], "easi": [247, 290, 348, 687, 697, 721, 725, 738, 740, 743, 745], "squad": [247, 264, 290, 305, 317, 318, 320, 370, 371, 373, 680, 696, 737, 748, 752], "distilbert": [247, 290, 680, 698, 738, 752], "xlnet": [247, 290, 680], "xlm": [247, 290, 680, 752], "101": [247, 290, 320, 373, 696, 727, 746, 752], "2043": [247, 290], "2001": [247, 290], "onnxrtbertdataset": [247, 290], "data_dir": [247, 290, 680], "model_name_or_path": [247, 290, 680, 697, 706, 707, 722, 729, 732, 733, 741], "max_seq_length": [247, 264, 290, 305, 605, 680, 748], "do_lower_cas": [247, 263, 264, 290, 304, 305, 680, 748], "mrpc": [247, 290, 320, 373, 680, 696, 706, 729, 732, 733, 737, 749, 752], "dynamic_length": [247, 290, 680], "shortcut": [247, 290, 680], "longer": [247, 264, 290, 305, 680, 748], "truncat": [247, 264, 290, 305, 680, 748], "shorter": [247, 264, 290, 305, 680, 748], "lowercas": [247, 290, 680], "choic": [247, 290, 659, 680, 696, 724, 746], "qqp": [247, 290, 680, 696, 752], "qnli": [247, 290, 680, 696, 752], "rte": [247, 290, 680, 696, 752], "st": [247, 290, 680, 696], "cola": [247, 290, 680, 696, 752], "mnli": [247, 290, 680, 696, 752], "wnli": [247, 290, 680, 696], "mobilebert": [247, 290, 680, 683], "roberta": [247, 290, 680, 752], "uncas": [247, 264, 290, 305, 680, 748, 752], "load_and_cache_exampl": [247, 290], "cach": [247, 290, 620, 688, 740, 743], "convert_examples_to_featur": [247, 264, 290, 305], "max_length": [247, 290], "label_list": [247, 290, 320, 373], "output_mod": [247, 290], "pad_token": [247, 290], "pad_token_segment_id": [247, 290], "mask_padding_with_zero": [247, 290], "inputfeatur": [247, 264, 290, 305], "properti": [247, 290, 446, 694], "input_id": [247, 264, 290, 305, 697], "vocabulari": [247, 263, 264, 290, 304, 305, 748], "attention_mask": [247, 290, 697], "usual": [247, 290, 660, 682, 683, 723, 736, 737, 740, 741, 746], "NOT": [247, 290, 689], "token_type_id": [247, 290, 697], "segment": [247, 290, 314, 316, 367, 369, 654], "portion": [247, 290], "regress": [247, 290, 654, 682], "seq_length": [247, 290], "tensorflowbertdataset": [247, 290], "label_fil": [247, 264, 290, 305, 680, 748], "tfrecord": [247, 248, 249, 290, 291, 292, 680], "guid": [247, 290, 655, 658, 678, 680, 683, 693, 701, 709, 718, 753], "parsedecodebert": [247, 290], "tensorflowmodelzoobertdataset": [247, 248, 290, 291], "num_cor": [247, 248, 252, 290, 291, 295, 680], "28": [247, 248, 252, 290, 291, 295, 680, 752], "coco": [248, 255, 259, 291, 298, 316, 320, 369, 373, 696, 737], "parsedecodecoco": [248, 291], "cocorecorddataset": [248, 291], "interleav": [248, 291, 680], "parallel": [248, 291, 422, 427, 620, 680, 697, 725, 728, 749], "cocoraw": [248, 291, 680], "img_dir": [248, 291, 680], "val2017": [248, 291, 680], "anno_dir": [248, 291, 680], "annot": [248, 291, 316, 369, 447, 660, 661, 680, 696, 737, 749], "instances_val2017": [248, 291, 680], "jpg": [248, 252, 254, 291, 295, 297, 658, 680], "imag": [248, 249, 252, 254, 260, 264, 291, 292, 295, 297, 302, 305, 316, 369, 658, 680, 685, 687, 737, 739, 746, 747, 748, 752], "coconpi": [248, 291, 680], "npy_dir": [248, 291, 680], "npy": [248, 291, 680], "tensorflowdataset": [249, 292], "pytorchdataset": [249, 292], "mxnetdataset": [249, 292], "onnxrtqldataset": [249, 292], "onnxrtitdataset": [249, 292], "IT": [249, 256, 292, 299, 738], "pytorchmxnetwrapdataset": [249, 292], "datafunc": [249, 292], "pytorchmxnetwrapfunct": [249, 264, 292, 305], "framework_dataset": [249, 292], "convent": [249, 292, 316, 369, 654, 683, 700], "imageclassifi": [249, 292], "tensorflow_itex": [249, 252, 254, 256, 292, 295, 297, 299, 679, 739], "onnxrt_qdq": [249, 256, 292, 299, 739], "onnxrt_qlinearop": [249, 256, 264, 292, 299, 305, 739], "onnxrt_integerop": [249, 256, 264, 292, 299, 305, 739], "pytorch_ipex": [249, 256, 292, 299, 697, 739, 751], "pytorch_fx": [249, 256, 292, 299, 697, 739], "dataset_registri": [249, 292], "dataset_typ": [249, 292], "dataset_format": [249, 292], "data_format": [249, 260, 292, 302], "raw_imag": [249, 292], "overwrit": [249, 292, 711, 715], "download_url": [249, 292], "filenam": [249, 292, 572, 649, 680, 724], "md5": [249, 292], "address": [249, 292, 653, 678, 698, 720, 723, 726, 738], "gen_bar_updat": [249, 292], "check_integr": [249, 292], "fpath": [249, 292], "checksum": [249, 292], "calculate_md5": [249, 292], "chunk_siz": [249, 292], "cifar10": [249, 292, 680], "cifar100": [249, 292, 680], "databas": [249, 292, 726], "www": [249, 292, 680, 752], "toronto": [249, 292, 680], "kriz": [249, 292, 680], "cifar": [249, 292, 680, 752], "tar": [249, 292, 680, 682, 713, 716], "gz": [249, 292, 680, 682, 713, 716], "manual": [249, 292, 680, 701, 707, 709, 712, 726, 731, 732, 733, 737], "subset": [249, 252, 292, 295, 680, 723], "internet": [249, 292, 680, 720], "again": [249, 292, 680, 721, 723, 742], "pytorchcifar10": [249, 292], "mxnetcifar10": [249, 292], "tensorflowcifar10": [249, 292], "pytorchcifar100": [249, 292], "mxnetcifar100": [249, 292], "tensorflowcifar100": [249, 292], "mnist": [249, 292, 680, 685], "nation": [249, 292, 653], "institut": [249, 292], "standard": [249, 264, 292, 305, 633, 654, 660, 678, 682, 687, 696, 748, 749], "technologi": [249, 292, 695, 697, 700], "fashionmnist": [249, 292, 680], "npz": [249, 292, 680], "idx1": [249, 292, 680], "ubyt": [249, 292, 680], "idx3": [249, 292, 680], "t10k": [249, 292, 680], "pytorchmnist": [249, 292], "mxnetmnist": [249, 292], "tensorflowmnist": [249, 292], "pytorchfashionmnist": [249, 292], "mxnetfashionmnist": [249, 292], "tensorflowfashionmnist": [249, 292], "imagefold": [249, 292, 680, 685, 697], "expect": [249, 292, 653, 654, 688, 695, 718, 740, 743, 749], "subfold": [249, 292, 721], "belong": [249, 292, 378, 740], "class_1": [249, 292, 680], "xxx": [249, 292, 680, 697], "png": [249, 292, 680], "xxy": [249, 292, 680], "xxz": [249, 292, 680], "class_n": [249, 292, 680], "123": [249, 292, 680, 748], "nsdf3": [249, 292, 680], "asd932_": [249, 292, 680], "categori": [249, 292, 315, 368, 676, 680, 708], "mxnetimagefold": [249, 292], "tensorflowtfrecorddataset": [249, 292], "tensorflowimagerecord": [249, 292], "imagenet": [249, 252, 260, 292, 295, 302, 656, 682, 697, 707, 723, 737, 747, 748, 751, 752], "000": [249, 292, 658, 680], "099": [249, 292, 680], "tensorflowvocrecord": [249, 292], "pascal": [249, 292], "voc": [249, 292, 320, 373], "2012": [249, 292], "00000": [249, 292], "00004": [249, 292], "00001": [249, 292], "00003": [249, 292], "dummydataset": [250, 251, 293, 294, 567], "127": [250, 251, 293, 294, 567, 680, 740, 746], "float32": [250, 251, 264, 293, 294, 305, 316, 369, 567, 644, 659, 676, 680, 697, 740, 743, 746, 748], "stand_norm": [250, 251, 293, 294, 567, 680], "dummy_v2": [251, 294, 567, 680], "sparse_dummy_v2": [251, 294, 680], "label_shap": [251, 294, 567, 680], "sparsedummydataset": [251, 294], "dense_shap": [251, 294, 680], "sparse_ratio": [251, 294, 680], "imagenetraw": [252, 295, 680], "data_path": [252, 295, 680], "image_list": [252, 295, 680], "img1": [252, 295, 680], "img2": [252, 295, 680], "imgx": [252, 295, 680], "val_map": [252, 295, 680], "txt": [252, 295, 680, 682, 693, 720, 722, 723, 725, 726], "pytorchimagenetraw": [252, 295], "mxnetimagenetraw": [252, 295], "tensorflowimagenetraw": [252, 295], "inteltensorflow": [252, 254, 295, 297, 693], "tensorflowimagenetdataset": [252, 295], "onnxrtimagenetdataset": [252, 295], "bert_dataset": [253, 258, 296, 301, 312, 365], "coco_dataset": [253, 258, 296, 301, 312, 365], "dummy_dataset": [253, 258, 296, 301, 312, 365], "dummy_dataset_v2": [253, 258, 296, 301, 312, 365], "imagenet_dataset": [253, 258, 296, 301, 312, 365], "style_transfer_dataset": [253, 258, 296, 301, 312, 365], "styletransferdataset": [254, 297], "content_fold": [254, 297, 680], "style_fold": [254, 297, 680], "crop_ratio": [254, 297, 680], "resize_shap": [254, 297, 680], "256": [254, 260, 297, 302, 629, 680, 685, 697, 748], "image_format": [254, 297, 680], "holder": [254, 297, 680], "labelbalancecocorecordfilt": [255, 298], "balanc": [255, 298, 700, 743, 746], "labelbalancecocorawfilt": [255, 298], "tensorflowfilt": [256, 299], "onnxrtqlfilt": [256, 299], "onnxrtitfilt": [256, 299], "pytorchfilt": [256, 299], "mxnetfilt": [256, 299], "filter_registri": [256, 299], "filter_typ": [256, 299], "__call__": [256, 299], "coco_filt": [257, 258, 300, 301, 312, 365], "imagenet_transform": [258, 261, 301, 303, 312, 365], "parsedecodecocotransform": 259, "quantizedinput": [260, 302, 748], "labelshift": [260, 302, 748], "label_shift": [260, 302, 748], "parsedecodeimagenet": [260, 302, 748], "proto": [260, 264, 302, 305, 748], "parsedecodeimagenettransform": [260, 302], "tensorflowtransposelastchannel": 260, "tensorflowshiftrescal": 260, "rescal": [260, 264, 305, 748], "tensorflowresizecropimagenettransform": [260, 302], "random_crop": [260, 302, 748], "resize_sid": [260, 302, 748], "resize_method": [260, 302], "bilinear": [260, 264, 302, 305, 748], "random_flip_left_right": [260, 302, 748], "mean_valu": [260, 302, 748], "channels_last": [260, 302, 701], "subpixel": [260, 302], "rgb": [260, 302], "seri": [260, 302, 658, 693, 697, 748], "applic": [260, 302, 661, 687, 701, 718, 720, 726, 727, 731, 732, 738, 743, 746, 747, 748, 750], "crop": [260, 264, 302, 305, 680, 748], "left": [260, 264, 302, 305, 712, 718, 746, 748], "std": [260, 264, 302, 305, 697, 748], "bilinearimagenettransform": [260, 302], "central_fract": [260, 302, 748], "875": [260, 302, 748], "fraction": [260, 302, 748], "onnxbilinearimagenettransform": [260, 302], "onnxresizecropimagenettransform": [260, 302], "std_valu": [260, 302], "229": [260, 302, 697], "225": [260, 302, 697, 752], "resizewithaspectratio": [260, 302], "87": [260, 302, 752], "inter_pol": [260, 302], "cv2": [260, 302], "inter_area": [260, 302], "aspect": [260, 264, 302, 305, 748], "postprocess_cl": [262, 272, 697], "user_postprocess": [262, 272], "convert_to_unicod": [263, 304], "unicod": [263, 304], "assum": [263, 304, 316, 327, 369, 659, 689, 718], "load_vocab": [263, 304], "vocab_fil": [263, 264, 304, 305, 748], "convert_by_vocab": [263, 304], "vocab": [263, 304], "whitespace_token": [263, 304], "whitespac": [263, 304, 318, 371], "clean": [263, 304, 697], "piec": [263, 304, 313, 366, 696, 743], "fulltoken": [263, 304], "tokenzi": [263, 304], "basictoken": [263, 304], "punctuat": [263, 304, 313, 318, 366, 371], "lower": [263, 264, 304, 305, 318, 371, 433, 684, 700, 737, 738, 740, 746, 748, 749], "wordpiecetoken": [263, 304], "unk_token": [263, 304], "unk": [263, 304], "max_input_chars_per_word": [263, 304], "wordpiec": [263, 264, 304, 305, 748], "concat_gener": [264, 305], "inc": [264, 305, 472, 653, 658, 660, 695, 701, 708, 718, 720, 725, 738, 739, 744, 749], "tensorflowtransform": [264, 305], "mxnettransform": [264, 305], "pytorchtransform": [264, 305], "onnxrtqltransform": [264, 305], "onnxrtittransform": [264, 305], "transform_registri": [264, 305], "transform_typ": [264, 305], "basetransform": [264, 305], "tensorflowwrapfunct": [264, 305], "transform_func": [264, 305], "pytorchmxnettransform": [264, 305], "get_torchvision_map": [264, 305], "torchvis": [264, 305, 658, 686, 690, 701, 707, 721], "composetransform": [264, 305], "transform_list": [264, 305, 748], "compos": [264, 305, 641, 748], "croptoboundingbox": [264, 305, 748], "offset_height": [264, 305, 748], "offset_width": [264, 305, 748], "target_height": [264, 305, 748], "target_width": [264, 305, 748], "box": [264, 305, 316, 320, 369, 373, 655, 696, 701, 712, 718, 747, 748, 749], "coordin": [264, 305, 352, 432, 725, 748, 749], "top": [264, 305, 311, 320, 335, 340, 348, 373, 654, 696, 718, 721, 723, 748], "corner": [264, 305, 654, 659, 661, 748], "horizont": [264, 305, 748], "mxnetcroptoboundingbox": [264, 305], "onnxrtcroptoboundingbox": [264, 305], "tensorflowcroptoboundingbox": [264, 305], "resizewithratio": [264, 305, 748], "min_dim": [264, 305, 748], "800": [264, 305, 748], "max_dim": [264, 305, 748], "1365": [264, 305, 748], "constant_valu": [264, 305], "longest": [264, 305, 748], "side": [264, 305, 680, 712, 748], "exce": [264, 305, 743, 748], "tensorflowresizewithratio": [264, 305], "permut": [264, 305, 748], "tensorflowtranspos": [264, 305], "mxnettranspos": [264, 305], "pytorchtranspos": [264, 305], "randomverticalflip": [264, 305, 748], "tensorflowrandomverticalflip": [264, 305], "randomhorizontalflip": [264, 305, 697, 748], "tensorflowrandomhorizontalflip": [264, 305], "toarrai": [264, 305, 748], "pil": [264, 305, 748], "casttftransform": [264, 305], "castonnxtransform": [264, 305], "castpytorchtransform": [264, 305], "centercroptftransform": [264, 305], "center": [264, 305, 657, 658, 693, 748, 749], "paddedcentercroptransform": [264, 305], "crop_pad": [264, 305], "resizetftransform": [264, 305], "bicub": [264, 305, 748], "resizepytorchtransform": [264, 305], "randomcroptftransform": [264, 305], "randomresizedcroppytorchtransform": [264, 305], "08": [264, 305, 695, 748, 752], "randomresizedcropmxnettransform": [264, 305], "randomresizedcroptftransform": [264, 305], "normalizetftransform": [264, 305], "deviat": [264, 305, 682, 748], "broadcast": [264, 305, 685, 748], "rescalekeraspretraintransform": [264, 305], "rescaletftransform": [264, 305], "rescaletransform": [264, 305], "alignimagechanneltransform": [264, 305], "align": [264, 305, 653, 743, 748], "must": [264, 305, 316, 369, 591, 620, 654, 655, 660, 676, 679, 693, 740, 748], "pytorchalignimagechannel": [264, 305], "tondarraytransform": [264, 305], "resizemxnettransform": [264, 305], "resizetransform": [264, 305], "cropresizetftransform": [264, 305], "boundari": [264, 305, 748], "area": [264, 305, 316, 369, 696, 700, 748], "pytorchcropresizetransform": [264, 305], "mxnetcropresizetransform": [264, 305], "cropresizetransform": [264, 305], "centercroptransform": [264, 305], "mxnetnormalizetransform": [264, 305], "pytorchnormalizetransform": [264, 305], "normalizetransform": [264, 305], "randomcroptransform": [264, 305], "randomresizedcroptransform": [264, 305], "get_final_text": [264, 305], "pred_text": [264, 305], "orig_text": [264, 305], "project": [264, 305, 652, 653, 654, 724, 738, 745, 749, 753], "squadexampl": [264, 305], "qas_id": [264, 305], "question_text": [264, 305], "doc_token": [264, 305], "orig_answer_text": [264, 305], "start_posit": [264, 305], "end_posit": [264, 305], "is_imposs": [264, 305], "answer": [264, 305, 317, 318, 370, 371, 653, 723, 737, 748, 752], "unique_id": [264, 305], "example_index": [264, 305], "doc_span_index": [264, 305], "token_to_orig_map": [264, 305], "token_is_max_context": [264, 305], "input_mask": [264, 305, 697], "segment_id": [264, 305, 697], "read_squad_exampl": [264, 305], "input_fil": [264, 305], "doc_strid": [264, 305, 748], "max_query_length": [264, 305, 748], "output_fn": [264, 305], "inputbatch": [264, 305], "collecttransform": [264, 305], "10833": [264, 305], "tfsquadv1posttransform": [264, 305], "n_best_siz": [264, 305, 748], "384": [264, 305, 748], "64": [264, 305, 629, 656, 695, 743, 746, 748, 752], "max_answer_length": [264, 305, 748], "30": [264, 305, 686, 690, 692, 748, 752], "nbest_predict": [264, 305, 748], "question": [264, 305, 317, 318, 370, 371, 653, 654, 658, 659, 693, 701, 725, 737, 746, 748, 752], "anoth": [264, 305, 313, 322, 366, 649, 682, 683, 711, 715, 748, 749], "long": [264, 305, 678, 688, 743, 748], "document": [264, 305, 447, 660, 661, 666, 685, 695, 698, 703, 713, 716, 717, 724, 725, 727, 737, 744, 748, 750], "chunk": [264, 305, 748], "tfmodelzoocollecttransform": [264, 305], "tfsquadv1modelzooposttransform": [264, 305], "squadv1": [264, 305, 748], "parsedecodevoctransform": [264, 305], "conf_fname_or_obj": [265, 274, 306, 311, 321, 322, 323, 324, 326, 335, 340, 348], "unnecessari": [265, 697], "setter": 267, "calib_dataload": [267, 349, 428, 451, 468, 469, 472, 655, 658, 679, 680, 682, 690, 691, 696, 697, 720, 721, 740, 741, 742, 743], "reason": [267, 653, 660, 679, 723, 743, 747, 749], "know": [267, 678, 685, 744], "metric_cl": [269, 373, 428, 697], "user_metr": [269, 373, 428], "recommend": [269, 373, 620, 658, 659, 680, 689, 709, 712, 717, 719, 737, 739, 749], "set_backend": 270, "tensorflowimagefold": 292, "qlinear2qdq": [307, 312, 365], "qlinearop": [308, 682, 692, 709, 740, 752], "check_model": 308, "onnx_qlinear_to_qdq": 308, "input_name_to_nod": 308, "tf_to_fp32_onnx": 309, "tf_to_int8_onnx": 309, "int8_model": [309, 310, 659], "get_node_map": 310, "fp32_onnx_path": 310, "module_node_map": 310, "get_quantizable_onnx_op": 310, "quantize_nod": 310, "dynamic_quant_export": 310, "pt_fp32_model": 310, "pt_int8_model": 310, "weight_typ": 310, "s8": 310, "static_quant_export": 310, "_quantiz": [310, 395], "torch_to_fp32_onnx": 310, "do_constant_fold": 310, "torch_to_int8_onnx": 310, "achiev": [311, 348, 687, 695, 697, 721, 736, 737, 738, 740, 746, 747, 749], "across": [311, 321, 348, 374, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 681, 697, 700, 725, 728, 737, 741, 746, 749], "variou": [311, 321, 348, 374, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 661, 692, 700, 701, 728, 737, 739, 741], "dl": [311, 321, 335, 340, 348, 374, 682, 691, 705, 718, 738, 752], "bring": [311, 348, 712, 725, 746], "vari": [311, 335, 340, 348, 723, 737, 746, 752], "roc": [311, 320, 335, 340, 348, 373], "flexibl": [311, 335, 340, 348, 658, 683, 725, 737, 743], "via": [311, 335, 340, 348, 653, 658, 685, 692, 697, 701, 718, 737, 738], "popular": [312, 365, 651, 658, 659, 660, 677, 683, 686, 687, 690, 695, 697, 737, 740, 743, 749, 750], "techniqu": [312, 365, 651, 658, 692, 697, 701, 720, 736, 737, 738, 739, 740, 750, 751, 752], "bleu": [312, 314, 319, 365, 367, 372, 696, 737], "bleu_util": [312, 319, 365, 372], "coco_label_map": [312, 319, 365, 372], "coco_tool": [312, 319, 365, 372], "evaluate_squad": [312, 319, 365, 372], "f1": [312, 317, 319, 320, 365, 370, 372, 373, 685, 696, 697, 721, 745, 752], "basic_na": [312, 325, 365], "nas_util": [312, 325, 365], "pruner_legaci": [312, 365], "gradient_sensit": [312, 331, 365], "group_lasso": [312, 331, 365], "pruning_recip": [312, 365], "tile_pattern": [312, 336, 337], "prune_util": [312, 341, 365], "tuning_sampl": [312, 354, 360, 365, 436, 442], "tuning_spac": [312, 354, 360, 361, 363, 365, 436, 442, 443, 445], "tuning_struct": [312, 354, 360, 361, 362, 365, 436, 442, 443, 444], "auto_mixed_precis": [312, 354, 365, 436], "graph_optim": [312, 365], "mixed_precis": [312, 365, 374, 697], "model_convers": [312, 365], "pruning_v2": [312, 365], "unicoderegex": [313, 366], "hoc": [313, 366], "hack": [313, 366], "recogn": [313, 366, 749], "nondigit_punct_r": [313, 366], "compil": [313, 366, 697], "express": [313, 366, 653], "preced": [313, 366, 746, 749], "digit": [313, 366, 649, 738], "punct_nondigit_r": [313, 366], "symbol_r": [313, 366], "bleu_token": [313, 366], "mose": [313, 366], "smt": [313, 366], "mosesdecod": [313, 366], "mteval": [313, 366], "v14": [313, 366], "pl": [313, 366], "l954": [313, 366], "l983": [313, 366], "bilingu": [313, 366], "understudi": [313, 366], "qualiti": [313, 366, 678], "machin": [313, 366, 687, 693, 704, 718, 720, 726, 738, 746, 747], "translat": [313, 314, 366, 367, 700, 737, 749], "natur": [313, 366, 687], "approxim": [313, 314, 366, 367, 660, 696, 743], "glue": [313, 320, 366, 373, 680, 696, 697, 707], "word": [313, 366, 678, 696, 737, 743, 752], "ngram": [313, 366, 696], "breviti": [313, 314, 366, 367, 696], "penalti": [313, 314, 366, 367, 696], "doe": [313, 366, 446, 678, 679, 680, 696, 697, 743, 744, 748], "beam": [313, 366, 696], "tensor2tensor": [314, 367], "bleu_hook": [314, 367], "compute_bleu": [314, 367], "reference_corpu": [314, 367], "translation_corpu": [314, 367], "max_ord": [314, 367], "use_bp": [314, 367], "against": [314, 367], "gram": [314, 367], "bleu_scor": [314, 367], "third": [316, 369, 654, 694], "parti": [316, 369, 654, 694, 740], "pycocotool": [316, 369, 688, 693], "noth": [316, 369, 749], "thu": [316, 369, 620, 697, 737, 740], "cannot": [316, 369, 655, 678, 688, 743, 747], "jonathanhuang": [316, 369], "image_id": [316, 369, 696], "invok": [316, 369, 620, 660], "groundtruth_dict": [316, 369], "exportgroundtruthtococo": [316, 369], "groundtruth_boxes_list": [316, 369], "groundtruth_classes_list": [316, 369], "max_num_class": [316, 369], "output_path": [316, 369], "detections_list": [316, 369], "exportdetectionstococo": [316, 369], "detection_boxes_list": [316, 369], "detection_scores_list": [316, 369], "detection_classes_list": [316, 369], "cocowrapp": [316, 369], "loadannot": [316, 369], "cocoevalwrapp": [316, 369], "agnostic_mod": [316, 369], "computemetr": [316, 369], "detection_typ": [316, 369], "bbox": [316, 369, 655, 696], "hold": [316, 352, 369, 432, 680], "iou_typ": [316, 369], "iou_thr": [316, 320, 369, 373, 696], "map_point": [316, 320, 369, 373, 696], "cocoev": [316, 369], "mscoco": [316, 369], "Then": [316, 369, 660, 682, 711, 713, 715, 716, 723, 746, 749], "exportsingleimagegroundtruthtococo": [316, 369], "next_annotation_id": [316, 369], "category_id_set": [316, 369], "groundtruth_box": [316, 369], "groundtruth_class": [316, 369], "groundtruth_mask": [316, 369], "groundtruth_is_crowd": [316, 369], "ingest": [316, 369], "here": [316, 369, 447, 660, 680, 685, 686, 687, 689, 690, 695, 696, 706, 713, 716, 718, 721, 724, 726, 740, 744, 745, 746, 752], "exportsingleimagedetectionstococo": [316, 369], "uniqu": [316, 349, 369, 740], "assign": [316, 369, 649, 685, 739, 749], "num_gt_box": [316, 369], "num_detect": [316, 320, 369, 373, 696, 697, 751], "image_height": [316, 369], "image_width": [316, 369], "detection_mask": [316, 369], "crowd": [316, 369], "insid": [316, 369, 620, 683, 684, 719, 737, 741, 749], "exportsingleimagedetectionboxestococo": [316, 369], "detection_box": [316, 369, 697, 751], "detection_scor": [316, 369, 697, 751], "detection_class": [316, 369, 697, 751], "exporsingleimagedetectionboxestococo": [316, 369], "exportsingleimagedetectionmaskstococo": [316, 369], "allenai": [317, 318, 370, 371], "bi": [317, 318, 370, 371], "att": [317, 318, 370, 371], "flow": [317, 318, 370, 371, 655, 656, 697], "f1_score": [317, 318, 370, 371], "ground_truth": [317, 318, 370, 371], "ground": [317, 318, 370, 371], "truth": [317, 318, 370, 371], "metric_max_over_ground_truth": [317, 318, 370, 371], "metric_fn": [317, 318, 370, 371], "exact_match_scor": [317, 370], "exact": [317, 370], "articl": [317, 318, 370, 371], "paragraph": [317, 318, 370, 371], "qa": [317, 318, 370, 371, 658], "normalize_answ": [318, 371], "newlin": [318, 371, 649], "tab": [318, 371, 718, 747], "harmon": [318, 320, 371, 373], "recal": [318, 320, 371, 373], "answer_start": [318, 371], "177": [318, 371, 752], "denver": [318, 371], "bronco": [318, 371], "nfl": [318, 371], "afc": [318, 371], "super": [318, 371, 656], "bowl": [318, 371], "50": [318, 371, 656, 660, 723, 737, 746, 752], "56be4db0acb8001400a502ec": [318, 371], "form": [318, 371, 682, 683, 718], "percentag": [318, 371, 392, 677, 743, 751], "tensorflowmetr": [320, 373], "maintain": [320, 373, 620, 653, 654, 678, 699, 701, 713, 716, 720, 725, 726, 737, 743, 744], "pytorchmetr": [320, 373], "mxnetmetr": [320, 373], "onnxrtqlmetr": [320, 373], "onnxrtitmetr": [320, 373], "metric_registri": [320, 373], "metric_typ": [320, 373], "decorator_metr": [320, 373], "basemetr": [320, 373, 428], "single_output": [320, 373], "hvd": [320, 373, 685], "wrappytorchmetr": [320, 373], "wrapmxnetmetr": [320, 373], "wraponnxrtmetr": [320, 373], "proport": [320, 373], "pred_list": [320, 373], "pytorchloss": [320, 373], "mae": [320, 373, 696], "compare_label": [320, 373, 428, 696], "rmse": [320, 373, 696, 749], "tensorflowtopk": [320, 373], "k": [320, 373, 428, 696, 720, 737], "among": [320, 373, 700, 712, 746], "outcom": [320, 373], "num_correct": [320, 373], "num_sampl": [320, 373], "generaltopk": [320, 373], "cocomapv2": [320, 373, 696], "anno_path": [320, 373, 696], "map_kei": [320, 373], "detectionboxes_precis": [320, 373], "output_index_map": [320, 373, 696], "tensorflowmap": [320, 373], "tensorflowcocomap": [320, 373], "tensorflowvocmap": [320, 373], "squadf1": [320, 373, 696], "miou": [320, 373], "num_class": [320, 373], "21": [320, 373, 706, 707, 729, 732, 733, 738, 746, 752], "iou": [320, 373], "intersect": [320, 373, 593, 659, 696], "union": [320, 373, 386, 391, 392, 394, 398, 405, 638, 696, 729], "onnxrtglu": [320, 373], "dlrm": [320, 373], "modelconvers": 322, "typic": [322, 349, 656, 658, 684, 686, 690, 723, 737, 752], "basicna": 323, "model_build": [323, 326], "conf_fnam": 323, "nasbas": [326, 656], "nas_registri": 327, "nas_method": 327, "create_search_space_pool": 327, "idx": [327, 680], "find_pareto_front": 327, "pareto": [327, 656], "front": [327, 656], "n_point": 327, "n_metric": 327, "n_pareto_point": 327, "gradientsensitivityprun": 329, "pytorchmodel": [329, 330, 332, 333, 334, 383], "overwritten": [329, 330, 332, 333, 334, 706], "grouplassoprun": 330, "legaci": 331, "basicmagnitudeprun": 332, "patternlockprun": [333, 345], "pruner_registri": 334, "clase": 334, "pruningconf": [335, 340], "tfpruningcallback": [335, 340], "input_model": [335, 340, 699, 721, 722, 723, 747], "pure": [335, 340, 737], "pattern_registri": 338, "pattern_typ": 338, "patternbas": 338, "mask_shap": [338, 339], "is_contigu": 338, "tile": [339, 678], "tilepatternbas": 339, "tilepattern_1x1": 339, "1x1": [339, 683, 697, 737], "tilepattern_2x2": 339, "2x2": [339, 746], "tilepattern_1x16": 339, "1x16": 339, "tilepattern_4x1": 339, "tilepattern_1x2": 339, "1x2": [339, 746], "patternnxm": 343, "patternninm": 343, "reset_non_value_to_default": 344, "parse_not_to_prun": 344, "update_frequency_on_step": [345, 739], "max_sparsity_ratio_per_lay": [345, 739], "magnitudeprun": 345, "snipprun": 345, "snipmomentumprun": 345, "moreoev": 345, "quantconf": 348, "separ": [349, 653, 678, 691, 694, 726, 728, 736, 739], "opt_model": [349, 697], "fulli": [349, 697, 726, 740, 746], "train_func": [349, 638, 685, 697, 740], "automixedprecisiontunestrategi": [350, 430], "basictunestrategi": [351, 431], "polici": [351, 355, 429, 431, 437, 653, 658, 751, 753], "bayesiantunestrategi": [352, 432], "acq_max": [352, 432], "ac": [352, 432], "gp": [352, 432], "y_max": [352, 432], "n_warmup": [352, 432], "10000": [352, 432, 737], "n_iter": [352, 432], "acquisit": [352, 432], "gaussian": [352, 432, 749], "relev": [352, 432, 660, 661, 678, 723, 737], "acq": [352, 432], "randomst": [352, 432], "scipi": [352, 432], "x_max": [352, 432], "targetspac": [352, 432], "pbound": [352, 432], "9527": [352, 432, 697, 751], "bayesianoptim": [352, 432], "exhaustivetunestrategi": [353, 434], "msetunestrategi": [355, 437], "mse_v2tunestrategi": [356, 438], "revert": [356, 364, 438, 446, 749], "randomtunestrategi": [357, 439], "strategy_registri": [358, 440, 749], "tunestrategi": [358, 440, 749], "tuningsamplerregistri": 361, "tuningsampl": [361, 443], "tuningord": [361, 443], "Not": [361, 362, 443, 444, 572, 649, 656, 678], "tuningspac": [361, 362, 443, 444], "tuning_order_lst": [361, 443], "initial_op_tuning_cfg": [361, 443], "modelwisetuningsampl": [361, 443], "tuning_items_prior": [361, 443], "op_dtype_dict": [361, 443], "optuningconfig": [361, 362, 363, 443, 444, 445], "optypewisetuningsampl": [361, 443], "opwisetuningsampl": [361, 443], "fallbacktuningsampl": [361, 443], "op_dtyp": [361, 443], "skip_first": [361, 443], "smoothquantsampl": [361, 443], "tuningitem": [362, 444], "item_typ": [362, 444], "pattern_to_intern": [362, 444], "default_dtyp": [362, 444], "pattern_to_path": [362, 444], "quant_mode_from_pattern": [362, 444], "internal_pattern": [362, 444], "initial_tuning_cfg_with_quant_mod": [362, 444], "op_name_typ": [362, 444], "step1": [362, 444], "step2": [362, 444], "complet": [362, 444, 659, 660, 737, 740, 749, 751, 752], "step3": [362, 444], "step4": [362, 444], "step5": [362, 444], "op_quant_mod": [363, 445], "ordereddefaultdict": [364, 446], "extract_data_typ": [364, 446], "reverted_data_typ": [364, 446], "signed_flag": [364, 446], "get_adaptor_nam": [364, 446], "experiment": [365, 656, 680, 684, 685, 687, 693, 697, 737, 739, 740, 744, 748], "base_model": [365, 376], "keras_model": [365, 376], "mxnet_model": [365, 376], "nets_factori": [365, 376, 568], "onnx_model": [365, 376, 386, 388, 389, 391, 392, 394, 403, 421, 721], "tensorflow_model": [365, 376, 426, 723], "torch_model": [365, 376], "collect_layer_histogram": [365, 642], "create_obj_from_config": [365, 642], "kl_diverg": [365, 642], "load_huggingfac": [365, 642, 697], "neural_insights_util": [365, 642], "weights_detail": [365, 642], "sub_class": [373, 428], "register_customer_metr": 373, "topk": [373, 428, 685, 696, 697, 720, 740], "frozen": [374, 382, 428, 570, 699], "savedmodel": [374, 382, 428, 570], "onnx_ml_pb2": [374, 699], "hybirdblock": [374, 428], "basemodel": [375, 468, 469, 472, 570], "plai": [375, 570, 738, 743, 746], "role": [375, 570, 743, 746], "kerasmodel": [377, 570], "get_model_fwk_nam": 378, "fwk": 378, "mxnetmodel": 379, "net": [380, 571, 658], "tfslimnetsfactori": [380, 571], "get_model_typ": [382, 570], "validate_graph_nod": [382, 570], "validate_and_inference_input_output": [382, 570], "graph_sess": [382, 570], "graph_def_sess": [382, 570], "frozen_pb_sess": [382, 570], "load_saved_model": [382, 570], "saved_model_tag": [382, 570], "signatur": [382, 570], "metagraphdef": [382, 570], "try_loading_kera": [382, 570], "keras_sess": [382, 570], "slim_sess": [382, 570], "checkpoint_sess": [382, 570], "estimator_sess": [382, 570], "saved_model_sess": [382, 570], "tensorflowbasemodel": [382, 426, 570], "tensorflowsavedmodelmodel": [382, 570], "tensorflowllmmodel": [382, 570], "exceed": [382, 570], "2gb": [382, 570], "tensorflowqatmodel": [382, 570], "tensorflowcheckpointmodel": [382, 570], "tensorflowmodel": [382, 570], "pytorchbasemodel": 383, "pytorchfxmodel": 383, "ipexmodel": 383, "driven": [384, 658, 697, 718, 735, 747], "objective_registri": 384, "objective_custom_registri": 384, "obj_cl": 384, "eural_compressor": 384, "objective_cl": 384, "user_object": 384, "__class__": 384, "__name__": 384, "objective_cfg": 384, "usr_cfg": 384, "user_obj_cfg": 384, "easili": [384, 659, 702, 706, 718, 735, 746], "peak": [384, 735], "multiobject": 384, "metric_criterion": 384, "metric_weight": 384, "obj_criterion": 384, "obj_weight": 384, "is_measur": 384, "pathlib": [386, 389, 391, 392, 394, 397, 398], "quant_func": 386, "data_read": [386, 391, 392, 395], "calibrationdataread": [386, 388, 389, 391, 392, 395, 397, 398, 399], "weight_dtyp": [391, 392, 394, 400, 466, 470], "weight_bit": [391, 392, 394, 398, 400, 660], "weight_group_s": [391, 392, 394, 400], "weight_sym": [391, 392, 394, 400, 466, 470], "91": [391, 743, 746, 752], "apply_awq_on_model": 391, "quant_config": [391, 392, 394, 397, 405, 455, 456, 468, 472, 572, 573, 590, 592, 597, 601, 603, 604, 605, 612, 616, 618, 632, 637, 700], "calibration_data_read": [391, 392, 397, 398], "nnx": 391, "return_modelproto": [392, 394], "stabil": [392, 743], "optionm": [392, 394], "apply_gptq_on_model": 392, "apply_rtn_on_model": 394, "nodeproto": 395, "reader": 395, "smooth_quant_entri": [397, 678], "smoohquantconfig": [397, 400], "rtn_quantize_entri": 397, "rtnconfig": [397, 398, 400, 405, 627, 629, 637], "gptq_quantize_entri": 397, "gptqconfig": [397, 398, 400, 629], "awq_quantize_entri": 397, "awqconfig": [397, 400], "model_input": 398, "base_tun": [398, 469, 628], "eval_arg": [398, 469, 628], "expand": 398, "l139": 399, "act_dtyp": [400, 466, 470, 700], "get_default_rtn_config": [400, 629], "get_default_gptq_config": [400, 629], "get_default_awq_config": 400, "fusedconv": 400, "calib_it": 400, "auto_alpha_arg": [400, 470, 746], "alpha_min": [400, 746], "alpha_max": [400, 746], "alpha_step": [400, 746], "attn_method": 400, "get_default_sq_config": [400, 470], "register_algo": [405, 572, 637, 678], "algos_map": [405, 572, 637], "example_algo": [405, 572, 637], "get_qrange_for_qtyp": 405, "check_model_with_infer_shap": 405, "parserfactori": 407, "onnxrtparserfactori": 409, "onnxprofilingpars": 411, "respons": [411, 412, 416, 731, 732, 733, 740], "profilingpars": 412, "profilingresult": 413, "total_execution_tim": 413, "accelerator_execution_tim": 413, "cpu_execution_tim": 413, "op_run": 413, "op_defin": 413, "tensorflowparserfactori": 414, "tensorflowprofilingpars": 416, "profilerfactori": [417, 419, 424], "create_onnx_config": 422, "ort": 422, "sessionopt": 422, "delete_assign": 427, "create_tf_config": 427, "tf_modul": 427, "configproto": 427, "set_eager_execut": 427, "entir": [428, 638, 655, 660, 661, 677, 725, 737], "autotunestrategi": 429, "conservativetunestrategi": 433, "o0": [433, 749], "who": [433, 653], "hawq_v2tunestrategi": 435, "made": [435, 659, 740, 744, 749], "impact": [435, 737, 744, 749], "tunestrategymeta": 440, "metaclass": 440, "lowerbitssampl": 443, "blockfallbacktuningsampl": 443, "op_block_lst": 443, "target_dtyp": [443, 593], "alpha_list": 443, "weightonlyquantsampl": 443, "quantopt": 446, "quant_typ": 446, "quant_opt": 446, "preprocess_user_cfg": 446, "op_user_cfg": 446, "op_user_cfg_modifi": 446, "build_slave_faker_model": 446, "slave": [446, 749], "virtual": [446, 738], "classregist": 446, "fun": 447, "attribute1": 447, "module_debug_level1": 447, "debug": [447, 645, 682, 711, 715, 719, 749, 750], "function1": 447, "param1": 447, "param2": 447, "parameter1": 447, "parameter2": 447, "function2": 447, "pep": [447, 678], "484": [447, 752], "output_model": [447, 697, 721, 723, 747], "function3": 447, "section": [447, 661, 678, 682, 683, 684, 718, 721, 724, 737, 739, 743, 751], "restructuredtext": 447, "liter": 447, "generator1": 447, "example_gener": 447, "exampleclass": 447, "param3": 447, "public": [447, 653, 713, 716], "attr1": 447, "attr2": 447, "attr5": 447, "api_doc_exampl": 448, "smoothquantconfig": [451, 470], "calib_iter": [451, 455, 468, 469, 472, 660], "scaler": 452, "kerasqueri": 455, "kerasconfigconvert": 455, "staticquantconfig": [455, 456, 466, 470, 572], "kerassurgeri": 455, "tensorflowconfig": 456, "tensorflowconfigconvert": 456, "weight_granular": [466, 470], "per_tensor": [466, 470, 660, 661, 689, 740, 751], "act_sym": [466, 470], "act_granular": [466, 470], "get_all_registered_config": 466, "get_default_static_quant_config": [466, 470], "static_quant_entri": 468, "weight_algorithm": 470, "act_algorithm": 470, "record_max_info": [470, 598], "weight_clip": 470, "default_sq_alpha_arg": 470, "quantize_model": 472, "quantize_model_with_single_config": 472, "dummydatasetv2": 567, "itex_instal": 572, "instal": [572, 685, 688, 690, 701, 703, 706, 709, 713, 716, 718, 719, 721, 722, 723, 753], "combine_histogram": [572, 649], "old_hist": [572, 649], "old": [572, 649, 697, 744], "get_all_fp32_data": [572, 649], "get_tensor_histogram": [572, 649], "scale_info": [572, 649], "dequantize_weight": [572, 649], "weight_tensor": [572, 649], "min_filter_tensor": [572, 649], "max_filter_tensor": [572, 649], "dump_data_to_loc": [572, 649], "pkl": [572, 649, 722], "load_data_from_pkl": [572, 649], "valid_keras_format": 572, "statist": [572, 602, 649, 650], "header": [572, 602, 649, 688], "field_nam": [572, 602, 649], "output_handl": [572, 602, 649], "printer": [572, 602, 649], "captureoutputtofil": [572, 649], "tmp_file_path": [572, 649], "stream": [572, 649, 752], "sy": [572, 649, 678, 704], "stderr": [572, 649], "captur": [572, 649], "half": [586, 588, 620, 698, 709], "halfprecisionconvert": 586, "configs_map": [586, 627], "half_precision_convert": 587, "module_wrapp": 587, "halfprecisionmodulewrapp": 588, "mxquantiz": 590, "ordereddict": [590, 597, 601, 604, 616, 678], "elemformat": 591, "roundingmod": 591, "member": [591, 653, 659], "quantize_elemwise_op": 591, "mx_spec": 591, "w8a8pt2equant": 592, "pattern_factori": 593, "fn": 593, "torchfunctyp": 593, "fn_arg": 593, "ellipsi": [593, 633], "gm": 593, "node_candidate_list": 593, "get_half_precision_node_set": 593, "unquantized_node_set": 593, "node_set_from_user_config": 593, "recover_model_from_json": [596, 648], "json_file_path": [596, 648], "smoothquantquant": 597, "get_quantizable_ops_recurs": [598, 602], "act_algo": 598, "carri": [598, 737], "scale_shar": 598, "staticquantquant": 601, "user_cfg": 602, "warm": 602, "dump_model_op_stat": 602, "parse_cfg": 602, "autoroundquant": 603, "get_autoround_default_run_fn": 603, "properli": [603, 726], "warn": [603, 645, 678], "awqquant": 604, "rawgptquant": 605, "export_compressed_model": [605, 644, 743], "use_layer_wis": [605, 629], "hqqmoduleconfig": 607, "immut": 607, "constructor": 607, "hqquantiz": 612, "configmappingtyp": 612, "rtnquantiz": 616, "trainableequivalenttransform": 618, "replace_forward": 619, "recover_forward": 619, "device_typ": 620, "_dtype": 620, "cache_en": 620, "manag": [620, 638, 641, 697, 701, 702, 712], "region": [620, 746], "chosen": [620, 660, 677], "enter": [620, 712, 718, 726], "backward": [620, 638, 683, 684, 685, 697, 736, 737, 740, 744], "hpu": 620, "float8_e4m3fn": 620, "autocastmodel": 620, "affect": [620, 746], "dataparallel": 620, "distributeddataparallel": 620, "torch_dtyp": [620, 661], "export_model_for_pt2e_qu": 624, "dynamic_shap": 624, "graph_modul": 624, "aten": 624, "ir": 624, "rtn_entri": 627, "run_fn": [628, 632], "run_arg": [628, 632], "use_sym": 629, "use_full_rang": 629, "use_mse_search": 629, "use_double_qu": 629, "double_quant_dtyp": 629, "double_quant_bit": 629, "double_quant_use_sym": 629, "double_quant_group_s": 629, "act_ord": 629, "static_group": [629, 743], "hqqconfig": 629, "quant_zero": 629, "quant_scal": 629, "scale_quant_group_s": 629, "skip_lm_head": 629, "get_default_hqq_config": 629, "hqq": 629, "get_woq_tuning_config": 629, "woq": [629, 695, 700], "monitor": [632, 726, 731, 732, 733], "register_acceler": 633, "cuda_acceler": 633, "cpu_acceler": 633, "xpu_acceler": 633, "hpu_acceler": 633, "get_quant": 637, "quantizer_cl": 637, "postprocess_model": 637, "loop": [638, 655, 656, 660, 661, 689, 728, 745, 749], "compressionmanag": 638, "deal": 638, "pruningconfig": 638, "orchestr": [638, 658, 692, 750], "on_train_begin": [638, 655, 683, 684, 697, 736, 737, 740], "train_loop": [638, 697, 736], "on_epoch_begin": [638, 641, 683, 684, 697, 736], "on_step_begin": [638, 641, 683, 684, 697, 736, 737], "on_after_compute_loss": [638, 683, 684, 697, 736], "on_before_optimizer_step": [638, 683, 684, 697, 736, 737], "on_step_end": [638, 641, 683, 684, 697, 736], "on_epoch_end": [638, 641, 683, 684, 697, 736], "on_train_end": [638, 683, 684, 697, 736, 737, 740], "path_to_sav": 638, "top1": [638, 696, 720, 737, 740, 752], "callbacks_list": 638, "layerhistogramcollector": 639, "layer_tensor": 639, "include_lay": 639, "get_func_from_config": 641, "func_dict": 641, "get_preprocess": 641, "get_metr": 641, "get_postprocess": 641, "get_algorithm": 641, "create_dataset": 641, "cfg_preprocess": 641, "cfg_filter": 641, "create_dataload": 641, "dataloader_cfg": 641, "create_eval_func": 641, "postprocess_cfg": 641, "baselin": [641, 745, 746, 747], "create_train_func": 641, "train_cfg": 641, "Their": 641, "auxiliari": 642, "optimizedmodel": 644, "from_pretrain": [644, 658, 697], "save_for_huggingface_upstream": [644, 697], "saved_dir": [644, 743], "use_optimum_format": [644, 743], "compression_dtyp": [644, 743], "compression_dim": [644, 743], "comoress": 644, "msg": [645, 727, 731, 732], "fatal": 645, "alia": [645, 649, 703, 708], "register_neural_insights_workload": 646, "workload_loc": [646, 649], "workload_mod": 646, "workload_nam": 646, "uuid": 646, "update_neural_insights_workload": 646, "workload_uuid": 646, "update_neural_insights_workload_accuracy_data": 646, "baseline_accuraci": 646, "optimized_accuraci": 646, "get_model_path": 646, "is_int8_model": 648, "load_weight_onli": 648, "checkpoint_dir": 648, "history_cfg": 648, "best_configur": 648, "best_model_weight": 648, "snapshot": [648, 722], "cfg_from_fil": 649, "yaml_fil": [649, 680, 685], "time_limit": 649, "get_siz": 649, "seen": [649, 659], "compute_spars": 649, "fault_tolerant_fil": 649, "equal_dict": 649, "d2": 649, "compare_kei": 649, "ignore_kei": 649, "ignor": [649, 677, 680, 743, 746, 749], "get_tuning_histori": 649, "tuning_history_path": 649, "offlin": [649, 653, 697, 740, 746], "str2arrai": 649, "global_st": 649, "show_memory_info": 649, "hint": 649, "dump_class_attr": 649, "compare_object": 649, "obj1": 649, "obj2": 649, "ignore_attr": 649, "comparison": [649, 743, 744, 747], "alias_param": 649, "param_nam": 649, "param_alia": 649, "alias": [649, 678], "print_tabl": 649, "column_map": 649, "table_entri": 649, "titl": [649, 694, 719, 749], "insert_newlin": 649, "prettyt": 649, "column": [649, 743, 746], "handler": [649, 749], "row": [649, 682, 721, 746], "decim": 649, "get_tensors_info": 649, "get_weights_detail": 649, "weightdetail": 649, "dump_tabl": 649, "file_typ": 649, "csv": [649, 656, 721, 722], "dump_table_to_csv": 649, "get_number_of_socket": 649, "platform": [649, 658, 692, 701, 709, 728, 738, 740], "opentri": 649, "activation_min": 649, "activation_max": 649, "print_op_list": 649, "get_op_list": 649, "minmax_file_path": 649, "input_model_tensor": 649, "optimized_model_tensor": 649, "activation_min_max": 649, "calculate_ms": 649, "mse_metric_gap": 649, "fp32_tensor": 649, "dequantize_tensor": 649, "euclidean": [649, 683], "distanc": [649, 683], "check_key_exist": 649, "weightsdetail": 650, "input_tensor_data": 650, "optimized_tensor_data": 650, "weightsstatist": 650, "welcom": [652, 653, 654, 658, 720, 727, 753], "interest": [653, 658, 720, 747], "foster": 653, "particip": [653, 728], "commun": [653, 720], "harass": 653, "experi": [653, 701, 723, 745, 746, 749], "everyon": 653, "regardless": 653, "ag": 653, "bodi": 653, "ethnic": 653, "characterist": 653, "gender": 653, "educ": 653, "socio": 653, "econom": 653, "race": 653, "religion": 653, "sexual": 653, "orient": 653, "contribut": [653, 658, 737], "inclus": 653, "Being": 653, "respect": [653, 689, 737, 746, 751], "viewpoint": 653, "gracefulli": 653, "focus": [653, 659, 700], "empathi": 653, "toward": [653, 683], "unaccept": 653, "imageri": 653, "unwelcom": 653, "troll": 653, "insult": 653, "derogatori": 653, "polit": 653, "attack": 653, "privat": 653, "publish": [653, 694, 695, 698, 719, 746], "electron": 653, "explicit": 653, "permiss": 653, "inappropri": 653, "profession": 653, "clarifi": 653, "appropri": [653, 677, 746], "fair": 653, "action": [653, 713, 716], "edit": 653, "reject": 653, "commit": [653, 654], "wiki": 653, "issu": [653, 654, 657, 658, 693, 721, 723, 740, 747], "ban": 653, "deem": 653, "threaten": 653, "offens": 653, "harm": 653, "mail": 653, "social": [653, 738], "media": [653, 738], "account": [653, 745, 749], "appoint": 653, "onlin": [653, 745], "event": [653, 747], "abus": 653, "report": [653, 654, 658, 728, 745], "contact": [653, 744, 745], "complaint": 653, "review": [653, 654, 658, 738], "investig": [653, 678, 723], "circumst": [653, 739], "oblig": [653, 724], "confidenti": [653, 720], "regard": [653, 742], "incid": 653, "good": [653, 740, 749], "faith": 653, "repercuss": 653, "leadership": 653, "faq": [653, 658], "page": [653, 654, 720, 723, 724], "send": [654, 660], "view": [654, 658, 686, 709, 718, 724, 744], "star": 654, "repositori": [654, 713, 716], "button": [654, 692, 712, 718], "fork": [654, 713, 716], "clone": [654, 682, 693, 711, 715, 720, 722, 723, 725, 726], "pc": 654, "git": [654, 682, 688, 693, 720, 722, 723, 725, 726], "modif": [654, 659, 689, 706, 725], "checkout": 654, "my": 654, "push": [654, 700, 737, 743, 746], "cover": [654, 687, 691, 738], "would": [654, 697, 722, 737, 740, 746], "adopt": [654, 701, 737, 738, 746], "certif": [654, 720], "agre": 654, "pr": [654, 679, 696, 713, 716, 744], "At": [654, 660, 700, 724, 728, 749], "approv": 654, "solv": [654, 740, 744], "licens": 654, "azur": [654, 658, 738], "devop": 654, "ci": 654, "cloud": [654, 658, 700, 728, 738], "deploi": [654, 683, 697, 724, 728, 743, 749], "e16": 654, "v5": 654, "scan": [654, 658], "pylint": 654, "bandit": 654, "copyright": [654, 694], "docstyl": 654, "spellcheck": 654, "dco": 654, "pytest": 654, "No": [654, 678, 688, 697, 726, 727, 738], "failur": [654, 655], "fault": 654, "coverag": 654, "runtim": [654, 658, 659, 660, 662, 679, 682, 686, 689, 692, 698, 700, 703, 708, 709, 739, 743, 744, 749], "submit": [654, 725, 728, 738], "bug": [654, 658], "intend": 654, "safe": 654, "collabor": [654, 658, 703, 709], "adher": 654, "toolkit": [655, 693, 701, 709, 738, 750], "tracer": 655, "resolv": [655, 657], "floatfunct": 655, "cat": [655, 687, 704, 731, 732, 733], "done": [655, 683, 684, 702, 718, 727, 731, 732, 737, 740], "10004": [655, 656, 659, 679, 683, 684, 685, 689, 692, 698, 700, 736, 739, 741, 743, 751], "neural_compressor": [655, 656, 658, 661, 676, 678, 679, 680, 682, 683, 684, 685, 687, 690, 691, 696, 697, 698, 699, 700, 720, 721, 735, 736, 737, 739, 740, 741, 742, 744, 745, 746, 748, 749, 751], "eval": [655, 678, 679, 682, 701, 740, 747], "conduct": [655, 697, 706, 718, 749, 750], "imper": 655, "therefor": [655, 697, 721, 723, 737, 740, 741, 744, 746], "lot": [655, 723, 746], "As": [655, 660, 679, 683, 696, 697, 712, 723, 737, 743, 749], "successfulli": [655, 658, 685, 727, 731, 732, 733, 738], "suggest": [655, 678, 745], "traceabl": 655, "proxi": 655, "tutori": [655, 709, 738, 750], "prototyp": 655, "html": [655, 658, 660, 677, 685, 692, 713, 716, 719, 721, 727, 731, 740], "highlight": 655, "untrac": 655, "ssd": [655, 687, 752], "resnet34": [655, 752], "r34": 655, "bboxes_labels_scor": 655, "prob": 655, "45": [655, 695, 752], "max_output": 655, "zip": [655, 727, 731, 732], "dbox": 655, "dlabel": 655, "dscore": 655, "decode_singl": 655, "autom": [656, 701, 718, 719, 738, 746], "artifici": 656, "ann": 656, "par": [656, 728], "outperform": 656, "hand": 656, "propos": [656, 659, 683, 698, 743, 746], "potenti": [656, 682], "lie": [656, 677], "predictor": 656, "shown": [656, 679, 682, 683, 696, 697, 700, 712, 721, 723, 735, 736, 737, 741, 746, 749], "figur": [656, 711, 712, 715, 741], "popul": 656, "inner": 656, "evolutionari": 656, "until": [656, 660, 749], "conclud": 656, "yet": [656, 713, 716, 719, 726, 740], "simplest": [656, 677, 704], "launcher": [656, 658, 683, 684, 709, 750], "agent": 656, "nsga2": 656, "supernet": 656, "ofa_mbv3_d234_e346_k357_w1": 656, "acc": [656, 695, 728, 737, 747, 752], "mac": [656, 719], "num_ev": 656, "250": [656, 737], "results_csv_path": 656, "search_result": 656, "dataset_path": 656, "ilsvrc2012": 656, "aim": [656, 658, 695, 701, 737, 746, 749, 750], "mobilenetv3": 656, "lt": [656, 680], "wmt": 656, "en": 656, "de": 656, "guidelin": [657, 658], "mainstream": [658, 750], "workflow": [658, 660, 661, 682, 683, 687, 693, 698, 700, 713, 716, 720, 747, 750], "particular": [658, 737, 743], "wide": [658, 686, 698, 737, 740], "hardwar": [658, 659, 683, 692, 697, 700, 718, 737, 738, 739], "xeon": [658, 693, 694, 695, 698, 738, 740, 742, 752], "scalabl": [658, 693, 695, 698, 738, 740, 742], "processor": [658, 695, 698, 726, 738, 740, 742], "flex": [658, 693], "amd": [658, 693, 752], "arm": [658, 692, 693, 752], "nvidia": [658, 677, 692, 693, 752], "llama2": 658, "falcon": [658, 695, 737, 746, 752], "j": [658, 695, 722, 737, 746, 752], "bloom": [658, 695, 737, 746, 752], "broad": [658, 692, 707, 750], "stabl": [658, 693, 737, 738], "diffus": [658, 738], "vision": [658, 687, 705, 746], "coder": [658, 692, 702, 703, 706, 709, 712, 725, 729, 738], "marketplac": [658, 719, 738], "googl": [658, 678, 698, 738], "amazon": [658, 701, 709], "web": [658, 720, 726, 731, 732, 733, 747], "servic": [658, 718, 725, 738], "softwar": [658, 694, 737, 738, 744], "alibaba": [658, 708, 715, 716, 738], "tencent": [658, 738], "taco": [658, 738], "oliv": [658, 738], "ai": [658, 700, 701, 738, 742, 750], "ecosystem": [658, 738], "lightn": [658, 708], "2024": [658, 752], "03": [658, 752], "sota": [658, 738], "gaudi2": 658, "pip": [658, 682, 685, 688, 690, 693, 703, 706, 711, 713, 715, 716, 720, 721, 722, 723, 744], "34": [658, 695, 733, 752], "program": [658, 685, 694, 701, 718], "demonstr": [658, 686, 700, 701, 731, 732, 733, 747], "gauid2": 658, "docker": 658, "gaudi": 658, "setup": [658, 682, 689, 693, 713, 716, 720, 722, 723, 725, 726, 737], "habana": 658, "habana_visible_devic": 658, "ompi_mca_btl_vader_single_copy_mechan": 658, "cap": 658, "sys_nic": 658, "host": [658, 685, 726, 728, 731, 732, 733], "ipc": 658, "vault": 658, "ubuntu22": 658, "04": [658, 693, 695, 752], "habanalab": 658, "latest": [658, 693, 738, 744], "login": [658, 713, 716, 745], "exec": 658, "container_id": 658, "bash": [658, 723, 747], "optimum": [658, 708, 709, 721, 743], "upgrad": [658, 697], "auto_round": 658, "automodel": 658, "autotoken": [658, 697], "get_dataload": 658, "eleutherai": [658, 695, 722, 746, 752], "neo": [658, 752], "125m": [658, 746], "trust_remote_cod": 658, "woq_conf": 658, "quantized_model": [658, 727, 731, 732], "int4": [658, 695, 740, 752], "resnet18": [658, 698, 703, 752], "static_quant_conf": 658, "overview": [658, 749], "jupyterlab": [658, 701, 707, 709, 711, 715, 750], "studio": [658, 709, 718, 728, 750], "topic": 658, "fp8": [658, 700, 738], "innov": [658, 709, 738], "blog": [658, 738], "llama": [658, 695, 737, 738, 741, 743, 746, 752], "oct": [658, 738], "2023": [658, 700, 733, 737, 743, 746], "emnlp": [658, 738], "teq": [658, 738, 741, 743], "sep": [658, 738], "releas": [658, 693, 707, 709, 711, 715, 717, 729, 732, 733, 753], "legal": [658, 753], "request": [658, 726, 727, 728, 731, 732, 733, 740], "ask": [658, 693], "email": 658, "research": [658, 694, 746, 752], "idea": [658, 720, 737, 746, 749], "discord": 658, "join": [658, 721, 726, 731, 732], "technic": 658, "discuss": 658, "wechat": [658, 738], "img": 658, "bridg": [659, 660, 692], "vanilla": [659, 660, 692], "abcadaptor": 659, "__init__": [659, 678, 679, 680, 696, 749], "query_fw_cap": [659, 661], "query_fused_pattern": 659, "he": 659, "besid": [659, 683, 723, 743], "describ": [659, 661, 678, 682, 689, 720, 747], "past": [659, 743], "mainten": 659, "difficult": [659, 746], "abil": [659, 660, 680, 689, 700, 746], "fragment": 659, "scenario": [659, 676, 683, 697, 737, 743], "granular": [659, 660, 661, 689, 692, 700, 704, 740, 746, 751], "semant": [659, 689], "mla": [659, 698, 740], "becom": [659, 687, 737, 743], "explor": [659, 700], "inspect_tensor": 659, "op_list": [659, 747], "iteration_list": 659, "inspect_typ": 659, "save_to_disk": 659, "quantization_cfg": 659, "set_tensor": 659, "tensor_dict": 659, "diagnosis_help": 659, "fw": 660, "outlin": [660, 661], "instruct": [660, 661, 683, 693, 698, 713, 716, 720, 721, 722, 723, 737, 738, 739, 740, 746, 752], "extend": [660, 661], "accommod": [660, 661], "incorpor": [660, 661, 684, 737, 749], "diagram": [660, 661, 682, 749], "illustr": [660, 661, 684, 749], "sequencediagram": [660, 661, 728], "autonumb": [660, 661], "query_framework_cap": 660, "opwis": 660, "optypewis": 660, "travers": [660, 661, 743, 749], "\u2776": 660, "\u2777": 660, "\u2778": 660, "\u2779": 660, "\u277a": 660, "\u277b": 660, "\u277c": 660, "These": [660, 692, 721], "chapter": 660, "node_op": 660, "confirm": 660, "int8_conv_config": 660, "optype_wise_": 660, "tuning_cfg_to_fw": 660, "Its": [660, 677, 737], "dispatch": [660, 692, 725, 728], "is_perchannel": 660, "is_asymmetr": 660, "convert_bf16": 660, "somewhat": 660, "distort": 660, "line": [660, 678, 685, 692, 701, 706, 707, 726, 747], "let": [661, 689, 706, 737, 739, 751], "overal": [661, 726, 751], "drive": 661, "uint4": 661, "asymmetr": [661, 740, 743, 749], "kullback": [661, 683], "leibler": [661, 683], "pytorch_cpu": 661, "1_11_capabl": 661, "cap_s8_1_11": 661, "cap_s8_1_11_conv1d": 661, "per_channel_symmetr": 661, "addition": [661, 685, 737, 749], "per_tensor_symmetr": 661, "due": [661, 687, 737, 740, 746, 747], "nativ": 661, "with_arg": 661, "qscheme": 661, "quant_min": 661, "quant_max": 661, "linux": [676, 688, 693, 712, 718], "x86_64": 676, "aarch64": 676, "prove": [677, 743, 746], "benefici": 677, "uniform": [677, 743], "\u03b2": 677, "\u03b1": 677, "fundament": [677, 697], "primari": [677, 749], "focu": [677, 749], "essenti": [677, 688], "remaind": 677, "enhanc": [677, 701, 737, 738, 742], "resolut": 677, "extrem": 677, "still": [677, 697, 724, 738, 740, 742], "retain": 677, "noteworthi": 677, "vanhouck": 677, "vincent": 677, "andrew": 677, "senior": 677, "mark": 677, "mao": 677, "speed": [677, 697, 709, 737, 738, 740, 749], "2011": 677, "szymon": 677, "migacz": 677, "2017": 677, "mckinstri": 677, "jeffrei": 677, "l": [677, 683, 747, 749], "discov": [677, 747], "preprint": [677, 700, 737, 743, 746], "1809": 677, "04191": 677, "2018": 677, "mostli": 678, "overli": 678, "argu": 678, "decis": [678, 696], "sub_modul": 678, "namespac": 678, "pollut": 678, "subprocess": [678, 679], "popen": 678, "statement": 678, "pipe": 678, "long_str": 678, "extran": 678, "pager": 678, "getenv": 678, "readabl": 678, "seem": 678, "worth": [678, 737], "4f": 678, "65421": 678, "sentenc": 678, "eval_result": 678, "declar": [678, 719], "typealia": 678, "_lossandgradi": 678, "complextfmap": 678, "xx_func": 678, "pylanc": 678, "cheeseshopaddress": 678, "chees": 678, "shop": 678, "outofcheeseerror": 678, "crbug": 678, "192795": 678, "cpufreq": [678, 704], "facilit": [678, 701], "__all__": 678, "get_all_config_set_from_config_registri": 678, "algorithm_entri": 678, "autotun": 678, "static_qu": 678, "snippet": [678, 692], "rtn_algo_entri": 678, "vscode": [678, 717, 719], "settings_recommend": 678, "encount": 679, "consum": 679, "previous": 679, "lack": [679, 688], "faster": [679, 681, 687, 738, 749, 752], "Of": 679, "evenli": 679, "divid": [679, 728, 746, 749], "discard": 679, "throw": 679, "awai": 679, "draw": [679, 745, 749], "pin": [679, 711, 715], "reshuffl": 679, "manner": [679, 683, 699], "newdataload": 679, "customis": [679, 680, 696], "ensp": [680, 748], "imagerecord": [680, 685, 751], "image_nam": 680, "cocorecord": 680, "gt": [680, 746, 748], "int64": 680, "offer": [680, 700], "style_transf": 680, "content": [680, 726, 727, 731, 732, 733], "tfrecorddataset": 680, "labelbal": 680, "300": [680, 737], "16": [680, 693, 731, 743, 752], "helloworld": [680, 698, 748], "aid": 681, "deploy": [681, 701, 718, 738, 741, 746], "infrastructur": 681, "diagnos": 682, "gui": [682, 692, 723, 737], "termin": [682, 711, 712, 715, 721], "repeat": [682, 749], "durat": [682, 727, 731, 732, 745], "cd": [682, 685, 693, 720, 722, 723, 725, 726, 731, 732, 733], "ilsvr2012": 682, "wget": [682, 688, 690, 720, 723], "caff": 682, "berkeleyvis": 682, "caffe_ilsvrc12": 682, "xvzf": 682, "image_recognit": [682, 723, 747], "resnet50_torchvis": 682, "ptq_static": [682, 722], "resnet50_v1": [682, 685, 697], "dataset_loc": [682, 723, 731, 747], "label_path": 682, "quantiti": 682, "vec": 682, "mu": 682, "frac": [682, 700, 746], "sigma": 682, "var": 682, "happen": 682, "dispers": [682, 721], "rule": [682, 701, 737], "v0": [682, 695, 723, 746, 747], "cg": [682, 723, 747], "conv0": [682, 723, 747], "expens": [683, 697, 749], "mobil": [683, 697, 752], "produc": 683, "logit": 683, "softmax": 683, "kd": 683, "patient": 683, "compact": [683, 697, 704, 737], "agnost": 683, "resourc": [683, 725, 728, 749], "convolut": [683, 738], "ia": 683, "attach": [683, 697, 746], "shallow": 683, "deepest": 683, "deeper": 683, "10006": [683, 684], "student_output": [683, 684], "student_loss": [683, 684], "training_func_for_nc": [683, 684], "distil_loss_conf": 683, "accordingli": [683, 709, 746], "promis": [684, 697, 737], "huge": [684, 723, 737, 741], "heavi": 684, "light": 684, "booster": 684, "degrad": [684, 737, 749], "novel": [684, 701, 712, 718], "comb": 684, "distillation_criterion": [684, 697, 736], "q_conf": 684, "horovod": 685, "enable_eager_execut": 685, "yaml_file_path": 685, "pre_process": 685, "simpli": [685, 699, 701, 703, 706, 718, 726], "evaluation_result": 685, "evaluation_time_cost": 685, "partit": [685, 737], "distributedsampl": 685, "train_sampl": 685, "train_dataset": [685, 740], "num_replica": 685, "rank": 685, "train_load": 685, "train_kwarg": 685, "adadelta": 685, "distributedoptim": 685, "named_paramet": 685, "broadcast_paramet": 685, "root_rank": 685, "broadcast_optimizer_st": 685, "set_epoch": 685, "batch_idx": 685, "zero_grad": [685, 697, 737], "nll_loss": 685, "log_interv": 685, "0f": 685, "tloss": 685, "6f": 685, "dry_run": 685, "test_func": 685, "num_of_process": 685, "002": 685, "ssh": [685, 718], "prompt": 685, "readm": [685, 731], "exactli": [685, 702], "recognit": [685, 687, 737, 747], "resizecropimagenet": [685, 748], "realiz": [685, 735, 742, 745], "tow": 685, "node1": [685, 731, 732], "node2": [685, 731, 732], "TO": [685, 703, 723], "your_node1_nam": 685, "your_node2_nam": 685, "resnet50_fp32_pretrained_model": 685, "nc_resnet50_v1": 685, "resnet": [685, 752], "varieti": [686, 739, 749], "speedup": [686, 692, 740], "2x": [686, 692], "vnni": [686, 692, 739, 740], "exchang": 687, "hope": 687, "inc_model": [687, 699], "fp32_onnx_config": 687, "verifi": [687, 695], "vgg16": [687, 752], "mobilenet": [687, 745, 752], "rcnn": 687, "torchscript": [687, 741, 746], "unsupport": [687, 697, 737], "add_relu": 687, "conv1d_relu": 687, "conv2d_relu": 687, "group_norm": 687, "hardswish": 687, "instance_norm": 687, "layer_norm": 687, "leaky_relu": 687, "sigmoid": 687, "toolchain": [688, 738], "bare": 688, "metal": 688, "sudo": [688, 704], "apt": [688, 693, 704, 712], "python3": 688, "dev": [688, 711, 715], "distutil": 688, "libgl1": 688, "mesa": 688, "glx": 688, "libglib2": 688, "ln": 688, "sf": 688, "usr": 688, "incompat": 688, "88": [688, 745, 752], "80": [688, 695, 741, 747, 752], "pyobject": 688, "reinstal": 688, "libgl": 688, "yum": [688, 693], "opencv": [688, 693, 712], "conda": [688, 693, 704, 712, 731, 732, 733, 744], "13": [688, 693, 695, 720, 744, 746, 752], "pend": [688, 727], "sqlalchemi": 688, "27": [688, 752], "alemb": 688, "forg": [688, 693], "quick": [689, 698, 737, 750, 751], "friendli": [689, 697, 700, 738, 746, 750, 751], "dive": [689, 750], "purpos": [689, 698, 718, 720, 739, 740], "syntax": 689, "go": [689, 713, 716, 724, 739, 743, 748], "up1": 689, "up2": 689, "valid_mixed_precis": 689, "addn": 689, "grappler_optim": 689, "constfold": 689, "arithmet": 689, "debug_stripp": 689, "googleapi": [690, 720, 723], "v1_6": [690, 720, 723], "mobilenet_v1_1": [690, 720, 731], "0_224_frozen": [690, 720, 731], "major": [691, 723, 740, 746], "concept": [691, 745, 750], "rather": [691, 743], "custom_metr": 691, "refin": [691, 737], "420": 692, "geomean": 692, "upload": [692, 713, 716], "click": [692, 701, 702, 709, 712, 718, 723, 738, 747], "qintegerop": [692, 740], "plan": 692, "oneapi": [693, 738, 750], "analyt": [693, 738, 750], "success": [693, 720], "11": [693, 695, 696, 698, 720, 746, 749, 752], "frequent": 693, "pypi": [693, 713, 716], "nightli": 693, "headless": [693, 712], "fastai": 693, "esri": 693, "consolid": 693, "eas": [693, 703, 738], "along": [693, 737, 743], "streamlin": [693, 725, 738], "scienc": 693, "websit": 693, "anaconda": [693, 725, 726], "suit": [693, 719, 747], "formerli": 693, "skylak": 693, "cascad": 693, "lake": [693, 698, 738], "cooper": [693, 698, 738], "ic": [693, 738], "sapphir": [693, 695], "rapid": [693, 695], "hbm": 693, "arctic": 693, "sound": 693, "pont": 693, "vecchio": 693, "cento": [693, 752], "ubuntu": 693, "22": [693, 695, 752], "maco": 693, "ventura": 693, "fortensorflow": 693, "forpytorch": 693, "17": [693, 731], "tf_enable_onednn_opt": 693, "onednn": [693, 698, 740], "newer": 693, "subject": 694, "accompani": [694, 749], "wish": 694, "bibtex": 694, "author": 694, "feng": 694, "tian": 694, "hanwen": 694, "haihao": [694, 737], "shen": [694, 737], "suyu": 694, "chen": 694, "howpublish": 694, "year": 694, "logo": 694, "atom": 694, "phi": 694, "pentium": 694, "vtune": 694, "corpor": 694, "subsidiari": 694, "brand": 694, "claim": 694, "sq": [695, 746], "4th": [695, 738, 740], "gen": [695, 698, 738, 740, 742], "codenam": [695, 698], "quickli": [695, 749, 750], "6b": [695, 722, 746, 752], "facebook": [695, 724, 746, 752], "3b": [695, 746], "30b": [695, 746, 752], "7b": [695, 746, 752], "13b": [695, 746, 752], "70b": [695, 752], "tiiuae": [695, 746, 752], "40b": 695, "baichuan": 695, "chat": [695, 746, 752], "baichuan2": 695, "bigscienc": [695, 746, 752], "1b7": [695, 746], "databrick": [695, 746, 752], "dolli": [695, 737, 746, 752], "12b": 695, "neox": [695, 752], "20b": [695, 752], "mistralai": 695, "mistral": 695, "thudm": 695, "chatglm2": 695, "wip": 695, "chatglm3": 695, "soon": 695, "lambada_openai": [695, 752], "67": [695, 752], "57": [695, 746, 752], "68": [695, 748, 752], "23": [695, 752], "0098": 695, "0000": [695, 699], "84": [695, 746, 752], "0040": 695, "71": [695, 752], "51": [695, 752], "70": [695, 752], "89": [695, 746, 752], "9913": 695, "53": [695, 752], "0003": [695, 752], "76": [695, 752], "0035": 695, "96": [695, 752], "0043": 695, "59": [695, 746, 752], "9988": 695, "24": [695, 737, 749, 752], "9936": 695, "9963": [695, 752], "46": [695, 752], "47": [695, 752], "0356": 695, "38": [695, 752], "0009": 695, "19": [695, 751, 752], "9968": 695, "35": [695, 737, 752], "9961": [695, 752], "79": [695, 747, 752], "0070": 695, "43": [695, 752], "0018": 695, "72": [695, 746, 752], "25": [695, 737, 752], "9989": 695, "9949": 695, "54": [695, 751, 752], "9940": 695, "58": [695, 732, 752], "0033": 695, "0117": 695, "49": [695, 752], "82": [695, 752], "0046": [695, 752], "0087": 695, "77": [695, 752], "9932": [695, 752], "75": [695, 737, 752], "9997": 695, "0086": [695, 746], "55": [695, 733, 752], "9991": 695, "09": [695, 752], "0057": 695, "97": [695, 697, 752], "0041": 695, "73": [695, 752], "92": [695, 752], "0005": 695, "9942": [695, 752], "9987": 695, "0030": [695, 752], "61": [695, 752], "9962": [695, 752], "9992": 695, "52": [695, 752], "9914": 695, "0023": 695, "9986": 695, "9919": [695, 752], "9977": 695, "94": [695, 748, 752], "0093": 695, "78": [695, 748, 752], "0203": 695, "74": [695, 752], "44": [695, 752], "0237": 695, "0013": 695, "00": [695, 752], "0044": 695, "popularli": 696, "industri": [696, 738], "label_map": 696, "ap": 696, "curv": 696, "turn": [696, 712, 741], "target_boxes_num": 696, "str_label": 696, "int_label": 696, "inturn": 696, "cocomap": 696, "vocmap": 696, "categor": 696, "multiclass": 696, "multilabel": 696, "newmetr": 696, "reset": 696, "reflect": [696, 748], "new_metr": 696, "deliv": [697, 738, 744], "conveni": [697, 725], "veri": [697, 719, 723, 740, 743, 749, 750], "comprehens": [697, 750], "resort": 697, "automodelforsequenceclassif": 697, "val_dataset": [697, 740], "val_dataload": [697, 740], "worker": [697, 728, 731, 732, 733, 740], "ping_memori": [697, 740], "formul": 697, "effort": 697, "written": 697, "onnxrt_integ": [697, 751], "onnxrt_qlinear": [697, 751], "image_tensor": [697, 751], "post_training_dynamic_qu": [697, 739, 749], "1000": [697, 727, 751], "2000": 697, "sampling_s": [697, 751], "model_wis": [697, 751], "op_dict": 697, "op_wis": [697, 747, 751], "sigopt_api_token": [697, 745, 749], "sigopt_project_id": [697, 745, 749], "sigopt_experiment_nam": [697, 745, 749], "demo": 697, "600": [697, 752], "training_arg": 697, "emul": [697, 740], "trainer": [697, 709], "briefli": [697, 746], "maxim": [697, 737, 749], "pruning_func": 697, "train_dataload": [697, 737, 740], "n_gpu": 697, "gradient_accumulation_step": 697, "clip_grad_norm_": 697, "max_grad_norm": 697, "start_epoch": [697, 739, 751], "end_epoch": [697, 739, 751], "newli": [697, 737], "on_after_optimizer_step": [697, 737], "layer3": [697, 737], "0004": 697, "nesterov": [697, 751], "randomresizedcrop": [697, 748], "totensor": [697, 748], "485": 697, "456": 697, "406": [697, 752], "nepoch": 697, "cnt": 697, "loss_sum": 697, "iter_bar": 697, "desc": 697, "teacher_logit": 697, "train_fun": 697, "training_func": 697, "recent": [697, 698], "growth": [697, 698, 700, 737], "significantli": [697, 698, 721, 723, 737, 749], "bandwidth": [697, 698, 743], "exit_polici": [697, 751], "determinist": 697, "meaning": [697, 736], "reli": [697, 746], "prune_conf": 697, "quantization_aware_training_conf": 697, "aforement": 697, "inset": 697, "p_conf": [697, 736], "ssd_mobilenet_v1": 697, "benchmarkconf": 697, "sixteen": 698, "launch": [698, 719, 724], "3rd": [698, 738, 740, 742], "boost": [698, 702, 718, 737, 738], "x86": 698, "avx512": [698, 740], "vcvtne2ps2bf16": 698, "vcvtneps2bf16": 698, "vdpbf16p": 698, "fbgemm": [698, 740], "tensorrtexecutionprovid": [698, 740], "cudaexecutionprovid": [698, 740], "dnnlexecutionprovid": [698, 740], "avx512_bf16": 698, "plu": 698, "persist": 699, "brought": [699, 702, 709, 740], "tf2": 699, "h5": 699, "hybridblock": 699, "saved_result": [699, 722, 743], "breakthrough": 700, "emerg": [700, 746], "analysi": [700, 701, 718, 737, 745], "chatbot": [700, 738], "fuel": 700, "nevertheless": 700, "challeng": [700, 741], "explos": 700, "pose": [700, 741], "obstacl": 700, "practic": 700, "promot": 700, "msfp": 700, "mxfp8": 700, "e5m2": 700, "e8m0": 700, "e4m3": 700, "mxfp6": 700, "fp6": 700, "e3m2": 700, "e2m3": 700, "mxfp4": 700, "e2m1": [700, 743], "mxint8": 700, "occupi": 700, "incur": 700, "energi": 700, "cost": [700, 740, 743], "silicon": 700, "seamlessli": [700, 725, 737, 749], "meticul": 700, "craft": 700, "empow": 700, "sacrif": [700, 738], "distinct": 700, "consumpt": [700, 746], "expon": 700, "floor": 700, "log2": 700, "10005": [700, 741], "mxquantconfig": 700, "w_dtype": 700, "user_model": 700, "darvish": 700, "rouhani": 700, "bita": 700, "narrow": 700, "inferenc": 700, "10271": 700, "10281": 700, "ocp": 700, "10537": 700, "simplifi": [701, 712, 718, 737, 738], "acquir": 701, "heurist": [701, 718], "great": 701, "autocast": 701, "my_model": 701, "no_grad": 701, "memory_format": 701, "112": 701, "plugin": [701, 719], "aw": [701, 709, 728, 738, 752], "sagemak": [701, 709], "neural_cod": [701, 703, 705, 706, 707, 709], "bench": 701, "superbench": 701, "enjoi": [702, 706, 709], "modern": [703, 743], "democrat": [703, 738], "programm": [703, 709, 718], "nano_bf16_channels_last": 703, "nano_bf16_ipex_channels_last": 703, "nano_bf16_ipex": 703, "nano_bf16": 703, "nano_fp32_channels_last": 703, "nano_fp32_ipex_channels_last": 703, "nano_fp32_ipex": 703, "nano_gpu_to_cpu": 703, "nano_int8": 703, "nano_jit_bf16_channels_last": 703, "nano_jit_bf16_ipex_channels_last": 703, "nano_jit_bf16_ipex": 703, "nano_jit_bf16": 703, "nano_jit_fp32_channels_last": 703, "nano_jit_fp32_ipex_channels_last": 703, "nano_jit_fp32_ipex": 703, "nano_jit_fp32": 703, "nano_onnxruntime_fp32": 703, "nano_onnxruntime_int8_qlinear": 703, "openvino": 703, "nano_openvino_fp32": 703, "nano_openvino_int8": 703, "bc": [704, 712], "conda_prefix": 704, "echo": 704, "tradit": [704, 737], "libjemalloc": 704, "libiomp5": 704, "home": 704, "lib": 704, "ld_preload": 704, "malloc_conf": 704, "oversize_threshold": 704, "background_thread": 704, "metadata_thp": 704, "dirty_decay_m": 704, "9000000000": 704, "muzzy_decay_m": 704, "kmp_affin": 704, "kmp_blocktim": 704, "dnnl_primitive_cache_capac": 704, "governor": 704, "scaling_governor": 704, "powersav": 704, "tee": 704, "pytorch_jit_script": [705, 708], "pytorch_channels_last": [705, 708], "run_bench": 705, "patch": [705, 718], "patch_path": 705, "your_patch_path": 705, "sweep": 705, "sweep_object": 705, "bench_config": 705, "bench_featur": 705, "sai": 706, "run_glu": [706, 707, 729, 732, 733], "requisit": 706, "task_nam": [706, 707, 729, 732, 733], "do_ev": [706, 707, 722, 729, 732, 733], "itself": [706, 737], "run_glue_optim": 706, "static_ipex": 706, "auto_qu": 707, "v4": [707, 729, 732, 733, 752], "albert": [707, 752], "sst2": 707, "alexnet": [707, 752], "pytorch_amp": 708, "optimize_for_infer": 708, "pytorch_jit_trac": 708, "pytorch_jit_script_ofi": 708, "pytorch_jit_trace_ofi": 708, "torchdynamo": 708, "pytorch_torchdynamo_jit_script": 708, "pytorch_torchdynamo_jit_trac": 708, "pytorch_torchdynamo_jit_script_ofi": 708, "pytorch_torchdynamo_jit_trace_ofi": 708, "pytorch_inc_bf16": 708, "pytorch_inc_static_quant_fx": 708, "pytorch_inc_static_quant_ipex": 708, "pytorch_inc_static_quant_ipex_xpu": 708, "pytorch_inc_dynamic_qu": 708, "pytorch_ipex_fp32": 708, "pytorch_ipex_bf16": 708, "pytorch_ipex_int8_static_qu": 708, "pytorch_ipex_int8_dynamic_qu": 708, "blade": 708, "disc": 708, "pytorch_aliblad": 708, "pytorch_lightning_bf16_cpu": 708, "tensorflow_amp": 708, "keras_amp": 708, "tensorflow_inc": 708, "keras_inc": 708, "onnx_inc_static_quant_qlinear": 708, "onnx_inc_static_quant_qdq": 708, "onnx_inc_dynamic_qu": 708, "pytorch_inc_huggingface_optimum_stat": 708, "pytorch_inc_huggingface_optimum_dynam": 708, "intel_extension_for_transform": 708, "bigdl": [708, 709], "nano": [708, 709], "nano_": 708, "inc_auto": 708, "delight": 709, "announc": 709, "v": [709, 718, 737, 749, 751], "500": [709, 727], "jupyt": [709, 711, 712, 715], "isa": 709, "adjust": [709, 740, 746], "delta": 709, "acc_delta": 709, "int8_acc": 709, "fp32_acc": 709, "ext": [711, 713, 715, 716, 717], "lab": [711, 712, 713, 715, 716], "nodej": [711, 715], "jlpm": [711, 715], "yarn": [711, 715], "npm": [711, 712, 715], "lieu": [711, 715], "labextens": [711, 712, 715], "typescript": [711, 715], "watch": [711, 715, 724], "immedi": [711, 715, 737], "refresh": [711, 715], "browser": [711, 715, 720, 724], "wait": [711, 715, 718, 728], "rebuilt": [711, 715], "easier": [711, 715, 718, 720, 738], "symlink": [711, 715], "down": 712, "finish": [712, 728], "blank": 712, "cell": 712, "gain": [712, 736, 738], "mkl": 712, "jemalloc": 712, "pip3": 712, "pyproject": [713, 716], "toml": [713, 716], "twine": [713, 716], "whl": [713, 716], "dist": [713, 716], "sdist": [713, 716], "bdist_wheel": [713, 716], "frontend": [713, 716, 726, 733], "cut": [713, 716], "admin_github_token": [713, 716], "pypi_token": [713, 716], "npm_token": [713, 716], "secret": [713, 716], "panel": [713, 716, 718], "draft": [713, 716], "changelog": [713, 716, 717], "pkg": [713, 716], "bot": [713, 716], "pick": [713, 716, 719], "feedstock": [713, 716], "hatch": 716, "notabl": 717, "daili": 718, "advantag": [718, 737, 739, 749], "remot": 718, "server": [718, 720, 723, 726, 731, 732, 733], "re": [718, 724, 743], "market": 718, "uninstal": 718, "fill": [718, 745, 748, 749], "upper": 718, "sidebar": 718, "hover": 718, "track": [718, 745], "argpars": 718, "pop": [718, 728], "diff": 718, "manifest": 719, "palett": 719, "registercommand": 719, "amodio": 719, "tsl": 719, "matcher": 719, "dbaeumer": 719, "eslint": [719, 724], "press": 719, "f5": 719, "ctrl": 719, "hello": 719, "world": 719, "breakpoint": 719, "consol": [719, 724], "relaunch": 719, "toolbar": 719, "node_modul": 719, "viewlet": 719, "dropdown": 719, "runner": [719, 724], "startup": 719, "bundl": 719, "neural_insight": [720, 722, 723], "tl": 720, "ui": 720, "12": [720, 752], "5000": 720, "338174d13706855fc6924cec7b3a8ae8": 720, "listen": 720, "firewal": 720, "8080": 720, "cert": 720, "path_to_cert": 720, "crt": 720, "path_to_private_kei": 720, "encrypt": 720, "expos": 720, "forfeit": 720, "client": [720, 726, 733], "extern": 720, "threat": 720, "diagnost": 720, "skill": 720, "feel": [720, 724], "layoutlmv3": [721, 752], "seqev": 721, "sentencepiec": 721, "timm": 721, "fvcore": 721, "pillow": 721, "einop": 721, "textdist": 721, "setuptool": 721, "cli": 721, "hypjudi": 721, "finetun": [721, 737, 743], "funsd": [721, 752], "calib_dataset": 721, "incdataset": 721, "eval_dataset": 721, "poor": [721, 747], "9049": 721, "2989": 721, "66": [721, 752], "9631": 721, "glob": 721, "panda": 721, "pd": 721, "set_opt": 721, "max_row": 721, "max_column": 721, "getmtim": 721, "activations_t": 721, "weights_tabl": [721, 722], "read_csv": 721, "nweight": 721, "descend": 721, "sorted_data": 721, "sort_valu": 721, "ascend": 721, "evid": 721, "tip": 721, "8981": 721, "7502": 721, "run_clm": 722, "wikitext": [722, 752], "dataset_config_nam": 722, "do_train": 722, "inspect_sav": 722, "inspect_result": 722, "quan": 722, "model_summari": 722, "incept": [723, 752], "v3": [723, 752], "inception_v3": [723, 747], "inceptionv3_fp32_pretrained_model": [723, 747], "prepare_dataset": 723, "sh": [723, 747], "raw_dir": 723, "img_raw": 723, "delet": [723, 737], "run_tun": 723, "nc_inception_v3": 723, "highest": [723, 729, 749], "satisfactori": 723, "webpag": 723, "spike": 723, "bottom": 723, "chart": [723, 740, 745, 747], "concentr": 723, "But": 723, "bigger": 723, "bootstrap": 724, "localhost": [724, 726, 731, 732], "3000": 724, "lint": 724, "interact": [724, 745], "correctli": 724, "hash": [724, 727], "readi": [724, 737], "aren": 724, "transit": 724, "webpack": 724, "babel": 724, "tweak": 724, "ever": 724, "curat": 724, "suitabl": 724, "middl": [724, 746], "shouldn": 724, "understand": [724, 740, 747, 750], "wouldn": 724, "couldn": 724, "troubleshoot": 724, "effortlessli": 725, "grpc": [725, 726, 730, 731, 732, 734], "queue": 725, "mpi": [725, 726, 749], "neural_solut": [725, 726, 731, 732, 733], "task_monitor_port": [726, 731, 732, 733], "22222": [726, 731, 732, 733], "result_monitor_port": [726, 731, 732, 733], "33333": [726, 731, 732, 733], "restful_api_port": [726, 731, 732, 733], "hostfil": [726, 728, 731, 732, 733], "grpc_api_port": [726, 731, 732, 733], "api_typ": [726, 731, 732, 733], "conda_env": [726, 731, 732, 733], "upload_path": [726, 731, 732, 733], "8000": [726, 731, 732, 733], "3333": [726, 731, 732, 733], "2222": [726, 731, 732, 733], "ns_workspac": [726, 731, 732, 733], "hf_model": [726, 730, 732, 733], "curl": [726, 727, 731, 732], "task_id": [726, 731, 732, 733], "usernam": 726, "db": [726, 728], "serve_log": [726, 731, 732, 733], "frontend_grpc": 726, "task_log": 726, "task_bdf0bd1b2cc14bc19bce12d4f9b333c7": 726, "task_workspac": 726, "bdf0bd1b2cc14bc19bce12d4f9b333c7": 726, "aliv": 726, "commonli": [726, 737], "hostnam": 726, "breakdown": 726, "ip": 726, "hous": 726, "host1": [726, 731, 732], "host2": [726, 731, 732], "query_id": 726, "oaa": 727, "host_ip": 727, "task_request": [727, 731, 732, 733], "tuning_info": [727, 731], "optimization_result": [727, 731], "result_path": [727, 731, 732], "closur": 727, "404": [727, 737, 752], "health": 727, "healthi": 727, "400": 727, "alloc": 728, "incom": 728, "taskmonitor": 728, "cluster": [728, 731, 732, 749], "tasklaunch": 728, "resultmonitor": 728, "receiv": [728, 745], "p1": 728, "notif": 728, "p2": 728, "p3": 728, "mpirun": [728, 749], "perf": 728, "p4": 728, "four": [728, 747, 752], "classdiagram": 728, "taskdb": 728, "get_statu": 728, "update_statu": 728, "task_collect": 728, "append_task": 728, "get_all_pending_task": 728, "update_task_statu": 728, "task_db": 728, "wait_new_task": 728, "schedule_task": 728, "dispatch_task": 728, "launch_task": 728, "query_task_statu": 728, "node_list": 728, "reserve_resourc": 728, "get_node_statu": 728, "gcp": [728, 738], "script_url": [729, 731, 732, 733], "archiv": 729, "tf_example1": [730, 731, 732], "hf_models_grpc": [730, 733], "00173": 731, "01024": 731, "task_request_distribut": 731, "custom_models_optim": 731, "7602cd63d4c849e7a686a8165a77f69d": [731, 732], "151": 731, "8617": 731, "8213": [731, 752], "number_of_socket": [731, 732], "number_of_thread": [731, 732], "cdf419910f9b4d2a8320d0e420ac1d0a": 732, "optimized_result": 732, "3162": 732, "6488": [732, 752], "06": [733, 751, 752], "d3e10a49326449fb9d0d62f2bfc1cb43": 733, "fastapi": 734, "multi_object": 735, "benefit": 736, "instanti": 736, "neuron": 737, "art": 737, "grown": 737, "unpreced": 737, "increasingli": 737, "crucial": 737, "stand": [737, 749], "shrink": 737, "contextu": 737, "scene": 737, "haven": 737, "color": [737, 741], "lowest": [737, 749], "formula": [737, 746], "emsp": 737, "downstream": 737, "prone": 737, "co": 737, "discourag": 737, "penal": 737, "parameter": 737, "lightweight": 737, "perceptron": 737, "mlp": 737, "valuabl": [737, 747], "basi": 737, "billion": 737, "mpt": [737, 746, 752], "lm": 737, "lamini": [737, 746], "mention": [737, 743], "tend": 737, "exemplifi": 737, "complement": 737, "fortieth": 737, "miss": [737, 740], "pruner2": 737, "few": [737, 738, 746, 749], "lm_head": 737, "yourself": 737, "uncertain": 737, "auto_config": 737, "quit": 737, "straightforward": [737, 743, 746], "pruning_pattern": 737, "pruning_start": 737, "pruning_end": 737, "sparse_gpt": 737, "embed_out": 737, "card": 737, "hesit": 737, "causal": 737, "clm": 737, "sst": [737, 752], "63": [737, 752], "flan": 737, "t5": 737, "english": 737, "romanian": 737, "381": 737, "yolov5": 737, "2x1": [737, 752], "801": 737, "7895": 737, "signific": [737, 738, 741, 746], "reduct": [737, 741, 751], "namhoon": 737, "lee": 737, "thalaiyasingam": 737, "ajanthan": 737, "philip": 737, "torr": 737, "2019": 737, "zafrir": 737, "ofir": 737, "ariel": 737, "larei": 737, "boudoukh": 737, "mosh": 737, "wasserblat": 737, "2111": 737, "05754": 737, "2021": 737, "kwon": 737, "kim": 737, "mahonei": 737, "hassoun": 737, "keutzer": 737, "gholami": 737, "pp": 737, "24101": 737, "24116": 737, "frantar": [737, 743], "alistarh": 737, "apr": 738, "medium": 738, "aug": 738, "juli": 738, "onnxcommunitymeetup2023": 738, "june": 738, "msft": 738, "netflix": 738, "mlperf": [738, 752], "5x": 738, "\u96c6\u6210\u82f1\u7279\u5c14": 738, "\u817e\u8baf\u4e91taco": 738, "kit\u4e3aai\u5e94\u7528\u5e26\u6765\u9ad8\u6548\u5f02\u6784\u52a0\u901f\u670d\u52a1": 738, "mar": 738, "heterogen": 738, "jan": 738, "busi": 738, "amx": 738, "journei": 738, "dec": 738, "mleffici": 738, "deepen": 738, "foundat": 738, "intellig": 738, "vmware": 738, "applianc": 738, "bitnami": 738, "nov": 738, "neurip": 738, "quala": 738, "minilm": [738, 752], "plug": 738, "twitter": 738, "linkedin": 738, "zone": 738, "land": 738, "pat": 738, "keynot": 738, "intelon": 738, "chines": 738, "purif": 738, "jun": 738, "partner": 738, "feb": 738, "joint": 738, "bilibili": 738, "gestalt": 738, "ml": 738, "youtub": 738, "doubl": 738, "abound": 738, "lpot": [738, 744], "nextplatform": 738, "cern": 738, "gan": 738, "3dgan": 738, "iml": 738, "workshop": 738, "asplo": 738, "18": [738, 752], "highli": [738, 743], "intelcaff": 738, "aris": 739, "henc": 739, "onnxrt_qoper": 739, "quant_aware_train": 739, "weight_compress": [739, 751], "initial_spars": [739, 751], "prune_typ": [739, 751], "basic_magnitud": [739, 751], "update_frequ": 739, "prune_domain": 739, "tile_pattern_1x1": 739, "invent": 740, "On": [740, 752], "theoret": [740, 743], "zeropoint": 740, "255": [740, 746], "overflow": 740, "unseen": 740, "peopl": 740, "mimic": 740, "fact": 740, "ultim": 740, "pain": 740, "lossi": 740, "philosophi": 740, "neither": 740, "nor": 740, "val_load": 740, "avg": 740, "themselv": 740, "dmlexecutionprovid": 740, "meanwhil": 741, "substanti": 741, "greatli": [741, 743], "even": [741, 743, 746], "constrain": 741, "grei": 741, "blue": 741, "rectangl": 741, "w8a8": [741, 743], "rtn_arg": [741, 743], "ouput_dir": 741, "fp32_model_path": 741, "int8_model_path": 741, "ON": 742, "forc": 742, "postposttrainingquantconfig": 742, "bf16wrapper": 742, "retrac": 742, "preval": 743, "grow": 743, "demand": 743, "trade": 743, "bottleneck": 743, "roughli": 743, "speak": 743, "capac": [743, 745], "flop": 743, "famou": 743, "approx": 743, "bmm": 743, "100x": 743, "excel": 743, "stai": [743, 746], "quantif": [743, 746], "think": 743, "intuit": [743, 746], "uniformli": 743, "qlora": 743, "invers": 743, "restor": 743, "protect": 743, "inspir": 743, "c_": 743, "normalfloat": 743, "bnb": 743, "805": 743, "awq_arg": 743, "gptq_arg": 743, "mitig": 743, "weightonlylinear": 743, "date": 743, "sym_full_rang": 743, "qweight_config_path": 743, "gptq_config_path": 743, "gptq_config": 743, "use_full_length": 743, "compressed_model": 743, "omit": 743, "rtn_g32asym": 743, "gptq_g32asym": 743, "gptq_g32asym_disable_last_matmul": 743, "gptq_g128asym": 743, "awq_g32asym": 743, "xiao": [743, 746], "guangxuan": [743, 746], "2211": [743, 746], "10438": [743, 746], "wei": [743, 746], "xiui": [743, 746], "suppress": [743, 746], "2209": [743, 746, 752], "13325": [743, 746], "lin": 743, "ji": 743, "00978": 743, "elia": 743, "dettmer": 743, "tim": 743, "2305": 743, "14314": 743, "site": 744, "sed": 744, "your_script": 744, "backbon": 745, "sigopt_experiment_id": 745, "nc": [745, 749], "suffici": 745, "ordinari": 745, "latenc": [745, 749], "8266": 745, "8372": 745, "2132": 745, "83": [745, 746, 752], "7495": 745, "8299": 745, "8294": 745, "85": [745, 746, 752], "0837": 745, "8291": 745, "4469": 745, "gigant": 746, "systemat": 746, "migrat": [746, 750], "difficulti": 746, "mathemat": 746, "allevi": 746, "coarsest": 746, "finer": [746, 749], "matric": 746, "similarli": 746, "finest": 746, "why": [746, 747], "suppos": 746, "6839": 746, "4741": 746, "7451": 746, "9301": 746, "1742": 746, "6835": 746, "q_min": 746, "q_max": 746, "q_x": 746, "clamp_": 746, "round_": 746, "w_q": 746, "00296431384049356": 746, "172": [746, 752], "192": 746, "w_dq": 746, "2220": 746, "1510": 746, "2420": 746, "2570": 746, "0500": 746, "1890": 746, "mseloss": 746, "1983354538679123": 746, "6848": 746, "4743": 746, "7440": 746, "9308": 746, "1749": 746, "385297635664756e": 746, "07": [746, 751, 752], "quantize_per_channel": 746, "x_tmp": 746, "detach": 746, "keepdim": 746, "dequantize_per_channel": 746, "0029": [746, 752], "0036": 746, "162": [746, 752], "48": [746, 752], "93": [746, 752], "207": [746, 752], "139": [746, 752], "6837": 746, "4734": 746, "1751": 746, "6821": 746, "637690492221736e": 746, "6376e": 746, "3852e": 746, "cdot": 746, "quantize_per_tensor_absmax": 746, "n_bit": 746, "div_": 746, "0806": 746, "7589": 746, "6038": 746, "3815": 746, "5040": 746, "7174": 746, "5444": 746, "5826": 746, "7772": 746, "5555": 746, "3740": 746, "3253": 746, "0698": 746, "1381": 746, "5972": [746, 752], "0737": 746, "8298": 746, "6883": 746, "2991": 746, "1601": 746, "6506": 746, "8246": 746, "3924": 746, "3845": 746, "8768": 746, "w_scale": 746, "x_q": 746, "x_scale": 746, "120": 746, "0059755356051027775": 746, "119": 746, "006533813662827015": 746, "y_q": 746, "17509": 746, "7608": 746, "4055": 746, "16599": 746, "21020": 746, "10016": 746, "9860": 746, "22444": 746, "y_dq": 746, "6836": 746, "2970": 746, "1583": 746, "6481": 746, "8207": 746, "3911": 746, "3850": 746, "8763": 746, "though": 746, "simplic": 746, "denot": 746, "fp1": 746, "fp2": 746, "subsect": [746, 751], "x1": [746, 749], "x2": [746, 749], "herebi": 746, "optdecoderlay": 746, "blockwis": 746, "waq": 746, "overhead": 746, "hardtanh": 746, "t5norm": 746, "llamanorm": 746, "groupnorm": 746, "lambada": 746, "openai": 746, "sweet": 746, "spot": 746, "560m": 746, "354": 746, "3542": 746, "4634": 746, "4936": 746, "518": 746, "5185": 746, "7b1": [746, 752], "5764": [746, 752], "5977": 746, "bloomz": [746, 752], "3947": 746, "3930": 746, "4828": 746, "4906": 746, "5018": 746, "4980": 746, "5593": [746, 752], "5552": 746, "379": 746, "3757": 746, "350m": 746, "4516": 746, "4533": 746, "5789": 746, "5742": 746, "6365": 746, "6404": 746, "6769": [746, 752], "6804": [746, 752], "6872": 746, "6814": 746, "7149": 746, "7128": 746, "66b": 746, "7398": 746, "7326": 746, "7361": [746, 752], "7357": 746, "7627": [746, 752], "7590": 746, "7759": [746, 752], "7840": 746, "65b": 746, "7908": 746, "7957": 746, "7392": [746, 752], "7335": 746, "7058": [746, 752], "6994": 746, "7677": [746, 752], "7615": [746, 752], "6831": [746, 752], "mbzuai": 746, "124m": 746, "3804": 746, "3887": 746, "774m": 746, "5048": 746, "5057": 746, "5b": 746, "5443": [746, 752], "5436": 746, "mosaicml": [746, 752], "655": [746, 752], "6499": 746, "stabilityai": 746, "stablelm": 746, "4172": 746, "4149": 746, "togethercomput": 746, "redpajama": 746, "incit": 746, "6542": 746, "6735": 746, "6718": 746, "6740": [746, 752], "6569": 746, "6621": 746, "7143": 746, "7221": 746, "6895": 746, "6953": [746, 752], "6866": [746, 752], "6297": 746, "6247": 746, "6437": [746, 752], "6392": 746, "7332": 746, "7632": 746, "asterisk": 746, "consider": 746, "arang": 746, "tolist": 746, "default_alpha": 746, "step_siz": 746, "shared_criterion": 746, "do_blockwis": 746, "jason": 746, "transact": 746, "yvinec": 746, "edouard": 746, "proceed": 746, "cvf": 746, "winter": 746, "instrument": 747, "writer": 747, "_pre_eval_hook": 747, "_post_eval_hook": 747, "submodul": 747, "whitelist": 747, "_recordingobserv": 747, "output_tensors_dict": 747, "current_it": 747, "get_tensor_valu": 747, "_observer_forward_hook": 747, "activation_post_process": 747, "_add_observer_": 747, "named_children": 747, "leaf": 747, "add_modul": 747, "register_forward_hook": 747, "dump_tim": 747, "summarywrit": 747, "_acc": 747, "tune_": 747, "add_graph": 747, "get_observer_dict": 747, "observer_dict": 747, "is_quant": 747, "add_histogram": 747, "shell": 747, "bind_al": 747, "logdir_spec": 747, "tune_0_acc0": 747, "tune_1": 747, "tune_1_acc0": 747, "baseline_acc_0": 747, "776": 747, "tune_1_acc_0": 747, "095": 747, "runs_v3": 747, "run_tuning_dump_tensor": 747, "inceptionv3": 747, "run_quant": 747, "topologi": 747, "nc_inceptionv3": 747, "inceptionv3_dump_tensor": 747, "eightbit": 747, "disappear": 747, "centercrop": 748, "randomcrop": 748, "cropres": 748, "decodeimag": 748, "jpeg": 748, "encodejp": 748, "alignimagechannel": 748, "116": 748, "103": [748, 752], "017": 748, "bilinearimagenet": [748, 751], "topilimag": 748, "padding_mod": 748, "border": 748, "pixel": 748, "edg": 748, "colorjitt": 748, "bright": 748, "satur": 748, "hue": 748, "jitter": 748, "tondarrai": 748, "o1": 749, "human": 749, "aggress": 749, "classic": 749, "flowchart": 749, "htmllabel": 749, "td": 749, "classdef": 749, "itemstyl": 749, "cce5ff": 749, "stroke": 749, "99ccff": 749, "s1": 749, "s2": 749, "s3": 749, "s4": 749, "s5": 749, "s6": 749, "s7": 749, "nbsp": [749, 752], "subgraphstyl": 749, "ffffff": 749, "attempt": 749, "post_training_auto_qu": 749, "increment": 749, "ii": 749, "spent": 749, "hawq_v2_loss": 749, "model_loss": 749, "black": 749, "compli": 749, "posterior": 749, "short": 749, "loglevel": 749, "endlessli": 749, "perspect": 749, "smbo": 749, "appl": 749, "surrog": 749, "densiti": 749, "parzen": 749, "greatest": 749, "hour": 749, "dai": 749, "next_tune_cfg": 749, "overridden": 749, "replic": 749, "replica": 749, "fed": 749, "synchron": 749, "number_of_process": 749, "run_cmd": 749, "abctunestrategi": 749, "familiar": 750, "notebook": 750, "introduct": 750, "organ": 751, "logic": 751, "mobilenet_v1": 751, "40": [751, 752], "beta_1": 751, "beta_2": 751, "epsilon": 751, "sparsecategoricalcrossentropi": 751, "sum_over_batch_s": 751, "from_logit": 751, "1x": 752, "platinum": 752, "8480": 752, "8ghz": 752, "56": 752, "ht": 752, "turbo": 752, "256gb": 752, "16x16gb": 752, "ddr5": 752, "4800": 752, "mt": 752, "bio": 752, "3a14": 752, "tel2p1": 752, "microcod": 752, "0x2b0001b0": 752, "gcc": 752, "20210514": 752, "red": 752, "hat": 752, "visit": 752, "1s4c14ins1bsthroughput": 752, "sec": 752, "1720": 752, "582": 752, "95x": 752, "1517": 752, "570": 752, "65": 752, "66x": 752, "resnet101": 752, "41": 752, "1058": 752, "382": 752, "77x": 752, "69": 752, "2080": 752, "951": 752, "19x": 752, "1587": 752, "863": 752, "37": 752, "84x": 752, "1052": 752, "434": 752, "42x": 752, "707": 752, "234": 752, "02x": 752, "320": 752, "179": 752, "79x": 752, "4312": 752, "1512": 752, "85x": 752, "2287": 752, "1406": 752, "63x": 752, "1367": 752, "59x": 752, "vgg19": 752, "1244": 752, "176": 752, "04x": 752, "resnetv2": 752, "780": 752, "34x": 752, "494": 752, "329": 752, "50x": 752, "152": 752, "349": 752, "235": 752, "48x": 752, "densenet": 752, "161": 752, "29": 752, "282": 752, "223": 752, "26x": 752, "1284": 752, "756": 752, "70x": 752, "1280": 752, "530": 752, "cnn": 752, "39": 752, "26": 752, "178": 752, "13x": 752, "yolov3": 752, "249": 752, "64x": 752, "28x": 752, "36": 752, "05x": 752, "86": 752, "390": 752, "212": 752, "83x": 752, "vit": 752, "81": 752, "230": 752, "142": 752, "62x": 752, "1989": 752, "31x": 752, "1165": 752, "303": 752, "953": 752, "302": 752, "15x": 752, "resnest50": 752, "365": 752, "21x": 752, "resnext101_32x8d": 752, "548": 752, "104": 752, "27x": 752, "efficientnet_b0": 752, "636": 752, "62": 752, "566": 752, "12x": 752, "efficientnet_b3": 752, "471": 752, "358": 752, "32x": 752, "peleenet": 752, "790": 752, "504": 752, "57x": 752, "yolo": 752, "137": 752, "88x": 752, "175": 752, "23x": 752, "camembert": 752, "393": 752, "174": 752, "783": 752, "344": 752, "684": 752, "99x": 752, "312": 752, "155": 752, "60": 752, "01x": 752, "funnel": 752, "281": 752, "395": 752, "173": 752, "373": 752, "405": 752, "30x": 752, "stsb": 752, "396": 752, "136": 752, "377": 752, "17x": 752, "391": 752, "25x": 752, "135": 752, "61x": 752, "117": 752, "93x": 752, "lvwerra": 752, "pegasu": 752, "samsum": 752, "1981": 752, "598": 752, "1095": 752, "298": 752, "67x": 752, "549": 752, "29x": 752, "375": 752, "hellaswag": 752, "winogrand": 752, "piqa": 752, "word_perplex": 752, "4954": 752, "6409": 752, "7541": 752, "6434": 752, "8816": 752, "gptqw4g128asym": 752, "679": 752, "4895": 752, "6433": 752, "7476": 752, "6399": 752, "9945": 752, "0999": 752, "gptqw4g32asym": 752, "6829": 752, "4923": 752, "6401": 752, "7486": 752, "6410": 752, "0141": 752, "gptqw4g128sym": 752, "685": 752, "4907": 752, "6361": 752, "7443": 752, "6390": 752, "1498": 752, "gptqw4g32sym": 752, "6911": 752, "4899": 752, "6448": 752, "7497": 752, "6439": 752, "0008": 752, "0927": 752, "5049": 752, "6543": 752, "7628": 752, "6497": 752, "2862": 752, "4984": 752, "6535": 752, "7568": 752, "6473": 752, "4193": 752, "6885": 752, "4973": 752, "753": 752, "6455": 752, "9935": 752, "4607": 752, "decapoda": 752, "5642": 752, "6709": 752, "7835": 752, "6887": 752, "4202": 752, "7244": 752, "5603": 752, "6614": 752, "6824": 752, "9909": 752, "5881": 752, "5911": 752, "7009": 752, "7878": 752, "7106": 752, "7518": 752, "5843": 752, "6961": 752, "7911": 752, "4319": 752, "7572": 752, "5898": 752, "7056": 752, "7894": 752, "7105": 752, "9998": 752, "3429": 752, "7596": 752, "5841": 752, "6977": 752, "7905": 752, "7080": 752, "4916": 752, "6266": 752, "7277": 752, "8096": 752, "7350": 752, "2384": 752, "778": 752, "624": 752, "7269": 752, "8047": 752, "7334": 752, "9979": 752, "4237": 752, "7706": 752, "6239": 752, "7285": 752, "8058": 752, "7322": 752, "4697": 752, "7836": 752, "6195": 752, "7337": 752, "9983": 752, "5604": 752, "5732": 752, "648": 752, "7715": 752, "6746": 752, "7107": 752, "6982": 752, "5637": 752, "6527": 752, "7704": 752, "6713": 752, "9950": 752, "9702": 752, "5682": 752, "6575": 752, "7758": 752, "6742": 752, "9994": 752, "9317": 752, "567": 752, "6902": 752, "7353": 752, "6622": 752, "7829": 752, "6862": 752, "9635": 752, "7246": 752, "5617": 752, "6756": 752, "7797": 752, "6854": 752, "9931": 752, "2799": 752, "7312": 752, "6059": 752, "7103": 752, "7077": 752, "2213": 752, "7273": 752, "6018": 752, "7088": 752, "7742": 752, "7030": 752, "9934": 752, "2538": 752, "083": 752, "7283": 752, "6053": 752, "7024": 752, "7764": 752, "7031": 752, "1889": 752, "374": 752, "727": 752, "5997": 752, "7018": 752, "9916": 752, "2504": 752, "497": 752, "7122": 752, "8984": 752, "5933": 752, "689": 752, "7851": 752, "7075": 752, "1556": 752, "448": 752, "7675": 752, "5934": 752, "7856": 752, "7111": 752, "9984": 752, "1514": 752, "927": 752, "7566": 752, "5899": 752, "7032": 752, "9953": 752, "1374": 752, "728": 752, "4628": 752, "6456": 752, "6029": 752, "6438": 752, "5799": 752, "4542": 752, "6004": 752, "9957": 752, "0626": 752, "4789": 752, "6134": 752, "7432": 752, "5525": 752, "4731": 752, "6504": 752, "7617": 752, "6094": 752, "7828": 752, "5098": 752, "7622": 752, "6505": 752, "3242": 752, "6878": 752, "5058": 752, "6393": 752, "7633": 752, "6491": 752, "9978": 752, "5514": 752, "6864": 752, "5084": 752, "6519": 752, "6509": 752, "0006": 752, "4728": 752, "6876": 752, "5045": 752, "6474": 752, "9952": 752, "6379": 752, "5282": 752, "614": 752, "7448": 752, "6312": 752, "6377": 752, "5228": 752, "5991": 752, "6261": 752, "4096": 752, "6224": 752, "4271": 752, "577": 752, "722": 752, "5871": 752, "9359": 752, "6123": 752, "4227": 752, "5738": 752, "7203": 752, "5823": 752, "9917": 752, "3377": 752, "615": 752, "4259": 752, "5714": 752, "7247": 752, "9951": 752, "2083": 752, "6154": 752, "4208": 752, "5777": 752, "7198": 752, "5834": 752, "9937": 752, "3121": 752, "7233": 752, "5359": 752, "7753": 752, "195": 752, "7186": 752, "5328": 752, "7699": 752, "6687": 752, "9922": 752, "3463": 752, "7268": 752, "533": 752, "659": 752, "6726": 752, "2897": 752, "5718": 752, "6859": 752, "7927": 752, "6890": 752, "9324": 752, "7006": 752, "5655": 752, "6803": 752, "7965": 752, "6857": 752, "1515": 752, "5752": 752, "6748": 752, "7845": 752, "6724": 752, "5951": 752, "6472": 752, "5716": 752, "6685": 752, "784": 752, "6678": 752, "8539": 752, "6918": 752, "5819": 752, "678": 752, "6861": 752, "8863": 752, "5765": 752, "6827": 752, "7873": 752, "6832": 752, "9958": 752, "1451": 752, "storywrit": 752, "693": 752, "5477": 752, "663": 752, "6719": 752, "9125": 752, "6661": 752, "7813": 752, "6693": 752, "1137": 752, "rw": 752, "6604": 752, "5419": 752, "6598": 752, "6594": 752, "7616": 752, "6484": 752, "5369": 752, "7807": 752, "6559": 752, "9947": 752, "9411": 752, "6571": 752, "5398": 752, "6582": 752, "6579": 752, "8809": 752, "652": 752, "535": 752, "7682": 752, "6532": 752, "9906": 752, "0048": 752, "5177": 752, "6669": 752, "7824": 752, "5053": 752, "6301": 752, "5142": 752, "6654": 752, "6483": 752, "9933": 752, "8146": 752, "517": 752, "9941": 752, "1666": 752, "734": 752, "1658": 752, "1495": 752, "733": 752, "1661": 752, "732": 752, "1713": 752, "767": 752, "1747": 752, "770": 752, "7519": 752, "4430": 752, "4413": 752, "72x": 752, "7190": 752, "4019": 752, "613": 752, "170": 752, "611": 752, "186": 752, "619": 752, "184": 752, "36x": 752, "623": 752, "5711": 752, "2584": 752, "6136": 752, "2630": 752, "33x": 752, "shufflenet": 752, "6820": 752, "3686": 752, "googlenet": 752, "1971": 752, "1120": 752, "76x": 752, "1838": 752, "1142": 752, "squeezenet": 752, "10163": 752, "5771": 752, "10339": 752, "6002": 752, "caffenet": 752, "2805": 752, "1077": 752, "60x": 752, "4351": 752, "822": 752, "2169": 752, "893": 752, "43x": 752, "2232": 752, "841": 752, "65x": 752, "zfnet": 752, "921": 752, "525": 752, "75x": 752, "925": 752, "534": 752, "73x": 752, "1862": 752, "1161": 752, "1956": 752, "1262": 752, "55x": 752, "efficientnet": 752, "2793": 752, "1383": 752, "beit": 752, "206": 752, "91x": 752, "duc": 752, "74x": 752, "ultra": 752, "8780": 752, "1920": 752, "emot": 752, "ferplu": 752, "6360": 752, "3067": 752, "07x": 752, "arcfac": 752, "449": 752, "511": 752, "222": 752, "18x": 752, "integerop": 752, "635": 752, "1324": 752, "244": 752, "47x": 752, "440": 752, "214": 752, "06x": 752, "715": 752, "201": 752, "03x": 752, "714": 752, "213": 752, "339": 752, "58x": 752, "215": 752, "89x": 752, "712": 752, "217": 752, "l12": 752, "h384": 752, "1209": 752, "588": 752, "1268": 752, "16x": 752, "1253": 752, "399": 752, "14x": 752, "l6": 752, "1139": 752, "94x": 752, "2365": 752, "08x": 752, "718": 752, "35x": 752, "electra": 752, "discrimin": 752, "1951": 752, "71x": 752, "2198": 752, "1129": 752, "mini": 752, "5814": 752, "3388": 752, "6396": 752, "3445": 752, "86x": 752, "bart": 752, "126": 752, "spanbert": 752, "multilingu": 752, "82x": 752, "118": 752, "46x": 752, "layoutlmv2": 752, "perplex": 752, "2788": 752, "7002": 752, "4124": 752, "9921": 752, "3950": 752, "9892": 752, "9163": 752, "7240": 752, "9902": 752, "0438": 752, "7634": 752, "1186": 752, "9944": 752, "1276": 752, "7543": 752, "6181": 752, "rtnw4g32asym": 752, "6496": 752, "9967": 752, "7964": 752, "6612": 752, "rtnw4g32sym": 752, "7941": 752, "7243": 752, "9971": 752, "taskdataset": 752, "accuracyspars": 752, "ratiospars": 752, "commentsbalancedor": 752, "unbalanc": 752, "answeringsquad": 752, "87f1": 752, "momentumunbalanc": 752, "momentumbalanc": 752, "90f1": 752, "59f1": 752, "23f1": 752, "classificationmrpc": 752, "52f1": 752, "26f1": 752, "classificationsst": 752, "61accuraci": 752, "recognitionimagenet": 752, "95top1": 752, "v5s6": 752, "detectioncoco": 752, "ap0": 752, "6ap0": 752, "584": 752, "34f1": 752, "lassounbalanc": 752, "classificationmnli": 752, "mm": 752, "allbalanc": 752, "32accuraci": 752, "sensitivitybalanc": 752, "classificationqqp": 752, "classificationqnli": 752, "54accuraci": 752, "em": 752, "mobilenetv2": 752, "wideresnet40": 752, "9522": 752, "8178": 752, "0213": 752, "8235": 752, "027": 752, "5494": 752, "7153": 752, "5540": 752, "5523": 752, "vgg": 752, "bn": 752, "7022": 752, "7415": 752, "7025": 752, "6739": 752, "7399": 752, "6845": 752, "0106": 752, "blendcnn": 752, "7034": 752, "8382": 752, "bilstm": 752, "8314": 752, "9403": 752, "9048": 752, "0734": 752, "7323": 752, "8256": 752, "8084": 752, "8814": 752, "7442": 752, "8371": 752, "0119": 752, "0115": 752, "tinybert": 752, "8018": 752, "8044": 752, "8363": 752, "8411": 752, "8025": 752, "8074": 752, "0007": 752, "8626": 752, "9091": 752, "8782": 752, "8684": 752, "8259": 752, "0058": 752, "distilroberta": 752, "6057": 752, "6187": 752, "0130": 752, "c6i": 752, "2xlarg": 752, "c6a": 752, "c6g": 752, "a100cuda": 752, "executionprovid": 752}, "objects": {"": [[0, 0, 0, "-", "block_mask"], [365, 0, 0, "-", "neural_compressor"]], "neural_compressor": [[2, 0, 0, "-", "adaptor"], [175, 0, 0, "-", "algorithm"], [178, 0, 0, "-", "benchmark"], [181, 0, 0, "-", "common"], [197, 0, 0, "-", "compression"], [230, 0, 0, "-", "conf"], [232, 0, 0, "-", "config"], [233, 0, 0, "-", "contrib"], [258, 0, 0, "-", "data"], [312, 0, 0, "-", "experimental"], [372, 0, 0, "-", "metric"], [374, 0, 0, "-", "mix_precision"], [376, 0, 0, "-", "model"], [384, 0, 0, "-", "objective"], [396, 0, 0, "-", "onnxrt"], [406, 0, 0, "-", "profiling"], [428, 0, 0, "-", "quantization"], [436, 0, 0, "-", "strategy"], [448, 0, 0, "-", "template"], [457, 0, 0, "-", "tensorflow"], [626, 0, 0, "-", "torch"], [638, 0, 0, "-", "training"], [642, 0, 0, "-", "utils"], [651, 0, 0, "-", "version"]], "neural_compressor.adaptor": [[1, 0, 0, "-", "adaptor"], [3, 0, 0, "-", "keras"], [7, 0, 0, "-", "keras_utils"], [11, 0, 0, "-", "mxnet"], [12, 0, 0, "-", "mxnet_utils"], [14, 0, 0, "-", "onnxrt"], [17, 0, 0, "-", "ox_utils"], [45, 0, 0, "-", "pytorch"], [46, 0, 0, "-", "query"], [47, 0, 0, "-", "tensorflow"], [111, 0, 0, "-", "tf_utils"], [154, 0, 0, "-", "torch_utils"]], "neural_compressor.adaptor.adaptor": [[1, 1, 1, "", "Adaptor"], [1, 2, 1, "", "adaptor_registry"]], "neural_compressor.adaptor.keras": [[3, 1, 1, "", "KerasAdaptor"]], "neural_compressor.adaptor.keras_utils": [[4, 0, 0, "-", "conv2d"], [5, 0, 0, "-", "dense"], [6, 0, 0, "-", "depthwise_conv2d"], [8, 0, 0, "-", "pool2d"], [9, 0, 0, "-", "quantizer"], [10, 0, 0, "-", "separable_conv2d"]], "neural_compressor.adaptor.mxnet": [[11, 1, 1, "", "MxNetAdaptor"]], "neural_compressor.adaptor.mxnet_utils": [[13, 0, 0, "-", "util"]], "neural_compressor.adaptor.mxnet_utils.util": [[13, 1, 1, "", "CalibCollector"], [13, 1, 1, "", "CalibData"], [13, 1, 1, "", "CollectorBase"], [13, 1, 1, "", "DataIterLoader"], [13, 1, 1, "", "DataLoaderWrap"], [13, 1, 1, "", "NameCollector"], [13, 1, 1, "", "OpType"], [13, 1, 1, "", "TensorCollector"], [13, 2, 1, "", "amp_convert"], [13, 2, 1, "", "calib_model"], [13, 2, 1, "", "check_mx_version"], [13, 2, 1, "", "combine_capabilities"], [13, 2, 1, "", "create_data_example"], [13, 2, 1, "", "distribute_calib_tensors"], [13, 2, 1, "", "ensure_list"], [13, 2, 1, "", "fuse"], [13, 2, 1, "", "get_framework_name"], [13, 2, 1, "", "is_model_quantized"], [13, 2, 1, "", "isiterable"], [13, 2, 1, "", "make_module"], [13, 2, 1, "", "make_nc_model"], [13, 2, 1, "", "make_symbol_block"], [13, 2, 1, "", "ndarray_to_device"], [13, 2, 1, "", "parse_tune_config"], [13, 2, 1, "", "prepare_dataloader"], [13, 2, 1, "", "prepare_model"], [13, 2, 1, "", "prepare_model_data"], [13, 2, 1, "", "quantize_sym_model"], [13, 2, 1, "", "query_quantizable_nodes"], [13, 2, 1, "", "run_forward"]], "neural_compressor.adaptor.onnxrt": [[14, 1, 1, "", "ONNXRT_IntegerOpsAdaptor"], [14, 1, 1, "", "ONNXRT_QDQAdaptor"], [14, 1, 1, "", "ONNXRT_QLinearOpsAdaptor"], [14, 1, 1, "", "ONNXRT_WeightOnlyAdaptor"], [14, 1, 1, "", "ONNXRUNTIMEAdaptor"]], "neural_compressor.adaptor.ox_utils": [[15, 0, 0, "-", "calibration"], [16, 0, 0, "-", "calibrator"], [29, 0, 0, "-", "operators"], [41, 0, 0, "-", "quantizer"], [42, 0, 0, "-", "smooth_quant"], [43, 0, 0, "-", "util"], [44, 0, 0, "-", "weight_only"]], "neural_compressor.adaptor.ox_utils.calibration": [[15, 1, 1, "", "ONNXRTAugment"]], "neural_compressor.adaptor.ox_utils.calibrator": [[16, 1, 1, "", "CalibratorBase"], [16, 1, 1, "", "HistogramCollector"], [16, 1, 1, "", "KLCalibrator"], [16, 1, 1, "", "MinMaxCalibrator"], [16, 1, 1, "", "PercentileCalibrator"], [16, 2, 1, "", "calib_registry"], [16, 2, 1, "", "smooth_distribution"]], "neural_compressor.adaptor.ox_utils.operators": [[18, 0, 0, "-", "activation"], [19, 0, 0, "-", "argmax"], [20, 0, 0, "-", "attention"], [21, 0, 0, "-", "binary_op"], [22, 0, 0, "-", "concat"], [23, 0, 0, "-", "conv"], [24, 0, 0, "-", "direct_q8"], [25, 0, 0, "-", "embed_layernorm"], [26, 0, 0, "-", "gather"], [27, 0, 0, "-", "gavgpool"], [28, 0, 0, "-", "gemm"], [30, 0, 0, "-", "lstm"], [31, 0, 0, "-", "matmul"], [32, 0, 0, "-", "maxpool"], [33, 0, 0, "-", "norm"], [34, 0, 0, "-", "ops"], [35, 0, 0, "-", "pad"], [36, 0, 0, "-", "pooling"], [37, 0, 0, "-", "reduce"], [38, 0, 0, "-", "resize"], [39, 0, 0, "-", "split"], [40, 0, 0, "-", "unary_op"]], "neural_compressor.adaptor.ox_utils.operators.activation": [[18, 1, 1, "", "ActivationOperator"], [18, 1, 1, "", "Float16ActivationOperator"], [18, 1, 1, "", "QActivationOperator"], [18, 1, 1, "", "RemovableActivationOperator"]], "neural_compressor.adaptor.ox_utils.operators.argmax": [[19, 1, 1, "", "ArgMaxOperator"], [19, 1, 1, "", "QArgMaxOperator"]], "neural_compressor.adaptor.ox_utils.operators.attention": [[20, 1, 1, "", "AttentionOperator"], [20, 1, 1, "", "QAttentionOperator"]], "neural_compressor.adaptor.ox_utils.operators.binary_op": [[21, 1, 1, "", "BinaryDirect8BitOperator"], [21, 1, 1, "", "BinaryOperator"], [21, 1, 1, "", "Float16BinaryOperator"], [21, 1, 1, "", "QBinaryOperator"]], "neural_compressor.adaptor.ox_utils.operators.concat": [[22, 1, 1, "", "ConcatOperator"], [22, 1, 1, "", "QConcatOperator"]], "neural_compressor.adaptor.ox_utils.operators.conv": [[23, 1, 1, "", "ConvOperator"], [23, 1, 1, "", "QConvOperator"]], "neural_compressor.adaptor.ox_utils.operators.direct_q8": [[24, 1, 1, "", "Direct8BitOperator"], [24, 1, 1, "", "QDirectOperator"]], "neural_compressor.adaptor.ox_utils.operators.embed_layernorm": [[25, 1, 1, "", "EmbedLayerNormalizationOperator"], [25, 1, 1, "", "QEmbedLayerNormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.gather": [[26, 1, 1, "", "GatherOperator"], [26, 1, 1, "", "QGatherOperator"]], "neural_compressor.adaptor.ox_utils.operators.gavgpool": [[27, 1, 1, "", "GlobalAveragePoolOperator"], [27, 1, 1, "", "QGlobalAveragePoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.gemm": [[28, 1, 1, "", "GemmOperator"], [28, 1, 1, "", "QGemmOperator"]], "neural_compressor.adaptor.ox_utils.operators.lstm": [[30, 1, 1, "", "LSTMOperator"]], "neural_compressor.adaptor.ox_utils.operators.matmul": [[31, 1, 1, "", "FusedMatMulOperator"], [31, 1, 1, "", "MatMulOperator"], [31, 1, 1, "", "QMatMulOperator"]], "neural_compressor.adaptor.ox_utils.operators.maxpool": [[32, 1, 1, "", "MaxPoolOperator"], [32, 1, 1, "", "QMaxPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.norm": [[33, 1, 1, "", "BatchNormalizationOperator"], [33, 1, 1, "", "NormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.ops": [[34, 1, 1, "", "Operator"], [34, 1, 1, "", "QOperator"], [34, 2, 1, "", "op_registry"], [34, 2, 1, "", "qop_registry"]], "neural_compressor.adaptor.ox_utils.operators.pad": [[35, 1, 1, "", "PadOperator"], [35, 1, 1, "", "QPadOperator"]], "neural_compressor.adaptor.ox_utils.operators.pooling": [[36, 1, 1, "", "PoolOperator"], [36, 1, 1, "", "QPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.reduce": [[37, 1, 1, "", "ReduceMinMaxOperator"], [37, 1, 1, "", "ReduceOperator"]], "neural_compressor.adaptor.ox_utils.operators.resize": [[38, 1, 1, "", "QResizeOperator"], [38, 1, 1, "", "ResizeOperator"]], "neural_compressor.adaptor.ox_utils.operators.split": [[39, 1, 1, "", "QSplitOperator"], [39, 1, 1, "", "SplitOperator"]], "neural_compressor.adaptor.ox_utils.operators.unary_op": [[40, 1, 1, "", "UnaryDirect8BitOperator"], [40, 1, 1, "", "UnaryOperator"]], "neural_compressor.adaptor.ox_utils.quantizer": [[41, 1, 1, "", "Quantizer"]], "neural_compressor.adaptor.ox_utils.smooth_quant": [[42, 1, 1, "", "ORTSmoothQuant"], [42, 2, 1, "", "get_quant_dequant_output"], [42, 2, 1, "", "make_sub_graph"], [42, 2, 1, "", "quant_dequant_data"]], "neural_compressor.adaptor.ox_utils.util": [[43, 1, 1, "", "QuantFormat"], [43, 1, 1, "", "QuantType"], [43, 1, 1, "", "QuantizationMode"], [43, 1, 1, "", "QuantizedInitializer"], [43, 1, 1, "", "QuantizedValue"], [43, 1, 1, "", "QuantizedValueType"], [43, 1, 1, "", "ValueInfo"], [43, 2, 1, "", "attribute_to_kwarg"], [43, 2, 1, "", "calculate_scale_zp"], [43, 2, 1, "", "cast_tensor"], [43, 2, 1, "", "collate_preds"], [43, 2, 1, "", "dequantize_data"], [43, 2, 1, "", "dequantize_data_with_scale_zero"], [43, 2, 1, "", "dtype_to_name"], [43, 2, 1, "", "find_by_name"], [43, 2, 1, "", "float_to_bfloat16"], [43, 2, 1, "", "float_to_float16"], [43, 2, 1, "", "get_node_original_name"], [43, 2, 1, "", "infer_shapes"], [43, 2, 1, "", "is_B_transposed"], [43, 2, 1, "", "make_dquant_node"], [43, 2, 1, "", "make_quant_node"], [43, 2, 1, "", "quantize_data"], [43, 2, 1, "", "quantize_data_per_channel"], [43, 2, 1, "", "quantize_data_with_scale_zero"], [43, 2, 1, "", "quantize_nparray"], [43, 2, 1, "", "remove_init_from_model_input"], [43, 2, 1, "", "simple_progress_bar"], [43, 2, 1, "", "split_shared_bias"], [43, 2, 1, "", "to_numpy"], [43, 2, 1, "", "trt_env_setup"]], "neural_compressor.adaptor.ox_utils.weight_only": [[44, 2, 1, "", "apply_awq_clip"], [44, 2, 1, "", "apply_awq_scale"], [44, 2, 1, "", "awq_quantize"], [44, 2, 1, "", "get_blob_size"], [44, 2, 1, "", "get_weight_scale"], [44, 2, 1, "", "gptq"], [44, 2, 1, "", "gptq_quantize"], [44, 2, 1, "", "make_matmul_weight_only_node"], [44, 2, 1, "", "pad_tensor"], [44, 2, 1, "", "prepare_inputs"], [44, 2, 1, "", "qdq_tensor"], [44, 2, 1, "", "quant_tensor"], [44, 2, 1, "", "rtn_quantize"]], "neural_compressor.adaptor.pytorch": [[45, 1, 1, "", "PyTorchAdaptor"], [45, 1, 1, "", "PyTorchWeightOnlyAdaptor"], [45, 1, 1, "", "PyTorch_FXAdaptor"], [45, 1, 1, "", "PyTorch_IPEXAdaptor"], [45, 1, 1, "", "TemplateAdaptor"], [45, 2, 1, "", "get_ops_recursively"]], "neural_compressor.adaptor.query": [[46, 1, 1, "", "QueryBackendCapability"]], "neural_compressor.adaptor.tensorflow": [[47, 1, 1, "", "TensorFlowAdaptor"], [47, 1, 1, "", "TensorflowQuery"], [47, 1, 1, "", "Tensorflow_ITEXAdaptor"]], "neural_compressor.adaptor.tf_utils": [[48, 0, 0, "-", "graph_converter"], [49, 0, 0, "-", "graph_converter_without_calib"], [87, 0, 0, "-", "graph_rewriter"], [110, 0, 0, "-", "graph_util"], [112, 0, 0, "-", "quantize_graph"], [139, 0, 0, "-", "quantize_graph_common"], [140, 0, 0, "-", "smooth_quant_calibration"], [141, 0, 0, "-", "smooth_quant_scaler"], [142, 0, 0, "-", "tf2onnx_converter"], [145, 0, 0, "-", "transform_graph"], [148, 0, 0, "-", "util"]], "neural_compressor.adaptor.tf_utils.graph_converter": [[48, 1, 1, "", "GraphConverter"]], "neural_compressor.adaptor.tf_utils.graph_converter_without_calib": [[49, 1, 1, "", "GraphConverterWithoutCalib"]], "neural_compressor.adaptor.tf_utils.graph_rewriter": [[52, 0, 0, "-", "bf16"], [76, 0, 0, "-", "generic"], [86, 0, 0, "-", "graph_base"], [95, 0, 0, "-", "int8"], [101, 0, 0, "-", "onnx"], [106, 0, 0, "-", "qdq"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16": [[50, 0, 0, "-", "bf16_convert"], [51, 0, 0, "-", "dequantize_cast_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert": [[50, 1, 1, "", "BF16Convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[51, 1, 1, "", "DequantizeCastOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic": [[53, 0, 0, "-", "convert_add_to_biasadd"], [54, 0, 0, "-", "convert_layout"], [55, 0, 0, "-", "convert_leakyrelu"], [56, 0, 0, "-", "convert_nan_to_random"], [57, 0, 0, "-", "convert_placeholder_to_const"], [58, 0, 0, "-", "dilated_contraction"], [59, 0, 0, "-", "dummy_biasadd"], [60, 0, 0, "-", "expanddims_optimizer"], [61, 0, 0, "-", "fetch_weight_from_reshape"], [62, 0, 0, "-", "fold_batch_norm"], [63, 0, 0, "-", "fold_constant"], [64, 0, 0, "-", "fuse_biasadd_add"], [65, 0, 0, "-", "fuse_column_wise_mul"], [66, 0, 0, "-", "fuse_conv_with_math"], [67, 0, 0, "-", "fuse_decomposed_bn"], [68, 0, 0, "-", "fuse_decomposed_in"], [69, 0, 0, "-", "fuse_gelu"], [70, 0, 0, "-", "fuse_layer_norm"], [71, 0, 0, "-", "fuse_pad_with_conv"], [72, 0, 0, "-", "fuse_pad_with_fp32_conv"], [73, 0, 0, "-", "fuse_reshape_transpose"], [74, 0, 0, "-", "graph_cse_optimizer"], [75, 0, 0, "-", "grappler_pass"], [77, 0, 0, "-", "insert_print_node"], [78, 0, 0, "-", "move_squeeze_after_relu"], [79, 0, 0, "-", "pre_optimize"], [80, 0, 0, "-", "remove_training_nodes"], [81, 0, 0, "-", "rename_batch_norm"], [82, 0, 0, "-", "split_shared_input"], [83, 0, 0, "-", "strip_equivalent_nodes"], [84, 0, 0, "-", "strip_unused_nodes"], [85, 0, 0, "-", "switch_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd": [[53, 1, 1, "", "ConvertAddToBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout": [[54, 1, 1, "", "ConvertLayoutOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu": [[55, 1, 1, "", "ConvertLeakyReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random": [[56, 1, 1, "", "ConvertNanToRandom"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const": [[57, 1, 1, "", "ConvertPlaceholderToConst"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction": [[58, 1, 1, "", "DilatedContraction"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd": [[59, 1, 1, "", "InjectDummyBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer": [[60, 1, 1, "", "ExpandDimsOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape": [[61, 1, 1, "", "FetchWeightFromReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm": [[62, 1, 1, "", "FoldBatchNormNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant": [[63, 1, 1, "", "GraphFoldConstantOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add": [[64, 1, 1, "", "FuseBiasAddAndAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul": [[65, 1, 1, "", "FuseColumnWiseMulOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math": [[66, 1, 1, "", "FuseConvWithMathOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn": [[67, 1, 1, "", "FuseDecomposedBNOptimizer"], [67, 2, 1, "", "bypass_reshape"], [67, 2, 1, "", "get_const_dim_count"], [67, 2, 1, "", "node_from_map"], [67, 2, 1, "", "node_name_from_input"], [67, 2, 1, "", "valid_reshape_inputs"], [67, 2, 1, "", "values_from_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in": [[68, 1, 1, "", "FuseDecomposedINOptimizer"], [68, 2, 1, "", "bypass_reshape"], [68, 2, 1, "", "get_const_dim_count"], [68, 2, 1, "", "node_from_map"], [68, 2, 1, "", "node_name_from_input"], [68, 2, 1, "", "valid_reshape_inputs"], [68, 2, 1, "", "values_from_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu": [[69, 1, 1, "", "FuseGeluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm": [[70, 1, 1, "", "FuseLayerNormOptimizer"], [70, 2, 1, "", "node_from_map"], [70, 2, 1, "", "node_name_from_input"], [70, 2, 1, "", "values_from_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv": [[71, 1, 1, "", "FusePadWithConv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[72, 1, 1, "", "FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose": [[73, 1, 1, "", "FuseTransposeReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer": [[74, 1, 1, "", "GraphCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass": [[75, 1, 1, "", "GrapplerOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node": [[77, 1, 1, "", "InsertPrintMinMaxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu": [[78, 1, 1, "", "MoveSqueezeAfterReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize": [[79, 1, 1, "", "PreOptimization"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes": [[80, 1, 1, "", "RemoveTrainingNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm": [[81, 1, 1, "", "RenameBatchNormOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input": [[82, 1, 1, "", "SplitSharedInputOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes": [[83, 1, 1, "", "StripEquivalentNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes": [[84, 1, 1, "", "StripUnusedNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer": [[85, 1, 1, "", "SwitchOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base": [[86, 1, 1, "", "GraphRewriterBase"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8": [[88, 0, 0, "-", "freeze_fake_quant"], [89, 0, 0, "-", "freeze_value"], [90, 0, 0, "-", "freeze_value_without_calib"], [91, 0, 0, "-", "fuse_conv_redundant_dequantize"], [92, 0, 0, "-", "fuse_conv_requantize"], [93, 0, 0, "-", "fuse_matmul_redundant_dequantize"], [94, 0, 0, "-", "fuse_matmul_requantize"], [96, 0, 0, "-", "meta_op_optimizer"], [97, 0, 0, "-", "post_hostconst_converter"], [98, 0, 0, "-", "post_quantized_op_cse"], [99, 0, 0, "-", "rnn_convert"], [100, 0, 0, "-", "scale_propagation"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant": [[88, 1, 1, "", "FreezeFakeQuantOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value": [[89, 1, 1, "", "FreezeValueTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib": [[90, 1, 1, "", "FreezeValueWithoutCalibTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[91, 1, 1, "", "FuseConvRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize": [[92, 1, 1, "", "FuseConvRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[93, 1, 1, "", "FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize": [[94, 1, 1, "", "FuseMatMulRequantizeDequantizeNewAPITransformer"], [94, 1, 1, "", "FuseMatMulRequantizeDequantizeTransformer"], [94, 1, 1, "", "FuseMatMulRequantizeNewAPITransformer"], [94, 1, 1, "", "FuseMatMulRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer": [[96, 1, 1, "", "MetaInfoChangingMemOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter": [[97, 1, 1, "", "PostHostConstConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse": [[98, 1, 1, "", "PostCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert": [[99, 1, 1, "", "QuantizedRNNConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation": [[100, 1, 1, "", "ScaleProPagationTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx": [[102, 0, 0, "-", "onnx_graph"], [103, 0, 0, "-", "onnx_node"], [104, 0, 0, "-", "onnx_schema"], [105, 0, 0, "-", "tf2onnx_utils"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph": [[102, 1, 1, "", "OnnxGraph"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node": [[103, 1, 1, "", "OnnxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema": [[104, 1, 1, "", "OnnxOpSchema"], [104, 2, 1, "", "get_max_supported_opset_version"], [104, 2, 1, "", "get_schema"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils": [[105, 1, 1, "", "SeqType"], [105, 2, 1, "", "add_port_to_name"], [105, 2, 1, "", "are_shapes_equal"], [105, 2, 1, "", "assert_error"], [105, 2, 1, "", "compute_const_folding_using_tf"], [105, 2, 1, "", "convert_tensorflow_tensor_to_onnx"], [105, 2, 1, "", "find_opset"], [105, 2, 1, "", "get_index_from_strided_slice_of_shape"], [105, 2, 1, "", "get_subgraphs_from_onnx"], [105, 2, 1, "", "get_tensorflow_node_attr"], [105, 2, 1, "", "get_tensorflow_node_shape_attr"], [105, 2, 1, "", "get_tensorflow_tensor_data"], [105, 2, 1, "", "get_tensorflow_tensor_shape"], [105, 2, 1, "", "infer_onnx_shape_dtype"], [105, 2, 1, "", "initialize_name_counter"], [105, 2, 1, "", "is_list_or_tuple"], [105, 2, 1, "", "is_onnx_domain"], [105, 2, 1, "", "make_onnx_inputs_outputs"], [105, 2, 1, "", "make_onnx_shape"], [105, 2, 1, "", "map_numpy_to_onnx_dtype"], [105, 2, 1, "", "map_onnx_to_numpy_type"], [105, 2, 1, "", "map_tensorflow_dtype"], [105, 2, 1, "", "read_tensorflow_node_attrs"], [105, 2, 1, "", "save_protobuf"], [105, 2, 1, "", "set_name"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq": [[107, 0, 0, "-", "insert_qdq_pattern"], [108, 0, 0, "-", "merge_duplicated_qdq"], [109, 0, 0, "-", "share_qdq_y_pattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern": [[107, 1, 1, "", "GenerateGraphWithQDQPattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq": [[108, 1, 1, "", "MergeDuplicatedQDQOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern": [[109, 1, 1, "", "ShareQDQForItexYPatternOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_util": [[110, 1, 1, "", "GraphAnalyzer"], [110, 1, 1, "", "GraphRewriterHelper"]], "neural_compressor.adaptor.tf_utils.quantize_graph": [[114, 0, 0, "-", "qat"], [130, 0, 0, "-", "qdq"], [132, 0, 0, "-", "quantize_graph_base"], [133, 0, 0, "-", "quantize_graph_bn"], [134, 0, 0, "-", "quantize_graph_concatv2"], [135, 0, 0, "-", "quantize_graph_conv"], [136, 0, 0, "-", "quantize_graph_for_intel_cpu"], [137, 0, 0, "-", "quantize_graph_matmul"], [138, 0, 0, "-", "quantize_graph_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat": [[113, 0, 0, "-", "fake_quantize"], [115, 0, 0, "-", "quantize_config"], [116, 0, 0, "-", "quantize_helper"], [117, 0, 0, "-", "quantize_layers"], [122, 0, 0, "-", "quantize_wrapper"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize": [[113, 1, 1, "", "FakeQuantize"], [113, 1, 1, "", "FakeQuantizeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config": [[115, 1, 1, "", "QuantizeConfig"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper": [[116, 2, 1, "", "init_quantize_config"], [116, 2, 1, "", "qat_clone_function"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers": [[118, 0, 0, "-", "optimize_layer"], [119, 0, 0, "-", "quantize_layer_add"], [120, 0, 0, "-", "quantize_layer_base"], [121, 0, 0, "-", "quantize_layer_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer": [[118, 2, 1, "", "config_quantizable_layers"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[119, 1, 1, "", "QuantizeLayerAdd"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[120, 1, 1, "", "QuantizeLayerBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[121, 1, 1, "", "QuantizeLayerBatchNormalization"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper": [[122, 1, 1, "", "QuantizeWrapper"], [122, 1, 1, "", "QuantizeWrapperBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq": [[123, 0, 0, "-", "fuse_qdq_bn"], [124, 0, 0, "-", "fuse_qdq_concatv2"], [125, 0, 0, "-", "fuse_qdq_conv"], [126, 0, 0, "-", "fuse_qdq_deconv"], [127, 0, 0, "-", "fuse_qdq_in"], [128, 0, 0, "-", "fuse_qdq_matmul"], [129, 0, 0, "-", "fuse_qdq_pooling"], [131, 0, 0, "-", "optimize_qdq"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn": [[123, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2": [[124, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv": [[125, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv": [[126, 1, 1, "", "FuseNodeStartWithDeconv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in": [[127, 1, 1, "", "FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul": [[128, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling": [[129, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq": [[131, 1, 1, "", "OptimizeQDQGraph"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base": [[132, 1, 1, "", "QuantizeGraphBase"], [132, 1, 1, "", "QuantizeNodeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn": [[133, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2": [[134, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv": [[135, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu": [[136, 1, 1, "", "QuantizeGraphForIntel"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul": [[137, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling": [[138, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph_common": [[139, 1, 1, "", "QuantizeGraphHelper"]], "neural_compressor.adaptor.tf_utils.smooth_quant_calibration": [[140, 1, 1, "", "SmoothQuantCalibration"], [140, 1, 1, "", "SmoothQuantCalibrationLLM"]], "neural_compressor.adaptor.tf_utils.smooth_quant_scaler": [[141, 1, 1, "", "SmoothQuantScaler"], [141, 1, 1, "", "SmoothQuantScalerLLM"]], "neural_compressor.adaptor.tf_utils.tf2onnx_converter": [[142, 1, 1, "", "TensorflowQDQToOnnxQDQConverter"]], "neural_compressor.adaptor.tf_utils.transform_graph": [[143, 0, 0, "-", "bias_correction"], [144, 0, 0, "-", "graph_transform_base"], [146, 0, 0, "-", "insert_logging"], [147, 0, 0, "-", "rerange_quantized_concat"]], "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction": [[143, 1, 1, "", "BiasCorrection"]], "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base": [[144, 1, 1, "", "GraphTransformBase"]], "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging": [[146, 1, 1, "", "InsertLogging"]], "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat": [[147, 1, 1, "", "RerangeQuantizedConcat"]], "neural_compressor.adaptor.tf_utils.util": [[148, 2, 1, "", "apply_inlining"], [148, 2, 1, "", "collate_tf_preds"], [148, 2, 1, "", "construct_function_from_graph_def"], [148, 2, 1, "", "disable_random"], [148, 2, 1, "", "fix_ref_type_of_graph_def"], [148, 2, 1, "", "generate_feed_dict"], [148, 2, 1, "", "get_estimator_graph"], [148, 2, 1, "", "get_graph_def"], [148, 2, 1, "", "get_input_output_node_names"], [148, 2, 1, "", "get_model_input_shape"], [148, 2, 1, "", "get_tensor_by_name"], [148, 2, 1, "", "get_tensor_val_from_graph_node"], [148, 2, 1, "", "get_weight_from_input_tensor"], [148, 2, 1, "", "int8_node_name_reverse"], [148, 2, 1, "", "is_ckpt_format"], [148, 2, 1, "", "is_saved_model_format"], [148, 2, 1, "", "iterator_sess_run"], [148, 2, 1, "", "parse_saved_model"], [148, 2, 1, "", "read_graph"], [148, 2, 1, "", "reconstruct_saved_model"], [148, 2, 1, "", "strip_equivalent_nodes"], [148, 2, 1, "", "strip_unused_nodes"], [148, 2, 1, "", "tf_diagnosis_helper"], [148, 2, 1, "", "version1_eq_version2"], [148, 2, 1, "", "version1_gt_version2"], [148, 2, 1, "", "version1_gte_version2"], [148, 2, 1, "", "version1_lt_version2"], [148, 2, 1, "", "version1_lte_version2"], [148, 2, 1, "", "write_graph"]], "neural_compressor.adaptor.torch_utils": [[149, 0, 0, "-", "auto_round"], [150, 0, 0, "-", "awq"], [151, 0, 0, "-", "bf16_convert"], [152, 0, 0, "-", "gptq"], [153, 0, 0, "-", "hawq_metric"], [155, 0, 0, "-", "layer_wise_quant"], [160, 0, 0, "-", "mixed_precision"], [161, 0, 0, "-", "model_wrapper"], [162, 0, 0, "-", "pattern_detector"], [163, 0, 0, "-", "symbolic_trace"], [164, 0, 0, "-", "teq"], [165, 0, 0, "-", "util"], [169, 0, 0, "-", "waq"], [172, 0, 0, "-", "weight_only"]], "neural_compressor.adaptor.torch_utils.awq": [[150, 1, 1, "", "ActAwareWeightQuant"]], "neural_compressor.adaptor.torch_utils.bf16_convert": [[151, 1, 1, "", "BF16ModuleWrapper"], [151, 2, 1, "", "Convert"], [151, 2, 1, "", "bf16_symbolic_trace"]], "neural_compressor.adaptor.torch_utils.gptq": [[152, 1, 1, "", "GPTQ"], [152, 1, 1, "", "GPTQuantizer"], [152, 2, 1, "", "find_layers"], [152, 2, 1, "", "find_layers_name"], [152, 2, 1, "", "is_leaf"], [152, 2, 1, "", "log_quantizable_layers_per_transformer"], [152, 2, 1, "", "quantize"], [152, 2, 1, "", "trace_gptq_target_blocks"]], "neural_compressor.adaptor.torch_utils.hawq_metric": [[153, 1, 1, "", "HessianTrace"], [153, 1, 1, "", "Node_collector"], [153, 2, 1, "", "compare_weights"], [153, 2, 1, "", "hawq_top"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant": [[156, 0, 0, "-", "modified_pickle"], [157, 0, 0, "-", "quantize"], [158, 0, 0, "-", "torch_load"], [159, 0, 0, "-", "utils"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle": [[156, 3, 1, "", "PickleError"], [156, 3, 1, "", "PicklingError"], [156, 3, 1, "", "UnpicklingError"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize": [[157, 1, 1, "", "LayerWiseQuant"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load": [[158, 2, 1, "", "load"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils": [[159, 2, 1, "", "dowload_hf_model"], [159, 2, 1, "", "get_children"], [159, 2, 1, "", "get_module"], [159, 2, 1, "", "get_named_children"], [159, 2, 1, "", "get_super_module_by_name"], [159, 2, 1, "", "load_empty_model"], [159, 2, 1, "", "load_layer_wise_quantized_model"], [159, 2, 1, "", "load_tensor"], [159, 2, 1, "", "load_tensor_from_shard"], [159, 2, 1, "", "update_module"]], "neural_compressor.adaptor.torch_utils.mixed_precision": [[160, 2, 1, "", "ipex_mixed_precision"]], "neural_compressor.adaptor.torch_utils.model_wrapper": [[161, 1, 1, "", "FakeAffineTensorQuantFunction"], [161, 1, 1, "", "MulLinear"], [161, 1, 1, "", "TEQLinearFakeQuant"]], "neural_compressor.adaptor.torch_utils.pattern_detector": [[162, 1, 1, "", "TransformerBasedModelBlockPatternDetector"]], "neural_compressor.adaptor.torch_utils.symbolic_trace": [[163, 2, 1, "", "symbolic_trace"], [163, 2, 1, "", "trace_and_fuse_sub_graph"]], "neural_compressor.adaptor.torch_utils.teq": [[164, 1, 1, "", "TEQuantizer"]], "neural_compressor.adaptor.torch_utils.util": [[165, 2, 1, "", "append_attr"], [165, 2, 1, "", "auto_copy"], [165, 2, 1, "", "calculate_quant_min_max"], [165, 2, 1, "", "calibration"], [165, 2, 1, "", "check_cfg_and_qconfig"], [165, 2, 1, "", "collate_torch_preds"], [165, 2, 1, "", "collect_weight_info"], [165, 2, 1, "", "fetch_module"], [165, 2, 1, "", "forward_wrapper"], [165, 2, 1, "", "generate_activation_observer"], [165, 2, 1, "", "get_absorb_layers"], [165, 2, 1, "", "get_block_prefix"], [165, 2, 1, "", "get_depth"], [165, 2, 1, "", "get_dict_at_depth"], [165, 2, 1, "", "get_element_under_depth"], [165, 2, 1, "", "get_embedding_contiguous"], [165, 2, 1, "", "get_example_input"], [165, 2, 1, "", "get_fallback_order"], [165, 2, 1, "", "get_hidden_states"], [165, 2, 1, "", "get_module_input_output"], [165, 2, 1, "", "get_mse_order_per_fp32"], [165, 2, 1, "", "get_mse_order_per_int8"], [165, 2, 1, "", "get_op_type_by_name"], [165, 2, 1, "", "get_quantizable_ops_from_cfgs"], [165, 2, 1, "", "get_torch_version"], [165, 2, 1, "", "input2tuple"], [165, 2, 1, "", "is_fused_module"], [165, 2, 1, "", "match_datatype_pattern"], [165, 2, 1, "", "move_input_device"], [165, 2, 1, "", "paser_cfgs"], [165, 2, 1, "", "set_module"], [165, 2, 1, "", "simple_inference"], [165, 2, 1, "", "update_sq_scale"]], "neural_compressor.adaptor.torch_utils.waq": [[166, 0, 0, "-", "auto_alpha"], [167, 0, 0, "-", "calibration"], [168, 0, 0, "-", "graph_trace"], [170, 0, 0, "-", "smooth_quant"], [171, 0, 0, "-", "utils"]], "neural_compressor.adaptor.torch_utils.waq.smooth_quant": [[170, 1, 1, "", "TorchSmoothQuant"]], "neural_compressor.adaptor.torch_utils.waq.utils": [[171, 2, 1, "", "get_module"], [171, 2, 1, "", "register_autotune"], [171, 2, 1, "", "reshape_in_channel_to_last"], [171, 2, 1, "", "reshape_scale_as_input"], [171, 2, 1, "", "reshape_scale_as_weight"], [171, 2, 1, "", "set_module"]], "neural_compressor.adaptor.torch_utils.weight_only": [[172, 2, 1, "", "autoround_quantize"], [172, 2, 1, "", "awq_quantize"], [172, 2, 1, "", "gptq_quantize"], [172, 2, 1, "", "qdq_weight_actor"], [172, 2, 1, "", "qdq_weight_asym"], [172, 2, 1, "", "qdq_weight_sym"], [172, 2, 1, "", "quant_weight"], [172, 2, 1, "", "quant_weight_w_scale"], [172, 2, 1, "", "quantize_4bit"], [172, 2, 1, "", "rtn_quantize"], [172, 2, 1, "", "search_clip"], [172, 2, 1, "", "teq_quantize"]], "neural_compressor.algorithm": [[173, 0, 0, "-", "algorithm"], [174, 0, 0, "-", "fast_bias_correction"], [176, 0, 0, "-", "smooth_quant"], [177, 0, 0, "-", "weight_correction"]], "neural_compressor.algorithm.algorithm": [[173, 1, 1, "", "ALGORITHMS"], [173, 1, 1, "", "Algorithm"], [173, 1, 1, "", "AlgorithmScheduler"], [173, 2, 1, "", "algorithm_registry"]], "neural_compressor.algorithm.fast_bias_correction": [[174, 1, 1, "", "FastBiasCorrection"]], "neural_compressor.algorithm.smooth_quant": [[176, 1, 1, "", "SmoothQuant"]], "neural_compressor.algorithm.weight_correction": [[177, 1, 1, "", "WeightCorrection"]], "neural_compressor.benchmark": [[178, 2, 1, "", "benchmark_with_raw_cmd"], [178, 2, 1, "", "call_one"], [178, 2, 1, "", "config_instance"], [178, 2, 1, "", "fit"], [178, 2, 1, "", "generate_prefix"], [178, 2, 1, "", "get_architecture"], [178, 2, 1, "", "get_bounded_threads"], [178, 2, 1, "", "get_core_ids"], [178, 2, 1, "", "get_physical_ids"], [178, 2, 1, "", "get_threads"], [178, 2, 1, "", "get_threads_per_core"], [178, 2, 1, "", "profile"], [178, 2, 1, "", "run_instance"], [178, 2, 1, "", "set_all_env_var"], [178, 2, 1, "", "set_env_var"], [178, 2, 1, "", "summary_benchmark"]], "neural_compressor.common": [[179, 0, 0, "-", "base_config"], [180, 0, 0, "-", "base_tuning"], [182, 0, 0, "-", "tuning_param"], [184, 0, 0, "-", "utils"]], "neural_compressor.common.base_config": [[179, 1, 1, "", "BaseConfig"], [179, 1, 1, "", "ComposableConfig"], [179, 2, 1, "", "register_config"], [179, 2, 1, "", "register_supported_configs_for_fwk"]], "neural_compressor.common.base_tuning": [[180, 1, 1, "", "Evaluator"], [180, 1, 1, "", "SequentialSampler"], [180, 1, 1, "", "TuningConfig"]], "neural_compressor.common.tuning_param": [[182, 1, 1, "", "ParamLevel"], [182, 1, 1, "", "TuningParam"]], "neural_compressor.common.utils": [[183, 0, 0, "-", "constants"], [185, 0, 0, "-", "logger"], [186, 0, 0, "-", "save_load"], [187, 0, 0, "-", "utility"]], "neural_compressor.common.utils.constants": [[183, 1, 1, "", "Mode"]], "neural_compressor.common.utils.logger": [[185, 1, 1, "", "Logger"], [185, 1, 1, "", "TuningLogger"]], "neural_compressor.common.utils.save_load": [[186, 2, 1, "", "load_config_mapping"], [186, 2, 1, "", "save_config_mapping"]], "neural_compressor.common.utils.utility": [[187, 1, 1, "", "CpuInfo"], [187, 1, 1, "", "LazyImport"], [187, 2, 1, "", "dump_elapsed_time"], [187, 2, 1, "", "set_random_seed"], [187, 2, 1, "", "set_resume_from"], [187, 2, 1, "", "set_tensorboard"], [187, 2, 1, "", "set_workspace"], [187, 2, 1, "", "singleton"]], "neural_compressor.compression": [[188, 0, 0, "-", "callbacks"], [190, 0, 0, "-", "distillation"], [193, 0, 0, "-", "hpo"], [200, 0, 0, "-", "pruner"]], "neural_compressor.compression.callbacks": [[188, 1, 1, "", "BaseCallbacks"], [188, 1, 1, "", "DistillationCallbacks"], [188, 1, 1, "", "PruningCallbacks"], [188, 1, 1, "", "QuantizationAwareTrainingCallbacks"]], "neural_compressor.compression.callbacks.DistillationCallbacks": [[188, 4, 1, "", "_epoch_ran"], [188, 4, 1, "", "best_model"], [188, 4, 1, "", "best_score"], [188, 4, 1, "", "eval_frequency"]], "neural_compressor.compression.distillation": [[189, 0, 0, "-", "criterions"], [191, 0, 0, "-", "optimizers"], [192, 0, 0, "-", "utility"]], "neural_compressor.compression.distillation.criterions": [[189, 1, 1, "", "Criterions"], [189, 1, 1, "", "IntermediateLayersKnowledgeDistillationLoss"], [189, 1, 1, "", "KnowledgeDistillationFramework"], [189, 1, 1, "", "KnowledgeDistillationLoss"], [189, 1, 1, "", "PyTorchCriterions"], [189, 1, 1, "", "PyTorchCrossEntropyLoss"], [189, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLoss"], [189, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"], [189, 1, 1, "", "PyTorchKnowledgeDistillationLoss"], [189, 1, 1, "", "PyTorchKnowledgeDistillationLossWrapper"], [189, 1, 1, "", "PyTorchSelfKnowledgeDistillationLoss"], [189, 1, 1, "", "PyTorchSelfKnowledgeDistillationLossWrapper"], [189, 1, 1, "", "SelfKnowledgeDistillationLoss"], [189, 1, 1, "", "TensorFlowCrossEntropyLoss"], [189, 1, 1, "", "TensorFlowSparseCategoricalCrossentropy"], [189, 1, 1, "", "TensorflowCriterions"], [189, 1, 1, "", "TensorflowKnowledgeDistillationLoss"], [189, 1, 1, "", "TensorflowKnowledgeDistillationLossExternal"], [189, 1, 1, "", "TensorflowKnowledgeDistillationLossWrapper"], [189, 2, 1, "", "criterion_registry"]], "neural_compressor.compression.distillation.optimizers": [[191, 1, 1, "", "Optimizers"], [191, 1, 1, "", "PyTorchOptimizers"], [191, 1, 1, "", "PyTorchSGD"], [191, 1, 1, "", "TensorFlowAdam"], [191, 1, 1, "", "TensorFlowAdamW"], [191, 1, 1, "", "TensorFlowSGD"], [191, 1, 1, "", "TensorflowOptimizers"], [191, 2, 1, "", "optimizer_registry"]], "neural_compressor.compression.distillation.utility": [[192, 2, 1, "", "get_activation"], [192, 2, 1, "", "record_output"]], "neural_compressor.compression.hpo": [[194, 0, 0, "-", "sa_optimizer"], [195, 0, 0, "-", "search_algorithms"], [196, 0, 0, "-", "search_space"]], "neural_compressor.compression.hpo.search_algorithms": [[195, 1, 1, "", "BayesianOptimizationSearcher"], [195, 1, 1, "", "GridSearcher"], [195, 1, 1, "", "RandomSearcher"], [195, 1, 1, "", "Searcher"], [195, 1, 1, "", "XgbSearcher"], [195, 2, 1, "", "register_searcher"]], "neural_compressor.compression.hpo.search_space": [[196, 1, 1, "", "BaseSearchSpace"], [196, 1, 1, "", "ContinuousSearchSpace"], [196, 1, 1, "", "DiscreteSearchSpace"], [196, 1, 1, "", "SearchSpace"], [196, 2, 1, "", "register_searchspace"]], "neural_compressor.compression.pruner": [[198, 0, 0, "-", "criteria"], [199, 0, 0, "-", "dsnot"], [202, 0, 0, "-", "model_slim"], [206, 0, 0, "-", "patterns"], [200, 2, 1, "", "prepare_pruning"], [213, 0, 0, "-", "pruners"], [219, 0, 0, "-", "pruning"], [220, 0, 0, "-", "regs"], [200, 2, 1, "", "save"], [221, 0, 0, "-", "schedulers"], [222, 0, 0, "-", "tf_criteria"], [223, 0, 0, "-", "utils"], [224, 0, 0, "-", "wanda"]], "neural_compressor.compression.pruner.criteria": [[198, 1, 1, "", "BlockMaskCriterion"], [198, 1, 1, "", "GradientCriterion"], [198, 1, 1, "", "MagnitudeCriterion"], [198, 1, 1, "", "PruningCriterion"], [198, 1, 1, "", "RetrainFreeCriterion"], [198, 1, 1, "", "SnipCriterion"], [198, 1, 1, "", "SnipMomentumCriterion"], [198, 2, 1, "", "get_criterion"], [198, 2, 1, "", "register_criterion"]], "neural_compressor.compression.pruner.criteria.BlockMaskCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.GradientCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.MagnitudeCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.PruningCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.RetrainFreeCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.SnipCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.SnipMomentumCriterion": [[198, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.dsnot": [[199, 2, 1, "", "DSnoT"], [199, 2, 1, "", "return_reorder_indice"]], "neural_compressor.compression.pruner.model_slim": [[201, 0, 0, "-", "auto_slim"], [203, 0, 0, "-", "pattern_analyzer"], [204, 0, 0, "-", "weight_slim"]], "neural_compressor.compression.pruner.model_slim.auto_slim": [[201, 2, 1, "", "generate_ffn2_pruning_config"], [201, 2, 1, "", "generate_mha_pruning_config"], [201, 2, 1, "", "model_slim"], [201, 2, 1, "", "model_slim_ffn2"], [201, 2, 1, "", "model_slim_mha"], [201, 2, 1, "", "parse_auto_slim_config"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer": [[203, 1, 1, "", "ClassifierHeadSearcher"], [203, 1, 1, "", "ClassifierHeadSearcherTF"], [203, 1, 1, "", "JitBasicSearcher"], [203, 1, 1, "", "Linear2LinearSearcher"], [203, 1, 1, "", "RecipeSearcher"], [203, 1, 1, "", "SelfMHASearcher"], [203, 2, 1, "", "get_attributes"], [203, 2, 1, "", "get_common_module"], [203, 2, 1, "", "print_iterables"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher": [[203, 4, 1, "", "device"], [203, 4, 1, "", "flatten_static_graph"], [203, 4, 1, "", "model"], [203, 4, 1, "", "static_graph"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF": [[203, 4, 1, "", "device"], [203, 4, 1, "", "flatten_static_graph"], [203, 4, 1, "", "model"], [203, 4, 1, "", "static_graph"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher": [[203, 4, 1, "", "device"], [203, 4, 1, "", "flatten_static_graph"], [203, 4, 1, "", "model"], [203, 4, 1, "", "searching_results"], [203, 4, 1, "", "static_graph"], [203, 4, 1, "", "target_layers"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher": [[203, 4, 1, "", "current_pattern"], [203, 4, 1, "", "device"], [203, 4, 1, "", "flatten_static_graph"], [203, 4, 1, "", "model"], [203, 4, 1, "", "searching_results"], [203, 4, 1, "", "static_graph"], [203, 4, 1, "", "target_layers"], [203, 4, 1, "", "target_op_lut"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher": [[203, 4, 1, "", "model"], [203, 4, 1, "", "recipe"], [203, 4, 1, "", "searching_results"], [203, 4, 1, "", "targets"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher": [[203, 4, 1, "", "device"], [203, 4, 1, "", "flatten_static_graph"], [203, 4, 1, "", "model"], [203, 4, 1, "", "static_graph"]], "neural_compressor.compression.pruner.model_slim.weight_slim": [[204, 1, 1, "", "LinearCompression"], [204, 1, 1, "", "LinearCompressionIterator"], [204, 1, 1, "", "PostCompressionUtils"]], "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression": [[204, 4, 1, "", "device"], [204, 4, 1, "", "layer_1"], [204, 4, 1, "", "layer_2"]], "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompressionIterator": [[204, 4, 1, "", "linear_patterns"]], "neural_compressor.compression.pruner.patterns": [[205, 0, 0, "-", "base"], [206, 2, 1, "", "get_pattern"], [207, 0, 0, "-", "mha"], [208, 0, 0, "-", "ninm"], [209, 0, 0, "-", "nxm"]], "neural_compressor.compression.pruner.patterns.base": [[205, 1, 1, "", "BasePattern"], [205, 1, 1, "", "KerasBasePattern"], [205, 1, 1, "", "PytorchBasePattern"], [205, 2, 1, "", "register_pattern"]], "neural_compressor.compression.pruner.patterns.base.BasePattern": [[205, 4, 1, "", "config"], [205, 4, 1, "", "invalid_layers"], [205, 4, 1, "", "is_global"], [205, 4, 1, "", "keep_mask_layers"], [205, 4, 1, "", "max_sparsity_ratio_per_op"], [205, 4, 1, "", "min_sparsity_ratio_per_op"], [205, 4, 1, "", "modules"], [205, 4, 1, "", "pattern"], [205, 4, 1, "", "target_sparsity"]], "neural_compressor.compression.pruner.patterns.base.KerasBasePattern": [[205, 4, 1, "", "config"], [205, 4, 1, "", "invalid_layers"], [205, 4, 1, "", "is_global"], [205, 4, 1, "", "keep_mask_layers"], [205, 4, 1, "", "max_sparsity_ratio_per_op"], [205, 4, 1, "", "min_sparsity_ratio_per_op"], [205, 4, 1, "", "modules"], [205, 4, 1, "", "pattern"], [205, 4, 1, "", "target_sparsity"]], "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern": [[205, 4, 1, "", "config"], [205, 4, 1, "", "invalid_layers"], [205, 4, 1, "", "is_global"], [205, 4, 1, "", "keep_mask_layers"], [205, 4, 1, "", "max_sparsity_ratio_per_op"], [205, 4, 1, "", "min_sparsity_ratio_per_op"], [205, 4, 1, "", "modules"], [205, 4, 1, "", "pattern"], [205, 4, 1, "", "target_sparsity"]], "neural_compressor.compression.pruner.patterns.mha": [[207, 1, 1, "", "PatternMHA"]], "neural_compressor.compression.pruner.patterns.mha.PatternMHA": [[207, 4, 1, "", "M"], [207, 4, 1, "", "N"]], "neural_compressor.compression.pruner.patterns.ninm": [[208, 1, 1, "", "PytorchPatternNInM"]], "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM": [[208, 4, 1, "", "M"], [208, 4, 1, "", "N"]], "neural_compressor.compression.pruner.patterns.nxm": [[209, 1, 1, "", "KerasPatternNxM"], [209, 1, 1, "", "PytorchPatternNxM"]], "neural_compressor.compression.pruner.patterns.nxm.KerasPatternNxM": [[209, 4, 1, "", "block_size"]], "neural_compressor.compression.pruner.patterns.nxm.PytorchPatternNxM": [[209, 4, 1, "", "block_size"]], "neural_compressor.compression.pruner.pruners": [[210, 0, 0, "-", "base"], [211, 0, 0, "-", "basic"], [212, 0, 0, "-", "block_mask"], [213, 2, 1, "", "get_pruner"], [214, 0, 0, "-", "mha"], [213, 2, 1, "", "parse_valid_pruner_types"], [215, 0, 0, "-", "pattern_lock"], [216, 0, 0, "-", "progressive"], [217, 0, 0, "-", "retrain_free"], [218, 0, 0, "-", "sparse_gpt"]], "neural_compressor.compression.pruner.pruners.base": [[210, 1, 1, "", "BasePruner"], [210, 1, 1, "", "KerasBasePruner"], [210, 1, 1, "", "PytorchBasePruner"], [210, 2, 1, "", "register_pruner"]], "neural_compressor.compression.pruner.pruners.base.BasePruner": [[210, 4, 1, "", "config"], [210, 4, 1, "", "current_sparsity_ratio"], [210, 4, 1, "", "end_step"], [210, 4, 1, "", "global_step"], [210, 4, 1, "", "masks"], [210, 4, 1, "", "max_sparsity_ratio_per_op"], [210, 4, 1, "", "modules"], [210, 4, 1, "", "pattern"], [210, 4, 1, "", "pruning_frequency"], [210, 4, 1, "", "scheduler"], [210, 4, 1, "", "scores"], [210, 4, 1, "", "start_step"], [210, 4, 1, "", "target_sparsity_ratio"]], "neural_compressor.compression.pruner.pruners.base.KerasBasePruner": [[210, 4, 1, "", "config"], [210, 4, 1, "", "current_sparsity_ratio"], [210, 4, 1, "", "end_step"], [210, 4, 1, "", "global_step"], [210, 4, 1, "", "masks"], [210, 4, 1, "", "max_sparsity_ratio_per_op"], [210, 4, 1, "", "modules"], [210, 4, 1, "", "pattern"], [210, 4, 1, "", "pruning_frequency"], [210, 4, 1, "", "scheduler"], [210, 4, 1, "", "scores"], [210, 4, 1, "", "start_step"], [210, 4, 1, "", "target_sparsity_ratio"]], "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner": [[210, 4, 1, "", "config"], [210, 4, 1, "", "current_sparsity_ratio"], [210, 4, 1, "", "end_step"], [210, 4, 1, "", "global_step"], [210, 4, 1, "", "masks"], [210, 4, 1, "", "max_sparsity_ratio_per_op"], [210, 4, 1, "", "modules"], [210, 4, 1, "", "pattern"], [210, 4, 1, "", "pruning_frequency"], [210, 4, 1, "", "scheduler"], [210, 4, 1, "", "scores"], [210, 4, 1, "", "start_step"], [210, 4, 1, "", "target_sparsity_ratio"]], "neural_compressor.compression.pruner.pruners.basic": [[211, 1, 1, "", "KerasBasicPruner"], [211, 1, 1, "", "PytorchBasicPruner"]], "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner": [[211, 4, 1, "", "criterion"], [211, 4, 1, "", "pattern"], [211, 4, 1, "", "reg"], [211, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner": [[211, 4, 1, "", "criterion"], [211, 4, 1, "", "pattern"], [211, 4, 1, "", "reg"], [211, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.block_mask": [[212, 1, 1, "", "PytorchBlockMaskPruner"]], "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner": [[212, 4, 1, "", "criterion"], [212, 4, 1, "", "pattern"], [212, 4, 1, "", "reg"], [212, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.mha": [[214, 1, 1, "", "PythonMultiheadAttentionPruner"]], "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner": [[214, 4, 1, "", "head_masks"], [214, 4, 1, "", "linear_layers"], [214, 4, 1, "", "mha_compressions"], [214, 4, 1, "", "mha_scores"]], "neural_compressor.compression.pruner.pruners.pattern_lock": [[215, 1, 1, "", "PytorchPatternLockPruner"]], "neural_compressor.compression.pruner.pruners.progressive": [[216, 1, 1, "", "PytorchProgressivePruner"]], "neural_compressor.compression.pruner.pruners.retrain_free": [[217, 1, 1, "", "PytorchRetrainFreePruner"]], "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner": [[217, 4, 1, "", "criterion"], [217, 4, 1, "", "pattern"], [217, 4, 1, "", "reg"], [217, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.sparse_gpt": [[218, 1, 1, "", "SparseGPTPruner"]], "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner": [[218, 4, 1, "", "criterion"], [218, 4, 1, "", "pattern"], [218, 4, 1, "", "reg"], [218, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruning": [[219, 1, 1, "", "BasePruning"], [219, 1, 1, "", "BasicPruning"], [219, 1, 1, "", "RetrainFreePruning"], [219, 1, 1, "", "SparseGPTPruning"], [219, 2, 1, "", "register_pruning"]], "neural_compressor.compression.pruner.pruning.BasePruning": [[219, 4, 1, "", "config_file_path"], [219, 4, 1, "", "model"], [219, 4, 1, "", "pruner_info"], [219, 4, 1, "", "pruners"]], "neural_compressor.compression.pruner.pruning.BasicPruning": [[219, 4, 1, "", "config_file_path"], [219, 4, 1, "", "model"], [219, 4, 1, "", "pruner_info"], [219, 4, 1, "", "pruners"]], "neural_compressor.compression.pruner.pruning.RetrainFreePruning": [[219, 4, 1, "", "config_file_path"], [219, 4, 1, "", "model"], [219, 4, 1, "", "pruner_info"], [219, 4, 1, "", "pruners"]], "neural_compressor.compression.pruner.regs": [[220, 1, 1, "", "BaseReg"], [220, 1, 1, "", "GroupLasso"], [220, 2, 1, "", "get_reg"], [220, 2, 1, "", "get_reg_type"], [220, 2, 1, "", "register_reg"]], "neural_compressor.compression.pruner.regs.GroupLasso": [[220, 4, 1, "", "alpha"], [220, 4, 1, "", "reg_terms"]], "neural_compressor.compression.pruner.schedulers": [[221, 1, 1, "", "IterativeScheduler"], [221, 1, 1, "", "OneshotScheduler"], [221, 1, 1, "", "PruningScheduler"], [221, 2, 1, "", "get_scheduler"], [221, 2, 1, "", "register_scheduler"]], "neural_compressor.compression.pruner.schedulers.PruningScheduler": [[221, 4, 1, "", "config"]], "neural_compressor.compression.pruner.tf_criteria": [[222, 1, 1, "", "MagnitudeCriterion"], [222, 1, 1, "", "PruningCriterion"], [222, 2, 1, "", "get_tf_criterion"], [222, 2, 1, "", "register_criterion"]], "neural_compressor.compression.pruner.tf_criteria.MagnitudeCriterion": [[222, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.tf_criteria.PruningCriterion": [[222, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.utils": [[223, 2, 1, "", "check_config"], [223, 2, 1, "", "check_key_validity"], [223, 2, 1, "", "collect_layer_inputs"], [223, 2, 1, "", "generate_pruner_config"], [223, 2, 1, "", "get_layers"], [223, 2, 1, "", "get_sparsity_ratio"], [223, 2, 1, "", "get_sparsity_ratio_tf"], [223, 2, 1, "", "parse_last_linear"], [223, 2, 1, "", "parse_last_linear_tf"], [223, 2, 1, "", "parse_to_prune"], [223, 2, 1, "", "parse_to_prune_tf"], [223, 2, 1, "", "process_and_check_config"], [223, 2, 1, "", "process_config"], [223, 2, 1, "", "process_weight_config"], [223, 2, 1, "", "process_yaml_config"], [223, 2, 1, "", "reset_none_to_default"], [223, 2, 1, "", "update_params"]], "neural_compressor.compression.pruner.wanda": [[225, 0, 0, "-", "prune"], [226, 0, 0, "-", "utils"], [227, 0, 0, "-", "wrapper"]], "neural_compressor.compression.pruner.wanda.prune": [[225, 2, 1, "", "prune_wanda"]], "neural_compressor.compression.pruner.wanda.utils": [[226, 2, 1, "", "find_layers"]], "neural_compressor.compression.pruner.wanda.wrapper": [[227, 1, 1, "", "WrappedGPT"]], "neural_compressor.conf": [[228, 0, 0, "-", "config"], [229, 0, 0, "-", "dotdict"], [231, 0, 0, "-", "pythonic_config"]], "neural_compressor.conf.config": [[228, 1, 1, "", "Benchmark_Conf"], [228, 1, 1, "", "Conf"], [228, 1, 1, "", "Distillation_Conf"], [228, 1, 1, "", "Graph_Optimization_Conf"], [228, 1, 1, "", "MixedPrecision_Conf"], [228, 1, 1, "", "NASConfig"], [228, 1, 1, "", "PrunerV2"], [228, 1, 1, "", "Pruning_Conf"], [228, 1, 1, "", "Quantization_Conf"]], "neural_compressor.conf.dotdict": [[229, 1, 1, "", "DotDict"], [229, 2, 1, "", "deep_get"], [229, 2, 1, "", "deep_set"]], "neural_compressor.conf.pythonic_config": [[231, 1, 1, "", "AccuracyCriterion"], [231, 1, 1, "", "BenchmarkConfig"], [231, 1, 1, "", "DistillationConfig"], [231, 1, 1, "", "KnowledgeDistillationLossConfig"], [231, 1, 1, "", "Options"], [231, 1, 1, "", "QuantizationConfig"], [231, 1, 1, "", "WeightPruningConfig"]], "neural_compressor.config": [[232, 1, 1, "", "AccuracyCriterion"], [232, 1, 1, "", "BenchmarkConfig"], [232, 1, 1, "", "DistillationConfig"], [232, 1, 1, "", "DotDict"], [232, 1, 1, "", "ExportConfig"], [232, 1, 1, "", "HPOConfig"], [232, 1, 1, "", "IntermediateLayersKnowledgeDistillationLossConfig"], [232, 1, 1, "", "Keras"], [232, 1, 1, "", "KnowledgeDistillationLossConfig"], [232, 1, 1, "", "MXNet"], [232, 1, 1, "", "MixedPrecisionConfig"], [232, 1, 1, "", "NASConfig"], [232, 1, 1, "", "ONNX"], [232, 1, 1, "", "ONNXQlinear2QDQConfig"], [232, 1, 1, "", "Options"], [232, 1, 1, "", "PostTrainingQuantConfig"], [232, 1, 1, "", "PyTorch"], [232, 1, 1, "", "QuantizationAwareTrainingConfig"], [232, 1, 1, "", "SelfKnowledgeDistillationLossConfig"], [232, 1, 1, "", "TF2ONNXConfig"], [232, 1, 1, "", "TensorFlow"], [232, 1, 1, "", "Torch2ONNXConfig"], [232, 1, 1, "", "TuningCriterion"], [232, 1, 1, "", "WeightPruningConfig"]], "neural_compressor.contrib": [[234, 0, 0, "-", "strategy"]], "neural_compressor.contrib.strategy": [[235, 0, 0, "-", "sigopt"], [236, 0, 0, "-", "tpe"]], "neural_compressor.contrib.strategy.sigopt": [[235, 1, 1, "", "SigOptTuneStrategy"]], "neural_compressor.contrib.strategy.tpe": [[236, 1, 1, "", "TpeTuneStrategy"]], "neural_compressor.data": [[241, 0, 0, "-", "dataloaders"], [253, 0, 0, "-", "datasets"], [257, 0, 0, "-", "filters"], [261, 0, 0, "-", "transforms"]], "neural_compressor.data.dataloaders": [[237, 0, 0, "-", "base_dataloader"], [238, 0, 0, "-", "dataloader"], [239, 0, 0, "-", "default_dataloader"], [240, 0, 0, "-", "fetcher"], [242, 0, 0, "-", "mxnet_dataloader"], [243, 0, 0, "-", "onnxrt_dataloader"], [244, 0, 0, "-", "pytorch_dataloader"], [245, 0, 0, "-", "sampler"], [246, 0, 0, "-", "tensorflow_dataloader"]], "neural_compressor.data.dataloaders.base_dataloader": [[237, 1, 1, "", "BaseDataLoader"]], "neural_compressor.data.dataloaders.dataloader": [[238, 1, 1, "", "DataLoader"], [238, 2, 1, "", "check_dataloader"]], "neural_compressor.data.dataloaders.default_dataloader": [[239, 1, 1, "", "DefaultDataLoader"], [239, 2, 1, "", "default_collate"]], "neural_compressor.data.dataloaders.fetcher": [[240, 1, 1, "", "Fetcher"], [240, 1, 1, "", "IndexFetcher"], [240, 1, 1, "", "IterableFetcher"]], "neural_compressor.data.dataloaders.mxnet_dataloader": [[242, 1, 1, "", "MXNetDataLoader"]], "neural_compressor.data.dataloaders.onnxrt_dataloader": [[243, 1, 1, "", "ONNXRTBertDataLoader"], [243, 1, 1, "", "ONNXRTDataLoader"]], "neural_compressor.data.dataloaders.pytorch_dataloader": [[244, 1, 1, "", "PyTorchDataLoader"]], "neural_compressor.data.dataloaders.sampler": [[245, 1, 1, "", "BatchSampler"], [245, 1, 1, "", "IterableSampler"], [245, 1, 1, "", "Sampler"], [245, 1, 1, "", "SequentialSampler"]], "neural_compressor.data.dataloaders.tensorflow_dataloader": [[246, 1, 1, "", "TFDataDataLoader"], [246, 1, 1, "", "TensorflowBertDataLoader"], [246, 1, 1, "", "TensorflowDataLoader"], [246, 1, 1, "", "TensorflowModelZooBertDataLoader"]], "neural_compressor.data.datasets": [[247, 0, 0, "-", "bert_dataset"], [248, 0, 0, "-", "coco_dataset"], [249, 0, 0, "-", "dataset"], [250, 0, 0, "-", "dummy_dataset"], [251, 0, 0, "-", "dummy_dataset_v2"], [252, 0, 0, "-", "imagenet_dataset"], [254, 0, 0, "-", "style_transfer_dataset"]], "neural_compressor.data.datasets.bert_dataset": [[247, 1, 1, "", "InputFeatures"], [247, 1, 1, "", "ONNXRTBertDataset"], [247, 1, 1, "", "ParseDecodeBert"], [247, 1, 1, "", "PytorchBertDataset"], [247, 1, 1, "", "TensorflowBertDataset"], [247, 1, 1, "", "TensorflowModelZooBertDataset"], [247, 2, 1, "", "convert_examples_to_features"], [247, 2, 1, "", "load_and_cache_examples"]], "neural_compressor.data.datasets.coco_dataset": [[248, 1, 1, "", "COCONpy"], [248, 1, 1, "", "COCORaw"], [248, 1, 1, "", "COCORecordDataset"], [248, 1, 1, "", "ParseDecodeCoco"]], "neural_compressor.data.datasets.dataset": [[249, 1, 1, "", "CIFAR10"], [249, 1, 1, "", "CIFAR100"], [249, 1, 1, "", "Dataset"], [249, 1, 1, "", "Datasets"], [249, 1, 1, "", "FashionMNIST"], [249, 1, 1, "", "ImageFolder"], [249, 1, 1, "", "IterableDataset"], [249, 1, 1, "", "MNIST"], [249, 1, 1, "", "MXNetCIFAR10"], [249, 1, 1, "", "MXNetCIFAR100"], [249, 1, 1, "", "MXNetDatasets"], [249, 1, 1, "", "MXNetFashionMNIST"], [249, 1, 1, "", "MXNetImageFolder"], [249, 1, 1, "", "MXNetMNIST"], [249, 1, 1, "", "ONNXRTITDatasets"], [249, 1, 1, "", "ONNXRTQLDatasets"], [249, 1, 1, "", "PyTorchDatasets"], [249, 1, 1, "", "PytorchCIFAR10"], [249, 1, 1, "", "PytorchCIFAR100"], [249, 1, 1, "", "PytorchFashionMNIST"], [249, 1, 1, "", "PytorchMNIST"], [249, 1, 1, "", "PytorchMxnetWrapDataset"], [249, 1, 1, "", "PytorchMxnetWrapFunction"], [249, 1, 1, "", "Tensorflow"], [249, 1, 1, "", "TensorflowCIFAR10"], [249, 1, 1, "", "TensorflowCIFAR100"], [249, 1, 1, "", "TensorflowDatasets"], [249, 1, 1, "", "TensorflowFashionMNIST"], [249, 1, 1, "", "TensorflowImageRecord"], [249, 1, 1, "", "TensorflowMNIST"], [249, 1, 1, "", "TensorflowTFRecordDataset"], [249, 1, 1, "", "TensorflowVOCRecord"], [249, 2, 1, "", "calculate_md5"], [249, 2, 1, "", "check_integrity"], [249, 2, 1, "", "dataset_registry"], [249, 2, 1, "", "download_url"], [249, 5, 1, "", "framework_datasets"], [249, 2, 1, "", "gen_bar_updater"]], "neural_compressor.data.datasets.dummy_dataset": [[250, 1, 1, "", "DummyDataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[251, 1, 1, "", "DummyDataset"], [251, 1, 1, "", "SparseDummyDataset"]], "neural_compressor.data.datasets.imagenet_dataset": [[252, 1, 1, "", "ImagenetRaw"], [252, 1, 1, "", "MXNetImagenetRaw"], [252, 1, 1, "", "ONNXRTImagenetDataset"], [252, 1, 1, "", "PytorchImagenetRaw"], [252, 1, 1, "", "TensorflowImagenetDataset"], [252, 1, 1, "", "TensorflowImagenetRaw"]], "neural_compressor.data.datasets.style_transfer_dataset": [[254, 1, 1, "", "StyleTransferDataset"]], "neural_compressor.data.filters": [[255, 0, 0, "-", "coco_filter"], [256, 0, 0, "-", "filter"]], "neural_compressor.data.filters.coco_filter": [[255, 1, 1, "", "LabelBalanceCOCORawFilter"], [255, 1, 1, "", "LabelBalanceCOCORecordFilter"]], "neural_compressor.data.filters.filter": [[256, 1, 1, "", "FILTERS"], [256, 1, 1, "", "Filter"], [256, 1, 1, "", "MXNetFilters"], [256, 1, 1, "", "ONNXRTITFilters"], [256, 1, 1, "", "ONNXRTQLFilters"], [256, 1, 1, "", "PyTorchFilters"], [256, 1, 1, "", "TensorflowFilters"], [256, 2, 1, "", "filter_registry"]], "neural_compressor.data.transforms": [[259, 0, 0, "-", "coco_transform"], [260, 0, 0, "-", "imagenet_transform"], [262, 0, 0, "-", "postprocess"], [263, 0, 0, "-", "tokenization"], [264, 0, 0, "-", "transform"]], "neural_compressor.data.transforms.coco_transform": [[259, 1, 1, "", "ParseDecodeCocoTransform"]], "neural_compressor.data.transforms.imagenet_transform": [[260, 1, 1, "", "BilinearImagenetTransform"], [260, 1, 1, "", "LabelShift"], [260, 1, 1, "", "ONNXResizeCropImagenetTransform"], [260, 1, 1, "", "OnnxBilinearImagenetTransform"], [260, 1, 1, "", "ParseDecodeImagenet"], [260, 1, 1, "", "ParseDecodeImagenetTransform"], [260, 1, 1, "", "QuantizedInput"], [260, 1, 1, "", "ResizeWithAspectRatio"], [260, 1, 1, "", "TensorflowResizeCropImagenetTransform"], [260, 1, 1, "", "TensorflowShiftRescale"], [260, 1, 1, "", "TensorflowTransposeLastChannel"]], "neural_compressor.data.transforms.postprocess": [[262, 1, 1, "", "Postprocess"]], "neural_compressor.data.transforms.tokenization": [[263, 1, 1, "", "BasicTokenizer"], [263, 1, 1, "", "FullTokenizer"], [263, 1, 1, "", "WordpieceTokenizer"], [263, 2, 1, "", "convert_by_vocab"], [263, 2, 1, "", "convert_to_unicode"], [263, 2, 1, "", "load_vocab"], [263, 2, 1, "", "whitespace_tokenize"]], "neural_compressor.data.transforms.transform": [[264, 1, 1, "", "AlignImageChannelTransform"], [264, 1, 1, "", "BaseTransform"], [264, 1, 1, "", "CastONNXTransform"], [264, 1, 1, "", "CastPyTorchTransform"], [264, 1, 1, "", "CastTFTransform"], [264, 1, 1, "", "CenterCropTFTransform"], [264, 1, 1, "", "CenterCropTransform"], [264, 1, 1, "", "CollectTransform"], [264, 1, 1, "", "ComposeTransform"], [264, 1, 1, "", "CropResizeTFTransform"], [264, 1, 1, "", "CropResizeTransform"], [264, 1, 1, "", "CropToBoundingBox"], [264, 1, 1, "", "InputFeatures"], [264, 1, 1, "", "MXNetCropResizeTransform"], [264, 1, 1, "", "MXNetCropToBoundingBox"], [264, 1, 1, "", "MXNetNormalizeTransform"], [264, 1, 1, "", "MXNetTransforms"], [264, 1, 1, "", "MXNetTranspose"], [264, 1, 1, "", "NormalizeTFTransform"], [264, 1, 1, "", "NormalizeTransform"], [264, 1, 1, "", "ONNXRTCropToBoundingBox"], [264, 1, 1, "", "ONNXRTITTransforms"], [264, 1, 1, "", "ONNXRTQLTransforms"], [264, 1, 1, "", "PaddedCenterCropTransform"], [264, 1, 1, "", "ParseDecodeVocTransform"], [264, 1, 1, "", "PyTorchAlignImageChannel"], [264, 1, 1, "", "PyTorchCropResizeTransform"], [264, 1, 1, "", "PyTorchNormalizeTransform"], [264, 1, 1, "", "PyTorchTransforms"], [264, 1, 1, "", "PyTorchTranspose"], [264, 1, 1, "", "PytorchMxnetTransform"], [264, 1, 1, "", "PytorchMxnetWrapFunction"], [264, 1, 1, "", "RandomCropTFTransform"], [264, 1, 1, "", "RandomCropTransform"], [264, 1, 1, "", "RandomHorizontalFlip"], [264, 1, 1, "", "RandomResizedCropMXNetTransform"], [264, 1, 1, "", "RandomResizedCropPytorchTransform"], [264, 1, 1, "", "RandomResizedCropTFTransform"], [264, 1, 1, "", "RandomResizedCropTransform"], [264, 1, 1, "", "RandomVerticalFlip"], [264, 1, 1, "", "RescaleKerasPretrainTransform"], [264, 1, 1, "", "RescaleTFTransform"], [264, 1, 1, "", "RescaleTransform"], [264, 1, 1, "", "ResizeMXNetTransform"], [264, 1, 1, "", "ResizePytorchTransform"], [264, 1, 1, "", "ResizeTFTransform"], [264, 1, 1, "", "ResizeTransform"], [264, 1, 1, "", "ResizeWithRatio"], [264, 1, 1, "", "SquadExample"], [264, 1, 1, "", "TFModelZooCollectTransform"], [264, 1, 1, "", "TFSquadV1ModelZooPostTransform"], [264, 1, 1, "", "TFSquadV1PostTransform"], [264, 1, 1, "", "TRANSFORMS"], [264, 1, 1, "", "TensorflowCropToBoundingBox"], [264, 1, 1, "", "TensorflowRandomHorizontalFlip"], [264, 1, 1, "", "TensorflowRandomVerticalFlip"], [264, 1, 1, "", "TensorflowResizeWithRatio"], [264, 1, 1, "", "TensorflowTransform"], [264, 1, 1, "", "TensorflowTransforms"], [264, 1, 1, "", "TensorflowTranspose"], [264, 1, 1, "", "TensorflowWrapFunction"], [264, 1, 1, "", "ToArray"], [264, 1, 1, "", "ToNDArrayTransform"], [264, 1, 1, "", "Transforms"], [264, 1, 1, "", "Transpose"], [264, 2, 1, "", "convert_examples_to_features"], [264, 2, 1, "", "get_final_text"], [264, 2, 1, "", "get_torchvision_map"], [264, 2, 1, "", "read_squad_examples"], [264, 2, 1, "", "transform_registry"]], "neural_compressor.experimental": [[265, 0, 0, "-", "benchmark"], [268, 0, 0, "-", "common"], [274, 0, 0, "-", "component"], [275, 0, 0, "-", "compression"], [276, 0, 0, "-", "contrib"], [301, 0, 0, "-", "data"], [306, 0, 0, "-", "distillation"], [307, 0, 0, "-", "export"], [311, 0, 0, "-", "graph_optimization"], [319, 0, 0, "-", "metric"], [321, 0, 0, "-", "mixed_precision"], [322, 0, 0, "-", "model_conversion"], [325, 0, 0, "-", "nas"], [331, 0, 0, "-", "pruner_legacy"], [335, 0, 0, "-", "pruning"], [336, 0, 0, "-", "pruning_recipes"], [340, 0, 0, "-", "pruning_v2"], [341, 0, 0, "-", "pytorch_pruner"], [348, 0, 0, "-", "quantization"], [349, 0, 0, "-", "scheduler"], [354, 0, 0, "-", "strategy"]], "neural_compressor.experimental.benchmark": [[265, 1, 1, "", "Benchmark"], [265, 2, 1, "", "get_architecture"], [265, 2, 1, "", "get_bounded_threads"], [265, 2, 1, "", "get_core_ids"], [265, 2, 1, "", "get_physical_ids"], [265, 2, 1, "", "get_threads"], [265, 2, 1, "", "get_threads_per_core"], [265, 2, 1, "", "set_all_env_var"], [265, 2, 1, "", "set_env_var"]], "neural_compressor.experimental.common": [[266, 0, 0, "-", "criterion"], [267, 0, 0, "-", "dataloader"], [269, 0, 0, "-", "metric"], [270, 0, 0, "-", "model"], [271, 0, 0, "-", "optimizer"], [272, 0, 0, "-", "postprocess"], [273, 0, 0, "-", "torch_utils"]], "neural_compressor.experimental.common.criterion": [[266, 1, 1, "", "Criterions"], [266, 1, 1, "", "IntermediateLayersKnowledgeDistillationLoss"], [266, 1, 1, "", "KnowledgeDistillationFramework"], [266, 1, 1, "", "KnowledgeDistillationLoss"], [266, 1, 1, "", "PyTorchCriterions"], [266, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLoss"], [266, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"], [266, 1, 1, "", "PyTorchKnowledgeDistillationLoss"], [266, 1, 1, "", "PyTorchKnowledgeDistillationLossWrapper"], [266, 1, 1, "", "SelfKnowledgeDistillationLoss"], [266, 1, 1, "", "TensorflowCriterions"], [266, 1, 1, "", "TensorflowKnowledgeDistillationLossExternal"], [266, 2, 1, "", "criterion_registry"]], "neural_compressor.experimental.common.dataloader": [[267, 1, 1, "", "DataLoader"]], "neural_compressor.experimental.common.metric": [[269, 1, 1, "", "Metric"]], "neural_compressor.experimental.common.model": [[270, 1, 1, "", "Model"], [270, 2, 1, "", "set_backend"]], "neural_compressor.experimental.common.optimizer": [[271, 1, 1, "", "Optimizers"], [271, 1, 1, "", "PyTorchOptimizers"], [271, 1, 1, "", "PyTorchSGD"], [271, 1, 1, "", "TensorFlowAdamW"], [271, 1, 1, "", "TensorFlowSGD"], [271, 1, 1, "", "TensorflowOptimizers"], [271, 2, 1, "", "optimizer_registry"]], "neural_compressor.experimental.common.postprocess": [[272, 1, 1, "", "Postprocess"]], "neural_compressor.experimental.common.torch_utils": [[273, 2, 1, "", "get_activation"], [273, 2, 1, "", "record_output"]], "neural_compressor.experimental.component": [[274, 1, 1, "", "Component"]], "neural_compressor.experimental.contrib": [[277, 0, 0, "-", "strategy"]], "neural_compressor.experimental.contrib.strategy": [[278, 0, 0, "-", "sigopt"], [279, 0, 0, "-", "tpe"]], "neural_compressor.experimental.contrib.strategy.sigopt": [[278, 1, 1, "", "SigOptTuneStrategy"]], "neural_compressor.experimental.contrib.strategy.tpe": [[279, 1, 1, "", "TpeTuneStrategy"]], "neural_compressor.experimental.data": [[284, 0, 0, "-", "dataloaders"], [296, 0, 0, "-", "datasets"], [300, 0, 0, "-", "filters"], [303, 0, 0, "-", "transforms"]], "neural_compressor.experimental.data.dataloaders": [[280, 0, 0, "-", "base_dataloader"], [281, 0, 0, "-", "dataloader"], [282, 0, 0, "-", "default_dataloader"], [283, 0, 0, "-", "fetcher"], [285, 0, 0, "-", "mxnet_dataloader"], [286, 0, 0, "-", "onnxrt_dataloader"], [287, 0, 0, "-", "pytorch_dataloader"], [288, 0, 0, "-", "sampler"], [289, 0, 0, "-", "tensorflow_dataloader"]], "neural_compressor.experimental.data.dataloaders.base_dataloader": [[280, 1, 1, "", "BaseDataLoader"]], "neural_compressor.experimental.data.dataloaders.default_dataloader": [[282, 1, 1, "", "DefaultDataLoader"], [282, 2, 1, "", "default_collate"]], "neural_compressor.experimental.data.dataloaders.fetcher": [[283, 1, 1, "", "Fetcher"], [283, 1, 1, "", "IndexFetcher"], [283, 1, 1, "", "IterableFetcher"]], "neural_compressor.experimental.data.dataloaders.mxnet_dataloader": [[285, 1, 1, "", "MXNetDataLoader"]], "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader": [[286, 1, 1, "", "ONNXRTBertDataLoader"], [286, 1, 1, "", "ONNXRTDataLoader"]], "neural_compressor.experimental.data.dataloaders.pytorch_dataloader": [[287, 1, 1, "", "PyTorchDataLoader"]], "neural_compressor.experimental.data.dataloaders.sampler": [[288, 1, 1, "", "BatchSampler"], [288, 1, 1, "", "IterableSampler"], [288, 1, 1, "", "Sampler"], [288, 1, 1, "", "SequentialSampler"]], "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader": [[289, 1, 1, "", "TFDataDataLoader"], [289, 1, 1, "", "TensorflowBertDataLoader"], [289, 1, 1, "", "TensorflowDataLoader"], [289, 1, 1, "", "TensorflowModelZooBertDataLoader"]], "neural_compressor.experimental.data.datasets": [[290, 0, 0, "-", "bert_dataset"], [291, 0, 0, "-", "coco_dataset"], [292, 0, 0, "-", "dataset"], [293, 0, 0, "-", "dummy_dataset"], [294, 0, 0, "-", "dummy_dataset_v2"], [295, 0, 0, "-", "imagenet_dataset"], [297, 0, 0, "-", "style_transfer_dataset"]], "neural_compressor.experimental.data.datasets.bert_dataset": [[290, 1, 1, "", "InputFeatures"], [290, 1, 1, "", "ONNXRTBertDataset"], [290, 1, 1, "", "ParseDecodeBert"], [290, 1, 1, "", "PytorchBertDataset"], [290, 1, 1, "", "TensorflowBertDataset"], [290, 1, 1, "", "TensorflowModelZooBertDataset"], [290, 2, 1, "", "convert_examples_to_features"], [290, 2, 1, "", "load_and_cache_examples"]], "neural_compressor.experimental.data.datasets.coco_dataset": [[291, 1, 1, "", "COCONpy"], [291, 1, 1, "", "COCORaw"], [291, 1, 1, "", "COCORecordDataset"], [291, 1, 1, "", "ParseDecodeCoco"]], "neural_compressor.experimental.data.datasets.dataset": [[292, 1, 1, "", "CIFAR10"], [292, 1, 1, "", "CIFAR100"], [292, 1, 1, "", "Dataset"], [292, 1, 1, "", "Datasets"], [292, 1, 1, "", "FashionMNIST"], [292, 1, 1, "", "ImageFolder"], [292, 1, 1, "", "IterableDataset"], [292, 1, 1, "", "MNIST"], [292, 1, 1, "", "MXNetCIFAR10"], [292, 1, 1, "", "MXNetCIFAR100"], [292, 1, 1, "", "MXNetDatasets"], [292, 1, 1, "", "MXNetFashionMNIST"], [292, 1, 1, "", "MXNetImageFolder"], [292, 1, 1, "", "MXNetMNIST"], [292, 1, 1, "", "ONNXRTITDatasets"], [292, 1, 1, "", "ONNXRTQLDatasets"], [292, 1, 1, "", "PyTorchDatasets"], [292, 1, 1, "", "PytorchCIFAR10"], [292, 1, 1, "", "PytorchCIFAR100"], [292, 1, 1, "", "PytorchFashionMNIST"], [292, 1, 1, "", "PytorchMNIST"], [292, 1, 1, "", "PytorchMxnetWrapDataset"], [292, 1, 1, "", "PytorchMxnetWrapFunction"], [292, 1, 1, "", "TensorflowCIFAR10"], [292, 1, 1, "", "TensorflowCIFAR100"], [292, 1, 1, "", "TensorflowDatasets"], [292, 1, 1, "", "TensorflowFashionMNIST"], [292, 1, 1, "", "TensorflowImageFolder"], [292, 1, 1, "", "TensorflowImageRecord"], [292, 1, 1, "", "TensorflowMNIST"], [292, 1, 1, "", "TensorflowTFRecordDataset"], [292, 1, 1, "", "TensorflowVOCRecord"], [292, 2, 1, "", "calculate_md5"], [292, 2, 1, "", "check_integrity"], [292, 2, 1, "", "dataset_registry"], [292, 2, 1, "", "download_url"], [292, 5, 1, "", "framework_datasets"], [292, 2, 1, "", "gen_bar_updater"]], "neural_compressor.experimental.data.datasets.dummy_dataset": [[293, 1, 1, "", "DummyDataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset_v2": [[294, 1, 1, "", "DummyDataset"], [294, 1, 1, "", "SparseDummyDataset"]], "neural_compressor.experimental.data.datasets.imagenet_dataset": [[295, 1, 1, "", "ImagenetRaw"], [295, 1, 1, "", "MXNetImagenetRaw"], [295, 1, 1, "", "ONNXRTImagenetDataset"], [295, 1, 1, "", "PytorchImagenetRaw"], [295, 1, 1, "", "TensorflowImagenetDataset"], [295, 1, 1, "", "TensorflowImagenetRaw"]], "neural_compressor.experimental.data.datasets.style_transfer_dataset": [[297, 1, 1, "", "StyleTransferDataset"]], "neural_compressor.experimental.data.filters": [[298, 0, 0, "-", "coco_filter"], [299, 0, 0, "-", "filter"]], "neural_compressor.experimental.data.filters.coco_filter": [[298, 1, 1, "", "LabelBalanceCOCORawFilter"], [298, 1, 1, "", "LabelBalanceCOCORecordFilter"]], "neural_compressor.experimental.data.filters.filter": [[299, 1, 1, "", "FILTERS"], [299, 1, 1, "", "Filter"], [299, 1, 1, "", "MXNetFilters"], [299, 1, 1, "", "ONNXRTITFilters"], [299, 1, 1, "", "ONNXRTQLFilters"], [299, 1, 1, "", "PyTorchFilters"], [299, 1, 1, "", "TensorflowFilters"], [299, 2, 1, "", "filter_registry"]], "neural_compressor.experimental.data.transforms": [[302, 0, 0, "-", "imagenet_transform"], [304, 0, 0, "-", "tokenization"], [305, 0, 0, "-", "transform"]], "neural_compressor.experimental.data.transforms.imagenet_transform": [[302, 1, 1, "", "BilinearImagenetTransform"], [302, 1, 1, "", "LabelShift"], [302, 1, 1, "", "ONNXResizeCropImagenetTransform"], [302, 1, 1, "", "OnnxBilinearImagenetTransform"], [302, 1, 1, "", "ParseDecodeImagenet"], [302, 1, 1, "", "ParseDecodeImagenetTransform"], [302, 1, 1, "", "QuantizedInput"], [302, 1, 1, "", "ResizeWithAspectRatio"], [302, 1, 1, "", "TensorflowResizeCropImagenetTransform"]], "neural_compressor.experimental.data.transforms.tokenization": [[304, 1, 1, "", "BasicTokenizer"], [304, 1, 1, "", "FullTokenizer"], [304, 1, 1, "", "WordpieceTokenizer"], [304, 2, 1, "", "convert_by_vocab"], [304, 2, 1, "", "convert_to_unicode"], [304, 2, 1, "", "load_vocab"], [304, 2, 1, "", "whitespace_tokenize"]], "neural_compressor.experimental.data.transforms.transform": [[305, 1, 1, "", "AlignImageChannelTransform"], [305, 1, 1, "", "BaseTransform"], [305, 1, 1, "", "CastONNXTransform"], [305, 1, 1, "", "CastPyTorchTransform"], [305, 1, 1, "", "CastTFTransform"], [305, 1, 1, "", "CenterCropTFTransform"], [305, 1, 1, "", "CenterCropTransform"], [305, 1, 1, "", "CollectTransform"], [305, 1, 1, "", "ComposeTransform"], [305, 1, 1, "", "CropResizeTFTransform"], [305, 1, 1, "", "CropResizeTransform"], [305, 1, 1, "", "CropToBoundingBox"], [305, 1, 1, "", "InputFeatures"], [305, 1, 1, "", "MXNetCropResizeTransform"], [305, 1, 1, "", "MXNetCropToBoundingBox"], [305, 1, 1, "", "MXNetNormalizeTransform"], [305, 1, 1, "", "MXNetTransforms"], [305, 1, 1, "", "MXNetTranspose"], [305, 1, 1, "", "NormalizeTFTransform"], [305, 1, 1, "", "NormalizeTransform"], [305, 1, 1, "", "ONNXRTCropToBoundingBox"], [305, 1, 1, "", "ONNXRTITTransforms"], [305, 1, 1, "", "ONNXRTQLTransforms"], [305, 1, 1, "", "PaddedCenterCropTransform"], [305, 1, 1, "", "ParseDecodeVocTransform"], [305, 1, 1, "", "PyTorchAlignImageChannel"], [305, 1, 1, "", "PyTorchCropResizeTransform"], [305, 1, 1, "", "PyTorchNormalizeTransform"], [305, 1, 1, "", "PyTorchTransforms"], [305, 1, 1, "", "PyTorchTranspose"], [305, 1, 1, "", "PytorchMxnetTransform"], [305, 1, 1, "", "PytorchMxnetWrapFunction"], [305, 1, 1, "", "RandomCropTFTransform"], [305, 1, 1, "", "RandomCropTransform"], [305, 1, 1, "", "RandomHorizontalFlip"], [305, 1, 1, "", "RandomResizedCropMXNetTransform"], [305, 1, 1, "", "RandomResizedCropPytorchTransform"], [305, 1, 1, "", "RandomResizedCropTFTransform"], [305, 1, 1, "", "RandomResizedCropTransform"], [305, 1, 1, "", "RandomVerticalFlip"], [305, 1, 1, "", "RescaleKerasPretrainTransform"], [305, 1, 1, "", "RescaleTFTransform"], [305, 1, 1, "", "RescaleTransform"], [305, 1, 1, "", "ResizeMXNetTransform"], [305, 1, 1, "", "ResizePytorchTransform"], [305, 1, 1, "", "ResizeTFTransform"], [305, 1, 1, "", "ResizeTransform"], [305, 1, 1, "", "ResizeWithRatio"], [305, 1, 1, "", "SquadExample"], [305, 1, 1, "", "TFModelZooCollectTransform"], [305, 1, 1, "", "TFSquadV1ModelZooPostTransform"], [305, 1, 1, "", "TFSquadV1PostTransform"], [305, 1, 1, "", "TRANSFORMS"], [305, 1, 1, "", "TensorflowCropToBoundingBox"], [305, 1, 1, "", "TensorflowRandomHorizontalFlip"], [305, 1, 1, "", "TensorflowRandomVerticalFlip"], [305, 1, 1, "", "TensorflowResizeWithRatio"], [305, 1, 1, "", "TensorflowTransform"], [305, 1, 1, "", "TensorflowTransforms"], [305, 1, 1, "", "TensorflowTranspose"], [305, 1, 1, "", "TensorflowWrapFunction"], [305, 1, 1, "", "ToArray"], [305, 1, 1, "", "ToNDArrayTransform"], [305, 1, 1, "", "Transforms"], [305, 1, 1, "", "Transpose"], [305, 2, 1, "", "convert_examples_to_features"], [305, 2, 1, "", "get_final_text"], [305, 2, 1, "", "get_torchvision_map"], [305, 2, 1, "", "read_squad_examples"], [305, 2, 1, "", "transform_registry"]], "neural_compressor.experimental.distillation": [[306, 1, 1, "", "Distillation"]], "neural_compressor.experimental.distillation.Distillation": [[306, 4, 1, "", "_epoch_ran"], [306, 4, 1, "", "best_model"], [306, 4, 1, "", "best_score"], [306, 4, 1, "", "eval_frequency"]], "neural_compressor.experimental.export": [[308, 0, 0, "-", "qlinear2qdq"], [309, 0, 0, "-", "tf2onnx"], [310, 0, 0, "-", "torch2onnx"]], "neural_compressor.experimental.export.qlinear2qdq": [[308, 2, 1, "", "check_model"], [308, 2, 1, "", "onnx_qlinear_to_qdq"]], "neural_compressor.experimental.export.tf2onnx": [[309, 2, 1, "", "tf_to_fp32_onnx"], [309, 2, 1, "", "tf_to_int8_onnx"]], "neural_compressor.experimental.export.torch2onnx": [[310, 2, 1, "", "dynamic_quant_export"], [310, 2, 1, "", "get_node_mapping"], [310, 2, 1, "", "get_quantizable_onnx_ops"], [310, 2, 1, "", "static_quant_export"], [310, 2, 1, "", "torch_to_fp32_onnx"], [310, 2, 1, "", "torch_to_int8_onnx"]], "neural_compressor.experimental.graph_optimization": [[311, 1, 1, "", "Graph_Optimization"]], "neural_compressor.experimental.metric": [[313, 0, 0, "-", "bleu"], [314, 0, 0, "-", "bleu_util"], [315, 0, 0, "-", "coco_label_map"], [316, 0, 0, "-", "coco_tools"], [317, 0, 0, "-", "evaluate_squad"], [318, 0, 0, "-", "f1"], [320, 0, 0, "-", "metric"]], "neural_compressor.experimental.metric.bleu": [[313, 1, 1, "", "BLEU"], [313, 1, 1, "", "UnicodeRegex"], [313, 2, 1, "", "bleu_tokenize"]], "neural_compressor.experimental.metric.bleu.BLEU": [[313, 4, 1, "", "labels"], [313, 4, 1, "", "predictions"]], "neural_compressor.experimental.metric.bleu.UnicodeRegex": [[313, 4, 1, "", "nondigit_punct_re"], [313, 4, 1, "", "punct_nondigit_re"], [313, 4, 1, "", "symbol_re"]], "neural_compressor.experimental.metric.bleu_util": [[314, 2, 1, "", "compute_bleu"]], "neural_compressor.experimental.metric.coco_tools": [[316, 1, 1, "", "COCOEvalWrapper"], [316, 1, 1, "", "COCOWrapper"], [316, 2, 1, "", "ExportSingleImageDetectionBoxesToCoco"], [316, 2, 1, "", "ExportSingleImageDetectionMasksToCoco"], [316, 2, 1, "", "ExportSingleImageGroundtruthToCoco"]], "neural_compressor.experimental.metric.coco_tools.COCOWrapper": [[316, 4, 1, "", "dataset"], [316, 4, 1, "", "detection_type"]], "neural_compressor.experimental.metric.evaluate_squad": [[317, 2, 1, "", "evaluate"], [317, 2, 1, "", "exact_match_score"], [317, 2, 1, "", "f1_score"], [317, 2, 1, "", "metric_max_over_ground_truths"]], "neural_compressor.experimental.metric.f1": [[318, 2, 1, "", "evaluate"], [318, 2, 1, "", "f1_score"], [318, 2, 1, "", "metric_max_over_ground_truths"], [318, 2, 1, "", "normalize_answer"]], "neural_compressor.experimental.metric.metric": [[320, 1, 1, "", "Accuracy"], [320, 1, 1, "", "BaseMetric"], [320, 1, 1, "", "COCOmAPv2"], [320, 1, 1, "", "F1"], [320, 1, 1, "", "GeneralTopK"], [320, 1, 1, "", "Loss"], [320, 1, 1, "", "MAE"], [320, 1, 1, "", "METRICS"], [320, 1, 1, "", "MSE"], [320, 1, 1, "", "MXNetMetrics"], [320, 1, 1, "", "ONNXRTGLUE"], [320, 1, 1, "", "ONNXRTITMetrics"], [320, 1, 1, "", "ONNXRTQLMetrics"], [320, 1, 1, "", "PyTorchLoss"], [320, 1, 1, "", "PyTorchMetrics"], [320, 1, 1, "", "RMSE"], [320, 1, 1, "", "ROC"], [320, 1, 1, "", "SquadF1"], [320, 1, 1, "", "TensorflowCOCOMAP"], [320, 1, 1, "", "TensorflowMAP"], [320, 1, 1, "", "TensorflowMetrics"], [320, 1, 1, "", "TensorflowTopK"], [320, 1, 1, "", "TensorflowVOCMAP"], [320, 1, 1, "", "WrapMXNetMetric"], [320, 1, 1, "", "WrapONNXRTMetric"], [320, 1, 1, "", "WrapPyTorchMetric"], [320, 1, 1, "", "mIOU"], [320, 2, 1, "", "metric_registry"]], "neural_compressor.experimental.metric.metric.Accuracy": [[320, 4, 1, "", "label_list"], [320, 4, 1, "", "pred_list"], [320, 4, 1, "", "sample"]], "neural_compressor.experimental.metric.metric.GeneralTopK": [[320, 4, 1, "", "k"], [320, 4, 1, "", "num_correct"], [320, 4, 1, "", "num_sample"]], "neural_compressor.experimental.metric.metric.Loss": [[320, 4, 1, "", "sample"], [320, 4, 1, "", "sum"]], "neural_compressor.experimental.metric.metric.MAE": [[320, 4, 1, "", "compare_label"], [320, 4, 1, "", "label_list"], [320, 4, 1, "", "pred_list"]], "neural_compressor.experimental.metric.metric.METRICS": [[320, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.MSE": [[320, 4, 1, "", "compare_label"], [320, 4, 1, "", "label_list"], [320, 4, 1, "", "pred_list"]], "neural_compressor.experimental.metric.metric.MXNetMetrics": [[320, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.ONNXRTITMetrics": [[320, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.ONNXRTQLMetrics": [[320, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.PyTorchMetrics": [[320, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.RMSE": [[320, 4, 1, "", "mse"]], "neural_compressor.experimental.metric.metric.TensorflowMetrics": [[320, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.TensorflowTopK": [[320, 4, 1, "", "k"], [320, 4, 1, "", "num_correct"], [320, 4, 1, "", "num_sample"]], "neural_compressor.experimental.mixed_precision": [[321, 1, 1, "", "MixedPrecision"]], "neural_compressor.experimental.model_conversion": [[322, 1, 1, "", "ModelConversion"]], "neural_compressor.experimental.nas": [[323, 0, 0, "-", "basic_nas"], [324, 0, 0, "-", "dynas"], [326, 0, 0, "-", "nas"], [327, 0, 0, "-", "nas_utils"], [328, 0, 0, "-", "search_algorithms"]], "neural_compressor.experimental.nas.basic_nas": [[323, 1, 1, "", "BasicNAS"]], "neural_compressor.experimental.nas.dynas": [[324, 1, 1, "", "DyNAS"]], "neural_compressor.experimental.nas.nas": [[326, 1, 1, "", "NAS"], [326, 1, 1, "", "NASBase"]], "neural_compressor.experimental.nas.nas_utils": [[327, 2, 1, "", "create_search_space_pool"], [327, 2, 1, "", "find_pareto_front"], [327, 2, 1, "", "nas_registry"]], "neural_compressor.experimental.nas.search_algorithms": [[328, 1, 1, "", "BayesianOptimizationSearcher"], [328, 1, 1, "", "GridSearcher"], [328, 1, 1, "", "RandomSearcher"], [328, 1, 1, "", "Searcher"]], "neural_compressor.experimental.pruner_legacy": [[329, 0, 0, "-", "gradient_sensitivity"], [330, 0, 0, "-", "group_lasso"], [332, 0, 0, "-", "magnitude"], [333, 0, 0, "-", "pattern_lock"], [334, 0, 0, "-", "pruner"]], "neural_compressor.experimental.pruner_legacy.gradient_sensitivity": [[329, 1, 1, "", "GradientSensitivityPruner"]], "neural_compressor.experimental.pruner_legacy.group_lasso": [[330, 1, 1, "", "GroupLassoPruner"]], "neural_compressor.experimental.pruner_legacy.magnitude": [[332, 1, 1, "", "BasicMagnitudePruner"]], "neural_compressor.experimental.pruner_legacy.pattern_lock": [[333, 1, 1, "", "PatternLockPruner"]], "neural_compressor.experimental.pruner_legacy.pruner": [[334, 1, 1, "", "Pruner"], [334, 2, 1, "", "pruner_registry"]], "neural_compressor.experimental.pruning": [[335, 1, 1, "", "Pruning"], [335, 1, 1, "", "TfPruningCallback"]], "neural_compressor.experimental.pruning.Pruning": [[335, 4, 1, "", "conf"], [335, 4, 1, "", "pruners"]], "neural_compressor.experimental.pruning_recipes": [[337, 0, 0, "-", "patterns"]], "neural_compressor.experimental.pruning_recipes.patterns": [[338, 0, 0, "-", "pattern"], [339, 0, 0, "-", "tile_pattern"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern": [[338, 1, 1, "", "PATTERNS"], [338, 1, 1, "", "PatternBase"], [338, 2, 1, "", "pattern_registry"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern.PATTERNS": [[338, 4, 1, "", "patterns"]], "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern": [[339, 1, 1, "", "TilePatternBase"], [339, 1, 1, "", "TilePattern_1x1"], [339, 1, 1, "", "TilePattern_1x16"], [339, 1, 1, "", "TilePattern_1x2"], [339, 1, 1, "", "TilePattern_2x2"], [339, 1, 1, "", "TilePattern_4x1"]], "neural_compressor.experimental.pruning_v2": [[340, 1, 1, "", "Pruning"], [340, 1, 1, "", "TfPruningCallback"]], "neural_compressor.experimental.pruning_v2.Pruning": [[340, 4, 1, "", "conf"], [340, 4, 1, "", "pruners"]], "neural_compressor.experimental.pytorch_pruner": [[342, 0, 0, "-", "logger"], [343, 0, 0, "-", "patterns"], [344, 0, 0, "-", "prune_utils"], [345, 0, 0, "-", "pruner"], [346, 0, 0, "-", "pruning"], [347, 0, 0, "-", "scheduler"]], "neural_compressor.experimental.pytorch_pruner.patterns": [[343, 1, 1, "", "Pattern"], [343, 1, 1, "", "PatternNInM"], [343, 1, 1, "", "PatternNxM"], [343, 2, 1, "", "get_pattern"], [343, 2, 1, "", "register_pattern"]], "neural_compressor.experimental.pytorch_pruner.patterns.Pattern": [[343, 4, 1, "", "is_global"], [343, 4, 1, "", "pattern"]], "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM": [[343, 4, 1, "", "M"], [343, 4, 1, "", "N"]], "neural_compressor.experimental.pytorch_pruner.patterns.PatternNxM": [[343, 4, 1, "", "block_size"]], "neural_compressor.experimental.pytorch_pruner.prune_utils": [[344, 2, 1, "", "check_config"], [344, 2, 1, "", "parse_not_to_prune"], [344, 2, 1, "", "parse_to_prune"], [344, 2, 1, "", "process_and_check_config"], [344, 2, 1, "", "process_config"], [344, 2, 1, "", "reset_non_value_to_default"]], "neural_compressor.experimental.pytorch_pruner.pruner": [[345, 1, 1, "", "MagnitudePruner"], [345, 1, 1, "", "PatternLockPruner"], [345, 1, 1, "", "Pruner"], [345, 1, 1, "", "SnipMomentumPruner"], [345, 1, 1, "", "SnipPruner"], [345, 2, 1, "", "get_pruner"], [345, 2, 1, "", "register_pruners"]], "neural_compressor.experimental.pytorch_pruner.pruner.Pruner": [[345, 4, 1, "", "config"], [345, 4, 1, "", "current_sparsity_ratio"], [345, 4, 1, "", "end_step"], [345, 4, 1, "", "global_step"], [345, 4, 1, "", "masks"], [345, 4, 1, "", "max_sparsity_ratio_per_layer"], [345, 4, 1, "", "modules"], [345, 4, 1, "", "pattern"], [345, 4, 1, "", "scheduler"], [345, 4, 1, "", "scores"], [345, 4, 1, "", "start_step"], [345, 4, 1, "", "target_sparsity_ratio"], [345, 4, 1, "", "update_frequency_on_step"]], "neural_compressor.experimental.pytorch_pruner.pruning": [[346, 1, 1, "", "Pruning"]], "neural_compressor.experimental.pytorch_pruner.pruning.Pruning": [[346, 4, 1, "", "config_file_path"], [346, 4, 1, "", "model"], [346, 4, 1, "", "pruner_info"], [346, 4, 1, "", "pruners"]], "neural_compressor.experimental.pytorch_pruner.scheduler": [[347, 1, 1, "", "IterativeScheduler"], [347, 1, 1, "", "OneshotScheduler"], [347, 1, 1, "", "Scheduler"], [347, 2, 1, "", "get_scheduler"], [347, 2, 1, "", "register_scheduler"]], "neural_compressor.experimental.pytorch_pruner.scheduler.Scheduler": [[347, 4, 1, "", "config"]], "neural_compressor.experimental.quantization": [[348, 1, 1, "", "Quantization"]], "neural_compressor.experimental.scheduler": [[349, 1, 1, "", "Scheduler"]], "neural_compressor.experimental.strategy": [[350, 0, 0, "-", "auto_mixed_precision"], [351, 0, 0, "-", "basic"], [352, 0, 0, "-", "bayesian"], [353, 0, 0, "-", "exhaustive"], [355, 0, 0, "-", "mse"], [356, 0, 0, "-", "mse_v2"], [357, 0, 0, "-", "random"], [358, 0, 0, "-", "strategy"], [360, 0, 0, "-", "utils"]], "neural_compressor.experimental.strategy.auto_mixed_precision": [[350, 1, 1, "", "AutoMixedPrecisionTuneStrategy"]], "neural_compressor.experimental.strategy.basic": [[351, 1, 1, "", "BasicTuneStrategy"]], "neural_compressor.experimental.strategy.bayesian": [[352, 1, 1, "", "BayesianOptimization"], [352, 1, 1, "", "BayesianTuneStrategy"], [352, 1, 1, "", "TargetSpace"], [352, 2, 1, "", "acq_max"]], "neural_compressor.experimental.strategy.exhaustive": [[353, 1, 1, "", "ExhaustiveTuneStrategy"]], "neural_compressor.experimental.strategy.mse": [[355, 1, 1, "", "MSETuneStrategy"]], "neural_compressor.experimental.strategy.mse_v2": [[356, 1, 1, "", "MSE_V2TuneStrategy"]], "neural_compressor.experimental.strategy.random": [[357, 1, 1, "", "RandomTuneStrategy"]], "neural_compressor.experimental.strategy.strategy": [[358, 1, 1, "", "TuneStrategy"], [358, 2, 1, "", "strategy_registry"]], "neural_compressor.experimental.strategy.utils": [[359, 0, 0, "-", "constant"], [361, 0, 0, "-", "tuning_sampler"], [362, 0, 0, "-", "tuning_space"], [363, 0, 0, "-", "tuning_structs"], [364, 0, 0, "-", "utility"]], "neural_compressor.experimental.strategy.utils.tuning_sampler": [[361, 1, 1, "", "FallbackTuningSampler"], [361, 1, 1, "", "ModelWiseTuningSampler"], [361, 1, 1, "", "OpTypeWiseTuningSampler"], [361, 1, 1, "", "OpWiseTuningSampler"], [361, 1, 1, "", "SmoothQuantSampler"], [361, 1, 1, "", "TuningOrder"], [361, 1, 1, "", "TuningSampler"], [361, 1, 1, "", "TuningSamplerRegistry"]], "neural_compressor.experimental.strategy.utils.tuning_space": [[362, 1, 1, "", "TuningItem"], [362, 1, 1, "", "TuningSpace"], [362, 2, 1, "", "initial_tuning_cfg_with_quant_mode"], [362, 2, 1, "", "pattern_to_internal"], [362, 2, 1, "", "pattern_to_path"], [362, 2, 1, "", "quant_mode_from_pattern"]], "neural_compressor.experimental.strategy.utils.tuning_structs": [[363, 1, 1, "", "OpTuningConfig"]], "neural_compressor.experimental.strategy.utils.utility": [[364, 1, 1, "", "OrderedDefaultDict"], [364, 2, 1, "", "extract_data_type"], [364, 2, 1, "", "get_adaptor_name"], [364, 2, 1, "", "reverted_data_type"]], "neural_compressor.metric": [[366, 0, 0, "-", "bleu"], [367, 0, 0, "-", "bleu_util"], [368, 0, 0, "-", "coco_label_map"], [369, 0, 0, "-", "coco_tools"], [370, 0, 0, "-", "evaluate_squad"], [371, 0, 0, "-", "f1"], [373, 0, 0, "-", "metric"]], "neural_compressor.metric.bleu": [[366, 1, 1, "", "BLEU"], [366, 1, 1, "", "UnicodeRegex"], [366, 2, 1, "", "bleu_tokenize"]], "neural_compressor.metric.bleu.BLEU": [[366, 4, 1, "", "labels"], [366, 4, 1, "", "predictions"]], "neural_compressor.metric.bleu.UnicodeRegex": [[366, 4, 1, "", "nondigit_punct_re"], [366, 4, 1, "", "punct_nondigit_re"], [366, 4, 1, "", "symbol_re"]], "neural_compressor.metric.bleu_util": [[367, 2, 1, "", "compute_bleu"]], "neural_compressor.metric.coco_tools": [[369, 1, 1, "", "COCOEvalWrapper"], [369, 1, 1, "", "COCOWrapper"], [369, 2, 1, "", "ExportSingleImageDetectionBoxesToCoco"], [369, 2, 1, "", "ExportSingleImageDetectionMasksToCoco"], [369, 2, 1, "", "ExportSingleImageGroundtruthToCoco"]], "neural_compressor.metric.coco_tools.COCOWrapper": [[369, 4, 1, "", "dataset"], [369, 4, 1, "", "detection_type"]], "neural_compressor.metric.evaluate_squad": [[370, 2, 1, "", "evaluate"], [370, 2, 1, "", "exact_match_score"], [370, 2, 1, "", "f1_score"], [370, 2, 1, "", "metric_max_over_ground_truths"]], "neural_compressor.metric.f1": [[371, 2, 1, "", "evaluate"], [371, 2, 1, "", "f1_score"], [371, 2, 1, "", "metric_max_over_ground_truths"], [371, 2, 1, "", "normalize_answer"]], "neural_compressor.metric.metric": [[373, 1, 1, "", "Accuracy"], [373, 1, 1, "", "BaseMetric"], [373, 1, 1, "", "COCOmAPv2"], [373, 1, 1, "", "F1"], [373, 1, 1, "", "GeneralTopK"], [373, 1, 1, "", "Loss"], [373, 1, 1, "", "MAE"], [373, 1, 1, "", "METRICS"], [373, 1, 1, "", "MSE"], [373, 1, 1, "", "MXNetMetrics"], [373, 1, 1, "", "Metric"], [373, 1, 1, "", "ONNXRTGLUE"], [373, 1, 1, "", "ONNXRTITMetrics"], [373, 1, 1, "", "ONNXRTQLMetrics"], [373, 1, 1, "", "PyTorchLoss"], [373, 1, 1, "", "PyTorchMetrics"], [373, 1, 1, "", "RMSE"], [373, 1, 1, "", "ROC"], [373, 1, 1, "", "SquadF1"], [373, 1, 1, "", "TensorflowCOCOMAP"], [373, 1, 1, "", "TensorflowMAP"], [373, 1, 1, "", "TensorflowMetrics"], [373, 1, 1, "", "TensorflowTopK"], [373, 1, 1, "", "TensorflowVOCMAP"], [373, 1, 1, "", "WrapMXNetMetric"], [373, 1, 1, "", "WrapONNXRTMetric"], [373, 1, 1, "", "WrapPyTorchMetric"], [373, 1, 1, "", "mIOU"], [373, 2, 1, "", "metric_registry"], [373, 2, 1, "", "register_customer_metric"]], "neural_compressor.metric.metric.Accuracy": [[373, 4, 1, "", "label_list"], [373, 4, 1, "", "pred_list"], [373, 4, 1, "", "sample"]], "neural_compressor.metric.metric.GeneralTopK": [[373, 4, 1, "", "k"], [373, 4, 1, "", "num_correct"], [373, 4, 1, "", "num_sample"]], "neural_compressor.metric.metric.Loss": [[373, 4, 1, "", "sample"], [373, 4, 1, "", "sum"]], "neural_compressor.metric.metric.MAE": [[373, 4, 1, "", "compare_label"], [373, 4, 1, "", "label_list"], [373, 4, 1, "", "pred_list"]], "neural_compressor.metric.metric.METRICS": [[373, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.MSE": [[373, 4, 1, "", "compare_label"], [373, 4, 1, "", "label_list"], [373, 4, 1, "", "pred_list"]], "neural_compressor.metric.metric.MXNetMetrics": [[373, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.ONNXRTITMetrics": [[373, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.ONNXRTQLMetrics": [[373, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.PyTorchMetrics": [[373, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.RMSE": [[373, 4, 1, "", "mse"]], "neural_compressor.metric.metric.TensorflowMetrics": [[373, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.TensorflowTopK": [[373, 4, 1, "", "k"], [373, 4, 1, "", "num_correct"], [373, 4, 1, "", "num_sample"]], "neural_compressor.mix_precision": [[374, 2, 1, "", "fit"]], "neural_compressor.model": [[375, 0, 0, "-", "base_model"], [377, 0, 0, "-", "keras_model"], [378, 0, 0, "-", "model"], [379, 0, 0, "-", "mxnet_model"], [380, 0, 0, "-", "nets_factory"], [381, 0, 0, "-", "onnx_model"], [382, 0, 0, "-", "tensorflow_model"], [383, 0, 0, "-", "torch_model"]], "neural_compressor.model.base_model": [[375, 1, 1, "", "BaseModel"]], "neural_compressor.model.keras_model": [[377, 1, 1, "", "KerasModel"]], "neural_compressor.model.model": [[378, 1, 1, "", "Model"], [378, 2, 1, "", "get_model_fwk_name"]], "neural_compressor.model.mxnet_model": [[379, 1, 1, "", "MXNetModel"]], "neural_compressor.model.nets_factory": [[380, 1, 1, "", "TFSlimNetsFactory"]], "neural_compressor.model.onnx_model": [[381, 1, 1, "", "ONNXModel"]], "neural_compressor.model.tensorflow_model": [[382, 1, 1, "", "TensorflowBaseModel"], [382, 1, 1, "", "TensorflowCheckpointModel"], [382, 1, 1, "", "TensorflowLLMModel"], [382, 1, 1, "", "TensorflowModel"], [382, 1, 1, "", "TensorflowQATModel"], [382, 1, 1, "", "TensorflowSavedModelModel"], [382, 2, 1, "", "checkpoint_session"], [382, 2, 1, "", "estimator_session"], [382, 2, 1, "", "frozen_pb_session"], [382, 2, 1, "", "get_model_type"], [382, 2, 1, "", "graph_def_session"], [382, 2, 1, "", "graph_session"], [382, 2, 1, "", "keras_session"], [382, 2, 1, "", "load_saved_model"], [382, 2, 1, "", "saved_model_session"], [382, 2, 1, "", "slim_session"], [382, 2, 1, "", "try_loading_keras"], [382, 2, 1, "", "validate_and_inference_input_output"], [382, 2, 1, "", "validate_graph_node"]], "neural_compressor.model.torch_model": [[383, 1, 1, "", "IPEXModel"], [383, 1, 1, "", "PyTorchBaseModel"], [383, 1, 1, "", "PyTorchFXModel"], [383, 1, 1, "", "PyTorchModel"]], "neural_compressor.objective": [[384, 1, 1, "", "Accuracy"], [384, 1, 1, "", "Footprint"], [384, 1, 1, "", "ModelSize"], [384, 1, 1, "", "MultiObjective"], [384, 1, 1, "", "Objective"], [384, 1, 1, "", "Performance"], [384, 2, 1, "", "objective_custom_registry"], [384, 2, 1, "", "objective_registry"]], "neural_compressor.onnxrt": [[385, 0, 0, "-", "algorithms"], [401, 0, 0, "-", "quantization"], [403, 0, 0, "-", "utils"]], "neural_compressor.onnxrt.algorithms": [[387, 0, 0, "-", "layer_wise"], [390, 0, 0, "-", "smoother"], [393, 0, 0, "-", "weight_only"]], "neural_compressor.onnxrt.algorithms.layer_wise": [[386, 0, 0, "-", "core"]], "neural_compressor.onnxrt.algorithms.layer_wise.core": [[386, 2, 1, "", "layer_wise_quant"]], "neural_compressor.onnxrt.algorithms.smoother": [[388, 0, 0, "-", "calibrator"], [389, 0, 0, "-", "core"]], "neural_compressor.onnxrt.algorithms.smoother.calibrator": [[388, 1, 1, "", "Calibrator"]], "neural_compressor.onnxrt.algorithms.smoother.core": [[389, 1, 1, "", "Smoother"]], "neural_compressor.onnxrt.algorithms.weight_only": [[391, 0, 0, "-", "awq"], [392, 0, 0, "-", "gptq"], [394, 0, 0, "-", "rtn"], [395, 0, 0, "-", "utility"]], "neural_compressor.onnxrt.algorithms.weight_only.awq": [[391, 2, 1, "", "apply_awq_on_model"], [391, 2, 1, "", "awq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.gptq": [[392, 2, 1, "", "apply_gptq_on_model"], [392, 2, 1, "", "gptq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.rtn": [[394, 2, 1, "", "apply_rtn_on_model"], [394, 2, 1, "", "rtn_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.utility": [[395, 2, 1, "", "make_matmul_weight_only_node"], [395, 2, 1, "", "pad_tensor"], [395, 2, 1, "", "prepare_inputs"], [395, 2, 1, "", "qdq_tensor"], [395, 2, 1, "", "quant_tensor"]], "neural_compressor.onnxrt.quantization": [[397, 0, 0, "-", "algorithm_entry"], [398, 0, 0, "-", "autotune"], [399, 0, 0, "-", "calibrate"], [400, 0, 0, "-", "config"], [402, 0, 0, "-", "quantize"]], "neural_compressor.onnxrt.quantization.algorithm_entry": [[397, 2, 1, "", "awq_quantize_entry"], [397, 2, 1, "", "gptq_quantize_entry"], [397, 2, 1, "", "rtn_quantize_entry"], [397, 2, 1, "", "smooth_quant_entry"]], "neural_compressor.onnxrt.quantization.autotune": [[398, 2, 1, "", "autotune"]], "neural_compressor.onnxrt.quantization.calibrate": [[399, 1, 1, "", "CalibrationDataReader"]], "neural_compressor.onnxrt.quantization.config": [[400, 1, 1, "", "AWQConfig"], [400, 1, 1, "", "GPTQConfig"], [400, 1, 1, "", "RTNConfig"], [400, 1, 1, "", "SmoohQuantConfig"], [400, 2, 1, "", "get_default_awq_config"], [400, 2, 1, "", "get_default_gptq_config"], [400, 2, 1, "", "get_default_rtn_config"], [400, 2, 1, "", "get_default_sq_config"]], "neural_compressor.onnxrt.utils": [[404, 0, 0, "-", "onnx_model"], [405, 0, 0, "-", "utility"]], "neural_compressor.onnxrt.utils.onnx_model": [[404, 1, 1, "", "ONNXModel"]], "neural_compressor.onnxrt.utils.utility": [[405, 2, 1, "", "check_model_with_infer_shapes"], [405, 2, 1, "", "find_by_name"], [405, 2, 1, "", "get_qrange_for_qType"], [405, 2, 1, "", "is_B_transposed"], [405, 2, 1, "", "quantize_data"], [405, 2, 1, "", "register_algo"], [405, 2, 1, "", "simple_progress_bar"]], "neural_compressor.profiling": [[408, 0, 0, "-", "parser"], [418, 0, 0, "-", "profiler"]], "neural_compressor.profiling.parser": [[407, 0, 0, "-", "factory"], [410, 0, 0, "-", "onnx_parser"], [412, 0, 0, "-", "parser"], [413, 0, 0, "-", "result"], [415, 0, 0, "-", "tensorflow_parser"]], "neural_compressor.profiling.parser.factory": [[407, 1, 1, "", "ParserFactory"]], "neural_compressor.profiling.parser.onnx_parser": [[409, 0, 0, "-", "factory"], [411, 0, 0, "-", "parser"]], "neural_compressor.profiling.parser.onnx_parser.factory": [[409, 1, 1, "", "OnnxrtParserFactory"]], "neural_compressor.profiling.parser.onnx_parser.parser": [[411, 1, 1, "", "OnnxProfilingParser"]], "neural_compressor.profiling.parser.parser": [[412, 1, 1, "", "ProfilingParser"]], "neural_compressor.profiling.parser.result": [[413, 1, 1, "", "ProfilingResult"]], "neural_compressor.profiling.parser.tensorflow_parser": [[414, 0, 0, "-", "factory"], [416, 0, 0, "-", "parser"]], "neural_compressor.profiling.parser.tensorflow_parser.factory": [[414, 1, 1, "", "TensorFlowParserFactory"]], "neural_compressor.profiling.parser.tensorflow_parser.parser": [[416, 1, 1, "", "TensorFlowProfilingParser"]], "neural_compressor.profiling.profiler": [[417, 0, 0, "-", "factory"], [420, 0, 0, "-", "onnxrt_profiler"], [423, 0, 0, "-", "profiler"], [425, 0, 0, "-", "tensorflow_profiler"]], "neural_compressor.profiling.profiler.factory": [[417, 1, 1, "", "ProfilerFactory"]], "neural_compressor.profiling.profiler.onnxrt_profiler": [[419, 0, 0, "-", "factory"], [421, 0, 0, "-", "profiler"], [422, 0, 0, "-", "utils"]], "neural_compressor.profiling.profiler.onnxrt_profiler.factory": [[419, 1, 1, "", "ProfilerFactory"]], "neural_compressor.profiling.profiler.onnxrt_profiler.profiler": [[421, 1, 1, "", "Profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.utils": [[422, 2, 1, "", "create_onnx_config"]], "neural_compressor.profiling.profiler.profiler": [[423, 1, 1, "", "Profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler": [[424, 0, 0, "-", "factory"], [426, 0, 0, "-", "profiler"], [427, 0, 0, "-", "utils"]], "neural_compressor.profiling.profiler.tensorflow_profiler.factory": [[424, 1, 1, "", "ProfilerFactory"]], "neural_compressor.profiling.profiler.tensorflow_profiler.profiler": [[426, 1, 1, "", "Profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.utils": [[427, 2, 1, "", "create_tf_config"], [427, 2, 1, "", "delete_assign"], [427, 2, 1, "", "set_eager_execution"]], "neural_compressor.quantization": [[428, 2, 1, "", "fit"]], "neural_compressor.strategy": [[429, 0, 0, "-", "auto"], [430, 0, 0, "-", "auto_mixed_precision"], [431, 0, 0, "-", "basic"], [432, 0, 0, "-", "bayesian"], [433, 0, 0, "-", "conservative"], [434, 0, 0, "-", "exhaustive"], [435, 0, 0, "-", "hawq_v2"], [437, 0, 0, "-", "mse"], [438, 0, 0, "-", "mse_v2"], [439, 0, 0, "-", "random"], [440, 0, 0, "-", "strategy"], [442, 0, 0, "-", "utils"]], "neural_compressor.strategy.auto": [[429, 1, 1, "", "AutoTuneStrategy"]], "neural_compressor.strategy.auto_mixed_precision": [[430, 1, 1, "", "AutoMixedPrecisionTuneStrategy"]], "neural_compressor.strategy.basic": [[431, 1, 1, "", "BasicTuneStrategy"]], "neural_compressor.strategy.bayesian": [[432, 1, 1, "", "BayesianOptimization"], [432, 1, 1, "", "BayesianTuneStrategy"], [432, 1, 1, "", "TargetSpace"], [432, 2, 1, "", "acq_max"]], "neural_compressor.strategy.conservative": [[433, 1, 1, "", "ConservativeTuneStrategy"]], "neural_compressor.strategy.exhaustive": [[434, 1, 1, "", "ExhaustiveTuneStrategy"]], "neural_compressor.strategy.hawq_v2": [[435, 1, 1, "", "HAWQ_V2TuneStrategy"]], "neural_compressor.strategy.mse": [[437, 1, 1, "", "MSETuneStrategy"]], "neural_compressor.strategy.mse_v2": [[438, 1, 1, "", "MSE_V2TuneStrategy"]], "neural_compressor.strategy.random": [[439, 1, 1, "", "RandomTuneStrategy"]], "neural_compressor.strategy.strategy": [[440, 1, 1, "", "TuneStrategy"], [440, 1, 1, "", "TuneStrategyMeta"], [440, 2, 1, "", "strategy_registry"]], "neural_compressor.strategy.utils": [[441, 0, 0, "-", "constant"], [443, 0, 0, "-", "tuning_sampler"], [444, 0, 0, "-", "tuning_space"], [445, 0, 0, "-", "tuning_structs"], [446, 0, 0, "-", "utility"]], "neural_compressor.strategy.utils.tuning_sampler": [[443, 1, 1, "", "BlockFallbackTuningSampler"], [443, 1, 1, "", "FallbackTuningSampler"], [443, 1, 1, "", "LowerBitsSampler"], [443, 1, 1, "", "ModelWiseTuningSampler"], [443, 1, 1, "", "OpTypeWiseTuningSampler"], [443, 1, 1, "", "OpWiseTuningSampler"], [443, 1, 1, "", "SmoothQuantSampler"], [443, 1, 1, "", "TuningOrder"], [443, 1, 1, "", "TuningSampler"], [443, 1, 1, "", "WeightOnlyQuantSampler"]], "neural_compressor.strategy.utils.tuning_space": [[444, 1, 1, "", "TuningItem"], [444, 1, 1, "", "TuningSpace"], [444, 2, 1, "", "initial_tuning_cfg_with_quant_mode"], [444, 2, 1, "", "pattern_to_internal"], [444, 2, 1, "", "pattern_to_path"], [444, 2, 1, "", "quant_mode_from_pattern"]], "neural_compressor.strategy.utils.tuning_structs": [[445, 1, 1, "", "OpTuningConfig"]], "neural_compressor.strategy.utils.utility": [[446, 1, 1, "", "ClassRegister"], [446, 1, 1, "", "OrderedDefaultDict"], [446, 1, 1, "", "QuantOptions"], [446, 1, 1, "", "QuantType"], [446, 2, 1, "", "build_slave_faker_model"], [446, 2, 1, "", "extract_data_type"], [446, 2, 1, "", "get_adaptor_name"], [446, 2, 1, "", "preprocess_user_cfg"], [446, 2, 1, "", "reverted_data_type"]], "neural_compressor.template": [[447, 0, 0, "-", "api_doc_example"]], "neural_compressor.template.api_doc_example": [[447, 1, 1, "", "ExampleClass"], [447, 4, 1, "", "attribute1"], [447, 2, 1, "", "function1"], [447, 2, 1, "", "function2"], [447, 2, 1, "", "function3"], [447, 2, 1, "", "generator1"], [447, 5, 1, "", "module_debug_level1"]], "neural_compressor.template.api_doc_example.ExampleClass": [[447, 4, 1, "", "attr1"], [447, 4, 1, "", "attr2"], [447, 4, 1, "", "attr5"]], "neural_compressor.tensorflow": [[449, 0, 0, "-", "algorithms"], [458, 0, 0, "-", "keras"], [471, 0, 0, "-", "quantization"], [568, 0, 0, "-", "utils"]], "neural_compressor.tensorflow.algorithms": [[452, 0, 0, "-", "smoother"], [454, 0, 0, "-", "static_quant"]], "neural_compressor.tensorflow.algorithms.smoother": [[450, 0, 0, "-", "calibration"], [451, 0, 0, "-", "core"], [453, 0, 0, "-", "scaler"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[450, 1, 1, "", "SmoothQuantCalibration"], [450, 1, 1, "", "SmoothQuantCalibrationLLM"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[451, 1, 1, "", "SmoothQuant"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[453, 1, 1, "", "SmoothQuantScaler"], [453, 1, 1, "", "SmoothQuantScalerLLM"]], "neural_compressor.tensorflow.algorithms.static_quant": [[455, 0, 0, "-", "keras"], [456, 0, 0, "-", "tensorflow"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[455, 1, 1, "", "KerasAdaptor"], [455, 1, 1, "", "KerasConfigConverter"], [455, 1, 1, "", "KerasQuery"], [455, 1, 1, "", "KerasSurgery"]], "neural_compressor.tensorflow.algorithms.static_quant.tensorflow": [[456, 1, 1, "", "TensorFlowAdaptor"], [456, 1, 1, "", "TensorFlowConfig"], [456, 1, 1, "", "TensorflowConfigConverter"], [456, 1, 1, "", "TensorflowQuery"], [456, 1, 1, "", "Tensorflow_ITEXAdaptor"]], "neural_compressor.tensorflow.keras": [[462, 0, 0, "-", "layers"], [467, 0, 0, "-", "quantization"]], "neural_compressor.tensorflow.keras.layers": [[459, 0, 0, "-", "conv2d"], [460, 0, 0, "-", "dense"], [461, 0, 0, "-", "depthwise_conv2d"], [463, 0, 0, "-", "layer_initializer"], [464, 0, 0, "-", "pool2d"], [465, 0, 0, "-", "separable_conv2d"]], "neural_compressor.tensorflow.keras.quantization": [[466, 0, 0, "-", "config"]], "neural_compressor.tensorflow.keras.quantization.config": [[466, 1, 1, "", "StaticQuantConfig"], [466, 2, 1, "", "get_all_registered_configs"], [466, 2, 1, "", "get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization": [[468, 0, 0, "-", "algorithm_entry"], [469, 0, 0, "-", "autotune"], [470, 0, 0, "-", "config"], [472, 0, 0, "-", "quantize"], [531, 0, 0, "-", "utils"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[468, 2, 1, "", "static_quant_entry"]], "neural_compressor.tensorflow.quantization.autotune": [[469, 2, 1, "", "autotune"]], "neural_compressor.tensorflow.quantization.config": [[470, 1, 1, "", "SmoothQuantConfig"], [470, 1, 1, "", "StaticQuantConfig"], [470, 2, 1, "", "get_default_sq_config"], [470, 2, 1, "", "get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization.quantize": [[472, 2, 1, "", "quantize_model"], [472, 2, 1, "", "quantize_model_with_single_config"]], "neural_compressor.tensorflow.quantization.utils": [[473, 0, 0, "-", "graph_converter"], [474, 0, 0, "-", "graph_converter_without_calib"], [512, 0, 0, "-", "graph_rewriter"], [530, 0, 0, "-", "graph_util"], [532, 0, 0, "-", "quantize_graph"], [559, 0, 0, "-", "quantize_graph_common"], [562, 0, 0, "-", "transform_graph"], [565, 0, 0, "-", "utility"]], "neural_compressor.tensorflow.quantization.utils.graph_converter": [[473, 1, 1, "", "GraphConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib": [[474, 1, 1, "", "GraphConverterWithoutCalib"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[477, 0, 0, "-", "bf16"], [501, 0, 0, "-", "generic"], [511, 0, 0, "-", "graph_base"], [520, 0, 0, "-", "int8"], [526, 0, 0, "-", "qdq"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16": [[475, 0, 0, "-", "bf16_convert"], [476, 0, 0, "-", "dequantize_cast_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert": [[475, 1, 1, "", "BF16Convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[476, 1, 1, "", "DequantizeCastOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[478, 0, 0, "-", "convert_add_to_biasadd"], [479, 0, 0, "-", "convert_layout"], [480, 0, 0, "-", "convert_leakyrelu"], [481, 0, 0, "-", "convert_nan_to_random"], [482, 0, 0, "-", "convert_placeholder_to_const"], [483, 0, 0, "-", "dilated_contraction"], [484, 0, 0, "-", "dummy_biasadd"], [485, 0, 0, "-", "expanddims_optimizer"], [486, 0, 0, "-", "fetch_weight_from_reshape"], [487, 0, 0, "-", "fold_batch_norm"], [488, 0, 0, "-", "fold_constant"], [489, 0, 0, "-", "fuse_biasadd_add"], [490, 0, 0, "-", "fuse_column_wise_mul"], [491, 0, 0, "-", "fuse_conv_with_math"], [492, 0, 0, "-", "fuse_decomposed_bn"], [493, 0, 0, "-", "fuse_decomposed_in"], [494, 0, 0, "-", "fuse_gelu"], [495, 0, 0, "-", "fuse_layer_norm"], [496, 0, 0, "-", "fuse_pad_with_conv"], [497, 0, 0, "-", "fuse_pad_with_fp32_conv"], [498, 0, 0, "-", "fuse_reshape_transpose"], [499, 0, 0, "-", "graph_cse_optimizer"], [500, 0, 0, "-", "grappler_pass"], [502, 0, 0, "-", "insert_print_node"], [503, 0, 0, "-", "move_squeeze_after_relu"], [504, 0, 0, "-", "pre_optimize"], [505, 0, 0, "-", "remove_training_nodes"], [506, 0, 0, "-", "rename_batch_norm"], [507, 0, 0, "-", "split_shared_input"], [508, 0, 0, "-", "strip_equivalent_nodes"], [509, 0, 0, "-", "strip_unused_nodes"], [510, 0, 0, "-", "switch_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[478, 1, 1, "", "ConvertAddToBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[479, 1, 1, "", "ConvertLayoutOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[480, 1, 1, "", "ConvertLeakyReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[481, 1, 1, "", "ConvertNanToRandom"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[482, 1, 1, "", "ConvertPlaceholderToConst"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[483, 1, 1, "", "DilatedContraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[484, 1, 1, "", "InjectDummyBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[485, 1, 1, "", "ExpandDimsOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[486, 1, 1, "", "FetchWeightFromReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[487, 1, 1, "", "FoldBatchNormNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[488, 1, 1, "", "GraphFoldConstantOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[489, 1, 1, "", "FuseBiasAddAndAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[490, 1, 1, "", "FuseColumnWiseMulOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[491, 1, 1, "", "FuseConvWithMathOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[492, 1, 1, "", "FuseDecomposedBNOptimizer"], [492, 2, 1, "", "bypass_reshape"], [492, 2, 1, "", "get_const_dim_count"], [492, 2, 1, "", "node_from_map"], [492, 2, 1, "", "node_name_from_input"], [492, 2, 1, "", "valid_reshape_inputs"], [492, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[493, 1, 1, "", "FuseDecomposedINOptimizer"], [493, 2, 1, "", "bypass_reshape"], [493, 2, 1, "", "get_const_dim_count"], [493, 2, 1, "", "node_from_map"], [493, 2, 1, "", "node_name_from_input"], [493, 2, 1, "", "valid_reshape_inputs"], [493, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[494, 1, 1, "", "FuseGeluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[495, 1, 1, "", "FuseLayerNormOptimizer"], [495, 2, 1, "", "node_from_map"], [495, 2, 1, "", "node_name_from_input"], [495, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[496, 1, 1, "", "FusePadWithConv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[497, 1, 1, "", "FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[498, 1, 1, "", "FuseTransposeReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[499, 1, 1, "", "GraphCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[500, 1, 1, "", "GrapplerOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[502, 1, 1, "", "InsertPrintMinMaxNode"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[503, 1, 1, "", "MoveSqueezeAfterReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[504, 1, 1, "", "PreOptimization"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[505, 1, 1, "", "RemoveTrainingNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[506, 1, 1, "", "RenameBatchNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[507, 1, 1, "", "SplitSharedInputOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[508, 1, 1, "", "StripEquivalentNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[509, 1, 1, "", "StripUnusedNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[510, 1, 1, "", "SwitchOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[511, 1, 1, "", "GraphRewriterBase"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8": [[513, 0, 0, "-", "freeze_fake_quant"], [514, 0, 0, "-", "freeze_value"], [515, 0, 0, "-", "freeze_value_without_calib"], [516, 0, 0, "-", "fuse_conv_redundant_dequantize"], [517, 0, 0, "-", "fuse_conv_requantize"], [518, 0, 0, "-", "fuse_matmul_redundant_dequantize"], [519, 0, 0, "-", "fuse_matmul_requantize"], [521, 0, 0, "-", "meta_op_optimizer"], [522, 0, 0, "-", "post_hostconst_converter"], [523, 0, 0, "-", "post_quantized_op_cse"], [524, 0, 0, "-", "rnn_convert"], [525, 0, 0, "-", "scale_propagation"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant": [[513, 1, 1, "", "FreezeFakeQuantOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value": [[514, 1, 1, "", "FreezeValueTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib": [[515, 1, 1, "", "FreezeValueWithoutCalibTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[516, 1, 1, "", "FuseConvRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize": [[517, 1, 1, "", "FuseConvRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[518, 1, 1, "", "FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize": [[519, 1, 1, "", "FuseMatMulRequantizeDequantizeNewAPITransformer"], [519, 1, 1, "", "FuseMatMulRequantizeDequantizeTransformer"], [519, 1, 1, "", "FuseMatMulRequantizeNewAPITransformer"], [519, 1, 1, "", "FuseMatMulRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer": [[521, 1, 1, "", "MetaInfoChangingMemOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter": [[522, 1, 1, "", "PostHostConstConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse": [[523, 1, 1, "", "PostCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert": [[524, 1, 1, "", "QuantizedRNNConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation": [[525, 1, 1, "", "ScaleProPagationTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq": [[527, 0, 0, "-", "insert_qdq_pattern"], [528, 0, 0, "-", "merge_duplicated_qdq"], [529, 0, 0, "-", "share_qdq_y_pattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern": [[527, 1, 1, "", "GenerateGraphWithQDQPattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq": [[528, 1, 1, "", "MergeDuplicatedQDQOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern": [[529, 1, 1, "", "ShareQDQForItexYPatternOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[530, 1, 1, "", "GraphAnalyzer"], [530, 1, 1, "", "GraphRewriterHelper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph": [[534, 0, 0, "-", "qat"], [550, 0, 0, "-", "qdq"], [552, 0, 0, "-", "quantize_graph_base"], [553, 0, 0, "-", "quantize_graph_bn"], [554, 0, 0, "-", "quantize_graph_concatv2"], [555, 0, 0, "-", "quantize_graph_conv"], [556, 0, 0, "-", "quantize_graph_for_intel_cpu"], [557, 0, 0, "-", "quantize_graph_matmul"], [558, 0, 0, "-", "quantize_graph_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat": [[533, 0, 0, "-", "fake_quantize"], [535, 0, 0, "-", "quantize_config"], [536, 0, 0, "-", "quantize_helper"], [537, 0, 0, "-", "quantize_layers"], [542, 0, 0, "-", "quantize_wrapper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize": [[533, 1, 1, "", "FakeQuantize"], [533, 1, 1, "", "FakeQuantizeBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config": [[535, 1, 1, "", "QuantizeConfig"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper": [[536, 2, 1, "", "init_quantize_config"], [536, 2, 1, "", "qat_clone_function"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers": [[538, 0, 0, "-", "optimize_layer"], [539, 0, 0, "-", "quantize_layer_add"], [540, 0, 0, "-", "quantize_layer_base"], [541, 0, 0, "-", "quantize_layer_bn"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer": [[538, 2, 1, "", "config_quantizable_layers"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[539, 1, 1, "", "QuantizeLayerAdd"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[540, 1, 1, "", "QuantizeLayerBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[541, 1, 1, "", "QuantizeLayerBatchNormalization"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper": [[542, 1, 1, "", "QuantizeWrapper"], [542, 1, 1, "", "QuantizeWrapperBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq": [[543, 0, 0, "-", "fuse_qdq_bn"], [544, 0, 0, "-", "fuse_qdq_concatv2"], [545, 0, 0, "-", "fuse_qdq_conv"], [546, 0, 0, "-", "fuse_qdq_deconv"], [547, 0, 0, "-", "fuse_qdq_in"], [548, 0, 0, "-", "fuse_qdq_matmul"], [549, 0, 0, "-", "fuse_qdq_pooling"], [551, 0, 0, "-", "optimize_qdq"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn": [[543, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2": [[544, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv": [[545, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv": [[546, 1, 1, "", "FuseNodeStartWithDeconv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in": [[547, 1, 1, "", "FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul": [[548, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling": [[549, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq": [[551, 1, 1, "", "OptimizeQDQGraph"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base": [[552, 1, 1, "", "QuantizeGraphBase"], [552, 1, 1, "", "QuantizeNodeBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn": [[553, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2": [[554, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv": [[555, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu": [[556, 1, 1, "", "QuantizeGraphForIntel"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul": [[557, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling": [[558, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[559, 1, 1, "", "QuantizeGraphHelper"]], "neural_compressor.tensorflow.quantization.utils.transform_graph": [[560, 0, 0, "-", "bias_correction"], [561, 0, 0, "-", "graph_transform_base"], [563, 0, 0, "-", "insert_logging"], [564, 0, 0, "-", "rerange_quantized_concat"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction": [[560, 1, 1, "", "BiasCorrection"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base": [[561, 1, 1, "", "GraphTransformBase"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging": [[563, 1, 1, "", "InsertLogging"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat": [[564, 1, 1, "", "RerangeQuantizedConcat"]], "neural_compressor.tensorflow.quantization.utils.utility": [[565, 2, 1, "", "apply_inlining"], [565, 2, 1, "", "collate_tf_preds"], [565, 2, 1, "", "construct_function_from_graph_def"], [565, 2, 1, "", "fix_ref_type_of_graph_def"], [565, 2, 1, "", "generate_feed_dict"], [565, 2, 1, "", "get_estimator_graph"], [565, 2, 1, "", "get_graph_def"], [565, 2, 1, "", "get_input_output_node_names"], [565, 2, 1, "", "get_model_input_shape"], [565, 2, 1, "", "get_tensor_by_name"], [565, 2, 1, "", "get_tensor_val_from_graph_node"], [565, 2, 1, "", "get_weight_from_input_tensor"], [565, 2, 1, "", "int8_node_name_reverse"], [565, 2, 1, "", "is_ckpt_format"], [565, 2, 1, "", "is_saved_model_format"], [565, 2, 1, "", "iterator_sess_run"], [565, 2, 1, "", "parse_saved_model"], [565, 2, 1, "", "read_graph"], [565, 2, 1, "", "reconstruct_saved_model"], [565, 2, 1, "", "strip_equivalent_nodes"], [565, 2, 1, "", "strip_unused_nodes"], [565, 2, 1, "", "write_graph"]], "neural_compressor.tensorflow.utils": [[566, 0, 0, "-", "constants"], [567, 0, 0, "-", "data"], [569, 0, 0, "-", "model"], [570, 0, 0, "-", "model_wrappers"], [571, 0, 0, "-", "nets_factory"], [572, 0, 0, "-", "utility"]], "neural_compressor.tensorflow.utils.data": [[567, 1, 1, "", "BaseDataLoader"], [567, 1, 1, "", "BatchSampler"], [567, 1, 1, "", "DummyDataset"], [567, 1, 1, "", "DummyDatasetV2"], [567, 1, 1, "", "IndexFetcher"], [567, 1, 1, "", "IterableFetcher"], [567, 1, 1, "", "IterableSampler"], [567, 1, 1, "", "SequentialSampler"], [567, 2, 1, "", "default_collate"]], "neural_compressor.tensorflow.utils.model": [[569, 1, 1, "", "Model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[570, 1, 1, "", "BaseModel"], [570, 1, 1, "", "KerasModel"], [570, 1, 1, "", "TensorflowBaseModel"], [570, 1, 1, "", "TensorflowCheckpointModel"], [570, 1, 1, "", "TensorflowLLMModel"], [570, 1, 1, "", "TensorflowModel"], [570, 1, 1, "", "TensorflowQATModel"], [570, 1, 1, "", "TensorflowSavedModelModel"], [570, 2, 1, "", "checkpoint_session"], [570, 2, 1, "", "estimator_session"], [570, 2, 1, "", "frozen_pb_session"], [570, 2, 1, "", "get_model_type"], [570, 2, 1, "", "graph_def_session"], [570, 2, 1, "", "graph_session"], [570, 2, 1, "", "keras_session"], [570, 2, 1, "", "load_saved_model"], [570, 2, 1, "", "saved_model_session"], [570, 2, 1, "", "slim_session"], [570, 2, 1, "", "try_loading_keras"], [570, 2, 1, "", "validate_and_inference_input_output"], [570, 2, 1, "", "validate_graph_node"]], "neural_compressor.tensorflow.utils.nets_factory": [[571, 1, 1, "", "TFSlimNetsFactory"]], "neural_compressor.tensorflow.utils.utility": [[572, 1, 1, "", "CaptureOutputToFile"], [572, 1, 1, "", "CpuInfo"], [572, 2, 1, "", "Dequantize"], [572, 1, 1, "", "LazyImport"], [572, 1, 1, "", "Statistics"], [572, 2, 1, "", "combine_histogram"], [572, 2, 1, "", "deep_get"], [572, 2, 1, "", "dequantize_weight"], [572, 2, 1, "", "disable_random"], [572, 2, 1, "", "dump_data_to_local"], [572, 2, 1, "", "dump_elapsed_time"], [572, 2, 1, "", "get_all_fp32_data"], [572, 2, 1, "", "get_tensor_histogram"], [572, 2, 1, "", "itex_installed"], [572, 2, 1, "", "load_data_from_pkl"], [572, 2, 1, "", "register_algo"], [572, 2, 1, "", "singleton"], [572, 2, 1, "", "valid_keras_format"], [572, 2, 1, "", "version1_eq_version2"], [572, 2, 1, "", "version1_gt_version2"], [572, 2, 1, "", "version1_gte_version2"], [572, 2, 1, "", "version1_lt_version2"], [572, 2, 1, "", "version1_lte_version2"]], "neural_compressor.torch": [[581, 0, 0, "-", "algorithms"], [623, 0, 0, "-", "amp"], [625, 0, 0, "-", "export"], [630, 0, 0, "-", "quantization"], [636, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms": [[573, 0, 0, "-", "base_algorithm"], [575, 0, 0, "-", "habana_fp8"], [582, 0, 0, "-", "layer_wise"], [587, 0, 0, "-", "mix_precision"], [589, 0, 0, "-", "mx_quant"], [594, 0, 0, "-", "pt2e_quant"], [595, 0, 0, "-", "smooth_quant"], [599, 0, 0, "-", "static_quant"], [614, 0, 0, "-", "weight_only"]], "neural_compressor.torch.algorithms.base_algorithm": [[573, 1, 1, "", "Quantizer"]], "neural_compressor.torch.algorithms.habana_fp8": [[574, 0, 0, "-", "fp8_quant"], [576, 0, 0, "-", "modules"], [577, 0, 0, "-", "observer"], [578, 0, 0, "-", "save_load"], [579, 0, 0, "-", "scale"], [580, 0, 0, "-", "tensor"]], "neural_compressor.torch.algorithms.layer_wise": [[583, 0, 0, "-", "load"], [584, 0, 0, "-", "modified_pickle"], [585, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms.layer_wise.load": [[583, 2, 1, "", "load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[584, 3, 1, "", "PickleError"], [584, 3, 1, "", "PicklingError"], [584, 3, 1, "", "UnpicklingError"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[585, 2, 1, "", "dowload_hf_model"], [585, 2, 1, "", "get_children"], [585, 2, 1, "", "get_module"], [585, 2, 1, "", "get_named_children"], [585, 2, 1, "", "get_super_module_by_name"], [585, 2, 1, "", "load_empty_model"], [585, 2, 1, "", "load_layer_wise_quantized_model"], [585, 2, 1, "", "load_tensor"], [585, 2, 1, "", "load_tensor_from_shard"], [585, 2, 1, "", "update_module"]], "neural_compressor.torch.algorithms.mix_precision": [[586, 0, 0, "-", "half_precision_convert"], [588, 0, 0, "-", "module_wrappers"]], "neural_compressor.torch.algorithms.mix_precision.half_precision_convert": [[586, 1, 1, "", "HalfPrecisionConverter"]], "neural_compressor.torch.algorithms.mix_precision.module_wrappers": [[588, 1, 1, "", "HalfPrecisionModuleWrapper"]], "neural_compressor.torch.algorithms.mx_quant": [[590, 0, 0, "-", "mx"], [591, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms.mx_quant.mx": [[590, 1, 1, "", "MXQuantizer"]], "neural_compressor.torch.algorithms.mx_quant.utils": [[591, 1, 1, "", "ElemFormat"], [591, 1, 1, "", "RoundingMode"], [591, 2, 1, "", "quantize_elemwise_op"]], "neural_compressor.torch.algorithms.pt2e_quant": [[592, 0, 0, "-", "core"], [593, 0, 0, "-", "half_precision_rewriter"]], "neural_compressor.torch.algorithms.pt2e_quant.core": [[592, 1, 1, "", "W8A8PT2EQuantizer"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter": [[593, 2, 1, "", "get_half_precision_node_set"], [593, 2, 1, "", "pattern_factory"], [593, 2, 1, "", "transformation"]], "neural_compressor.torch.algorithms.smooth_quant": [[596, 0, 0, "-", "save_load"], [597, 0, 0, "-", "smooth_quant"], [598, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.smooth_quant.save_load": [[596, 2, 1, "", "recover_model_from_json"]], "neural_compressor.torch.algorithms.smooth_quant.smooth_quant": [[597, 1, 1, "", "SmoothQuantQuantizer"]], "neural_compressor.torch.algorithms.smooth_quant.utility": [[598, 1, 1, "", "TorchSmoothQuant"], [598, 2, 1, "", "check_cfg_and_qconfig"], [598, 2, 1, "", "get_module"], [598, 2, 1, "", "get_quantizable_ops_recursively"], [598, 2, 1, "", "register_autotune"], [598, 2, 1, "", "reshape_in_channel_to_last"], [598, 2, 1, "", "reshape_scale_as_input"], [598, 2, 1, "", "reshape_scale_as_weight"], [598, 2, 1, "", "set_module"], [598, 2, 1, "", "update_sq_scale"]], "neural_compressor.torch.algorithms.static_quant": [[600, 0, 0, "-", "save_load"], [601, 0, 0, "-", "static_quant"], [602, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[601, 1, 1, "", "StaticQuantQuantizer"]], "neural_compressor.torch.algorithms.static_quant.utility": [[602, 1, 1, "", "Statistics"], [602, 1, 1, "", "TransformerBasedModelBlockPatternDetector"], [602, 2, 1, "", "check_cfg_and_qconfig"], [602, 2, 1, "", "dump_model_op_stats"], [602, 2, 1, "", "generate_activation_observer"], [602, 2, 1, "", "get_depth"], [602, 2, 1, "", "get_dict_at_depth"], [602, 2, 1, "", "get_element_under_depth"], [602, 2, 1, "", "get_quantizable_ops_from_cfgs"], [602, 2, 1, "", "get_quantizable_ops_recursively"], [602, 2, 1, "", "parse_cfgs"], [602, 2, 1, "", "simple_inference"]], "neural_compressor.torch.algorithms.weight_only": [[603, 0, 0, "-", "autoround"], [604, 0, 0, "-", "awq"], [605, 0, 0, "-", "gptq"], [609, 0, 0, "-", "hqq"], [615, 0, 0, "-", "modules"], [616, 0, 0, "-", "rtn"], [617, 0, 0, "-", "save_load"], [618, 0, 0, "-", "teq"], [619, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.weight_only.autoround": [[603, 1, 1, "", "AutoRoundQuantizer"], [603, 2, 1, "", "get_autoround_default_run_fn"]], "neural_compressor.torch.algorithms.weight_only.awq": [[604, 1, 1, "", "AWQQuantizer"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[605, 1, 1, "", "GPTQ"], [605, 1, 1, "", "GPTQuantizer"], [605, 1, 1, "", "RAWGPTQuantizer"], [605, 2, 1, "", "find_layers"], [605, 2, 1, "", "find_layers_name"], [605, 2, 1, "", "is_leaf"], [605, 2, 1, "", "log_quantizable_layers_per_transformer"], [605, 2, 1, "", "quantize"], [605, 2, 1, "", "trace_gptq_target_blocks"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[606, 0, 0, "-", "bitpack"], [607, 0, 0, "-", "config"], [608, 0, 0, "-", "core"], [610, 0, 0, "-", "optimizer"], [611, 0, 0, "-", "qtensor"], [612, 0, 0, "-", "quantizer"], [613, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[607, 1, 1, "", "HQQModuleConfig"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[612, 1, 1, "", "HQQuantizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.utility": [[613, 2, 1, "", "dump_elapsed_time"]], "neural_compressor.torch.algorithms.weight_only.modules": [[615, 1, 1, "", "FakeAffineTensorQuantFunction"], [615, 1, 1, "", "MulLinear"], [615, 1, 1, "", "TEQLinearFakeQuant"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[616, 1, 1, "", "RTNQuantizer"]], "neural_compressor.torch.algorithms.weight_only.teq": [[618, 1, 1, "", "TEQuantizer"], [618, 1, 1, "", "TrainableEquivalentTransformation"]], "neural_compressor.torch.algorithms.weight_only.utility": [[619, 2, 1, "", "fetch_module"], [619, 2, 1, "", "get_absorb_layers"], [619, 2, 1, "", "get_block_prefix"], [619, 2, 1, "", "get_example_input"], [619, 2, 1, "", "get_module"], [619, 2, 1, "", "get_module_input_output"], [619, 2, 1, "", "qdq_weight_actor"], [619, 2, 1, "", "qdq_weight_asym"], [619, 2, 1, "", "qdq_weight_sym"], [619, 2, 1, "", "quant_tensor"], [619, 2, 1, "", "quant_weight_w_scale"], [619, 2, 1, "", "quantize_4bit"], [619, 2, 1, "", "recover_forward"], [619, 2, 1, "", "replace_forward"], [619, 2, 1, "", "search_clip"], [619, 2, 1, "", "set_module"]], "neural_compressor.torch.amp": [[620, 0, 0, "-", "autocast"], [622, 0, 0, "-", "fp8"]], "neural_compressor.torch.amp.autocast": [[620, 1, 1, "", "autocast"]], "neural_compressor.torch.amp.fp8": [[621, 0, 0, "-", "functions"]], "neural_compressor.torch.export": [[624, 0, 0, "-", "_export"]], "neural_compressor.torch.export._export": [[624, 2, 1, "", "export_model_for_pt2e_quant"]], "neural_compressor.torch.quantization": [[627, 0, 0, "-", "algorithm_entry"], [628, 0, 0, "-", "autotune"], [629, 0, 0, "-", "config"], [631, 0, 0, "-", "load_entry"], [632, 0, 0, "-", "quantize"]], "neural_compressor.torch.quantization.algorithm_entry": [[627, 2, 1, "", "rtn_entry"]], "neural_compressor.torch.quantization.autotune": [[628, 2, 1, "", "autotune"]], "neural_compressor.torch.quantization.config": [[629, 1, 1, "", "GPTQConfig"], [629, 1, 1, "", "HQQConfig"], [629, 1, 1, "", "RTNConfig"], [629, 2, 1, "", "get_default_gptq_config"], [629, 2, 1, "", "get_default_hqq_config"], [629, 2, 1, "", "get_default_rtn_config"], [629, 2, 1, "", "get_woq_tuning_config"]], "neural_compressor.torch.quantization.quantize": [[632, 2, 1, "", "convert"], [632, 2, 1, "", "prepare"], [632, 2, 1, "", "quantize"]], "neural_compressor.torch.utils": [[633, 0, 0, "-", "auto_accelerator"], [634, 0, 0, "-", "constants"], [635, 0, 0, "-", "environ"], [637, 0, 0, "-", "utility"]], "neural_compressor.torch.utils.auto_accelerator": [[633, 1, 1, "", "Auto_Accelerator"], [633, 1, 1, "", "CPU_Accelerator"], [633, 1, 1, "", "CUDA_Accelerator"], [633, 1, 1, "", "HPU_Accelerator"], [633, 1, 1, "", "XPU_Accelerator"], [633, 2, 1, "", "register_accelerator"]], "neural_compressor.torch.utils.utility": [[637, 2, 1, "", "fetch_module"], [637, 2, 1, "", "get_quantizer"], [637, 2, 1, "", "postprocess_model"], [637, 2, 1, "", "register_algo"], [637, 2, 1, "", "set_module"]], "neural_compressor.training": [[638, 1, 1, "", "CallBacks"], [638, 1, 1, "", "CompressionManager"], [638, 2, 1, "", "fit"], [638, 2, 1, "", "prepare_compression"]], "neural_compressor.utils": [[639, 0, 0, "-", "collect_layer_histogram"], [640, 0, 0, "-", "constant"], [641, 0, 0, "-", "create_obj_from_config"], [643, 0, 0, "-", "kl_divergence"], [644, 0, 0, "-", "load_huggingface"], [645, 0, 0, "-", "logger"], [646, 0, 0, "-", "neural_insights_utils"], [647, 0, 0, "-", "options"], [648, 0, 0, "-", "pytorch"], [649, 0, 0, "-", "utility"], [650, 0, 0, "-", "weights_details"]], "neural_compressor.utils.collect_layer_histogram": [[639, 1, 1, "", "LayerHistogramCollector"]], "neural_compressor.utils.create_obj_from_config": [[641, 2, 1, "", "create_dataloader"], [641, 2, 1, "", "create_dataset"], [641, 2, 1, "", "create_eval_func"], [641, 2, 1, "", "create_train_func"], [641, 2, 1, "", "get_algorithm"], [641, 2, 1, "", "get_func_from_config"], [641, 2, 1, "", "get_metrics"], [641, 2, 1, "", "get_postprocess"], [641, 2, 1, "", "get_preprocess"]], "neural_compressor.utils.kl_divergence": [[643, 1, 1, "", "KL_Divergence"]], "neural_compressor.utils.load_huggingface": [[644, 1, 1, "", "OptimizedModel"], [644, 2, 1, "", "export_compressed_model"], [644, 2, 1, "", "save_for_huggingface_upstream"]], "neural_compressor.utils.logger": [[645, 1, 1, "", "Logger"], [645, 2, 1, "", "debug"], [645, 2, 1, "", "error"], [645, 2, 1, "", "fatal"], [645, 2, 1, "", "info"], [645, 2, 1, "", "log"], [645, 2, 1, "", "warn"], [645, 2, 1, "", "warning"]], "neural_compressor.utils.neural_insights_utils": [[646, 2, 1, "", "get_model_path"], [646, 2, 1, "", "register_neural_insights_workload"], [646, 2, 1, "", "update_neural_insights_workload"], [646, 2, 1, "", "update_neural_insights_workload_accuracy_data"]], "neural_compressor.utils.options": [[647, 1, 1, "", "onnxrt"]], "neural_compressor.utils.pytorch": [[648, 2, 1, "", "is_int8_model"], [648, 2, 1, "", "load"], [648, 2, 1, "", "load_weight_only"], [648, 2, 1, "", "recover_model_from_json"]], "neural_compressor.utils.utility": [[649, 1, 1, "", "CaptureOutputToFile"], [649, 1, 1, "", "CpuInfo"], [649, 2, 1, "", "Dequantize"], [649, 1, 1, "", "DotDict"], [649, 1, 1, "", "GLOBAL_STATE"], [649, 1, 1, "", "LazyImport"], [649, 1, 1, "", "MODE"], [649, 1, 1, "", "OpEntry"], [649, 1, 1, "", "Statistics"], [649, 2, 1, "", "alias_param"], [649, 2, 1, "", "calculate_mse"], [649, 2, 1, "", "check_key_exist"], [649, 2, 1, "", "combine_histogram"], [649, 2, 1, "", "compare_objects"], [649, 2, 1, "", "compute_sparsity"], [649, 2, 1, "", "dequantize_weight"], [649, 2, 1, "", "dump_class_attrs"], [649, 2, 1, "", "dump_data_to_local"], [649, 2, 1, "", "dump_elapsed_time"], [649, 2, 1, "", "dump_table"], [649, 2, 1, "", "dump_table_to_csv"], [649, 2, 1, "", "equal_dicts"], [649, 2, 1, "", "fault_tolerant_file"], [649, 2, 1, "", "get_all_fp32_data"], [649, 2, 1, "", "get_number_of_sockets"], [649, 2, 1, "", "get_op_list"], [649, 2, 1, "", "get_size"], [649, 2, 1, "", "get_tensor_histogram"], [649, 2, 1, "", "get_tensors_info"], [649, 2, 1, "", "get_tuning_history"], [649, 2, 1, "", "get_weights_details"], [649, 2, 1, "", "load_data_from_pkl"], [649, 2, 1, "", "mse_metric_gap"], [649, 2, 1, "", "print_op_list"], [649, 2, 1, "", "print_table"], [649, 2, 1, "", "recover"], [649, 2, 1, "", "set_random_seed"], [649, 2, 1, "", "set_resume_from"], [649, 2, 1, "", "set_tensorboard"], [649, 2, 1, "", "set_workspace"], [649, 2, 1, "", "show_memory_info"], [649, 2, 1, "", "singleton"], [649, 2, 1, "", "str2array"], [649, 2, 1, "", "time_limit"], [649, 2, 1, "", "version1_eq_version2"], [649, 2, 1, "", "version1_gt_version2"], [649, 2, 1, "", "version1_gte_version2"], [649, 2, 1, "", "version1_lt_version2"], [649, 2, 1, "", "version1_lte_version2"]], "neural_compressor.utils.weights_details": [[650, 1, 1, "", "WeightsDetails"], [650, 1, 1, "", "WeightsStatistics"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:function", "3": "py:exception", "4": "py:attribute", "5": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "function", "Python function"], "3": ["py", "exception", "Python exception"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "data", "Python data"]}, "titleterms": {"block_mask": [0, 212], "neural_compressor": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651], "adaptor": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 659, 660, 662], "modul": [1, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 182, 183, 185, 186, 187, 188, 189, 191, 192, 195, 196, 198, 199, 201, 203, 204, 205, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 232, 235, 236, 237, 238, 239, 240, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 255, 256, 259, 260, 262, 263, 264, 265, 266, 267, 269, 270, 271, 272, 273, 274, 278, 279, 280, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 298, 299, 302, 304, 305, 306, 308, 309, 310, 311, 313, 314, 316, 317, 318, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 332, 333, 334, 335, 338, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 361, 362, 363, 364, 366, 367, 369, 370, 371, 373, 374, 375, 377, 378, 379, 380, 381, 382, 383, 384, 386, 388, 389, 391, 392, 394, 395, 397, 398, 399, 400, 404, 405, 407, 409, 411, 412, 413, 414, 416, 417, 419, 421, 422, 423, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 443, 444, 445, 446, 447, 450, 451, 453, 455, 456, 466, 468, 469, 470, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 527, 528, 529, 530, 533, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 564, 565, 567, 569, 570, 571, 572, 573, 576, 583, 584, 585, 586, 588, 590, 591, 592, 593, 596, 597, 598, 601, 602, 603, 604, 605, 606, 607, 608, 611, 612, 613, 615, 616, 618, 619, 620, 624, 627, 628, 629, 632, 633, 637, 638, 639, 641, 643, 644, 645, 646, 647, 648, 649, 650], "content": [1, 2, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 185, 186, 187, 188, 189, 191, 192, 195, 196, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 232, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 278, 279, 280, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 316, 317, 318, 319, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 361, 362, 363, 364, 366, 367, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 394, 395, 396, 397, 398, 399, 400, 401, 403, 404, 405, 407, 409, 411, 412, 413, 414, 416, 417, 419, 421, 422, 423, 424, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 443, 444, 445, 446, 447, 450, 451, 453, 455, 456, 466, 468, 469, 470, 472, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 527, 528, 529, 530, 533, 535, 536, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 564, 565, 567, 569, 570, 571, 572, 573, 583, 584, 585, 586, 588, 590, 591, 592, 593, 596, 597, 598, 601, 602, 603, 604, 605, 606, 607, 608, 611, 612, 613, 615, 616, 618, 619, 620, 624, 627, 628, 629, 632, 633, 637, 638, 639, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 658, 728], "class": [1, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 150, 151, 152, 153, 157, 161, 162, 164, 170, 173, 174, 175, 176, 177, 179, 180, 181, 182, 183, 185, 187, 188, 189, 191, 195, 196, 198, 203, 204, 205, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 227, 228, 229, 231, 232, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 278, 279, 280, 282, 283, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 311, 312, 313, 316, 319, 320, 321, 322, 323, 324, 326, 328, 329, 330, 332, 333, 334, 335, 336, 337, 338, 339, 340, 343, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356, 357, 358, 361, 362, 363, 364, 366, 369, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 388, 389, 390, 396, 399, 400, 401, 403, 404, 407, 409, 411, 412, 413, 414, 416, 417, 419, 421, 423, 424, 426, 429, 430, 431, 432, 433, 434, 435, 437, 438, 439, 440, 443, 444, 445, 446, 447, 450, 451, 453, 455, 456, 466, 470, 473, 474, 475, 476, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 513, 514, 515, 516, 517, 518, 519, 521, 522, 523, 524, 525, 527, 528, 529, 530, 533, 535, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 563, 564, 567, 569, 570, 571, 572, 573, 586, 588, 590, 591, 592, 597, 598, 601, 602, 603, 604, 605, 606, 607, 608, 611, 612, 615, 616, 618, 619, 620, 629, 633, 638, 639, 642, 643, 644, 645, 647, 649, 650, 659, 728], "function": [1, 13, 16, 34, 42, 43, 44, 45, 67, 68, 70, 104, 105, 116, 118, 148, 151, 152, 153, 158, 159, 160, 163, 165, 171, 172, 173, 175, 178, 179, 180, 181, 186, 187, 189, 191, 192, 195, 196, 198, 199, 200, 201, 203, 205, 206, 210, 213, 219, 220, 221, 222, 223, 225, 226, 229, 238, 239, 247, 249, 253, 256, 257, 258, 261, 263, 264, 265, 266, 268, 270, 271, 273, 282, 290, 292, 296, 299, 300, 301, 303, 304, 305, 308, 309, 310, 313, 314, 316, 317, 318, 319, 320, 327, 334, 338, 343, 344, 345, 347, 352, 358, 362, 364, 366, 367, 369, 370, 371, 372, 373, 374, 378, 382, 384, 385, 386, 387, 391, 392, 394, 395, 396, 397, 398, 400, 401, 405, 422, 427, 428, 432, 440, 444, 446, 447, 466, 468, 469, 470, 472, 492, 493, 495, 536, 538, 565, 567, 570, 572, 583, 585, 591, 593, 596, 598, 602, 603, 605, 613, 619, 621, 624, 627, 628, 629, 632, 633, 637, 638, 641, 642, 644, 645, 646, 648, 649, 685], "subpackag": [2, 17, 87, 111, 112, 114, 154, 197, 200, 233, 258, 276, 301, 312, 336, 354, 365, 436, 512, 531, 532, 534, 581], "submodul": [2, 12, 17, 29, 52, 76, 87, 95, 101, 106, 111, 112, 114, 117, 130, 145, 154, 155, 175, 184, 190, 193, 197, 200, 202, 206, 213, 224, 230, 234, 241, 253, 257, 261, 268, 277, 284, 296, 300, 303, 307, 312, 319, 325, 331, 337, 341, 354, 360, 365, 372, 376, 390, 403, 408, 410, 415, 418, 420, 425, 436, 442, 448, 452, 454, 477, 501, 512, 520, 526, 531, 532, 534, 537, 550, 562, 568, 582, 587, 614, 642], "packag": [2, 29, 175, 181, 200, 206, 213, 241, 253, 257, 258, 261, 268, 284, 296, 300, 301, 303, 312, 319, 331, 336, 337, 354, 372, 376, 385, 387, 390, 396, 401, 403, 436, 642, 711, 713, 715, 716], "kera": [3, 455, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467], "keras_util": [4, 5, 6, 7, 8, 9, 10], "conv2d": [4, 459], "dens": [5, 460], "depthwise_conv2d": [6, 461], "pool2d": [8, 464], "quantiz": [9, 41, 157, 348, 397, 398, 399, 400, 401, 402, 428, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 612, 627, 628, 629, 630, 631, 632, 655, 658, 660, 661, 673, 677, 682, 684, 687, 690, 693, 695, 697, 698, 700, 707, 718, 720, 721, 722, 723, 731, 732, 733, 739, 740, 741, 742, 743, 746, 752], "separable_conv2d": [10, 465], "mxnet": [11, 680, 696, 740, 748], "mxnet_util": [12, 13], "util": [13, 43, 148, 159, 165, 171, 183, 184, 185, 186, 187, 192, 223, 226, 359, 360, 361, 362, 363, 364, 395, 403, 404, 405, 422, 427, 441, 442, 443, 444, 445, 446, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 585, 591, 598, 602, 613, 619, 633, 634, 635, 636, 637, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 664], "onnxrt": [14, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 680, 696, 748], "ox_util": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "calibr": [15, 16, 167, 388, 399, 450, 660, 677], "oper": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 660, 661], "activ": [18, 721], "argmax": 19, "attent": 20, "binary_op": 21, "concat": 22, "conv": 23, "direct_q8": 24, "embed_layernorm": 25, "gather": 26, "gavgpool": 27, "gemm": 28, "lstm": 30, "matmul": [31, 746], "maxpool": 32, "norm": 33, "op": [34, 687], "pad": 35, "pool": 36, "reduc": 37, "resiz": 38, "split": [39, 724], "unary_op": 40, "smooth_quant": [42, 170, 176, 595, 596, 597, 598], "weight_onli": [44, 172, 391, 392, 393, 394, 395, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619], "pytorch": [45, 648, 680, 685, 687, 696, 722, 740, 741, 742, 747, 748, 752], "queri": [46, 659, 726, 731, 732, 733], "tensorflow": [47, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 680, 685, 687, 696, 740, 742, 747, 748, 752], "tf_util": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148], "graph_convert": [48, 473], "graph_converter_without_calib": [49, 474], "graph_rewrit": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529], "bf16": [50, 51, 52, 475, 476, 477, 698], "bf16_convert": [50, 151, 475], "dequantize_cast_optim": [51, 476], "gener": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 660], "convert_add_to_biasadd": [53, 478], "convert_layout": [54, 479], "convert_leakyrelu": [55, 480], "convert_nan_to_random": [56, 481], "convert_placeholder_to_const": [57, 482], "dilated_contract": [58, 483], "dummy_biasadd": [59, 484], "expanddims_optim": [60, 485], "fetch_weight_from_reshap": [61, 486], "fold_batch_norm": [62, 487], "fold_const": [63, 488], "fuse_biasadd_add": [64, 489], "fuse_column_wise_mul": [65, 490], "fuse_conv_with_math": [66, 491], "fuse_decomposed_bn": [67, 492], "fuse_decomposed_in": [68, 493], "fuse_gelu": [69, 494], "fuse_layer_norm": [70, 495], "fuse_pad_with_conv": [71, 496], "fuse_pad_with_fp32_conv": [72, 497], "fuse_reshape_transpos": [73, 498], "graph_cse_optim": [74, 499], "grappler_pass": [75, 500], "insert_print_nod": [77, 502], "move_squeeze_after_relu": [78, 503], "pre_optim": [79, 504], "remove_training_nod": [80, 505], "rename_batch_norm": [81, 506], "split_shared_input": [82, 507], "strip_equivalent_nod": [83, 508], "strip_unused_nod": [84, 509], "switch_optim": [85, 510], "graph_bas": [86, 511], "int8": [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 687, 752], "freeze_fake_qu": [88, 513], "freeze_valu": [89, 514], "freeze_value_without_calib": [90, 515], "fuse_conv_redundant_dequant": [91, 516], "fuse_conv_requant": [92, 517], "fuse_matmul_redundant_dequant": [93, 518], "fuse_matmul_requant": [94, 519], "meta_op_optim": [96, 521], "post_hostconst_convert": [97, 522], "post_quantized_op_cs": [98, 523], "rnn_convert": [99, 524], "scale_propag": [100, 525], "onnx": [101, 102, 103, 104, 105, 663, 693, 740, 741, 752], "onnx_graph": 102, "onnx_nod": 103, "onnx_schema": 104, "tf2onnx_util": 105, "qdq": [106, 107, 108, 109, 123, 124, 125, 126, 127, 128, 129, 130, 131, 526, 527, 528, 529, 543, 544, 545, 546, 547, 548, 549, 550, 551, 752], "insert_qdq_pattern": [107, 527], "merge_duplicated_qdq": [108, 528], "share_qdq_y_pattern": [109, 529], "graph_util": [110, 530], "quantize_graph": [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558], "qat": [113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 752], "fake_quant": [113, 533], "quantize_config": [115, 535], "quantize_help": [116, 536], "quantize_lay": [117, 118, 119, 120, 121, 537, 538, 539, 540, 541], "optimize_lay": [118, 538], "quantize_layer_add": [119, 539], "quantize_layer_bas": [120, 540], "quantize_layer_bn": [121, 541], "quantize_wrapp": [122, 542], "fuse_qdq_bn": [123, 543], "fuse_qdq_concatv2": [124, 544], "fuse_qdq_conv": [125, 545], "fuse_qdq_deconv": [126, 546], "fuse_qdq_in": [127, 547], "fuse_qdq_matmul": [128, 548], "fuse_qdq_pool": [129, 549], "optimize_qdq": [131, 551], "quantize_graph_bas": [132, 552], "quantize_graph_bn": [133, 553], "quantize_graph_concatv2": [134, 554], "quantize_graph_conv": [135, 555], "quantize_graph_for_intel_cpu": [136, 556], "quantize_graph_matmul": [137, 557], "quantize_graph_pool": [138, 558], "quantize_graph_common": [139, 559], "smooth_quant_calibr": 140, "smooth_quant_scal": 141, "tf2onnx_convert": 142, "transform_graph": [143, 144, 145, 146, 147, 560, 561, 562, 563, 564], "bias_correct": [143, 560], "graph_transform_bas": [144, 561], "insert_log": [146, 563], "rerange_quantized_concat": [147, 564], "torch_util": [149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 273], "auto_round": 149, "awq": [150, 391, 604], "gptq": [152, 392, 605], "hawq_metr": 153, "layer_wise_qu": [155, 156, 157, 158, 159], "modified_pickl": [156, 584], "torch_load": 158, "mixed_precis": [160, 321], "model_wrapp": [161, 570], "pattern_detector": 162, "symbolic_trac": 163, "teq": [164, 618], "waq": [166, 167, 168, 169, 170, 171], "auto_alpha": 166, "graph_trac": 168, "algorithm": [173, 174, 175, 176, 177, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 449, 450, 451, 452, 453, 454, 455, 456, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 677, 743, 746, 749], "fast_bias_correct": 174, "weight_correct": 177, "benchmark": [178, 265, 667, 676, 682, 697, 739], "common": [179, 180, 181, 182, 183, 184, 185, 186, 187, 266, 267, 268, 269, 270, 271, 272, 273, 655, 688], "base_config": 179, "attribut": [179, 180, 181, 185, 241, 249, 258, 292, 301, 312, 336, 376, 400, 403, 405, 447, 607, 619, 642, 653], "base_tun": 180, "tuning_param": 182, "constant": [183, 359, 441, 566, 634, 640], "logger": [185, 342, 645, 678], "save_load": [186, 578, 596, 600, 617], "compress": [188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 275, 668, 743], "callback": 188, "distil": [189, 190, 191, 192, 306, 683, 684, 697, 739, 752], "criterion": [189, 266], "optim": [191, 271, 610, 708, 718, 728, 731, 732, 733, 736, 737, 750], "hpo": [193, 194, 195, 196], "sa_optim": 194, "search_algorithm": [195, 328], "search_spac": 196, "pruner": [198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 334, 345], "criteria": [198, 654, 737, 749], "dsnot": 199, "model_slim": [201, 202, 203, 204], "auto_slim": 201, "pattern_analyz": 203, "weight_slim": 204, "pattern": [205, 206, 207, 208, 209, 337, 338, 339, 343, 737], "base": [205, 210, 693, 727, 750], "mha": [207, 214], "ninm": 208, "nxm": 209, "basic": [211, 351, 431, 656, 749], "pattern_lock": [215, 333], "progress": [216, 724], "retrain_fre": 217, "sparse_gpt": 218, "prune": [219, 225, 335, 346, 697, 737, 739, 752], "reg": 220, "schedul": [221, 347, 349, 737], "tf_criteria": 222, "wanda": [224, 225, 226, 227], "wrapper": 227, "conf": [228, 229, 230, 231], "config": [228, 232, 400, 466, 470, 607, 629, 669, 680, 735], "dotdict": 229, "pythonic_config": 231, "contrib": [233, 234, 235, 236, 276, 277, 278, 279], "strategi": [234, 235, 236, 277, 278, 279, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 674, 745, 749], "sigopt": [235, 278, 745, 749], "tpe": [236, 279, 749], "data": [237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 567, 660, 661, 682, 686, 722], "dataload": [237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 267, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 679, 680], "base_dataload": [237, 280], "default_dataload": [239, 282], "fetcher": [240, 283], "mxnet_dataload": [242, 285], "onnxrt_dataload": [243, 286], "pytorch_dataload": [244, 287], "sampler": [245, 288], "tensorflow_dataload": [246, 289], "dataset": [247, 248, 249, 250, 251, 252, 253, 254, 290, 291, 292, 293, 294, 295, 296, 297, 680, 682, 691, 723], "bert_dataset": [247, 290], "coco_dataset": [248, 291], "dummy_dataset": [250, 293], "dummy_dataset_v2": [251, 294], "imagenet_dataset": [252, 295], "style_transfer_dataset": [254, 297], "filter": [255, 256, 257, 298, 299, 300], "coco_filt": [255, 298], "transform": [259, 260, 261, 262, 263, 264, 302, 303, 304, 305, 691, 748], "coco_transform": 259, "imagenet_transform": [260, 302], "postprocess": [262, 272], "token": [263, 304], "experiment": [265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364], "metric": [269, 313, 314, 315, 316, 317, 318, 319, 320, 366, 367, 368, 369, 370, 371, 372, 373, 691, 696], "model": [270, 375, 376, 377, 378, 379, 380, 381, 382, 383, 569, 660, 671, 687, 690, 693, 695, 697, 699, 700, 707, 721, 722, 723, 731, 732, 733, 737, 741, 743, 746, 752], "compon": 274, "export": [307, 308, 309, 310, 624, 625, 687, 743], "qlinear2qdq": 308, "tf2onnx": 309, "torch2onnx": 310, "graph_optim": 311, "bleu": [313, 366], "bleu_util": [314, 367], "coco_label_map": [315, 368], "coco_tool": [316, 369], "evaluate_squad": [317, 370], "f1": [318, 371], "model_convers": 322, "na": [323, 324, 325, 326, 327, 328, 656, 739], "basic_na": 323, "dyna": 324, "nas_util": 327, "pruner_legaci": [329, 330, 331, 332, 333, 334], "gradient_sensit": 329, "group_lasso": 330, "magnitud": 332, "pruning_recip": [336, 337, 338, 339], "tile_pattern": 339, "pruning_v2": 340, "pytorch_prun": [341, 342, 343, 344, 345, 346, 347], "prune_util": 344, "auto_mixed_precis": [350, 430], "bayesian": [352, 432, 749], "exhaust": [353, 434, 749], "mse": [355, 437, 749], "mse_v2": [356, 438, 749], "random": [357, 439, 749], "tuning_sampl": [361, 443], "tuning_spac": [362, 444], "tuning_struct": [363, 445], "mix_precis": [374, 586, 587, 588], "base_model": 375, "keras_model": 377, "mxnet_model": 379, "nets_factori": [380, 571], "onnx_model": [381, 404], "tensorflow_model": 382, "torch_model": 383, "object": [384, 672, 731, 732, 733, 735], "layer_wis": [386, 387, 582, 583, 584, 585], "core": [386, 389, 451, 592, 608], "smoother": [388, 389, 390, 450, 451, 452, 453], "rtn": [394, 616], "algorithm_entri": [397, 468, 627], "autotun": [398, 469, 628], "profil": [406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 682], "parser": [407, 408, 409, 410, 411, 412, 413, 414, 415, 416], "factori": [407, 409, 414, 417, 419, 424], "onnx_pars": [409, 410, 411], "result": [413, 721, 723, 731, 732, 733], "tensorflow_pars": [414, 415, 416], "onnxrt_profil": [419, 420, 421, 422], "tensorflow_profil": [424, 425, 426, 427], "auto": [429, 712, 718, 742, 746, 749], "conserv": [433, 749], "hawq_v2": [435, 749], "templat": [447, 448, 654], "api_doc_exampl": 447, "scaler": 453, "static_qu": [454, 455, 456, 599, 600, 601, 602], "layer": [459, 460, 461, 462, 463, 464, 465, 683, 741, 746], "layer_initi": 463, "torch": [573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 664, 752], "base_algorithm": 573, "habana_fp8": [574, 575, 576, 577, 578, 579, 580], "fp8_quant": 574, "observ": 577, "scale": 579, "tensor": [580, 720, 746], "load": 583, "half_precision_convert": 586, "module_wrapp": 588, "mx_quant": [589, 590, 591], "mx": 590, "pt2e_quant": [592, 593, 594], "half_precision_rewrit": 593, "autoround": 603, "hqq": [606, 607, 608, 609, 610, 611, 612, 613], "bitpack": 606, "qtensor": 611, "amp": [620, 621, 622, 623], "autocast": 620, "fp8": [621, 622], "_export": 624, "load_entri": 631, "auto_acceler": 633, "environ": [635, 693, 704], "train": [638, 655, 675, 685, 697, 737, 740], "collect_layer_histogram": 639, "create_obj_from_config": 641, "kl_diverg": 643, "load_huggingfac": 644, "neural_insights_util": 646, "option": [647, 685, 706], "weights_detail": 650, "version": 651, "intel": [652, 658, 679, 682, 692, 693, 696, 697, 704, 712, 718, 753], "neural": [652, 655, 656, 658, 679, 682, 692, 693, 696, 697, 701, 705, 707, 712, 718, 720, 721, 722, 723, 725, 726, 727, 731, 732, 733, 737, 745, 750, 753], "compressor": [652, 655, 658, 679, 682, 692, 693, 696, 697, 712, 718, 745, 753], "document": [652, 658, 665, 753], "section": [652, 753], "contributor": [653, 654], "coven": [653, 654], "code": [653, 654, 656, 678, 697, 719, 724, 743, 750], "conduct": [653, 654], "our": [653, 746], "pledg": 653, "standard": 653, "respons": [653, 727], "scope": [653, 737], "enforc": 653, "contribut": [654, 711, 715], "guidelin": 654, "creat": [654, 724], "pull": 654, "request": [654, 698, 729], "step": [654, 720, 721, 722, 723], "checklist": 654, "accept": 654, "statu": [654, 726, 727], "check": 654, "overview": [654, 728, 750], "support": [654, 655, 656, 659, 661, 676, 677, 679, 680, 682, 683, 684, 685, 687, 689, 692, 693, 696, 698, 699, 700, 702, 703, 707, 708, 735, 736, 737, 739, 740, 741, 743, 746, 747, 748, 751], "fx": 655, "introduct": [655, 656, 659, 660, 661, 676, 677, 679, 680, 682, 683, 684, 685, 687, 689, 692, 696, 698, 699, 700, 718, 721, 722, 723, 735, 736, 737, 739, 740, 741, 743, 745, 746, 747, 748, 749, 751], "mode": [655, 752], "matrix": [655, 656, 659, 676, 677, 679, 680, 682, 683, 684, 685, 687, 689, 692, 696, 698, 699, 700, 703, 735, 736, 737, 739, 740, 741, 743, 746, 747, 751], "get": [655, 656, 658, 659, 676, 679, 680, 682, 683, 684, 685, 689, 690, 696, 698, 700, 701, 712, 719, 720, 724, 725, 726, 727, 735, 736, 737, 739, 740, 747, 751], "start": [655, 656, 658, 659, 676, 679, 680, 682, 683, 684, 685, 689, 690, 696, 698, 700, 701, 702, 706, 712, 720, 724, 725, 726, 731, 732, 733, 735, 736, 737, 739, 740, 747, 751], "post": [655, 697, 727, 740], "static": [655, 658, 740], "dynam": [655, 656, 740], "awar": [655, 697, 737, 740], "exampl": [655, 656, 659, 665, 676, 679, 680, 682, 683, 684, 685, 686, 687, 696, 697, 698, 699, 700, 703, 707, 720, 721, 722, 723, 725, 730, 731, 732, 733, 735, 736, 737, 740, 741, 743, 746, 747, 752], "note": [655, 744], "detail": 655, "problem": 655, "architectur": [656, 681, 692, 693], "search": [656, 718], "api": [656, 659, 660, 665, 666, 676, 679, 680, 683, 684, 685, 690, 691, 696, 698, 700, 701, 705, 719, 720, 727, 733, 735, 736, 737, 739, 750], "usag": [656, 707, 718, 727, 746, 747, 749], "1": [656, 685, 688, 691, 697, 718, 725, 726, 738, 752], "python": [656, 679, 690, 696, 701, 705, 706, 713, 716, 720, 739, 750], "yaml": [656, 660, 680, 685, 689, 751], "2": [656, 685, 688, 691, 697, 718, 725, 726, 752], "onli": [656, 658, 743], "advanc": [656, 724, 750], "custom": [656, 679, 696, 731, 749], "secur": [657, 685], "polici": [657, 749], "report": 657, "vulner": 657, "what": [658, 701, 719, 725], "": [658, 693, 719, 725], "new": [658, 659, 661, 713, 716, 749], "instal": [658, 682, 693, 702, 704, 711, 712, 715, 720, 725, 726], "from": [658, 660, 693, 697, 720, 725, 726], "pypi": [658, 707, 720], "weight": [658, 721, 722, 723, 743], "llm": [658, 695], "non": 658, "select": [658, 712], "public": [658, 678, 738], "event": [658, 738], "addit": 658, "commun": 658, "work": [659, 725, 740], "flow": [659, 740], "background": [659, 678, 718], "ad": 659, "backend": [659, 740], "capabl": [659, 743], "implement": [659, 660], "onnxrtadaptor": 659, "how": [660, 661, 682, 721, 722, 723, 725], "add": [660, 726], "an": [660, 731, 732, 733], "list": [660, 686, 730, 748], "need": 660, "design": [660, 681, 728, 749], "framework": [660, 679, 680, 687, 689, 699, 700, 739, 741, 743, 746], "query_fw_cap": 660, "accord": [660, 661], "tune_cfg": 660, "prepar": [660, 682, 721, 722, 723, 745], "fp32": [660, 687], "graph": 660, "run": [660, 682, 719, 721, 722, 723, 724], "sampl": [660, 690], "iter": 660, "calcul": 660, "rang": 660, "type": [661, 678, 737], "like": 661, "int4": 661, "few": 661, "line": 661, "chang": [661, 691, 717, 719, 744], "defin": [661, 685], "abil": 661, "specif": [661, 680], "invok": 661, "kernel": 661, "tune": [661, 740, 743, 746, 749], "configur": [661, 685, 689, 724, 739, 745, 751], "us": [661, 679, 696, 725, 726, 746], "summari": [661, 721], "runtim": [663, 693, 740, 741, 752], "mix": [670, 697, 698, 742], "precis": [670, 697, 698, 742], "refer": [677, 678, 700, 737, 740, 743, 746], "inc": 678, "convent": 678, "rule": [678, 740], "import": 678, "string": 678, "annot": 678, "comment": 678, "todo": 678, "intern": 678, "interfac": 678, "folder": [678, 719], "structur": 678, "recommend": 678, "v": [678, 719], "set": [678, 682, 704, 718], "json": 678, "build": [679, 688, 696, 724, 725, 726], "file": [680, 689, 751], "user": [680, 685, 691, 739, 743, 750, 751], "workflow": [681, 728], "diagnosi": [682, 720], "featur": [682, 685, 689, 692, 707, 708, 712, 739, 740, 747, 751], "modifi": 682, "script": [682, 724], "see": 682, "do": [682, 701], "paramet": [682, 727], "descript": [682, 727, 729], "suggest": 682, "fallback": 682, "knowledg": [683, 752], "intermedi": 683, "self": 683, "distribut": [685, 707, 749], "infer": 685, "evalu": 685, "pure": 685, "horovodrun": 685, "execut": 685, "releas": [686, 713, 716, 744], "appendix": 687, "frequent": 688, "ask": 688, "question": 688, "issu": [688, 744], "3": [688, 702, 718], "4": [688, 709, 718, 738], "quick": [690, 706], "valid": [690, 693, 746, 752], "incompat": [691, 744], "between": 691, "v1": 691, "face": [691, 732, 733], "built": [691, 693, 696], "infrastructur": 692, "prerequisit": [693, 725, 726], "binari": 693, "sourc": [693, 720, 722, 723, 725, 726], "ai": 693, "kit": 693, "system": 693, "requir": [693, 711, 715, 721, 722, 723, 731], "hardwar": [693, 698, 752], "cpu": [693, 704, 752], "64": 693, "compat": 693, "processor": 693, "gpu": 693, "xe": 693, "multipl": [693, 735, 752], "vendor": 693, "through": [693, 746, 752], "softwar": [693, 698], "legal": 694, "inform": 694, "licens": 694, "citat": 694, "trademark": 694, "recip": [695, 740], "larg": [695, 737], "languag": [695, 737], "accuraci": [695, 698, 721, 723, 740, 749], "migrat": 697, "x": 697, "orchestr": [697, 736], "fp16": 698, "dure": [698, 742], "driven": 698, "microsc": 700, "coder": [701, 705, 707, 718, 750], "we": 701, "offer": 701, "jupyt": [701, 702, 713, 716], "lab": [701, 702], "extens": [701, 711, 712, 715, 718, 719, 728], "launcher": [701, 706], "contact": [701, 725], "aw": 702, "amazon": 702, "sagemak": 702, "For": 702, "studio": 702, "notebook": 702, "instanc": 702, "guid": [702, 750], "bigdl": 703, "nano": 703, "platform": [704, 745], "best": [704, 712], "perform": [704, 745], "mkl": 704, "openmp": 704, "jemalloc": 704, "numa": 704, "control": 704, "variabl": 704, "frequenc": 704, "govern": 704, "enabl": [705, 712, 718], "bench": 705, "superbench": 705, "argument": 706, "v0": 709, "highlight": 709, "other": 709, "changelog": [710, 714], "neural_compressor_ext_lab": [711, 713], "uninstal": [711, 715], "develop": [711, 715], "jupyterlab": 712, "Or": 712, "let": 712, "u": 712, "help": 712, "you": 712, "pre": 712, "requisit": 712, "make": [713, 716, 719, 724], "manual": [713, 716], "npm": [713, 716, 724], "autom": [713, 716], "publish": [713, 716], "conda": [713, 716], "forg": [713, 716], "neural_compressor_ext_lab_alibaba": [715, 716], "log": [717, 726, 727], "unreleas": 717, "vscode": 718, "open": [718, 723], "icon": 718, "5": 718, "welcom": 719, "your": 719, "setup": 719, "up": 719, "straight": 719, "awai": 719, "explor": 719, "test": [719, 724], "go": 719, "further": 719, "insight": [720, 721, 722, 723], "dump": [720, 722], "research": 720, "collabor": 720, "debug": [721, 723], "analyz": [721, 723, 724], "histogram": 723, "react": 724, "app": 724, "avail": 724, "eject": 724, "learn": [724, 725], "more": [724, 725], "bundl": 724, "size": 724, "web": 724, "deploy": [724, 737], "fail": 724, "minifi": 724, "solut": [725, 726, 727, 731, 732, 733], "why": 725, "doe": 725, "method": [725, 726], "pip": [725, 726], "end": [725, 731, 732, 733], "servic": [726, 728, 731, 732, 733], "submit": [726, 727, 731, 732, 733], "task": [726, 727, 729, 731, 732, 733], "stop": [726, 731, 732, 733], "inspect": 726, "manag": [726, 731, 732], "resourc": [726, 731, 732], "node": 726, "state": 726, "cluster": [726, 727], "remov": 726, "url": 727, "endpoint": 727, "task_id": 727, "websocket": 727, "screen": 727, "ping": 727, "download": [727, 731, 732], "doc": 728, "wip": 728, "oaa": 728, "definit": 728, "diagram": 728, "hug": [732, 733], "grpc": 733, "client": 734, "singl": 735, "One": 736, "shot": 736, "network": 737, "sparsiti": 737, "decai": 737, "regular": 737, "retrain": 737, "free": 737, "spars": 737, "hyperparamet": 737, "full": 738, "80": 738, "2024": 738, "2023": 738, "25": 738, "2022": 738, "35": 738, "2021": 738, "15": [738, 752], "2018": 738, "2020": 738, "style": 739, "access": 739, "fundament": [740, 746], "scheme": 740, "ipex": 740, "approach": 740, "With": 740, "without": 740, "specifi": 740, "devic": 740, "wise": 741, "lwq": 741, "turn": 742, "off": 742, "woq": [743, 752], "known": 744, "benefit": 745, "comparison": 745, "differ": 745, "smooth": 746, "quant": 746, "per": 746, "channel": 746, "limit": 746, "smoothquant": 746, "enhanc": 746, "alpha": 746, "engin": 746, "fix": 746, "determin": 746, "entir": 746, "each": 746, "block": 746, "tensorboard": 747, "space": 749, "exit": 749, "process": 749, "zero": 750, "topic": 750, "innov": 750, "product": 750, "0": 752, "ptq": 752, "17": 752}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"block_mask": [[0, "module-block_mask"]], "neural_compressor.adaptor.adaptor": [[1, "module-neural_compressor.adaptor.adaptor"]], "Module Contents": [[1, "module-contents"], [3, "module-contents"], [11, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [50, "module-contents"], [51, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [77, "module-contents"], [78, "module-contents"], [79, "module-contents"], [80, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [85, "module-contents"], [86, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [100, "module-contents"], [102, "module-contents"], [103, "module-contents"], [104, "module-contents"], [105, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [110, "module-contents"], [113, "module-contents"], [115, "module-contents"], [116, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [121, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [146, "module-contents"], [147, "module-contents"], [148, "module-contents"], [150, "module-contents"], [151, "module-contents"], [152, "module-contents"], [153, "module-contents"], [156, "module-contents"], [157, "module-contents"], [158, "module-contents"], [159, "module-contents"], [160, "module-contents"], [161, "module-contents"], [162, "module-contents"], [163, "module-contents"], [164, "module-contents"], [165, "module-contents"], [170, "module-contents"], [171, "module-contents"], [172, "module-contents"], [173, "module-contents"], [174, "module-contents"], [176, "module-contents"], [177, "module-contents"], [178, "module-contents"], [179, "module-contents"], [180, "module-contents"], [182, "module-contents"], [183, "module-contents"], [185, "module-contents"], [186, "module-contents"], [187, "module-contents"], [188, "module-contents"], [189, "module-contents"], [191, "module-contents"], [192, "module-contents"], [195, "module-contents"], [196, "module-contents"], [198, "module-contents"], [199, "module-contents"], [201, "module-contents"], [203, "module-contents"], [204, "module-contents"], [205, "module-contents"], [207, "module-contents"], [208, "module-contents"], [209, "module-contents"], [210, "module-contents"], [211, "module-contents"], [212, "module-contents"], [214, "module-contents"], [215, "module-contents"], [216, "module-contents"], [217, "module-contents"], [218, "module-contents"], [219, "module-contents"], [220, "module-contents"], [221, "module-contents"], [222, "module-contents"], [223, "module-contents"], [225, "module-contents"], [226, "module-contents"], [227, "module-contents"], [228, "module-contents"], [229, "module-contents"], [231, "module-contents"], [232, "module-contents"], [235, "module-contents"], [236, "module-contents"], [237, "module-contents"], [238, "module-contents"], [239, "module-contents"], [240, "module-contents"], [242, "module-contents"], [243, "module-contents"], [244, "module-contents"], [245, "module-contents"], [246, "module-contents"], [247, "module-contents"], [248, "module-contents"], [249, "module-contents"], [250, "module-contents"], [251, "module-contents"], [252, "module-contents"], [254, "module-contents"], [255, "module-contents"], [256, "module-contents"], [259, "module-contents"], [260, "module-contents"], [262, "module-contents"], [263, "module-contents"], [264, "module-contents"], [265, "module-contents"], [266, "module-contents"], [267, "module-contents"], [269, "module-contents"], [270, "module-contents"], [271, "module-contents"], [272, "module-contents"], [273, "module-contents"], [274, "module-contents"], [278, "module-contents"], [279, "module-contents"], [280, "module-contents"], [282, "module-contents"], [283, "module-contents"], [285, "module-contents"], [286, "module-contents"], [287, "module-contents"], [288, "module-contents"], [289, "module-contents"], [290, "module-contents"], [291, "module-contents"], [292, "module-contents"], [293, "module-contents"], [294, "module-contents"], [295, "module-contents"], [297, "module-contents"], [298, "module-contents"], [299, "module-contents"], [302, "module-contents"], [304, "module-contents"], [305, "module-contents"], [306, "module-contents"], [308, "module-contents"], [309, "module-contents"], [310, "module-contents"], [311, "module-contents"], [313, "module-contents"], [314, "module-contents"], [316, "module-contents"], [317, "module-contents"], [318, "module-contents"], [320, "module-contents"], [321, "module-contents"], [322, "module-contents"], [323, "module-contents"], [324, "module-contents"], [326, "module-contents"], [327, "module-contents"], [328, "module-contents"], [329, "module-contents"], [330, "module-contents"], [332, "module-contents"], [333, "module-contents"], [334, "module-contents"], [335, "module-contents"], [338, "module-contents"], [339, "module-contents"], [340, "module-contents"], [343, "module-contents"], [344, "module-contents"], [345, "module-contents"], [346, "module-contents"], [347, "module-contents"], [348, "module-contents"], [349, "module-contents"], [350, "module-contents"], [351, "module-contents"], [352, "module-contents"], [353, "module-contents"], [355, "module-contents"], [356, "module-contents"], [357, "module-contents"], [358, "module-contents"], [361, "module-contents"], [362, "module-contents"], [363, "module-contents"], [364, "module-contents"], [366, "module-contents"], [367, "module-contents"], [369, "module-contents"], [370, "module-contents"], [371, "module-contents"], [373, "module-contents"], [374, "module-contents"], [375, "module-contents"], [377, "module-contents"], [378, "module-contents"], [379, "module-contents"], [380, "module-contents"], [381, "module-contents"], [382, "module-contents"], [383, "module-contents"], [384, "module-contents"], [386, "module-contents"], [388, "module-contents"], [389, "module-contents"], [391, "module-contents"], [392, "module-contents"], [394, "module-contents"], [395, "module-contents"], [397, "module-contents"], [398, "module-contents"], [399, "module-contents"], [400, "module-contents"], [404, "module-contents"], [405, "module-contents"], [407, "module-contents"], [409, "module-contents"], [411, "module-contents"], [412, "module-contents"], [413, "module-contents"], [414, "module-contents"], [416, "module-contents"], [417, "module-contents"], [419, "module-contents"], [421, "module-contents"], [422, "module-contents"], [423, "module-contents"], [424, "module-contents"], [426, "module-contents"], [427, "module-contents"], [428, "module-contents"], [429, "module-contents"], [430, "module-contents"], [431, "module-contents"], [432, "module-contents"], [433, "module-contents"], [434, "module-contents"], [435, "module-contents"], [437, "module-contents"], [438, "module-contents"], [439, "module-contents"], [440, "module-contents"], [443, "module-contents"], [444, "module-contents"], [445, "module-contents"], [446, "module-contents"], [447, "module-contents"], [450, "module-contents"], [451, "module-contents"], [453, "module-contents"], [455, "module-contents"], [456, "module-contents"], [466, "module-contents"], [468, "module-contents"], [469, "module-contents"], [470, "module-contents"], [472, "module-contents"], [473, "module-contents"], [474, "module-contents"], [475, "module-contents"], [476, "module-contents"], [478, "module-contents"], [479, "module-contents"], [480, "module-contents"], [481, "module-contents"], [482, "module-contents"], [483, "module-contents"], [484, "module-contents"], [485, "module-contents"], [486, "module-contents"], [487, "module-contents"], [488, "module-contents"], [489, "module-contents"], [490, "module-contents"], [491, "module-contents"], [492, "module-contents"], [493, "module-contents"], [494, "module-contents"], [495, "module-contents"], [496, "module-contents"], [497, "module-contents"], [498, "module-contents"], [499, "module-contents"], [500, "module-contents"], [502, "module-contents"], [503, "module-contents"], [504, "module-contents"], [505, "module-contents"], [506, "module-contents"], [507, "module-contents"], [508, "module-contents"], [509, "module-contents"], [510, "module-contents"], [511, "module-contents"], [513, "module-contents"], [514, "module-contents"], [515, "module-contents"], [516, "module-contents"], [517, "module-contents"], [518, "module-contents"], [519, "module-contents"], [521, "module-contents"], [522, "module-contents"], [523, "module-contents"], [524, "module-contents"], [525, "module-contents"], [527, "module-contents"], [528, "module-contents"], [529, "module-contents"], [530, "module-contents"], [533, "module-contents"], [535, "module-contents"], [536, "module-contents"], [538, "module-contents"], [539, "module-contents"], [540, "module-contents"], [541, "module-contents"], [542, "module-contents"], [543, "module-contents"], [544, "module-contents"], [545, "module-contents"], [546, "module-contents"], [547, "module-contents"], [548, "module-contents"], [549, "module-contents"], [551, "module-contents"], [552, "module-contents"], [553, "module-contents"], [554, "module-contents"], [555, "module-contents"], [556, "module-contents"], [557, "module-contents"], [558, "module-contents"], [559, "module-contents"], [560, "module-contents"], [561, "module-contents"], [563, "module-contents"], [564, "module-contents"], [565, "module-contents"], [567, "module-contents"], [569, "module-contents"], [570, "module-contents"], [571, "module-contents"], [572, "module-contents"], [573, "module-contents"], [583, "module-contents"], [584, "module-contents"], [585, "module-contents"], [586, "module-contents"], [588, "module-contents"], [590, "module-contents"], [591, "module-contents"], [592, "module-contents"], [593, "module-contents"], [596, "module-contents"], [597, "module-contents"], [598, "module-contents"], [601, "module-contents"], [602, "module-contents"], [603, "module-contents"], [604, "module-contents"], [605, "module-contents"], [606, "module-contents"], [607, "module-contents"], [608, "module-contents"], [611, "module-contents"], [612, "module-contents"], [613, "module-contents"], [615, "module-contents"], [616, "module-contents"], [618, "module-contents"], [619, "module-contents"], [620, "module-contents"], [624, "module-contents"], [627, "module-contents"], [628, "module-contents"], [629, "module-contents"], [632, "module-contents"], [633, "module-contents"], [637, "module-contents"], [638, "module-contents"], [639, "module-contents"], [641, "module-contents"], [643, "module-contents"], [644, "module-contents"], [645, "module-contents"], [646, "module-contents"], [647, "module-contents"], [648, "module-contents"], [649, "module-contents"], [650, "module-contents"]], "Classes": [[1, "classes"], [3, "classes"], [11, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [45, "classes"], [46, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [50, "classes"], [51, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [75, "classes"], [77, "classes"], [78, "classes"], [79, "classes"], [80, "classes"], [81, "classes"], [82, "classes"], [83, "classes"], [84, "classes"], [85, "classes"], [86, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [99, "classes"], [100, "classes"], [102, "classes"], [103, "classes"], [104, "classes"], [105, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [110, "classes"], [113, "classes"], [115, "classes"], [119, "classes"], [120, "classes"], [121, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [146, "classes"], [147, "classes"], [150, "classes"], [151, "classes"], [152, "classes"], [153, "classes"], [157, "classes"], [161, "classes"], [162, "classes"], [164, "classes"], [170, "classes"], [173, "classes"], [174, "classes"], [175, "classes"], [176, "classes"], [177, "classes"], [179, "classes"], [180, "classes"], [181, "classes"], [182, "classes"], [183, "classes"], [185, "classes"], [187, "classes"], [188, "classes"], [189, "classes"], [191, "classes"], [195, "classes"], [196, "classes"], [198, "classes"], [203, "classes"], [204, "classes"], [205, "classes"], [207, "classes"], [208, "classes"], [209, "classes"], [210, "classes"], [211, "classes"], [212, "classes"], [214, "classes"], [215, "classes"], [216, "classes"], [217, "classes"], [218, "classes"], [219, "classes"], [220, "classes"], [221, "classes"], [222, "classes"], [227, "classes"], [228, "classes"], [229, "classes"], [231, "classes"], [232, "classes"], [235, "classes"], [236, "classes"], [237, "classes"], [238, "classes"], [239, "classes"], [240, "classes"], [241, "classes"], [242, "classes"], [243, "classes"], [244, "classes"], [245, "classes"], [246, "classes"], [247, "classes"], [248, "classes"], [249, "classes"], [250, "classes"], [251, "classes"], [252, "classes"], [253, "classes"], [254, "classes"], [255, "classes"], [256, "classes"], [257, "classes"], [258, "classes"], [259, "classes"], [260, "classes"], [261, "classes"], [262, "classes"], [263, "classes"], [264, "classes"], [265, "classes"], [266, "classes"], [267, "classes"], [268, "classes"], [269, "classes"], [270, "classes"], [271, "classes"], [272, "classes"], [274, "classes"], [278, "classes"], [279, "classes"], [280, "classes"], [282, "classes"], [283, "classes"], [285, "classes"], [286, "classes"], [287, "classes"], [288, "classes"], [289, "classes"], [290, "classes"], [291, "classes"], [292, "classes"], [293, "classes"], [294, "classes"], [295, "classes"], [296, "classes"], [297, "classes"], [298, "classes"], [299, "classes"], [300, "classes"], [301, "classes"], [302, "classes"], [303, "classes"], [304, "classes"], [305, "classes"], [306, "classes"], [311, "classes"], [312, "classes"], [313, "classes"], [316, "classes"], [319, "classes"], [320, "classes"], [321, "classes"], [322, "classes"], [323, "classes"], [324, "classes"], [326, "classes"], [328, "classes"], [329, "classes"], [330, "classes"], [332, "classes"], [333, "classes"], [334, "classes"], [335, "classes"], [336, "classes"], [337, "classes"], [338, "classes"], [339, "classes"], [340, "classes"], [343, "classes"], [345, "classes"], [346, "classes"], [347, "classes"], [348, "classes"], [349, "classes"], [350, "classes"], [351, "classes"], [352, "classes"], [353, "classes"], [355, "classes"], [356, "classes"], [357, "classes"], [358, "classes"], [361, "classes"], [362, "classes"], [363, "classes"], [364, "classes"], [366, "classes"], [369, "classes"], [372, "classes"], [373, "classes"], [375, "classes"], [376, "classes"], [377, "classes"], [378, "classes"], [379, "classes"], [380, "classes"], [381, "classes"], [382, "classes"], [383, "classes"], [384, "classes"], [385, "classes"], [388, "classes"], [389, "classes"], [390, "classes"], [396, "classes"], [399, "classes"], [400, "classes"], [401, "classes"], [403, "classes"], [404, "classes"], [407, "classes"], [409, "classes"], [411, "classes"], [412, "classes"], [413, "classes"], [414, "classes"], [416, "classes"], [417, "classes"], [419, "classes"], [421, "classes"], [423, "classes"], [424, "classes"], [426, "classes"], [429, "classes"], [430, "classes"], [431, "classes"], [432, "classes"], [433, "classes"], [434, "classes"], [435, "classes"], [437, "classes"], [438, "classes"], [439, "classes"], [440, "classes"], [443, "classes"], [444, "classes"], [445, "classes"], [446, "classes"], [447, "classes"], [450, "classes"], [451, "classes"], [453, "classes"], [455, "classes"], [456, "classes"], [466, "classes"], [470, "classes"], [473, "classes"], [474, "classes"], [475, "classes"], [476, "classes"], [478, "classes"], [479, "classes"], [480, "classes"], [481, "classes"], [482, "classes"], [483, "classes"], [484, "classes"], [485, "classes"], [486, "classes"], [487, "classes"], [488, "classes"], [489, "classes"], [490, "classes"], [491, "classes"], [492, "classes"], [493, "classes"], [494, "classes"], [495, "classes"], [496, "classes"], [497, "classes"], [498, "classes"], [499, "classes"], [500, "classes"], [502, "classes"], [503, "classes"], [504, "classes"], [505, "classes"], [506, "classes"], [507, "classes"], [508, "classes"], [509, "classes"], [510, "classes"], [511, "classes"], [513, "classes"], [514, "classes"], [515, "classes"], [516, "classes"], [517, "classes"], [518, "classes"], [519, "classes"], [521, "classes"], [522, "classes"], [523, "classes"], [524, "classes"], [525, "classes"], [527, "classes"], [528, "classes"], [529, "classes"], [530, "classes"], [533, "classes"], [535, "classes"], [539, "classes"], [540, "classes"], [541, "classes"], [542, "classes"], [543, "classes"], [544, "classes"], [545, "classes"], [546, "classes"], [547, "classes"], [548, "classes"], [549, "classes"], [551, "classes"], [552, "classes"], [553, "classes"], [554, "classes"], [555, "classes"], [556, "classes"], [557, "classes"], [558, "classes"], [559, "classes"], [560, "classes"], [561, "classes"], [563, "classes"], [564, "classes"], [567, "classes"], [569, "classes"], [570, "classes"], [571, "classes"], [572, "classes"], [573, "classes"], [586, "classes"], [588, "classes"], [590, "classes"], [591, "classes"], [592, "classes"], [597, "classes"], [598, "classes"], [601, "classes"], [602, "classes"], [603, "classes"], [604, "classes"], [605, "classes"], [606, "classes"], [607, "classes"], [608, "classes"], [611, "classes"], [612, "classes"], [615, "classes"], [616, "classes"], [618, "classes"], [619, "classes"], [620, "classes"], [629, "classes"], [633, "classes"], [638, "classes"], [639, "classes"], [642, "classes"], [643, "classes"], [644, "classes"], [645, "classes"], [647, "classes"], [649, "classes"], [650, "classes"]], "Functions": [[1, "functions"], [13, "functions"], [16, "functions"], [34, "functions"], [42, "functions"], [43, "functions"], [44, "functions"], [45, "functions"], [67, "functions"], [68, "functions"], [70, "functions"], [104, "functions"], [105, "functions"], [116, "functions"], [118, "functions"], [148, "functions"], [151, "functions"], [152, "functions"], [153, "functions"], [158, "functions"], [159, "functions"], [160, "functions"], [163, "functions"], [165, "functions"], [171, "functions"], [172, "functions"], [173, "functions"], [175, "functions"], [178, "functions"], [179, "functions"], [180, "functions"], [181, "functions"], [186, "functions"], [187, "functions"], [189, "functions"], [191, "functions"], [192, "functions"], [195, "functions"], [196, "functions"], [198, "functions"], [199, "functions"], [200, "functions"], [201, "functions"], [203, "functions"], [205, "functions"], [206, "functions"], [210, "functions"], [213, "functions"], [219, "functions"], [220, "functions"], [221, "functions"], [222, "functions"], [223, "functions"], [225, "functions"], [226, "functions"], [229, "functions"], [238, "functions"], [239, "functions"], [247, "functions"], [249, "functions"], [253, "functions"], [256, "functions"], [257, "functions"], [258, "functions"], [261, "functions"], [263, "functions"], [264, "functions"], [265, "functions"], [266, "functions"], [268, "functions"], [270, "functions"], [271, "functions"], [273, "functions"], [282, "functions"], [290, "functions"], [292, "functions"], [296, "functions"], [299, "functions"], [300, "functions"], [301, "functions"], [303, "functions"], [304, "functions"], [305, "functions"], [308, "functions"], [309, "functions"], [310, "functions"], [313, "functions"], [314, "functions"], [316, "functions"], [317, "functions"], [318, "functions"], [319, "functions"], [320, "functions"], [327, "functions"], [334, "functions"], [338, "functions"], [343, "functions"], [344, "functions"], [345, "functions"], [347, "functions"], [352, "functions"], [358, "functions"], [362, "functions"], [364, "functions"], [366, "functions"], [367, "functions"], [369, "functions"], [370, "functions"], [371, "functions"], [372, "functions"], [373, "functions"], [374, "functions"], [378, "functions"], [382, "functions"], [384, "functions"], [385, "functions"], [386, "functions"], [387, "functions"], [391, "functions"], [392, "functions"], [394, "functions"], [395, "functions"], [396, "functions"], [397, "functions"], [398, "functions"], [400, "functions"], [401, "functions"], [405, "functions"], [422, "functions"], [427, "functions"], [428, "functions"], [432, "functions"], [440, "functions"], [444, "functions"], [446, "functions"], [447, "functions"], [466, "functions"], [468, "functions"], [469, "functions"], [470, "functions"], [472, "functions"], [492, "functions"], [493, "functions"], [495, "functions"], [536, "functions"], [538, "functions"], [565, "functions"], [567, "functions"], [570, "functions"], [572, "functions"], [583, "functions"], [585, "functions"], [591, "functions"], [593, "functions"], [596, "functions"], [598, "functions"], [602, "functions"], [603, "functions"], [605, "functions"], [613, "functions"], [619, "functions"], [624, "functions"], [627, "functions"], [628, "functions"], [629, "functions"], [632, "functions"], [633, "functions"], [637, "functions"], [638, "functions"], [641, "functions"], [642, "functions"], [644, "functions"], [645, "functions"], [646, "functions"], [648, "functions"], [649, "functions"]], "neural_compressor.adaptor": [[2, "module-neural_compressor.adaptor"]], "Subpackages": [[2, "subpackages"], [17, "subpackages"], [87, "subpackages"], [111, "subpackages"], [112, "subpackages"], [114, "subpackages"], [154, "subpackages"], [197, "subpackages"], [200, "subpackages"], [233, "subpackages"], [258, "subpackages"], [276, "subpackages"], [301, "subpackages"], [312, "subpackages"], [336, "subpackages"], [354, "subpackages"], [365, "subpackages"], [436, "subpackages"], [512, "subpackages"], [531, "subpackages"], [532, "subpackages"], [534, "subpackages"], [581, "subpackages"]], "Submodules": [[2, "submodules"], [12, "submodules"], [17, "submodules"], [29, "submodules"], [52, "submodules"], [76, "submodules"], [87, "submodules"], [95, "submodules"], [101, "submodules"], [106, "submodules"], [111, "submodules"], [112, "submodules"], [114, "submodules"], [117, "submodules"], [130, "submodules"], [145, "submodules"], [154, "submodules"], [155, "submodules"], [175, "submodules"], [184, "submodules"], [190, "submodules"], [193, "submodules"], [197, "submodules"], [200, "submodules"], [202, "submodules"], [206, "submodules"], [213, "submodules"], [224, "submodules"], [230, "submodules"], [234, "submodules"], [241, "submodules"], [253, "submodules"], [257, "submodules"], [261, "submodules"], [268, "submodules"], [277, "submodules"], [284, "submodules"], [296, "submodules"], [300, "submodules"], [303, "submodules"], [307, "submodules"], [312, "submodules"], [319, "submodules"], [325, "submodules"], [331, "submodules"], [337, "submodules"], [341, "submodules"], [354, "submodules"], [360, "submodules"], [365, "submodules"], [372, "submodules"], [376, "submodules"], [390, "submodules"], [403, "submodules"], [408, "submodules"], [410, "submodules"], [415, "submodules"], [418, "submodules"], [420, "submodules"], [425, "submodules"], [436, "submodules"], [442, "submodules"], [448, "submodules"], [452, "submodules"], [454, "submodules"], [477, "submodules"], [501, "submodules"], [512, "submodules"], [520, "submodules"], [526, "submodules"], [531, "submodules"], [532, "submodules"], [534, "submodules"], [537, "submodules"], [550, "submodules"], [562, "submodules"], [568, "submodules"], [582, "submodules"], [587, "submodules"], [614, "submodules"], [642, "submodules"]], "Package Contents": [[2, "package-contents"], [29, "package-contents"], [175, "package-contents"], [181, "package-contents"], [200, "package-contents"], [206, "package-contents"], [213, "package-contents"], [241, "package-contents"], [253, "package-contents"], [257, "package-contents"], [258, "package-contents"], [261, "package-contents"], [268, "package-contents"], [284, "package-contents"], [296, "package-contents"], [300, "package-contents"], [301, "package-contents"], [303, "package-contents"], [312, "package-contents"], [319, "package-contents"], [331, "package-contents"], [336, "package-contents"], [337, "package-contents"], [354, "package-contents"], [372, "package-contents"], [376, "package-contents"], [385, "package-contents"], [387, "package-contents"], [390, "package-contents"], [396, "package-contents"], [401, "package-contents"], [403, "package-contents"], [436, "package-contents"], [642, "package-contents"]], "neural_compressor.adaptor.keras": [[3, "module-neural_compressor.adaptor.keras"]], "neural_compressor.adaptor.keras_utils.conv2d": [[4, "module-neural_compressor.adaptor.keras_utils.conv2d"]], "neural_compressor.adaptor.keras_utils.dense": [[5, "module-neural_compressor.adaptor.keras_utils.dense"]], "neural_compressor.adaptor.keras_utils.depthwise_conv2d": [[6, "module-neural_compressor.adaptor.keras_utils.depthwise_conv2d"]], "neural_compressor.adaptor.keras_utils": [[7, "module-neural_compressor.adaptor.keras_utils"]], "neural_compressor.adaptor.keras_utils.pool2d": [[8, "module-neural_compressor.adaptor.keras_utils.pool2d"]], "neural_compressor.adaptor.keras_utils.quantizer": [[9, "module-neural_compressor.adaptor.keras_utils.quantizer"]], "neural_compressor.adaptor.keras_utils.separable_conv2d": [[10, "module-neural_compressor.adaptor.keras_utils.separable_conv2d"]], "neural_compressor.adaptor.mxnet": [[11, "module-neural_compressor.adaptor.mxnet"]], "neural_compressor.adaptor.mxnet_utils": [[12, "module-neural_compressor.adaptor.mxnet_utils"]], "neural_compressor.adaptor.mxnet_utils.util": [[13, "module-neural_compressor.adaptor.mxnet_utils.util"]], "neural_compressor.adaptor.onnxrt": [[14, "module-neural_compressor.adaptor.onnxrt"]], "neural_compressor.adaptor.ox_utils.calibration": [[15, "module-neural_compressor.adaptor.ox_utils.calibration"]], "neural_compressor.adaptor.ox_utils.calibrator": [[16, "module-neural_compressor.adaptor.ox_utils.calibrator"]], "neural_compressor.adaptor.ox_utils": [[17, "module-neural_compressor.adaptor.ox_utils"]], "neural_compressor.adaptor.ox_utils.operators.activation": [[18, "module-neural_compressor.adaptor.ox_utils.operators.activation"]], "neural_compressor.adaptor.ox_utils.operators.argmax": [[19, "module-neural_compressor.adaptor.ox_utils.operators.argmax"]], "neural_compressor.adaptor.ox_utils.operators.attention": [[20, "module-neural_compressor.adaptor.ox_utils.operators.attention"]], "neural_compressor.adaptor.ox_utils.operators.binary_op": [[21, "module-neural_compressor.adaptor.ox_utils.operators.binary_op"]], "neural_compressor.adaptor.ox_utils.operators.concat": [[22, "module-neural_compressor.adaptor.ox_utils.operators.concat"]], "neural_compressor.adaptor.ox_utils.operators.conv": [[23, "module-neural_compressor.adaptor.ox_utils.operators.conv"]], "neural_compressor.adaptor.ox_utils.operators.direct_q8": [[24, "module-neural_compressor.adaptor.ox_utils.operators.direct_q8"]], "neural_compressor.adaptor.ox_utils.operators.embed_layernorm": [[25, "module-neural_compressor.adaptor.ox_utils.operators.embed_layernorm"]], "neural_compressor.adaptor.ox_utils.operators.gather": [[26, "module-neural_compressor.adaptor.ox_utils.operators.gather"]], "neural_compressor.adaptor.ox_utils.operators.gavgpool": [[27, "module-neural_compressor.adaptor.ox_utils.operators.gavgpool"]], "neural_compressor.adaptor.ox_utils.operators.gemm": [[28, "module-neural_compressor.adaptor.ox_utils.operators.gemm"]], "neural_compressor.adaptor.ox_utils.operators": [[29, "module-neural_compressor.adaptor.ox_utils.operators"]], "neural_compressor.adaptor.ox_utils.operators.lstm": [[30, "module-neural_compressor.adaptor.ox_utils.operators.lstm"]], "neural_compressor.adaptor.ox_utils.operators.matmul": [[31, "module-neural_compressor.adaptor.ox_utils.operators.matmul"]], "neural_compressor.adaptor.ox_utils.operators.maxpool": [[32, "module-neural_compressor.adaptor.ox_utils.operators.maxpool"]], "neural_compressor.adaptor.ox_utils.operators.norm": [[33, "module-neural_compressor.adaptor.ox_utils.operators.norm"]], "neural_compressor.adaptor.ox_utils.operators.ops": [[34, "module-neural_compressor.adaptor.ox_utils.operators.ops"]], "neural_compressor.adaptor.ox_utils.operators.pad": [[35, "module-neural_compressor.adaptor.ox_utils.operators.pad"]], "neural_compressor.adaptor.ox_utils.operators.pooling": [[36, "module-neural_compressor.adaptor.ox_utils.operators.pooling"]], "neural_compressor.adaptor.ox_utils.operators.reduce": [[37, "module-neural_compressor.adaptor.ox_utils.operators.reduce"]], "neural_compressor.adaptor.ox_utils.operators.resize": [[38, "module-neural_compressor.adaptor.ox_utils.operators.resize"]], "neural_compressor.adaptor.ox_utils.operators.split": [[39, "module-neural_compressor.adaptor.ox_utils.operators.split"]], "neural_compressor.adaptor.ox_utils.operators.unary_op": [[40, "module-neural_compressor.adaptor.ox_utils.operators.unary_op"]], "neural_compressor.adaptor.ox_utils.quantizer": [[41, "module-neural_compressor.adaptor.ox_utils.quantizer"]], "neural_compressor.adaptor.ox_utils.smooth_quant": [[42, "module-neural_compressor.adaptor.ox_utils.smooth_quant"]], "neural_compressor.adaptor.ox_utils.util": [[43, "module-neural_compressor.adaptor.ox_utils.util"]], "neural_compressor.adaptor.ox_utils.weight_only": [[44, "module-neural_compressor.adaptor.ox_utils.weight_only"]], "neural_compressor.adaptor.pytorch": [[45, "module-neural_compressor.adaptor.pytorch"]], "neural_compressor.adaptor.query": [[46, "module-neural_compressor.adaptor.query"]], "neural_compressor.adaptor.tensorflow": [[47, "module-neural_compressor.adaptor.tensorflow"]], "neural_compressor.adaptor.tf_utils.graph_converter": [[48, "module-neural_compressor.adaptor.tf_utils.graph_converter"]], "neural_compressor.adaptor.tf_utils.graph_converter_without_calib": [[49, "module-neural_compressor.adaptor.tf_utils.graph_converter_without_calib"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert": [[50, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[51, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16": [[52, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd": [[53, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout": [[54, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu": [[55, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random": [[56, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const": [[57, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction": [[58, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd": [[59, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer": [[60, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape": [[61, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm": [[62, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant": [[63, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add": [[64, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul": [[65, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math": [[66, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn": [[67, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in": [[68, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu": [[69, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm": [[70, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv": [[71, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[72, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose": [[73, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer": [[74, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass": [[75, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic": [[76, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node": [[77, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu": [[78, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize": [[79, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes": [[80, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm": [[81, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input": [[82, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes": [[83, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes": [[84, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer": [[85, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base": [[86, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base"]], "neural_compressor.adaptor.tf_utils.graph_rewriter": [[87, "module-neural_compressor.adaptor.tf_utils.graph_rewriter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant": [[88, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value": [[89, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib": [[90, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[91, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize": [[92, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[93, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize": [[94, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8": [[95, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer": [[96, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter": [[97, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse": [[98, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert": [[99, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation": [[100, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx": [[101, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph": [[102, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node": [[103, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema": [[104, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils": [[105, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq": [[106, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern": [[107, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq": [[108, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern": [[109, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "neural_compressor.adaptor.tf_utils.graph_util": [[110, "module-neural_compressor.adaptor.tf_utils.graph_util"]], "neural_compressor.adaptor.tf_utils": [[111, "module-neural_compressor.adaptor.tf_utils"]], "neural_compressor.adaptor.tf_utils.quantize_graph": [[112, "module-neural_compressor.adaptor.tf_utils.quantize_graph"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize": [[113, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat": [[114, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config": [[115, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper": [[116, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers": [[117, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer": [[118, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[119, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[120, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[121, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper": [[122, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn": [[123, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2": [[124, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv": [[125, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv": [[126, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in": [[127, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul": [[128, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling": [[129, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq": [[130, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq": [[131, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base": [[132, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn": [[133, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2": [[134, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv": [[135, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu": [[136, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul": [[137, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling": [[138, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph_common": [[139, "module-neural_compressor.adaptor.tf_utils.quantize_graph_common"]], "neural_compressor.adaptor.tf_utils.smooth_quant_calibration": [[140, "module-neural_compressor.adaptor.tf_utils.smooth_quant_calibration"]], "neural_compressor.adaptor.tf_utils.smooth_quant_scaler": [[141, "module-neural_compressor.adaptor.tf_utils.smooth_quant_scaler"]], "neural_compressor.adaptor.tf_utils.tf2onnx_converter": [[142, "module-neural_compressor.adaptor.tf_utils.tf2onnx_converter"]], "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction": [[143, "module-neural_compressor.adaptor.tf_utils.transform_graph.bias_correction"]], "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base": [[144, "module-neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base"]], "neural_compressor.adaptor.tf_utils.transform_graph": [[145, "module-neural_compressor.adaptor.tf_utils.transform_graph"]], "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging": [[146, "module-neural_compressor.adaptor.tf_utils.transform_graph.insert_logging"]], "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat": [[147, "module-neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat"]], "neural_compressor.adaptor.tf_utils.util": [[148, "module-neural_compressor.adaptor.tf_utils.util"]], "neural_compressor.adaptor.torch_utils.auto_round": [[149, "module-neural_compressor.adaptor.torch_utils.auto_round"]], "neural_compressor.adaptor.torch_utils.awq": [[150, "module-neural_compressor.adaptor.torch_utils.awq"]], "neural_compressor.adaptor.torch_utils.bf16_convert": [[151, "module-neural_compressor.adaptor.torch_utils.bf16_convert"]], "neural_compressor.adaptor.torch_utils.gptq": [[152, "module-neural_compressor.adaptor.torch_utils.gptq"]], "neural_compressor.adaptor.torch_utils.hawq_metric": [[153, "module-neural_compressor.adaptor.torch_utils.hawq_metric"]], "neural_compressor.adaptor.torch_utils": [[154, "module-neural_compressor.adaptor.torch_utils"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant": [[155, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle": [[156, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize": [[157, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load": [[158, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils": [[159, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.utils"]], "neural_compressor.adaptor.torch_utils.mixed_precision": [[160, "module-neural_compressor.adaptor.torch_utils.mixed_precision"]], "neural_compressor.adaptor.torch_utils.model_wrapper": [[161, "module-neural_compressor.adaptor.torch_utils.model_wrapper"]], "neural_compressor.adaptor.torch_utils.pattern_detector": [[162, "module-neural_compressor.adaptor.torch_utils.pattern_detector"]], "neural_compressor.adaptor.torch_utils.symbolic_trace": [[163, "module-neural_compressor.adaptor.torch_utils.symbolic_trace"]], "neural_compressor.adaptor.torch_utils.teq": [[164, "module-neural_compressor.adaptor.torch_utils.teq"]], "neural_compressor.adaptor.torch_utils.util": [[165, "module-neural_compressor.adaptor.torch_utils.util"]], "}": [[165, "id3"]], "neural_compressor.adaptor.torch_utils.waq.auto_alpha": [[166, "module-neural_compressor.adaptor.torch_utils.waq.auto_alpha"]], "neural_compressor.adaptor.torch_utils.waq.calibration": [[167, "module-neural_compressor.adaptor.torch_utils.waq.calibration"]], "neural_compressor.adaptor.torch_utils.waq.graph_trace": [[168, "module-neural_compressor.adaptor.torch_utils.waq.graph_trace"]], "neural_compressor.adaptor.torch_utils.waq": [[169, "module-neural_compressor.adaptor.torch_utils.waq"]], "neural_compressor.adaptor.torch_utils.waq.smooth_quant": [[170, "module-neural_compressor.adaptor.torch_utils.waq.smooth_quant"]], "neural_compressor.adaptor.torch_utils.waq.utils": [[171, "module-neural_compressor.adaptor.torch_utils.waq.utils"]], "neural_compressor.adaptor.torch_utils.weight_only": [[172, "module-neural_compressor.adaptor.torch_utils.weight_only"]], "neural_compressor.algorithm.algorithm": [[173, "module-neural_compressor.algorithm.algorithm"]], "neural_compressor.algorithm.fast_bias_correction": [[174, "module-neural_compressor.algorithm.fast_bias_correction"]], "neural_compressor.algorithm": [[175, "module-neural_compressor.algorithm"]], "neural_compressor.algorithm.smooth_quant": [[176, "module-neural_compressor.algorithm.smooth_quant"]], "neural_compressor.algorithm.weight_correction": [[177, "module-neural_compressor.algorithm.weight_correction"]], "neural_compressor.benchmark": [[178, "module-neural_compressor.benchmark"]], "neural_compressor.common.base_config": [[179, "module-neural_compressor.common.base_config"]], "Attributes": [[179, "attributes"], [180, "attributes"], [181, "attributes"], [185, "attributes"], [241, "attributes"], [249, "attributes"], [258, "attributes"], [292, "attributes"], [301, "attributes"], [312, "attributes"], [336, "attributes"], [376, "attributes"], [400, "attributes"], [403, "attributes"], [405, "attributes"], [447, "attributes"], [607, "attributes"], [619, "attributes"], [642, "attributes"]], "neural_compressor.common.base_tuning": [[180, "module-neural_compressor.common.base_tuning"]], "neural_compressor.common": [[181, "module-neural_compressor.common"]], "neural_compressor.common.tuning_param": [[182, "module-neural_compressor.common.tuning_param"]], "neural_compressor.common.utils.constants": [[183, "module-neural_compressor.common.utils.constants"]], "neural_compressor.common.utils": [[184, "module-neural_compressor.common.utils"]], "neural_compressor.common.utils.logger": [[185, "module-neural_compressor.common.utils.logger"]], "neural_compressor.common.utils.save_load": [[186, "module-neural_compressor.common.utils.save_load"]], "neural_compressor.common.utils.utility": [[187, "module-neural_compressor.common.utils.utility"]], "neural_compressor.compression.callbacks": [[188, "module-neural_compressor.compression.callbacks"]], "neural_compressor.compression.distillation.criterions": [[189, "module-neural_compressor.compression.distillation.criterions"]], "neural_compressor.compression.distillation": [[190, "module-neural_compressor.compression.distillation"]], "neural_compressor.compression.distillation.optimizers": [[191, "module-neural_compressor.compression.distillation.optimizers"]], "neural_compressor.compression.distillation.utility": [[192, "module-neural_compressor.compression.distillation.utility"]], "neural_compressor.compression.hpo": [[193, "module-neural_compressor.compression.hpo"]], "neural_compressor.compression.hpo.sa_optimizer": [[194, "module-neural_compressor.compression.hpo.sa_optimizer"]], "neural_compressor.compression.hpo.search_algorithms": [[195, "module-neural_compressor.compression.hpo.search_algorithms"]], "neural_compressor.compression.hpo.search_space": [[196, "module-neural_compressor.compression.hpo.search_space"]], "neural_compressor.compression": [[197, "module-neural_compressor.compression"]], "neural_compressor.compression.pruner.criteria": [[198, "module-neural_compressor.compression.pruner.criteria"]], "neural_compressor.compression.pruner.dsnot": [[199, "module-neural_compressor.compression.pruner.dsnot"]], "neural_compressor.compression.pruner": [[200, "module-neural_compressor.compression.pruner"]], "neural_compressor.compression.pruner.model_slim.auto_slim": [[201, "module-neural_compressor.compression.pruner.model_slim.auto_slim"]], "neural_compressor.compression.pruner.model_slim": [[202, "module-neural_compressor.compression.pruner.model_slim"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer": [[203, "module-neural_compressor.compression.pruner.model_slim.pattern_analyzer"]], "neural_compressor.compression.pruner.model_slim.weight_slim": [[204, "module-neural_compressor.compression.pruner.model_slim.weight_slim"]], "neural_compressor.compression.pruner.patterns.base": [[205, "module-neural_compressor.compression.pruner.patterns.base"]], "neural_compressor.compression.pruner.patterns": [[206, "module-neural_compressor.compression.pruner.patterns"]], "neural_compressor.compression.pruner.patterns.mha": [[207, "module-neural_compressor.compression.pruner.patterns.mha"]], "neural_compressor.compression.pruner.patterns.ninm": [[208, "module-neural_compressor.compression.pruner.patterns.ninm"]], "neural_compressor.compression.pruner.patterns.nxm": [[209, "module-neural_compressor.compression.pruner.patterns.nxm"]], "neural_compressor.compression.pruner.pruners.base": [[210, "module-neural_compressor.compression.pruner.pruners.base"]], "neural_compressor.compression.pruner.pruners.basic": [[211, "module-neural_compressor.compression.pruner.pruners.basic"]], "neural_compressor.compression.pruner.pruners.block_mask": [[212, "module-neural_compressor.compression.pruner.pruners.block_mask"]], "neural_compressor.compression.pruner.pruners": [[213, "module-neural_compressor.compression.pruner.pruners"]], "neural_compressor.compression.pruner.pruners.mha": [[214, "module-neural_compressor.compression.pruner.pruners.mha"]], "neural_compressor.compression.pruner.pruners.pattern_lock": [[215, "module-neural_compressor.compression.pruner.pruners.pattern_lock"]], "neural_compressor.compression.pruner.pruners.progressive": [[216, "module-neural_compressor.compression.pruner.pruners.progressive"]], "neural_compressor.compression.pruner.pruners.retrain_free": [[217, "module-neural_compressor.compression.pruner.pruners.retrain_free"]], "neural_compressor.compression.pruner.pruners.sparse_gpt": [[218, "module-neural_compressor.compression.pruner.pruners.sparse_gpt"]], "neural_compressor.compression.pruner.pruning": [[219, "module-neural_compressor.compression.pruner.pruning"]], "neural_compressor.compression.pruner.regs": [[220, "module-neural_compressor.compression.pruner.regs"]], "neural_compressor.compression.pruner.schedulers": [[221, "module-neural_compressor.compression.pruner.schedulers"]], "neural_compressor.compression.pruner.tf_criteria": [[222, "module-neural_compressor.compression.pruner.tf_criteria"]], "neural_compressor.compression.pruner.utils": [[223, "module-neural_compressor.compression.pruner.utils"]], "neural_compressor.compression.pruner.wanda": [[224, "module-neural_compressor.compression.pruner.wanda"]], "neural_compressor.compression.pruner.wanda.prune": [[225, "module-neural_compressor.compression.pruner.wanda.prune"]], "neural_compressor.compression.pruner.wanda.utils": [[226, "module-neural_compressor.compression.pruner.wanda.utils"]], "neural_compressor.compression.pruner.wanda.wrapper": [[227, "module-neural_compressor.compression.pruner.wanda.wrapper"]], "neural_compressor.conf.config": [[228, "module-neural_compressor.conf.config"]], "neural_compressor.conf.dotdict": [[229, "module-neural_compressor.conf.dotdict"]], "neural_compressor.conf": [[230, "module-neural_compressor.conf"]], "neural_compressor.conf.pythonic_config": [[231, "module-neural_compressor.conf.pythonic_config"]], "neural_compressor.config": [[232, "module-neural_compressor.config"]], "neural_compressor.contrib": [[233, "module-neural_compressor.contrib"]], "neural_compressor.contrib.strategy": [[234, "module-neural_compressor.contrib.strategy"]], "neural_compressor.contrib.strategy.sigopt": [[235, "module-neural_compressor.contrib.strategy.sigopt"]], "neural_compressor.contrib.strategy.tpe": [[236, "module-neural_compressor.contrib.strategy.tpe"]], "neural_compressor.data.dataloaders.base_dataloader": [[237, "module-neural_compressor.data.dataloaders.base_dataloader"]], "neural_compressor.data.dataloaders.dataloader": [[238, "module-neural_compressor.data.dataloaders.dataloader"]], "neural_compressor.data.dataloaders.default_dataloader": [[239, "module-neural_compressor.data.dataloaders.default_dataloader"]], "neural_compressor.data.dataloaders.fetcher": [[240, "module-neural_compressor.data.dataloaders.fetcher"]], "neural_compressor.data.dataloaders": [[241, "module-neural_compressor.data.dataloaders"]], "neural_compressor.data.dataloaders.mxnet_dataloader": [[242, "module-neural_compressor.data.dataloaders.mxnet_dataloader"]], "neural_compressor.data.dataloaders.onnxrt_dataloader": [[243, "module-neural_compressor.data.dataloaders.onnxrt_dataloader"]], "neural_compressor.data.dataloaders.pytorch_dataloader": [[244, "module-neural_compressor.data.dataloaders.pytorch_dataloader"]], "neural_compressor.data.dataloaders.sampler": [[245, "module-neural_compressor.data.dataloaders.sampler"]], "neural_compressor.data.dataloaders.tensorflow_dataloader": [[246, "module-neural_compressor.data.dataloaders.tensorflow_dataloader"]], "neural_compressor.data.datasets.bert_dataset": [[247, "module-neural_compressor.data.datasets.bert_dataset"]], "neural_compressor.data.datasets.coco_dataset": [[248, "module-neural_compressor.data.datasets.coco_dataset"]], "neural_compressor.data.datasets.dataset": [[249, "module-neural_compressor.data.datasets.dataset"]], "neural_compressor.data.datasets.dummy_dataset": [[250, "module-neural_compressor.data.datasets.dummy_dataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[251, "module-neural_compressor.data.datasets.dummy_dataset_v2"]], "neural_compressor.data.datasets.imagenet_dataset": [[252, "module-neural_compressor.data.datasets.imagenet_dataset"]], "neural_compressor.data.datasets": [[253, "module-neural_compressor.data.datasets"]], "neural_compressor.data.datasets.style_transfer_dataset": [[254, "module-neural_compressor.data.datasets.style_transfer_dataset"]], "neural_compressor.data.filters.coco_filter": [[255, "module-neural_compressor.data.filters.coco_filter"]], "neural_compressor.data.filters.filter": [[256, "module-neural_compressor.data.filters.filter"]], "neural_compressor.data.filters": [[257, "module-neural_compressor.data.filters"]], "neural_compressor.data": [[258, "module-neural_compressor.data"]], "neural_compressor.data.transforms.coco_transform": [[259, "module-neural_compressor.data.transforms.coco_transform"]], "neural_compressor.data.transforms.imagenet_transform": [[260, "module-neural_compressor.data.transforms.imagenet_transform"]], "neural_compressor.data.transforms": [[261, "module-neural_compressor.data.transforms"]], "neural_compressor.data.transforms.postprocess": [[262, "module-neural_compressor.data.transforms.postprocess"]], "neural_compressor.data.transforms.tokenization": [[263, "module-neural_compressor.data.transforms.tokenization"]], "neural_compressor.data.transforms.transform": [[264, "module-neural_compressor.data.transforms.transform"]], "neural_compressor.experimental.benchmark": [[265, "module-neural_compressor.experimental.benchmark"]], "neural_compressor.experimental.common.criterion": [[266, "module-neural_compressor.experimental.common.criterion"]], "neural_compressor.experimental.common.dataloader": [[267, "module-neural_compressor.experimental.common.dataloader"]], "neural_compressor.experimental.common": [[268, "module-neural_compressor.experimental.common"]], "neural_compressor.experimental.common.metric": [[269, "module-neural_compressor.experimental.common.metric"]], "neural_compressor.experimental.common.model": [[270, "module-neural_compressor.experimental.common.model"]], "neural_compressor.experimental.common.optimizer": [[271, "module-neural_compressor.experimental.common.optimizer"]], "neural_compressor.experimental.common.postprocess": [[272, "module-neural_compressor.experimental.common.postprocess"]], "neural_compressor.experimental.common.torch_utils": [[273, "module-neural_compressor.experimental.common.torch_utils"]], "neural_compressor.experimental.component": [[274, "module-neural_compressor.experimental.component"]], "neural_compressor.experimental.compression": [[275, "module-neural_compressor.experimental.compression"]], "neural_compressor.experimental.contrib": [[276, "module-neural_compressor.experimental.contrib"]], "neural_compressor.experimental.contrib.strategy": [[277, "module-neural_compressor.experimental.contrib.strategy"]], "neural_compressor.experimental.contrib.strategy.sigopt": [[278, "module-neural_compressor.experimental.contrib.strategy.sigopt"]], "neural_compressor.experimental.contrib.strategy.tpe": [[279, "module-neural_compressor.experimental.contrib.strategy.tpe"]], "neural_compressor.experimental.data.dataloaders.base_dataloader": [[280, "module-neural_compressor.experimental.data.dataloaders.base_dataloader"]], "neural_compressor.experimental.data.dataloaders.dataloader": [[281, "module-neural_compressor.experimental.data.dataloaders.dataloader"]], "neural_compressor.experimental.data.dataloaders.default_dataloader": [[282, "module-neural_compressor.experimental.data.dataloaders.default_dataloader"]], "neural_compressor.experimental.data.dataloaders.fetcher": [[283, "module-neural_compressor.experimental.data.dataloaders.fetcher"]], "neural_compressor.experimental.data.dataloaders": [[284, "module-neural_compressor.experimental.data.dataloaders"]], "neural_compressor.experimental.data.dataloaders.mxnet_dataloader": [[285, "module-neural_compressor.experimental.data.dataloaders.mxnet_dataloader"]], "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader": [[286, "module-neural_compressor.experimental.data.dataloaders.onnxrt_dataloader"]], "neural_compressor.experimental.data.dataloaders.pytorch_dataloader": [[287, "module-neural_compressor.experimental.data.dataloaders.pytorch_dataloader"]], "neural_compressor.experimental.data.dataloaders.sampler": [[288, "module-neural_compressor.experimental.data.dataloaders.sampler"]], "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader": [[289, "module-neural_compressor.experimental.data.dataloaders.tensorflow_dataloader"]], "neural_compressor.experimental.data.datasets.bert_dataset": [[290, "module-neural_compressor.experimental.data.datasets.bert_dataset"]], "neural_compressor.experimental.data.datasets.coco_dataset": [[291, "module-neural_compressor.experimental.data.datasets.coco_dataset"]], "neural_compressor.experimental.data.datasets.dataset": [[292, "module-neural_compressor.experimental.data.datasets.dataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset": [[293, "module-neural_compressor.experimental.data.datasets.dummy_dataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset_v2": [[294, "module-neural_compressor.experimental.data.datasets.dummy_dataset_v2"]], "neural_compressor.experimental.data.datasets.imagenet_dataset": [[295, "module-neural_compressor.experimental.data.datasets.imagenet_dataset"]], "neural_compressor.experimental.data.datasets": [[296, "module-neural_compressor.experimental.data.datasets"]], "neural_compressor.experimental.data.datasets.style_transfer_dataset": [[297, "module-neural_compressor.experimental.data.datasets.style_transfer_dataset"]], "neural_compressor.experimental.data.filters.coco_filter": [[298, "module-neural_compressor.experimental.data.filters.coco_filter"]], "neural_compressor.experimental.data.filters.filter": [[299, "module-neural_compressor.experimental.data.filters.filter"]], "neural_compressor.experimental.data.filters": [[300, "module-neural_compressor.experimental.data.filters"]], "neural_compressor.experimental.data": [[301, "module-neural_compressor.experimental.data"]], "neural_compressor.experimental.data.transforms.imagenet_transform": [[302, "module-neural_compressor.experimental.data.transforms.imagenet_transform"]], "neural_compressor.experimental.data.transforms": [[303, "module-neural_compressor.experimental.data.transforms"]], "neural_compressor.experimental.data.transforms.tokenization": [[304, "module-neural_compressor.experimental.data.transforms.tokenization"]], "neural_compressor.experimental.data.transforms.transform": [[305, "module-neural_compressor.experimental.data.transforms.transform"]], "neural_compressor.experimental.distillation": [[306, "module-neural_compressor.experimental.distillation"]], "neural_compressor.experimental.export": [[307, "module-neural_compressor.experimental.export"]], "neural_compressor.experimental.export.qlinear2qdq": [[308, "module-neural_compressor.experimental.export.qlinear2qdq"]], "neural_compressor.experimental.export.tf2onnx": [[309, "module-neural_compressor.experimental.export.tf2onnx"]], "neural_compressor.experimental.export.torch2onnx": [[310, "module-neural_compressor.experimental.export.torch2onnx"]], "neural_compressor.experimental.graph_optimization": [[311, "module-neural_compressor.experimental.graph_optimization"]], "neural_compressor.experimental": [[312, "module-neural_compressor.experimental"]], "neural_compressor.experimental.metric.bleu": [[313, "module-neural_compressor.experimental.metric.bleu"]], "neural_compressor.experimental.metric.bleu_util": [[314, "module-neural_compressor.experimental.metric.bleu_util"]], "neural_compressor.experimental.metric.coco_label_map": [[315, "module-neural_compressor.experimental.metric.coco_label_map"]], "neural_compressor.experimental.metric.coco_tools": [[316, "module-neural_compressor.experimental.metric.coco_tools"]], "neural_compressor.experimental.metric.evaluate_squad": [[317, "module-neural_compressor.experimental.metric.evaluate_squad"]], "neural_compressor.experimental.metric.f1": [[318, "module-neural_compressor.experimental.metric.f1"]], "neural_compressor.experimental.metric": [[319, "module-neural_compressor.experimental.metric"]], "neural_compressor.experimental.metric.metric": [[320, "module-neural_compressor.experimental.metric.metric"]], "neural_compressor.experimental.mixed_precision": [[321, "module-neural_compressor.experimental.mixed_precision"]], "neural_compressor.experimental.model_conversion": [[322, "module-neural_compressor.experimental.model_conversion"]], "neural_compressor.experimental.nas.basic_nas": [[323, "module-neural_compressor.experimental.nas.basic_nas"]], "neural_compressor.experimental.nas.dynas": [[324, "module-neural_compressor.experimental.nas.dynas"]], "neural_compressor.experimental.nas": [[325, "module-neural_compressor.experimental.nas"]], "neural_compressor.experimental.nas.nas": [[326, "module-neural_compressor.experimental.nas.nas"]], "neural_compressor.experimental.nas.nas_utils": [[327, "module-neural_compressor.experimental.nas.nas_utils"]], "neural_compressor.experimental.nas.search_algorithms": [[328, "module-neural_compressor.experimental.nas.search_algorithms"]], "neural_compressor.experimental.pruner_legacy.gradient_sensitivity": [[329, "module-neural_compressor.experimental.pruner_legacy.gradient_sensitivity"]], "neural_compressor.experimental.pruner_legacy.group_lasso": [[330, "module-neural_compressor.experimental.pruner_legacy.group_lasso"]], "neural_compressor.experimental.pruner_legacy": [[331, "module-neural_compressor.experimental.pruner_legacy"]], "neural_compressor.experimental.pruner_legacy.magnitude": [[332, "module-neural_compressor.experimental.pruner_legacy.magnitude"]], "neural_compressor.experimental.pruner_legacy.pattern_lock": [[333, "module-neural_compressor.experimental.pruner_legacy.pattern_lock"]], "neural_compressor.experimental.pruner_legacy.pruner": [[334, "module-neural_compressor.experimental.pruner_legacy.pruner"]], "neural_compressor.experimental.pruning": [[335, "module-neural_compressor.experimental.pruning"]], "neural_compressor.experimental.pruning_recipes": [[336, "module-neural_compressor.experimental.pruning_recipes"]], "neural_compressor.experimental.pruning_recipes.patterns": [[337, "module-neural_compressor.experimental.pruning_recipes.patterns"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern": [[338, "module-neural_compressor.experimental.pruning_recipes.patterns.pattern"]], "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern": [[339, "module-neural_compressor.experimental.pruning_recipes.patterns.tile_pattern"]], "neural_compressor.experimental.pruning_v2": [[340, "module-neural_compressor.experimental.pruning_v2"]], "neural_compressor.experimental.pytorch_pruner": [[341, "module-neural_compressor.experimental.pytorch_pruner"]], "neural_compressor.experimental.pytorch_pruner.logger": [[342, "module-neural_compressor.experimental.pytorch_pruner.logger"]], "neural_compressor.experimental.pytorch_pruner.patterns": [[343, "module-neural_compressor.experimental.pytorch_pruner.patterns"]], "neural_compressor.experimental.pytorch_pruner.prune_utils": [[344, "module-neural_compressor.experimental.pytorch_pruner.prune_utils"]], "neural_compressor.experimental.pytorch_pruner.pruner": [[345, "module-neural_compressor.experimental.pytorch_pruner.pruner"]], "neural_compressor.experimental.pytorch_pruner.pruning": [[346, "module-neural_compressor.experimental.pytorch_pruner.pruning"]], "neural_compressor.experimental.pytorch_pruner.scheduler": [[347, "module-neural_compressor.experimental.pytorch_pruner.scheduler"]], "neural_compressor.experimental.quantization": [[348, "module-neural_compressor.experimental.quantization"]], "neural_compressor.experimental.scheduler": [[349, "module-neural_compressor.experimental.scheduler"]], "neural_compressor.experimental.strategy.auto_mixed_precision": [[350, "module-neural_compressor.experimental.strategy.auto_mixed_precision"]], "neural_compressor.experimental.strategy.basic": [[351, "module-neural_compressor.experimental.strategy.basic"]], "neural_compressor.experimental.strategy.bayesian": [[352, "module-neural_compressor.experimental.strategy.bayesian"]], "neural_compressor.experimental.strategy.exhaustive": [[353, "module-neural_compressor.experimental.strategy.exhaustive"]], "neural_compressor.experimental.strategy": [[354, "module-neural_compressor.experimental.strategy"]], "neural_compressor.experimental.strategy.mse": [[355, "module-neural_compressor.experimental.strategy.mse"]], "neural_compressor.experimental.strategy.mse_v2": [[356, "module-neural_compressor.experimental.strategy.mse_v2"]], "neural_compressor.experimental.strategy.random": [[357, "module-neural_compressor.experimental.strategy.random"]], "neural_compressor.experimental.strategy.strategy": [[358, "module-neural_compressor.experimental.strategy.strategy"]], "neural_compressor.experimental.strategy.utils.constant": [[359, "module-neural_compressor.experimental.strategy.utils.constant"]], "neural_compressor.experimental.strategy.utils": [[360, "module-neural_compressor.experimental.strategy.utils"]], "neural_compressor.experimental.strategy.utils.tuning_sampler": [[361, "module-neural_compressor.experimental.strategy.utils.tuning_sampler"]], "neural_compressor.experimental.strategy.utils.tuning_space": [[362, "module-neural_compressor.experimental.strategy.utils.tuning_space"]], "neural_compressor.experimental.strategy.utils.tuning_structs": [[363, "module-neural_compressor.experimental.strategy.utils.tuning_structs"]], "neural_compressor.experimental.strategy.utils.utility": [[364, "module-neural_compressor.experimental.strategy.utils.utility"]], "neural_compressor": [[365, "module-neural_compressor"]], "neural_compressor.metric.bleu": [[366, "module-neural_compressor.metric.bleu"]], "neural_compressor.metric.bleu_util": [[367, "module-neural_compressor.metric.bleu_util"]], "neural_compressor.metric.coco_label_map": [[368, "module-neural_compressor.metric.coco_label_map"]], "neural_compressor.metric.coco_tools": [[369, "module-neural_compressor.metric.coco_tools"]], "neural_compressor.metric.evaluate_squad": [[370, "module-neural_compressor.metric.evaluate_squad"]], "neural_compressor.metric.f1": [[371, "module-neural_compressor.metric.f1"]], "neural_compressor.metric": [[372, "module-neural_compressor.metric"]], "neural_compressor.metric.metric": [[373, "module-neural_compressor.metric.metric"]], "neural_compressor.mix_precision": [[374, "module-neural_compressor.mix_precision"]], "neural_compressor.model.base_model": [[375, "module-neural_compressor.model.base_model"]], "neural_compressor.model": [[376, "module-neural_compressor.model"]], "neural_compressor.model.keras_model": [[377, "module-neural_compressor.model.keras_model"]], "neural_compressor.model.model": [[378, "module-neural_compressor.model.model"]], "neural_compressor.model.mxnet_model": [[379, "module-neural_compressor.model.mxnet_model"]], "neural_compressor.model.nets_factory": [[380, "module-neural_compressor.model.nets_factory"]], "neural_compressor.model.onnx_model": [[381, "module-neural_compressor.model.onnx_model"]], "neural_compressor.model.tensorflow_model": [[382, "module-neural_compressor.model.tensorflow_model"]], "neural_compressor.model.torch_model": [[383, "module-neural_compressor.model.torch_model"]], "neural_compressor.objective": [[384, "module-neural_compressor.objective"]], "neural_compressor.onnxrt.algorithms": [[385, "module-neural_compressor.onnxrt.algorithms"]], "neural_compressor.onnxrt.algorithms.layer_wise.core": [[386, "module-neural_compressor.onnxrt.algorithms.layer_wise.core"]], "neural_compressor.onnxrt.algorithms.layer_wise": [[387, "module-neural_compressor.onnxrt.algorithms.layer_wise"]], "neural_compressor.onnxrt.algorithms.smoother.calibrator": [[388, "module-neural_compressor.onnxrt.algorithms.smoother.calibrator"]], "neural_compressor.onnxrt.algorithms.smoother.core": [[389, "module-neural_compressor.onnxrt.algorithms.smoother.core"]], "neural_compressor.onnxrt.algorithms.smoother": [[390, "module-neural_compressor.onnxrt.algorithms.smoother"]], "neural_compressor.onnxrt.algorithms.weight_only.awq": [[391, "module-neural_compressor.onnxrt.algorithms.weight_only.awq"]], "neural_compressor.onnxrt.algorithms.weight_only.gptq": [[392, "module-neural_compressor.onnxrt.algorithms.weight_only.gptq"]], "neural_compressor.onnxrt.algorithms.weight_only": [[393, "module-neural_compressor.onnxrt.algorithms.weight_only"]], "neural_compressor.onnxrt.algorithms.weight_only.rtn": [[394, "module-neural_compressor.onnxrt.algorithms.weight_only.rtn"]], "neural_compressor.onnxrt.algorithms.weight_only.utility": [[395, "module-neural_compressor.onnxrt.algorithms.weight_only.utility"]], "neural_compressor.onnxrt": [[396, "module-neural_compressor.onnxrt"]], "neural_compressor.onnxrt.quantization.algorithm_entry": [[397, "module-neural_compressor.onnxrt.quantization.algorithm_entry"]], "neural_compressor.onnxrt.quantization.autotune": [[398, "module-neural_compressor.onnxrt.quantization.autotune"]], "neural_compressor.onnxrt.quantization.calibrate": [[399, "module-neural_compressor.onnxrt.quantization.calibrate"]], "neural_compressor.onnxrt.quantization.config": [[400, "module-neural_compressor.onnxrt.quantization.config"]], "neural_compressor.onnxrt.quantization": [[401, "module-neural_compressor.onnxrt.quantization"]], "neural_compressor.onnxrt.quantization.quantize": [[402, "module-neural_compressor.onnxrt.quantization.quantize"]], "neural_compressor.onnxrt.utils": [[403, "module-neural_compressor.onnxrt.utils"]], "neural_compressor.onnxrt.utils.onnx_model": [[404, "module-neural_compressor.onnxrt.utils.onnx_model"]], "neural_compressor.onnxrt.utils.utility": [[405, "module-neural_compressor.onnxrt.utils.utility"]], "neural_compressor.profiling": [[406, "module-neural_compressor.profiling"]], "neural_compressor.profiling.parser.factory": [[407, "module-neural_compressor.profiling.parser.factory"]], "neural_compressor.profiling.parser": [[408, "module-neural_compressor.profiling.parser"]], "neural_compressor.profiling.parser.onnx_parser.factory": [[409, "module-neural_compressor.profiling.parser.onnx_parser.factory"]], "neural_compressor.profiling.parser.onnx_parser": [[410, "module-neural_compressor.profiling.parser.onnx_parser"]], "neural_compressor.profiling.parser.onnx_parser.parser": [[411, "module-neural_compressor.profiling.parser.onnx_parser.parser"]], "neural_compressor.profiling.parser.parser": [[412, "module-neural_compressor.profiling.parser.parser"]], "neural_compressor.profiling.parser.result": [[413, "module-neural_compressor.profiling.parser.result"]], "neural_compressor.profiling.parser.tensorflow_parser.factory": [[414, "module-neural_compressor.profiling.parser.tensorflow_parser.factory"]], "neural_compressor.profiling.parser.tensorflow_parser": [[415, "module-neural_compressor.profiling.parser.tensorflow_parser"]], "neural_compressor.profiling.parser.tensorflow_parser.parser": [[416, "module-neural_compressor.profiling.parser.tensorflow_parser.parser"]], "neural_compressor.profiling.profiler.factory": [[417, "module-neural_compressor.profiling.profiler.factory"]], "neural_compressor.profiling.profiler": [[418, "module-neural_compressor.profiling.profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.factory": [[419, "module-neural_compressor.profiling.profiler.onnxrt_profiler.factory"]], "neural_compressor.profiling.profiler.onnxrt_profiler": [[420, "module-neural_compressor.profiling.profiler.onnxrt_profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.profiler": [[421, "module-neural_compressor.profiling.profiler.onnxrt_profiler.profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.utils": [[422, "module-neural_compressor.profiling.profiler.onnxrt_profiler.utils"]], "neural_compressor.profiling.profiler.profiler": [[423, "module-neural_compressor.profiling.profiler.profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.factory": [[424, "module-neural_compressor.profiling.profiler.tensorflow_profiler.factory"]], "neural_compressor.profiling.profiler.tensorflow_profiler": [[425, "module-neural_compressor.profiling.profiler.tensorflow_profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.profiler": [[426, "module-neural_compressor.profiling.profiler.tensorflow_profiler.profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.utils": [[427, "module-neural_compressor.profiling.profiler.tensorflow_profiler.utils"]], "neural_compressor.quantization": [[428, "module-neural_compressor.quantization"]], "neural_compressor.strategy.auto": [[429, "module-neural_compressor.strategy.auto"]], "neural_compressor.strategy.auto_mixed_precision": [[430, "module-neural_compressor.strategy.auto_mixed_precision"]], "neural_compressor.strategy.basic": [[431, "module-neural_compressor.strategy.basic"]], "neural_compressor.strategy.bayesian": [[432, "module-neural_compressor.strategy.bayesian"]], "neural_compressor.strategy.conservative": [[433, "module-neural_compressor.strategy.conservative"]], "neural_compressor.strategy.exhaustive": [[434, "module-neural_compressor.strategy.exhaustive"]], "neural_compressor.strategy.hawq_v2": [[435, "module-neural_compressor.strategy.hawq_v2"]], "neural_compressor.strategy": [[436, "module-neural_compressor.strategy"]], "neural_compressor.strategy.mse": [[437, "module-neural_compressor.strategy.mse"]], "neural_compressor.strategy.mse_v2": [[438, "module-neural_compressor.strategy.mse_v2"]], "neural_compressor.strategy.random": [[439, "module-neural_compressor.strategy.random"]], "neural_compressor.strategy.strategy": [[440, "module-neural_compressor.strategy.strategy"]], "neural_compressor.strategy.utils.constant": [[441, "module-neural_compressor.strategy.utils.constant"]], "neural_compressor.strategy.utils": [[442, "module-neural_compressor.strategy.utils"]], "neural_compressor.strategy.utils.tuning_sampler": [[443, "module-neural_compressor.strategy.utils.tuning_sampler"]], "neural_compressor.strategy.utils.tuning_space": [[444, "module-neural_compressor.strategy.utils.tuning_space"]], "neural_compressor.strategy.utils.tuning_structs": [[445, "module-neural_compressor.strategy.utils.tuning_structs"]], "neural_compressor.strategy.utils.utility": [[446, "module-neural_compressor.strategy.utils.utility"]], "neural_compressor.template.api_doc_example": [[447, "module-neural_compressor.template.api_doc_example"]], "neural_compressor.template": [[448, "module-neural_compressor.template"]], "neural_compressor.tensorflow.algorithms": [[449, "module-neural_compressor.tensorflow.algorithms"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[450, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[451, "module-neural_compressor.tensorflow.algorithms.smoother.core"]], "neural_compressor.tensorflow.algorithms.smoother": [[452, "module-neural_compressor.tensorflow.algorithms.smoother"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[453, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"]], "neural_compressor.tensorflow.algorithms.static_quant": [[454, "module-neural_compressor.tensorflow.algorithms.static_quant"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[455, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"]], "neural_compressor.tensorflow.algorithms.static_quant.tensorflow": [[456, "module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow"]], "neural_compressor.tensorflow": [[457, "module-neural_compressor.tensorflow"]], "neural_compressor.tensorflow.keras": [[458, "module-neural_compressor.tensorflow.keras"]], "neural_compressor.tensorflow.keras.layers.conv2d": [[459, "module-neural_compressor.tensorflow.keras.layers.conv2d"]], "neural_compressor.tensorflow.keras.layers.dense": [[460, "module-neural_compressor.tensorflow.keras.layers.dense"]], "neural_compressor.tensorflow.keras.layers.depthwise_conv2d": [[461, "module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d"]], "neural_compressor.tensorflow.keras.layers": [[462, "module-neural_compressor.tensorflow.keras.layers"]], "neural_compressor.tensorflow.keras.layers.layer_initializer": [[463, "module-neural_compressor.tensorflow.keras.layers.layer_initializer"]], "neural_compressor.tensorflow.keras.layers.pool2d": [[464, "module-neural_compressor.tensorflow.keras.layers.pool2d"]], "neural_compressor.tensorflow.keras.layers.separable_conv2d": [[465, "module-neural_compressor.tensorflow.keras.layers.separable_conv2d"]], "neural_compressor.tensorflow.keras.quantization.config": [[466, "module-neural_compressor.tensorflow.keras.quantization.config"]], "neural_compressor.tensorflow.keras.quantization": [[467, "module-neural_compressor.tensorflow.keras.quantization"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[468, "module-neural_compressor.tensorflow.quantization.algorithm_entry"]], "neural_compressor.tensorflow.quantization.autotune": [[469, "module-neural_compressor.tensorflow.quantization.autotune"]], "neural_compressor.tensorflow.quantization.config": [[470, "module-neural_compressor.tensorflow.quantization.config"]], "neural_compressor.tensorflow.quantization": [[471, "module-neural_compressor.tensorflow.quantization"]], "neural_compressor.tensorflow.quantization.quantize": [[472, "module-neural_compressor.tensorflow.quantization.quantize"]], "neural_compressor.tensorflow.quantization.utils.graph_converter": [[473, "module-neural_compressor.tensorflow.quantization.utils.graph_converter"]], "neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib": [[474, "module-neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert": [[475, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[476, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16": [[477, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[478, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[479, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[480, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[481, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[482, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[483, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[484, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[485, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[486, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[487, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[488, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[489, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[490, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[491, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[492, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[493, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[494, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[495, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[496, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[497, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[498, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[499, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[500, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[501, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[502, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[503, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[504, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[505, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[506, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[507, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[508, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[509, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[510, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[511, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[512, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant": [[513, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value": [[514, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib": [[515, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[516, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize": [[517, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[518, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize": [[519, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8": [[520, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer": [[521, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter": [[522, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse": [[523, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert": [[524, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation": [[525, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq": [[526, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern": [[527, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq": [[528, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern": [[529, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[530, "module-neural_compressor.tensorflow.quantization.utils.graph_util"]], "neural_compressor.tensorflow.quantization.utils": [[531, "module-neural_compressor.tensorflow.quantization.utils"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph": [[532, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize": [[533, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat": [[534, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config": [[535, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper": [[536, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers": [[537, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer": [[538, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[539, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[540, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[541, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper": [[542, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn": [[543, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2": [[544, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv": [[545, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv": [[546, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in": [[547, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul": [[548, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling": [[549, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq": [[550, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq": [[551, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base": [[552, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn": [[553, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2": [[554, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv": [[555, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu": [[556, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul": [[557, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling": [[558, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[559, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction": [[560, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base": [[561, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base"]], "neural_compressor.tensorflow.quantization.utils.transform_graph": [[562, "module-neural_compressor.tensorflow.quantization.utils.transform_graph"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging": [[563, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat": [[564, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat"]], "neural_compressor.tensorflow.quantization.utils.utility": [[565, "module-neural_compressor.tensorflow.quantization.utils.utility"]], "neural_compressor.tensorflow.utils.constants": [[566, "module-neural_compressor.tensorflow.utils.constants"]], "neural_compressor.tensorflow.utils.data": [[567, "module-neural_compressor.tensorflow.utils.data"]], "neural_compressor.tensorflow.utils": [[568, "module-neural_compressor.tensorflow.utils"]], "neural_compressor.tensorflow.utils.model": [[569, "module-neural_compressor.tensorflow.utils.model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[570, "module-neural_compressor.tensorflow.utils.model_wrappers"]], "neural_compressor.tensorflow.utils.nets_factory": [[571, "module-neural_compressor.tensorflow.utils.nets_factory"]], "neural_compressor.tensorflow.utils.utility": [[572, "module-neural_compressor.tensorflow.utils.utility"]], "neural_compressor.torch.algorithms.base_algorithm": [[573, "module-neural_compressor.torch.algorithms.base_algorithm"]], "neural_compressor.torch.algorithms.habana_fp8.fp8_quant": [[574, "module-neural_compressor.torch.algorithms.habana_fp8.fp8_quant"]], "neural_compressor.torch.algorithms.habana_fp8": [[575, "module-neural_compressor.torch.algorithms.habana_fp8"]], "neural_compressor.torch.algorithms.habana_fp8.modules": [[576, "module-neural_compressor.torch.algorithms.habana_fp8.modules"]], "neural_compressor.torch.algorithms.habana_fp8.observer": [[577, "module-neural_compressor.torch.algorithms.habana_fp8.observer"]], "neural_compressor.torch.algorithms.habana_fp8.save_load": [[578, "module-neural_compressor.torch.algorithms.habana_fp8.save_load"]], "neural_compressor.torch.algorithms.habana_fp8.scale": [[579, "module-neural_compressor.torch.algorithms.habana_fp8.scale"]], "neural_compressor.torch.algorithms.habana_fp8.tensor": [[580, "module-neural_compressor.torch.algorithms.habana_fp8.tensor"]], "neural_compressor.torch.algorithms": [[581, "module-neural_compressor.torch.algorithms"]], "neural_compressor.torch.algorithms.layer_wise": [[582, "module-neural_compressor.torch.algorithms.layer_wise"]], "neural_compressor.torch.algorithms.layer_wise.load": [[583, "module-neural_compressor.torch.algorithms.layer_wise.load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[584, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[585, "module-neural_compressor.torch.algorithms.layer_wise.utils"]], "neural_compressor.torch.algorithms.mix_precision.half_precision_convert": [[586, "module-neural_compressor.torch.algorithms.mix_precision.half_precision_convert"]], "neural_compressor.torch.algorithms.mix_precision": [[587, "module-neural_compressor.torch.algorithms.mix_precision"]], "neural_compressor.torch.algorithms.mix_precision.module_wrappers": [[588, "module-neural_compressor.torch.algorithms.mix_precision.module_wrappers"]], "neural_compressor.torch.algorithms.mx_quant": [[589, "module-neural_compressor.torch.algorithms.mx_quant"]], "neural_compressor.torch.algorithms.mx_quant.mx": [[590, "module-neural_compressor.torch.algorithms.mx_quant.mx"]], "neural_compressor.torch.algorithms.mx_quant.utils": [[591, "module-neural_compressor.torch.algorithms.mx_quant.utils"]], "neural_compressor.torch.algorithms.pt2e_quant.core": [[592, "module-neural_compressor.torch.algorithms.pt2e_quant.core"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter": [[593, "module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter"]], "neural_compressor.torch.algorithms.pt2e_quant": [[594, "module-neural_compressor.torch.algorithms.pt2e_quant"]], "neural_compressor.torch.algorithms.smooth_quant": [[595, "module-neural_compressor.torch.algorithms.smooth_quant"]], "neural_compressor.torch.algorithms.smooth_quant.save_load": [[596, "module-neural_compressor.torch.algorithms.smooth_quant.save_load"]], "neural_compressor.torch.algorithms.smooth_quant.smooth_quant": [[597, "module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant"]], "neural_compressor.torch.algorithms.smooth_quant.utility": [[598, "module-neural_compressor.torch.algorithms.smooth_quant.utility"]], "neural_compressor.torch.algorithms.static_quant": [[599, "module-neural_compressor.torch.algorithms.static_quant"]], "neural_compressor.torch.algorithms.static_quant.save_load": [[600, "module-neural_compressor.torch.algorithms.static_quant.save_load"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[601, "module-neural_compressor.torch.algorithms.static_quant.static_quant"]], "neural_compressor.torch.algorithms.static_quant.utility": [[602, "module-neural_compressor.torch.algorithms.static_quant.utility"]], "neural_compressor.torch.algorithms.weight_only.autoround": [[603, "module-neural_compressor.torch.algorithms.weight_only.autoround"]], "neural_compressor.torch.algorithms.weight_only.awq": [[604, "module-neural_compressor.torch.algorithms.weight_only.awq"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[605, "module-neural_compressor.torch.algorithms.weight_only.gptq"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[606, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[607, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[608, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[609, "module-neural_compressor.torch.algorithms.weight_only.hqq"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[610, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[611, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[612, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.utility": [[613, "module-neural_compressor.torch.algorithms.weight_only.hqq.utility"]], "neural_compressor.torch.algorithms.weight_only": [[614, "module-neural_compressor.torch.algorithms.weight_only"]], "neural_compressor.torch.algorithms.weight_only.modules": [[615, "module-neural_compressor.torch.algorithms.weight_only.modules"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[616, "module-neural_compressor.torch.algorithms.weight_only.rtn"]], "neural_compressor.torch.algorithms.weight_only.save_load": [[617, "module-neural_compressor.torch.algorithms.weight_only.save_load"]], "neural_compressor.torch.algorithms.weight_only.teq": [[618, "module-neural_compressor.torch.algorithms.weight_only.teq"]], "neural_compressor.torch.algorithms.weight_only.utility": [[619, "module-neural_compressor.torch.algorithms.weight_only.utility"]], "neural_compressor.torch.amp.autocast": [[620, "module-neural_compressor.torch.amp.autocast"]], "neural_compressor.torch.amp.fp8.functions": [[621, "module-neural_compressor.torch.amp.fp8.functions"]], "neural_compressor.torch.amp.fp8": [[622, "module-neural_compressor.torch.amp.fp8"]], "neural_compressor.torch.amp": [[623, "module-neural_compressor.torch.amp"]], "neural_compressor.torch.export._export": [[624, "module-neural_compressor.torch.export._export"]], "neural_compressor.torch.export": [[625, "module-neural_compressor.torch.export"]], "neural_compressor.torch": [[626, "module-neural_compressor.torch"]], "neural_compressor.torch.quantization.algorithm_entry": [[627, "module-neural_compressor.torch.quantization.algorithm_entry"]], "neural_compressor.torch.quantization.autotune": [[628, "module-neural_compressor.torch.quantization.autotune"]], "neural_compressor.torch.quantization.config": [[629, "module-neural_compressor.torch.quantization.config"]], "neural_compressor.torch.quantization": [[630, "module-neural_compressor.torch.quantization"]], "neural_compressor.torch.quantization.load_entry": [[631, "module-neural_compressor.torch.quantization.load_entry"]], "neural_compressor.torch.quantization.quantize": [[632, "module-neural_compressor.torch.quantization.quantize"]], "neural_compressor.torch.utils.auto_accelerator": [[633, "module-neural_compressor.torch.utils.auto_accelerator"]], "neural_compressor.torch.utils.constants": [[634, "module-neural_compressor.torch.utils.constants"]], "neural_compressor.torch.utils.environ": [[635, "module-neural_compressor.torch.utils.environ"]], "neural_compressor.torch.utils": [[636, "module-neural_compressor.torch.utils"]], "neural_compressor.torch.utils.utility": [[637, "module-neural_compressor.torch.utils.utility"]], "neural_compressor.training": [[638, "module-neural_compressor.training"]], "neural_compressor.utils.collect_layer_histogram": [[639, "module-neural_compressor.utils.collect_layer_histogram"]], "neural_compressor.utils.constant": [[640, "module-neural_compressor.utils.constant"]], "neural_compressor.utils.create_obj_from_config": [[641, "module-neural_compressor.utils.create_obj_from_config"]], "neural_compressor.utils": [[642, "module-neural_compressor.utils"]], "neural_compressor.utils.kl_divergence": [[643, "module-neural_compressor.utils.kl_divergence"]], "neural_compressor.utils.load_huggingface": [[644, "module-neural_compressor.utils.load_huggingface"]], "neural_compressor.utils.logger": [[645, "module-neural_compressor.utils.logger"]], "neural_compressor.utils.neural_insights_utils": [[646, "module-neural_compressor.utils.neural_insights_utils"]], "neural_compressor.utils.options": [[647, "module-neural_compressor.utils.options"]], "neural_compressor.utils.pytorch": [[648, "module-neural_compressor.utils.pytorch"]], "neural_compressor.utils.utility": [[649, "module-neural_compressor.utils.utility"]], "neural_compressor.utils.weights_details": [[650, "module-neural_compressor.utils.weights_details"]], "neural_compressor.version": [[651, "module-neural_compressor.version"]], "Intel\u00ae Neural Compressor Documentation": [[652, "intel-neural-compressor-documentation"], [753, "intel-neural-compressor-documentation"]], "Sections": [[652, "sections"], [753, "sections"]], "Contributor Covenant Code of Conduct": [[653, "contributor-covenant-code-of-conduct"], [654, "contributor-covenant-code-of-conduct"]], "Our Pledge": [[653, "our-pledge"]], "Our Standards": [[653, "our-standards"]], "Our Responsibilities": [[653, "our-responsibilities"]], "Scope": [[653, "scope"]], "Enforcement": [[653, "enforcement"]], "Attribution": [[653, "attribution"]], "Contribution Guidelines": [[654, "contribution-guidelines"]], "Create Pull Request": [[654, "create-pull-request"]], "Step-by-Step guidelines": [[654, "step-by-step-guidelines"]], "Pull Request Checklist": [[654, "pull-request-checklist"]], "Pull Request Template": [[654, "pull-request-template"]], "Pull Request Acceptance Criteria": [[654, "pull-request-acceptance-criteria"]], "Pull Request Status Checks Overview": [[654, "pull-request-status-checks-overview"]], "Support": [[654, "support"]], "FX": [[655, "fx"]], "Introduction": [[655, "introduction"], [656, "introduction"], [659, "introduction"], [660, "introduction"], [661, "introduction"], [676, "introduction"], [677, "introduction"], [679, "introduction"], [680, "introduction"], [683, "introduction"], [684, "introduction"], [685, "introduction"], [687, "introduction"], [689, "introduction"], [692, "introduction"], [696, "introduction"], [698, "introduction"], [699, "introduction"], [700, "introduction"], [721, "introduction"], [722, "introduction"], [723, "introduction"], [735, "introduction"], [736, "introduction"], [737, "introduction"], [739, "introduction"], [741, "introduction"], [743, "introduction"], [745, "introduction"], [746, "introduction"], [747, "introduction"], [748, "introduction"], [749, "introduction"], [751, "introduction"]], "FX Mode Support Matrix in Neural Compressor": [[655, "fx-mode-support-matrix-in-neural-compressor"]], "Get Started": [[655, "get-started"], [682, "get-started"], [725, "get-started"], [740, "get-started"]], "Post Training Static Quantization": [[655, "post-training-static-quantization"], [740, "post-training-static-quantization"]], "Post Training Dynamic Quantization": [[655, "post-training-dynamic-quantization"], [740, "post-training-dynamic-quantization"]], "Quantization-Aware Training": [[655, "quantization-aware-training"]], "Examples": [[655, "examples"], [656, "examples"], [676, "examples"], [679, "examples"], [680, "examples"], [683, "examples"], [684, "examples"], [685, "examples"], [686, "examples"], [687, "examples"], [697, "examples"], [698, "examples"], [699, "examples"], [700, "examples"], [736, "examples"], [737, "examples"], [740, "examples"], [741, "examples"], [743, "examples"], [747, "examples"]], "Note": [[655, "note"]], "Details": [[655, "details"]], "Common Problem": [[655, "common-problem"]], "Dynamic Quantization": [[655, "dynamic-quantization"]], "Static Quantization & Quantization Aware Training": [[655, "static-quantization-quantization-aware-training"]], "Neural Architecture Search": [[656, "neural-architecture-search"]], "Basic NAS": [[656, "basic-nas"]], "Dynamic NAS": [[656, "dynamic-nas"]], "NAS Support Matrix": [[656, "nas-support-matrix"]], "Get Started with NAS API": [[656, "get-started-with-nas-api"]], "Basic Usage": [[656, "basic-usage"]], "1. Python code + YAML": [[656, "python-code-yaml"]], "2. Python code only": [[656, "python-code-only"]], "Advanced Usage (Custom NAS)": [[656, "advanced-usage-custom-nas"]], "Security Policy": [[657, "security-policy"]], "Report a Vulnerability": [[657, "report-a-vulnerability"]], "Intel\u00ae Neural Compressor": [[658, "intel-neural-compressor"], [718, "intel-neural-compressor"]], "What\u2019s New": [[658, "what-s-new"]], "Installation": [[658, "installation"], [693, "installation"], [693, "id1"], [712, "installation"], [720, "installation"], [725, "installation"]], "Install from pypi": [[658, "install-from-pypi"], [720, "install-from-pypi"]], "Getting Started": [[658, "getting-started"], [690, "getting-started"], [720, "getting-started"]], "Weight-Only Quantization (LLMs)": [[658, "weight-only-quantization-llms"]], "Static Quantization (Non-LLMs)": [[658, "static-quantization-non-llms"]], "Documentation": [[658, "documentation"]], "Selected Publications/Events": [[658, "selected-publications-events"]], "Additional Content": [[658, "additional-content"]], "Communication": [[658, "communication"]], "Adaptor": [[659, "adaptor"], [662, "adaptor"]], "Adaptor Support Matrix": [[659, "adaptor-support-matrix"]], "Working Flow": [[659, "working-flow"], [740, "working-flow"]], "Get Started with Adaptor API": [[659, "get-started-with-adaptor-api"]], "Query API": [[659, "query-api"]], "Background": [[659, "background"], [678, "background"]], "Query API Introduction": [[659, "query-api-introduction"]], "Example of Adding a New Backend Support": [[659, "example-of-adding-a-new-backend-support"]], "Capability": [[659, "capability"]], "Implement ONNXRTAdaptor Class": [[659, "implement-onnxrtadaptor-class"]], "How to Add An Adaptor": [[660, "how-to-add-an-adaptor"]], "API List that Need to Implement": [[660, "api-list-that-need-to-implement"]], "Design the framework YAML": [[660, "design-the-framework-yaml"]], "Add query_fw_capability to Adaptor": [[660, "add-query-fw-capability-to-adaptor"]], "Add quantize API according to tune_cfg": [[660, "add-quantize-api-according-to-tune-cfg"]], "Prepare calibration model from fp32 graph": [[660, "prepare-calibration-model-from-fp32-graph"]], "Run sampling iterations of the fp32 graph to calibrate quantizable operators.": [[660, "run-sampling-iterations-of-the-fp32-graph-to-calibrate-quantizable-operators"]], "Calculate the data range and generate quantized model": [[660, "calculate-the-data-range-and-generate-quantized-model"]], "How to Support New Data Type, Like Int4, with a Few Line Changes": [[661, "how-to-support-new-data-type-like-int4-with-a-few-line-changes"]], "Define the Quantization Ability of the Specific Operator": [[661, "define-the-quantization-ability-of-the-specific-operator"]], "Invoke the Operator Kernel According to the Tuning Configuration": [[661, "invoke-the-operator-kernel-according-to-the-tuning-configuration"]], "Use the New Data Type": [[661, "use-the-new-data-type"]], "Summary": [[661, "summary"]], "ONNX Runtime": [[663, "onnx-runtime"]], "Torch Utils": [[664, "torch-utils"]], "API Document Example": [[665, "api-document-example"]], "APIs": [[666, "apis"]], "Benchmark": [[667, "benchmark"], [697, "benchmark"], [739, "benchmark"]], "Compression": [[668, "compression"]], "Config": [[669, "config"]], "Mix Precision": [[670, "mix-precision"], [697, "mix-precision"]], "Model": [[671, "model"], [699, "model"], [721, "model"], [723, "model"]], "Objective": [[672, "objective"], [731, "objective"], [732, "objective"], [733, "objective"], [735, "objective"]], "Quantization": [[673, "quantization"], [739, "quantization"], [740, "quantization"]], "Strategy": [[674, "strategy"]], "Training": [[675, "training"]], "Benchmarking": [[676, "benchmarking"]], "Benchmark Support Matrix": [[676, "benchmark-support-matrix"]], "Get Started with Benchmark API": [[676, "get-started-with-benchmark-api"]], "Calibration Algorithms in Quantization": [[677, "calibration-algorithms-in-quantization"]], "Calibration Algorithms": [[677, "calibration-algorithms"]], "Support Matrix": [[677, "support-matrix"], [703, "support-matrix"]], "Reference": [[677, "reference"], [678, "reference"], [700, "reference"], [737, "reference"], [740, "reference"], [743, "reference"], [746, "reference"]], "INC Coding Conventions": [[678, "inc-coding-conventions"]], "Rules": [[678, "rules"]], "Imports": [[678, "imports"]], "Strings": [[678, "strings"]], "Logger": [[678, "logger"]], "Type Annotations": [[678, "type-annotations"]], "Comments": [[678, "comments"]], "TODO Comments": [[678, "todo-comments"]], "Public and Internal Interfaces": [[678, "public-and-internal-interfaces"]], "Folder structure": [[678, "folder-structure"]], "Recommend VS Code settings.json": [[678, "recommend-vs-code-settings-json"]], "DataLoader": [[679, "dataloader"]], "Supported Framework Dataloader Matrix": [[679, "supported-framework-dataloader-matrix"]], "Get Started with DataLoader": [[679, "get-started-with-dataloader"]], "Use Intel\u00ae Neural Compressor DataLoader API": [[679, "use-intel-neural-compressor-dataloader-api"]], "Build Custom Dataloader with Python API": [[679, "build-custom-dataloader-with-python-api"]], "Dataset": [[680, "dataset"]], "Supported Framework Dataset Matrix": [[680, "supported-framework-dataset-matrix"]], "TensorFlow": [[680, "tensorflow"], [696, "tensorflow"], [748, "tensorflow"]], "PyTorch": [[680, "pytorch"], [696, "pytorch"], [742, "pytorch"]], "MXNet": [[680, "mxnet"], [696, "mxnet"], [748, "mxnet"]], "ONNXRT": [[680, "onnxrt"], [696, "onnxrt"], [748, "onnxrt"]], "Get start with Dataset API": [[680, "get-start-with-dataset-api"]], "Config dataloader in a yaml file": [[680, "config-dataloader-in-a-yaml-file"]], "User-specific dataset": [[680, "user-specific-dataset"]], "Design": [[681, "design"], [749, "design"], [749, "id1"], [749, "id3"], [749, "id5"], [749, "id7"], [749, "id9"], [749, "id11"], [749, "id13"], [749, "id15"], [749, "id17"], [749, "id19"], [749, "id21"]], "Architecture": [[681, "architecture"], [692, "architecture"]], "Workflow": [[681, "workflow"]], "Diagnosis": [[682, "diagnosis"]], "Diagnosis Introduction": [[682, "diagnosis-introduction"]], "Supported Feature Matrix": [[682, "supported-feature-matrix"], [685, "supported-feature-matrix"], [689, "supported-feature-matrix"], [692, "supported-feature-matrix"], [739, "supported-feature-matrix"], [740, "supported-feature-matrix"], [747, "supported-feature-matrix"], [751, "supported-feature-matrix"]], "Install Intel\u00ae Neural Compressor": [[682, "install-intel-neural-compressor"]], "Modify script": [[682, "modify-script"]], "Quantization diagnosis": [[682, "quantization-diagnosis"]], "Benchmark diagnosis": [[682, "benchmark-diagnosis"]], "Example": [[682, "example"], [696, "example"], [703, "example"], [707, "example"], [735, "example"]], "Prepare dataset": [[682, "prepare-dataset"]], "Run quantization script": [[682, "run-quantization-script"]], "Run benchmark script": [[682, "run-benchmark-script"]], "See quantization data": [[682, "see-quantization-data"]], "How to do diagnosis": [[682, "how-to-do-diagnosis"]], "Parameter description": [[682, "parameter-description"]], "Diagnosis suggestions": [[682, "diagnosis-suggestions"]], "Fallback setting example": [[682, "fallback-setting-example"]], "See profiling data": [[682, "see-profiling-data"]], "Distillation": [[683, "distillation"], [697, "distillation"], [739, "distillation"]], "Knowledge Distillation": [[683, "knowledge-distillation"]], "Intermediate Layer Knowledge Distillation": [[683, "intermediate-layer-knowledge-distillation"]], "Self Distillation": [[683, "self-distillation"]], "Distillation Support Matrix": [[683, "distillation-support-matrix"]], "Get Started with Distillation API": [[683, "get-started-with-distillation-api"]], "Distillation for Quantization": [[684, "distillation-for-quantization"]], "Distillation for Quantization Support Matrix": [[684, "distillation-for-quantization-support-matrix"]], "Get Started with Distillation for Quantization API": [[684, "get-started-with-distillation-for-quantization-api"]], "Distributed Training and Inference (Evaluation)": [[685, "distributed-training-and-inference-evaluation"]], "Get Started with Distributed Training and Inference API": [[685, "get-started-with-distributed-training-and-inference-api"]], "Option 1: Pure Yaml Configuration": [[685, "option-1-pure-yaml-configuration"]], "Option 2: User Defined Training Function": [[685, "option-2-user-defined-training-function"]], "Horovodrun Execution": [[685, "horovodrun-execution"]], "Security": [[685, "security"]], "PyTorch Examples:": [[685, "pytorch-examples"]], "TensorFlow Examples:": [[685, "tensorflow-examples"]], "Example List": [[686, "example-list"]], "Release Data": [[686, "release-data"]], "Export": [[687, "export"]], "Supported Framework Model Matrix": [[687, "supported-framework-model-matrix"], [699, "supported-framework-model-matrix"], [700, "supported-framework-model-matrix"], [741, "supported-framework-model-matrix"], [743, "supported-framework-model-matrix"]], "PyTorch Model": [[687, "pytorch-model"]], "FP32 Model Export": [[687, "fp32-model-export"], [687, "id1"]], "INT8 Model Export": [[687, "int8-model-export"], [687, "id2"]], "Tensorflow Model": [[687, "tensorflow-model"]], "Appendix": [[687, "appendix"]], "Supported quantized ops": [[687, "supported-quantized-ops"]], "Frequently Asked Questions": [[688, "frequently-asked-questions"]], "Common Build Issues": [[688, "common-build-issues"]], "Issue 1:": [[688, "issue-1"]], "Issue 2:": [[688, "issue-2"]], "Issue 3:": [[688, "issue-3"]], "Issue 4:": [[688, "issue-4"]], "Framework YAML Configuration Files": [[689, "framework-yaml-configuration-files"]], "Get started with Framework YAML Files": [[689, "get-started-with-framework-yaml-files"]], "Quick Samples": [[690, "quick-samples"]], "Quantization with Python API": [[690, "quantization-with-python-api"], [720, "quantization-with-python-api"]], "Validated Models": [[690, "validated-models"], [746, "validated-models"], [752, "validated-models"]], "Incompatible changes between v1.2 and v1.1": [[691, "incompatible-changes-between-v1-2-and-v1-1"]], "User-facing APIs": [[691, "user-facing-apis"]], "Built-in transform/dataset/metric APIs": [[691, "built-in-transform-dataset-metric-apis"]], "Infrastructure of Intel\u00ae Neural Compressor": [[692, "infrastructure-of-intel-neural-compressor"]], "Prerequisites": [[693, "prerequisites"], [725, "prerequisites"], [726, "prerequisites"]], "Install from Binary": [[693, "install-from-binary"]], "Install from Source": [[693, "install-from-source"], [720, "install-from-source"]], "Install from AI Kit": [[693, "install-from-ai-kit"]], "System Requirements": [[693, "system-requirements"]], "Validated Hardware Environment": [[693, "validated-hardware-environment"]], "Intel\u00ae Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:": [[693, "intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors"]], "Intel\u00ae Neural Compressor supports GPUs built on Intel\u2019s Xe architecture:": [[693, "intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture"]], "Intel\u00ae Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:": [[693, "intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime"]], "Validated Software Environment": [[693, "validated-software-environment"]], "Legal Information": [[694, "legal-information"]], "License": [[694, "license"]], "Citation": [[694, "citation"]], "Trademarks": [[694, "trademarks"]], "LLMs Quantization Recipes": [[695, "llms-quantization-recipes"]], "Large Language Models Recipes": [[695, "large-language-models-recipes"]], "Large Language Models Accuracy": [[695, "large-language-models-accuracy"]], "Metrics": [[696, "metrics"]], "Supported Built-in Metric Matrix": [[696, "supported-built-in-metric-matrix"]], "Get Started with Metric": [[696, "get-started-with-metric"]], "Use Intel\u00ae Neural Compressor Metric API": [[696, "use-intel-neural-compressor-metric-api"]], "Build Custom Metric with Python API": [[696, "build-custom-metric-with-python-api"]], "Code Migration from Intel Neural Compressor 1.X to Intel Neural Compressor 2.X": [[697, "code-migration-from-intel-neural-compressor-1-x-to-intel-neural-compressor-2-x"]], "Model Quantization": [[697, "model-quantization"]], "Post-training Quantization": [[697, "post-training-quantization"]], "Quantization Aware Training": [[697, "quantization-aware-training"], [740, "quantization-aware-training"], [740, "id1"]], "Pruning": [[697, "pruning"], [737, "pruning"], [739, "pruning"]], "Orchestration": [[697, "orchestration"]], "Mixed Precision": [[698, "mixed-precision"]], "Mixed Precision Support Matrix": [[698, "mixed-precision-support-matrix"]], "Hardware and Software requests for BF16": [[698, "hardware-and-software-requests-for-bf16"]], "Hardware and Software requests for FP16": [[698, "hardware-and-software-requests-for-fp16"]], "During quantization mixed precision": [[698, "during-quantization-mixed-precision"]], "Accuracy-driven mixed precision": [[698, "accuracy-driven-mixed-precision"]], "Get Started with Mixed Precision API": [[698, "get-started-with-mixed-precision-api"]], "Microscaling Quantization": [[700, "microscaling-quantization"]], "Get Started with Microscaling Quantization API": [[700, "get-started-with-microscaling-quantization-api"]], "Neural Coder": [[701, "neural-coder"], [718, "neural-coder"], [718, "id1"]], "What do we offer?": [[701, "what-do-we-offer"]], "Getting Started!": [[701, "getting-started"], [712, "getting-started"]], "Jupyter Lab Extension": [[701, "jupyter-lab-extension"]], "Python Launcher": [[701, "python-launcher"], [706, "python-launcher"]], "Python API": [[701, "python-api"]], "Contact": [[701, "contact"], [725, "contact"]], "AWS Amazon SageMaker Support": [[702, "aws-amazon-sagemaker-support"]], "Start Jupyter Lab 3": [[702, "start-jupyter-lab-3"]], "For SageMaker Studio": [[702, "for-sagemaker-studio"]], "For SageMaker Notebook instance": [[702, "for-sagemaker-notebook-instance"]], "Installation Guide": [[702, "installation-guide"]], "BigDL Nano Support": [[703, "bigdl-nano-support"]], "Intel CPU Platforms: Best Performance Setting": [[704, "intel-cpu-platforms-best-performance-setting"]], "Install MKL, OpenMP and JEMALLOC": [[704, "install-mkl-openmp-and-jemalloc"]], "Install NUMA Controller": [[704, "install-numa-controller"]], "Environment Variables": [[704, "environment-variables"]], "Frequency Governers": [[704, "frequency-governers"]], "Neural Coder as Python API": [[705, "neural-coder-as-python-api"]], "Enable": [[705, "enable"]], "Bench": [[705, "bench"]], "SuperBench": [[705, "superbench"]], "Quick-Start": [[706, "quick-start"]], "Launcher Arguments (Optional)": [[706, "launcher-arguments-optional"]], "Neural Coder for Quantization": [[707, "neural-coder-for-quantization"]], "Features Supported": [[707, "features-supported"]], "Models Supported": [[707, "models-supported"]], "Usage": [[707, "usage"], [727, "usage"], [727, "id2"], [727, "id6"], [727, "id9"], [727, "id16"], [727, "id19"], [727, "id22"], [727, "id25"], [746, "usage"], [747, "usage"], [747, "id1"], [749, "usage"], [749, "id2"], [749, "id4"], [749, "id6"], [749, "id8"], [749, "id10"], [749, "id12"], [749, "id14"], [749, "id16"], [749, "id18"], [749, "id20"], [749, "id22"]], "PyPI distribution:": [[707, "pypi-distribution"]], "Supported Optimization Features": [[708, "supported-optimization-features"]], "v0.4": [[709, "v0-4"]], "Highlights": [[709, "highlights"]], "Others": [[709, "others"]], "Changelog": [[710, "changelog"], [714, "changelog"]], "neural_compressor_ext_lab": [[711, "neural-compressor-ext-lab"]], "Requirements": [[711, "requirements"], [715, "requirements"], [721, "requirements"], [722, "requirements"], [723, "requirements"], [731, "requirements"]], "Install": [[711, "install"]], "Uninstall": [[711, "uninstall"]], "Contributing": [[711, "contributing"], [715, "contributing"]], "Development install": [[711, "development-install"], [715, "development-install"]], "Development uninstall": [[711, "development-uninstall"], [715, "development-uninstall"]], "Packaging the extension": [[711, "packaging-the-extension"], [715, "packaging-the-extension"]], "Intel\u00ae Neural Compressor as JupyterLab Extension": [[712, "intel-neural-compressor-as-jupyterlab-extension"]], "Auto-enable a feature": [[712, "auto-enable-a-feature"]], "Or let us help you auto-select the best feature": [[712, "or-let-us-help-you-auto-select-the-best-feature"]], "Pre-requisites": [[712, "pre-requisites"]], "Making a new release of neural_compressor_ext_lab": [[713, "making-a-new-release-of-neural-compressor-ext-lab"]], "Manual release": [[713, "manual-release"], [716, "manual-release"]], "Python package": [[713, "python-package"], [716, "python-package"]], "NPM package": [[713, "npm-package"], [716, "npm-package"]], "Automated releases with the Jupyter Releaser": [[713, "automated-releases-with-the-jupyter-releaser"], [716, "automated-releases-with-the-jupyter-releaser"]], "Publishing to conda-forge": [[713, "publishing-to-conda-forge"], [716, "publishing-to-conda-forge"]], "neural_compressor_ext_lab_alibaba": [[715, "neural-compressor-ext-lab-alibaba"]], "Making a new release of neural_compressor_ext_lab_alibaba": [[716, "making-a-new-release-of-neural-compressor-ext-lab-alibaba"]], "Change Log": [[717, "change-log"]], "[Unreleased]": [[717, "unreleased"]], "Background Introduction": [[718, "background-introduction"]], "Neural Coder Extension in VSCode": [[718, "neural-coder-extension-in-vscode"]], "Neural Coder Extension Usage": [[718, "neural-coder-extension-usage"]], "1. Open": [[718, "open"]], "2. Search": [[718, "search"]], "3. Setting": [[718, "setting"]], "4. Icon": [[718, "icon"]], "5. optimization (quantization)": [[718, "optimization-quantization"]], "5.1 Enable": [[718, "enable"]], "5.2 Auto": [[718, "auto"]], "Welcome to your VS Code Extension": [[719, "welcome-to-your-vs-code-extension"]], "What\u2019s in the folder": [[719, "what-s-in-the-folder"]], "Setup": [[719, "setup"]], "Get up and running straight away": [[719, "get-up-and-running-straight-away"]], "Make changes": [[719, "make-changes"]], "Explore the API": [[719, "explore-the-api"]], "Run tests": [[719, "run-tests"]], "Go further": [[719, "go-further"]], "Neural Insights": [[720, "neural-insights"]], "Start the Neural Insights": [[720, "start-the-neural-insights"]], "Tensor dump examples": [[720, "tensor-dump-examples"]], "Step by Step Diagnosis Example": [[720, "step-by-step-diagnosis-example"]], "Research Collaborations": [[720, "research-collaborations"]], "Step by step example how to debug accuracy with Neural Insights": [[721, "step-by-step-example-how-to-debug-accuracy-with-neural-insights"], [723, "step-by-step-example-how-to-debug-accuracy-with-neural-insights"]], "Preparation": [[721, "preparation"], [722, "preparation"], [723, "preparation"], [745, "preparation"]], "Running the quantization": [[721, "running-the-quantization"], [722, "running-the-quantization"], [723, "running-the-quantization"]], "Analyzing the result of quantization": [[721, "analyzing-the-result-of-quantization"], [723, "analyzing-the-result-of-quantization"]], "Weights summary": [[721, "weights-summary"]], "Activations summary": [[721, "activations-summary"]], "Step by step example how to dump weights data for PyTorch model with Neural Insights": [[722, "step-by-step-example-how-to-dump-weights-data-for-pytorch-model-with-neural-insights"]], "Source": [[722, "source"], [723, "source"]], "Prepare the dataset": [[723, "prepare-the-dataset"]], "Analyzing weight histograms": [[723, "analyzing-weight-histograms"]], "Open Neural Insights": [[723, "open-neural-insights"]], "Getting Started with Create React App": [[724, "getting-started-with-create-react-app"]], "Available Scripts": [[724, "available-scripts"]], "npm start": [[724, "npm-start"]], "npm test": [[724, "npm-test"]], "npm run build": [[724, "npm-run-build"]], "npm run eject": [[724, "npm-run-eject"]], "Learn More": [[724, "learn-more"], [725, "learn-more"]], "Code Splitting": [[724, "code-splitting"]], "Analyzing the Bundle Size": [[724, "analyzing-the-bundle-size"]], "Making a Progressive Web App": [[724, "making-a-progressive-web-app"]], "Advanced Configuration": [[724, "advanced-configuration"]], "Deployment": [[724, "deployment"]], "npm run build fails to minify": [[724, "npm-run-build-fails-to-minify"]], "What\u2019s Neural Solution?": [[725, "what-s-neural-solution"]], "Why Neural Solution?": [[725, "why-neural-solution"]], "How does Neural Solution Work?": [[725, "how-does-neural-solution-work"]], "Method 1. Using pip:": [[725, "method-1-using-pip"]], "Method 2. Building from source:": [[725, "method-2-building-from-source"]], "End-to-end examples": [[725, "end-to-end-examples"]], "Get started": [[726, "get-started"]], "Install Neural Solution": [[726, "install-neural-solution"]], "Method 1. Using pip": [[726, "method-1-using-pip"]], "Method 2. Building from source": [[726, "method-2-building-from-source"]], "Start service": [[726, "start-service"]], "Submit task": [[726, "submit-task"]], "Query task status": [[726, "query-task-status"]], "Stop service": [[726, "stop-service"]], "Inspect logs": [[726, "inspect-logs"]], "Manage resource": [[726, "manage-resource"], [731, "manage-resource"], [732, "manage-resource"]], "Node States": [[726, "node-states"]], "Query cluster": [[726, "query-cluster"]], "Add node": [[726, "add-node"]], "Remove node": [[726, "remove-node"]], "Neural Solution API": [[727, "neural-solution-api"]], "Base URL": [[727, "base-url"]], "Endpoints": [[727, "endpoints"]], "GET /": [[727, "get"]], "Description": [[727, "description"], [727, "id1"], [727, "id4"], [727, "id8"], [727, "id12"], [727, "id15"], [727, "id18"], [727, "id21"], [727, "id24"]], "Responses": [[727, "responses"], [727, "id3"], [727, "id7"], [727, "id11"], [727, "id14"], [727, "id17"], [727, "id20"], [727, "id23"], [727, "id26"]], "POST /task/submit": [[727, "post-task-submit"]], "Parameters": [[727, "parameters"], [727, "id5"], [727, "id10"], [727, "id13"]], "GET /task/status/{task_id}": [[727, "get-task-status-task-id"]], "GET /task/log/{task_id}": [[727, "get-task-log-task-id"]], "WebSocket /task/screen/{task_id}": [[727, "websocket-task-screen-task-id"]], "GET /ping": [[727, "get-ping"]], "GET /cluster": [[727, "get-cluster"]], "GET /download/{task_id}": [[727, "get-download-task-id"]], "GET /description": [[727, "get-description"]], "Design Doc for Optimization as a Service [WIP]": [[728, "design-doc-for-optimization-as-a-service-wip"]], "Contents": [[728, "contents"]], "Overview": [[728, "overview"], [750, "overview"]], "Workflow of OaaS": [[728, "workflow-of-oaas"]], "Class definition diagram": [[728, "class-definition-diagram"]], "Extensibility": [[728, "extensibility"]], "Task request description": [[729, "task-request-description"]], "Examples List": [[730, "examples-list"]], "An end-to-end example: quantize a custom model with Neural Solution": [[731, "an-end-to-end-example-quantize-a-custom-model-with-neural-solution"]], "Start the Neural Solution Service": [[731, "start-the-neural-solution-service"], [732, "start-the-neural-solution-service"], [733, "start-the-neural-solution-service"]], "Submit optimization task": [[731, "submit-optimization-task"], [732, "submit-optimization-task"], [733, "submit-optimization-task"]], "Query optimization result": [[731, "query-optimization-result"], [732, "query-optimization-result"], [733, "query-optimization-result"]], "Download optimized model": [[731, "download-optimized-model"], [732, "download-optimized-model"]], "Stop the service": [[731, "stop-the-service"], [732, "stop-the-service"], [733, "stop-the-service"]], "An end-to-end example: quantize a Hugging Face model with Neural Solution": [[732, "an-end-to-end-example-quantize-a-hugging-face-model-with-neural-solution"]], "An end-to-end example: quantize a Hugging Face model with Neural Solution gRPC API": [[733, "an-end-to-end-example-quantize-a-hugging-face-model-with-neural-solution-grpc-api"]], "Client": [[734, "client"]], "Single Objective": [[735, "single-objective"]], "Multiple Objectives": [[735, "multiple-objectives"]], "Objective Support Matrix": [[735, "objective-support-matrix"]], "Get Started with Objective API": [[735, "get-started-with-objective-api"]], "Config Single Objective": [[735, "config-single-objective"]], "Config Multiple Objectives": [[735, "config-multiple-objectives"]], "Optimization Orchestration": [[736, "optimization-orchestration"]], "One-shot": [[736, "one-shot"]], "Orchestration Support Matrix": [[736, "orchestration-support-matrix"]], "Get Started with Orchestration API": [[736, "get-started-with-orchestration-api"]], "Neural Network Pruning": [[737, "neural-network-pruning"]], "Pruning Patterns": [[737, "pruning-patterns"]], "Pruning Criteria": [[737, "pruning-criteria"]], "Pruning Types": [[737, "pruning-types"]], "Pruning Schedules": [[737, "pruning-schedules"]], "Pruning Scope": [[737, "pruning-scope"]], "Sparsity Decay Types": [[737, "sparsity-decay-types"]], "Regularization": [[737, "regularization"]], "Large Language Model Pruning": [[737, "large-language-model-pruning"]], "Pruning Support Matrix": [[737, "pruning-support-matrix"]], "Get Started with Pruning API": [[737, "get-started-with-pruning-api"]], "Training-aware pruning API": [[737, "training-aware-pruning-api"]], "Retrain-free Pruning API": [[737, "retrain-free-pruning-api"]], "Sparse Model Deployment": [[737, "sparse-model-deployment"]], "Pruning with Hyperparameter Optimization": [[737, "pruning-with-hyperparameter-optimization"]], "Full Publications/Events (80)": [[738, "full-publications-events-80"]], "2024 (1)": [[738, "id1"]], "2023 (25)": [[738, "id2"]], "2022 (35)": [[738, "id3"]], "2021 (15)": [[738, "id4"]], "2018 - 2020 (4)": [[738, "id5"]], "Pythonic Style Access for Configurations": [[739, "pythonic-style-access-for-configurations"]], "Pythonic API for User Configurations": [[739, "pythonic-api-for-user-configurations"], [739, "id1"]], "Pythonic API for Framework Configurations": [[739, "pythonic-api-for-framework-configurations"], [739, "id2"]], "Get Started with Pythonic API for Configurations": [[739, "get-started-with-pythonic-api-for-configurations"]], "NAS": [[739, "nas"]], "Quantization Introduction": [[740, "quantization-introduction"]], "Quantization Fundamentals": [[740, "quantization-fundamentals"], [746, "quantization-fundamentals"]], "Quantization Support Matrix": [[740, "quantization-support-matrix"]], "Quantization Scheme in TensorFlow": [[740, "quantization-scheme-in-tensorflow"]], "Quantization Scheme in PyTorch": [[740, "quantization-scheme-in-pytorch"]], "Quantization Scheme in IPEX": [[740, "quantization-scheme-in-ipex"]], "Quantization Scheme in MXNet": [[740, "quantization-scheme-in-mxnet"]], "Quantization Scheme in ONNX Runtime": [[740, "quantization-scheme-in-onnx-runtime"]], "Quantization Approaches": [[740, "quantization-approaches"]], "With or Without Accuracy Aware Tuning": [[740, "with-or-without-accuracy-aware-tuning"]], "Post Training Quantization": [[740, "post-training-quantization"]], "Specify Quantization Rules": [[740, "specify-quantization-rules"]], "Specify Quantization Recipes": [[740, "specify-quantization-recipes"]], "Specify Quantization Backend and Device": [[740, "specify-quantization-backend-and-device"]], "Layer Wise Quantization (LWQ)": [[741, "layer-wise-quantization-lwq"]], "PyTorch framework example": [[741, "pytorch-framework-example"]], "ONNX Runtime framework example": [[741, "onnx-runtime-framework-example"]], "Turn OFF Auto Mixed Precision during Quantization": [[742, "turn-off-auto-mixed-precision-during-quantization"]], "Tensorflow": [[742, "tensorflow"]], "Weight Only Quantization (WOQ)": [[743, "weight-only-quantization-woq"]], "Quantization Capability": [[743, "quantization-capability"]], "Export Compressed Model": [[743, "export-compressed-model"]], "User Code Example": [[743, "user-code-example"]], "WOQ Algorithms Tuning": [[743, "woq-algorithms-tuning"]], "User code example": [[743, "id1"]], "Release": [[744, "release"]], "Release Notes": [[744, "release-notes"]], "Known Issues": [[744, "known-issues"]], "Incompatible Changes": [[744, "incompatible-changes"]], "SigOpt Strategy": [[745, "sigopt-strategy"]], "SigOpt Platform": [[745, "sigopt-platform"]], "Neural Compressor Configuration": [[745, "neural-compressor-configuration"]], "Performance": [[745, "performance"]], "Benefit of SigOpt Strategy": [[745, "benefit-of-sigopt-strategy"]], "Performance Comparison of Different Strategies": [[745, "performance-comparison-of-different-strategies"]], "Smooth Quant": [[746, "smooth-quant"]], "Per-tensor & Per-channel": [[746, "per-tensor-per-channel"]], "Per-tensor example": [[746, "per-tensor-example"]], "Per-channel example": [[746, "per-channel-example"]], "Matmul quantization example": [[746, "matmul-quantization-example"]], "Per-channel limitation": [[746, "per-channel-limitation"]], "SmoothQuant and Our Enhancement": [[746, "smoothquant-and-our-enhancement"]], "SmoothQuant": [[746, "smoothquant"]], "Our enhancement:": [[746, "our-enhancement"]], "Algorithm: Auto-tuning of $\\alpha$.": [[746, "algorithm-auto-tuning-of-alpha"]], "Engineering": [[746, "engineering"]], "Using a fixed alpha": [[746, "using-a-fixed-alpha"]], "Determining the alpha through auto-tuning": [[746, "determining-the-alpha-through-auto-tuning"]], "Auto-tune the alpha for the entire model": [[746, "auto-tune-the-alpha-for-the-entire-model"]], "Auto-tune the alpha for each layer/block": [[746, "auto-tune-the-alpha-for-each-layer-block"]], "Supported Framework Matrix": [[746, "supported-framework-matrix"]], "TensorBoard": [[747, "tensorboard"]], "Get Started with TensorBoard": [[747, "get-started-with-tensorboard"]], "PyTorch TensorBoard": [[747, "pytorch-tensorboard"]], "TensorFlow Tensorboard": [[747, "tensorflow-tensorboard"]], "PyTorch Examples": [[747, "pytorch-examples"]], "TensorFlow Examples": [[747, "tensorflow-examples"]], "Transform": [[748, "transform"]], "Transform Support List": [[748, "transform-support-list"]], "Pytorch": [[748, "pytorch"]], "Tuning Strategies": [[749, "tuning-strategies"]], "Strategy Design": [[749, "strategy-design"]], "Tuning Space": [[749, "tuning-space"]], "Exit Policy": [[749, "exit-policy"]], "Accuracy Criteria": [[749, "accuracy-criteria"]], "Tuning Process": [[749, "tuning-process"]], "Tuning Algorithms": [[749, "tuning-algorithms"]], "Auto": [[749, "auto"]], "Conservative Tuning": [[749, "conservative-tuning"]], "Basic": [[749, "basic"]], "MSE": [[749, "mse"]], "MSE_V2": [[749, "mse-v2"]], "HAWQ_V2": [[749, "hawq-v2"]], "Bayesian": [[749, "bayesian"]], "Exhaustive": [[749, "exhaustive"]], "Random": [[749, "random"]], "SigOpt": [[749, "sigopt"]], "TPE": [[749, "tpe"]], "Distributed Tuning": [[749, "distributed-tuning"]], "Customize a New Tuning Strategy": [[749, "customize-a-new-tuning-strategy"]], "User Guide": [[750, "user-guide"]], "Python-based APIs": [[750, "python-based-apis"]], "Neural Coder (Zero-code Optimization)": [[750, "neural-coder-zero-code-optimization"]], "Advanced Topics": [[750, "advanced-topics"]], "Innovations for Productivity": [[750, "innovations-for-productivity"]], "User YAML Configuration Files": [[751, "user-yaml-configuration-files"]], "Get started with User YAML Files": [[751, "get-started-with-user-yaml-files"]], "Validated Quantization Examples": [[752, "validated-quantization-examples"]], "TensorFlow Models with TensorFlow 2.15.0": [[752, "tensorflow-models-with-tensorflow-2-15-0"]], "PyTorch Models with Torch 2.2.1+cpu in PTQ Mode": [[752, "pytorch-models-with-torch-2-2-1-cpu-in-ptq-mode"]], "PyTorch Models with Torch 2.2.1+cpu in QAT Mode": [[752, "pytorch-models-with-torch-2-2-1-cpu-in-qat-mode"]], "PyTorch Models with Torch 2.0.1+cpu in WOQ Mode": [[752, "pytorch-models-with-torch-2-0-1-cpu-in-woq-mode"]], "ONNX Models with ONNX Runtime 1.17.1": [[752, "onnx-models-with-onnx-runtime-1-17-1"]], "ONNX Models with ONNX Runtime 1.15.0 in WOQ Mode": [[752, "onnx-models-with-onnx-runtime-1-15-0-in-woq-mode"]], "Validated Pruning Examples": [[752, "validated-pruning-examples"]], "Validated Knowledge Distillation Examples": [[752, "validated-knowledge-distillation-examples"]], "Validated ONNX QDQ INT8 Models on Multiple Hardware through ONNX Runtime": [[752, "validated-onnx-qdq-int8-models-on-multiple-hardware-through-onnx-runtime"]]}, "indexentries": {"block_mask": [[0, "module-block_mask"]], "module": [[0, "module-block_mask"], [1, "module-neural_compressor.adaptor.adaptor"], [2, "module-neural_compressor.adaptor"], [3, "module-neural_compressor.adaptor.keras"], [4, "module-neural_compressor.adaptor.keras_utils.conv2d"], [5, "module-neural_compressor.adaptor.keras_utils.dense"], [6, "module-neural_compressor.adaptor.keras_utils.depthwise_conv2d"], [7, "module-neural_compressor.adaptor.keras_utils"], [8, "module-neural_compressor.adaptor.keras_utils.pool2d"], [9, "module-neural_compressor.adaptor.keras_utils.quantizer"], [10, "module-neural_compressor.adaptor.keras_utils.separable_conv2d"], [11, "module-neural_compressor.adaptor.mxnet"], [12, "module-neural_compressor.adaptor.mxnet_utils"], [13, "module-neural_compressor.adaptor.mxnet_utils.util"], [14, "module-neural_compressor.adaptor.onnxrt"], [15, "module-neural_compressor.adaptor.ox_utils.calibration"], [16, "module-neural_compressor.adaptor.ox_utils.calibrator"], [17, "module-neural_compressor.adaptor.ox_utils"], [18, "module-neural_compressor.adaptor.ox_utils.operators.activation"], [19, "module-neural_compressor.adaptor.ox_utils.operators.argmax"], [20, "module-neural_compressor.adaptor.ox_utils.operators.attention"], [21, "module-neural_compressor.adaptor.ox_utils.operators.binary_op"], [22, "module-neural_compressor.adaptor.ox_utils.operators.concat"], [23, "module-neural_compressor.adaptor.ox_utils.operators.conv"], [24, "module-neural_compressor.adaptor.ox_utils.operators.direct_q8"], [25, "module-neural_compressor.adaptor.ox_utils.operators.embed_layernorm"], [26, "module-neural_compressor.adaptor.ox_utils.operators.gather"], [27, "module-neural_compressor.adaptor.ox_utils.operators.gavgpool"], [28, "module-neural_compressor.adaptor.ox_utils.operators.gemm"], [29, "module-neural_compressor.adaptor.ox_utils.operators"], [30, "module-neural_compressor.adaptor.ox_utils.operators.lstm"], [31, "module-neural_compressor.adaptor.ox_utils.operators.matmul"], [32, "module-neural_compressor.adaptor.ox_utils.operators.maxpool"], [33, "module-neural_compressor.adaptor.ox_utils.operators.norm"], [34, "module-neural_compressor.adaptor.ox_utils.operators.ops"], [35, "module-neural_compressor.adaptor.ox_utils.operators.pad"], [36, "module-neural_compressor.adaptor.ox_utils.operators.pooling"], [37, "module-neural_compressor.adaptor.ox_utils.operators.reduce"], [38, "module-neural_compressor.adaptor.ox_utils.operators.resize"], [39, "module-neural_compressor.adaptor.ox_utils.operators.split"], [40, "module-neural_compressor.adaptor.ox_utils.operators.unary_op"], [41, "module-neural_compressor.adaptor.ox_utils.quantizer"], [42, "module-neural_compressor.adaptor.ox_utils.smooth_quant"], [43, "module-neural_compressor.adaptor.ox_utils.util"], [44, "module-neural_compressor.adaptor.ox_utils.weight_only"], [45, "module-neural_compressor.adaptor.pytorch"], [46, "module-neural_compressor.adaptor.query"], [47, "module-neural_compressor.adaptor.tensorflow"], [48, "module-neural_compressor.adaptor.tf_utils.graph_converter"], [49, "module-neural_compressor.adaptor.tf_utils.graph_converter_without_calib"], [50, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert"], [51, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer"], [52, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16"], [53, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd"], [54, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout"], [55, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu"], [56, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random"], [57, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const"], [58, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction"], [59, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd"], [60, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer"], [61, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape"], [62, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm"], [63, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant"], [64, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add"], [65, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul"], [66, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math"], [67, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn"], [68, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in"], [69, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu"], [70, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm"], [71, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv"], [72, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"], [73, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose"], [74, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer"], [75, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass"], [76, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic"], [77, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node"], [78, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu"], [79, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize"], [80, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes"], [81, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm"], [82, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input"], [83, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes"], [84, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes"], [85, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer"], [86, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base"], [87, "module-neural_compressor.adaptor.tf_utils.graph_rewriter"], [88, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant"], [89, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value"], [90, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib"], [91, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"], [92, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize"], [93, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"], [94, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize"], [95, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8"], [96, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer"], [97, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter"], [98, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse"], [99, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert"], [100, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation"], [101, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx"], [102, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph"], [103, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node"], [104, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema"], [105, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils"], [106, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq"], [107, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern"], [108, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq"], [109, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern"], [110, "module-neural_compressor.adaptor.tf_utils.graph_util"], [111, "module-neural_compressor.adaptor.tf_utils"], [112, "module-neural_compressor.adaptor.tf_utils.quantize_graph"], [113, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize"], [114, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat"], [115, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config"], [116, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper"], [117, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers"], [118, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer"], [119, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add"], [120, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base"], [121, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"], [122, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper"], [123, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn"], [124, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2"], [125, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv"], [126, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv"], [127, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in"], [128, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul"], [129, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling"], [130, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq"], [131, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq"], [132, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base"], [133, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn"], [134, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2"], [135, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv"], [136, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu"], [137, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul"], [138, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling"], [139, "module-neural_compressor.adaptor.tf_utils.quantize_graph_common"], [140, "module-neural_compressor.adaptor.tf_utils.smooth_quant_calibration"], [141, "module-neural_compressor.adaptor.tf_utils.smooth_quant_scaler"], [142, "module-neural_compressor.adaptor.tf_utils.tf2onnx_converter"], [143, "module-neural_compressor.adaptor.tf_utils.transform_graph.bias_correction"], [144, "module-neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base"], [145, "module-neural_compressor.adaptor.tf_utils.transform_graph"], [146, "module-neural_compressor.adaptor.tf_utils.transform_graph.insert_logging"], [147, "module-neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat"], [148, "module-neural_compressor.adaptor.tf_utils.util"], [149, "module-neural_compressor.adaptor.torch_utils.auto_round"], [150, "module-neural_compressor.adaptor.torch_utils.awq"], [151, "module-neural_compressor.adaptor.torch_utils.bf16_convert"], [152, "module-neural_compressor.adaptor.torch_utils.gptq"], [153, "module-neural_compressor.adaptor.torch_utils.hawq_metric"], [154, "module-neural_compressor.adaptor.torch_utils"], [155, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant"], [156, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle"], [157, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize"], [158, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load"], [159, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.utils"], [160, "module-neural_compressor.adaptor.torch_utils.mixed_precision"], [161, "module-neural_compressor.adaptor.torch_utils.model_wrapper"], [162, "module-neural_compressor.adaptor.torch_utils.pattern_detector"], [163, "module-neural_compressor.adaptor.torch_utils.symbolic_trace"], [164, "module-neural_compressor.adaptor.torch_utils.teq"], [165, "module-neural_compressor.adaptor.torch_utils.util"], [166, "module-neural_compressor.adaptor.torch_utils.waq.auto_alpha"], [167, "module-neural_compressor.adaptor.torch_utils.waq.calibration"], [168, "module-neural_compressor.adaptor.torch_utils.waq.graph_trace"], [169, "module-neural_compressor.adaptor.torch_utils.waq"], [170, "module-neural_compressor.adaptor.torch_utils.waq.smooth_quant"], [171, "module-neural_compressor.adaptor.torch_utils.waq.utils"], [172, "module-neural_compressor.adaptor.torch_utils.weight_only"], [173, "module-neural_compressor.algorithm.algorithm"], [174, "module-neural_compressor.algorithm.fast_bias_correction"], [175, "module-neural_compressor.algorithm"], [176, "module-neural_compressor.algorithm.smooth_quant"], [177, "module-neural_compressor.algorithm.weight_correction"], [178, "module-neural_compressor.benchmark"], [179, "module-neural_compressor.common.base_config"], [180, "module-neural_compressor.common.base_tuning"], [181, "module-neural_compressor.common"], [182, "module-neural_compressor.common.tuning_param"], [183, "module-neural_compressor.common.utils.constants"], [184, "module-neural_compressor.common.utils"], [185, "module-neural_compressor.common.utils.logger"], [186, "module-neural_compressor.common.utils.save_load"], [187, "module-neural_compressor.common.utils.utility"], [188, "module-neural_compressor.compression.callbacks"], [189, "module-neural_compressor.compression.distillation.criterions"], [190, "module-neural_compressor.compression.distillation"], [191, "module-neural_compressor.compression.distillation.optimizers"], [192, "module-neural_compressor.compression.distillation.utility"], [193, "module-neural_compressor.compression.hpo"], [194, "module-neural_compressor.compression.hpo.sa_optimizer"], [195, "module-neural_compressor.compression.hpo.search_algorithms"], [196, "module-neural_compressor.compression.hpo.search_space"], [197, "module-neural_compressor.compression"], [198, "module-neural_compressor.compression.pruner.criteria"], [199, "module-neural_compressor.compression.pruner.dsnot"], [200, "module-neural_compressor.compression.pruner"], [201, "module-neural_compressor.compression.pruner.model_slim.auto_slim"], [202, "module-neural_compressor.compression.pruner.model_slim"], [203, "module-neural_compressor.compression.pruner.model_slim.pattern_analyzer"], [204, "module-neural_compressor.compression.pruner.model_slim.weight_slim"], [205, "module-neural_compressor.compression.pruner.patterns.base"], [206, "module-neural_compressor.compression.pruner.patterns"], [207, "module-neural_compressor.compression.pruner.patterns.mha"], [208, "module-neural_compressor.compression.pruner.patterns.ninm"], [209, "module-neural_compressor.compression.pruner.patterns.nxm"], [210, "module-neural_compressor.compression.pruner.pruners.base"], [211, "module-neural_compressor.compression.pruner.pruners.basic"], [212, "module-neural_compressor.compression.pruner.pruners.block_mask"], [213, "module-neural_compressor.compression.pruner.pruners"], [214, "module-neural_compressor.compression.pruner.pruners.mha"], [215, "module-neural_compressor.compression.pruner.pruners.pattern_lock"], [216, "module-neural_compressor.compression.pruner.pruners.progressive"], [217, "module-neural_compressor.compression.pruner.pruners.retrain_free"], [218, "module-neural_compressor.compression.pruner.pruners.sparse_gpt"], [219, "module-neural_compressor.compression.pruner.pruning"], [220, "module-neural_compressor.compression.pruner.regs"], [221, "module-neural_compressor.compression.pruner.schedulers"], [222, "module-neural_compressor.compression.pruner.tf_criteria"], [223, "module-neural_compressor.compression.pruner.utils"], [224, "module-neural_compressor.compression.pruner.wanda"], [225, "module-neural_compressor.compression.pruner.wanda.prune"], [226, "module-neural_compressor.compression.pruner.wanda.utils"], [227, "module-neural_compressor.compression.pruner.wanda.wrapper"], [228, "module-neural_compressor.conf.config"], [229, "module-neural_compressor.conf.dotdict"], [230, "module-neural_compressor.conf"], [231, "module-neural_compressor.conf.pythonic_config"], [232, "module-neural_compressor.config"], [233, "module-neural_compressor.contrib"], [234, "module-neural_compressor.contrib.strategy"], [235, "module-neural_compressor.contrib.strategy.sigopt"], [236, "module-neural_compressor.contrib.strategy.tpe"], [237, "module-neural_compressor.data.dataloaders.base_dataloader"], [238, "module-neural_compressor.data.dataloaders.dataloader"], [239, "module-neural_compressor.data.dataloaders.default_dataloader"], [240, "module-neural_compressor.data.dataloaders.fetcher"], [241, "module-neural_compressor.data.dataloaders"], [242, "module-neural_compressor.data.dataloaders.mxnet_dataloader"], [243, "module-neural_compressor.data.dataloaders.onnxrt_dataloader"], [244, "module-neural_compressor.data.dataloaders.pytorch_dataloader"], [245, "module-neural_compressor.data.dataloaders.sampler"], [246, "module-neural_compressor.data.dataloaders.tensorflow_dataloader"], [247, "module-neural_compressor.data.datasets.bert_dataset"], [248, "module-neural_compressor.data.datasets.coco_dataset"], [249, "module-neural_compressor.data.datasets.dataset"], [250, "module-neural_compressor.data.datasets.dummy_dataset"], [251, "module-neural_compressor.data.datasets.dummy_dataset_v2"], [252, "module-neural_compressor.data.datasets.imagenet_dataset"], [253, "module-neural_compressor.data.datasets"], [254, "module-neural_compressor.data.datasets.style_transfer_dataset"], [255, "module-neural_compressor.data.filters.coco_filter"], [256, "module-neural_compressor.data.filters.filter"], [257, "module-neural_compressor.data.filters"], [258, "module-neural_compressor.data"], [259, "module-neural_compressor.data.transforms.coco_transform"], [260, "module-neural_compressor.data.transforms.imagenet_transform"], [261, "module-neural_compressor.data.transforms"], [262, "module-neural_compressor.data.transforms.postprocess"], [263, "module-neural_compressor.data.transforms.tokenization"], [264, "module-neural_compressor.data.transforms.transform"], [265, "module-neural_compressor.experimental.benchmark"], [266, "module-neural_compressor.experimental.common.criterion"], [267, "module-neural_compressor.experimental.common.dataloader"], [268, "module-neural_compressor.experimental.common"], [269, "module-neural_compressor.experimental.common.metric"], [270, "module-neural_compressor.experimental.common.model"], [271, "module-neural_compressor.experimental.common.optimizer"], [272, "module-neural_compressor.experimental.common.postprocess"], [273, "module-neural_compressor.experimental.common.torch_utils"], [274, "module-neural_compressor.experimental.component"], [275, "module-neural_compressor.experimental.compression"], [276, "module-neural_compressor.experimental.contrib"], [277, "module-neural_compressor.experimental.contrib.strategy"], [278, "module-neural_compressor.experimental.contrib.strategy.sigopt"], [279, "module-neural_compressor.experimental.contrib.strategy.tpe"], [280, "module-neural_compressor.experimental.data.dataloaders.base_dataloader"], [281, "module-neural_compressor.experimental.data.dataloaders.dataloader"], [282, "module-neural_compressor.experimental.data.dataloaders.default_dataloader"], [283, "module-neural_compressor.experimental.data.dataloaders.fetcher"], [284, "module-neural_compressor.experimental.data.dataloaders"], [285, "module-neural_compressor.experimental.data.dataloaders.mxnet_dataloader"], [286, "module-neural_compressor.experimental.data.dataloaders.onnxrt_dataloader"], [287, "module-neural_compressor.experimental.data.dataloaders.pytorch_dataloader"], [288, "module-neural_compressor.experimental.data.dataloaders.sampler"], [289, "module-neural_compressor.experimental.data.dataloaders.tensorflow_dataloader"], [290, "module-neural_compressor.experimental.data.datasets.bert_dataset"], [291, "module-neural_compressor.experimental.data.datasets.coco_dataset"], [292, "module-neural_compressor.experimental.data.datasets.dataset"], [293, "module-neural_compressor.experimental.data.datasets.dummy_dataset"], [294, "module-neural_compressor.experimental.data.datasets.dummy_dataset_v2"], [295, "module-neural_compressor.experimental.data.datasets.imagenet_dataset"], [296, "module-neural_compressor.experimental.data.datasets"], [297, "module-neural_compressor.experimental.data.datasets.style_transfer_dataset"], [298, "module-neural_compressor.experimental.data.filters.coco_filter"], [299, "module-neural_compressor.experimental.data.filters.filter"], [300, "module-neural_compressor.experimental.data.filters"], [301, "module-neural_compressor.experimental.data"], [302, "module-neural_compressor.experimental.data.transforms.imagenet_transform"], [303, "module-neural_compressor.experimental.data.transforms"], [304, "module-neural_compressor.experimental.data.transforms.tokenization"], [305, "module-neural_compressor.experimental.data.transforms.transform"], [306, "module-neural_compressor.experimental.distillation"], [307, "module-neural_compressor.experimental.export"], [308, "module-neural_compressor.experimental.export.qlinear2qdq"], [309, "module-neural_compressor.experimental.export.tf2onnx"], [310, "module-neural_compressor.experimental.export.torch2onnx"], [311, "module-neural_compressor.experimental.graph_optimization"], [312, "module-neural_compressor.experimental"], [313, "module-neural_compressor.experimental.metric.bleu"], [314, "module-neural_compressor.experimental.metric.bleu_util"], [315, "module-neural_compressor.experimental.metric.coco_label_map"], [316, "module-neural_compressor.experimental.metric.coco_tools"], [317, "module-neural_compressor.experimental.metric.evaluate_squad"], [318, "module-neural_compressor.experimental.metric.f1"], [319, "module-neural_compressor.experimental.metric"], [320, "module-neural_compressor.experimental.metric.metric"], [321, "module-neural_compressor.experimental.mixed_precision"], [322, "module-neural_compressor.experimental.model_conversion"], [323, "module-neural_compressor.experimental.nas.basic_nas"], [324, "module-neural_compressor.experimental.nas.dynas"], [325, "module-neural_compressor.experimental.nas"], [326, "module-neural_compressor.experimental.nas.nas"], [327, "module-neural_compressor.experimental.nas.nas_utils"], [328, "module-neural_compressor.experimental.nas.search_algorithms"], [329, "module-neural_compressor.experimental.pruner_legacy.gradient_sensitivity"], [330, "module-neural_compressor.experimental.pruner_legacy.group_lasso"], [331, "module-neural_compressor.experimental.pruner_legacy"], [332, "module-neural_compressor.experimental.pruner_legacy.magnitude"], [333, "module-neural_compressor.experimental.pruner_legacy.pattern_lock"], [334, "module-neural_compressor.experimental.pruner_legacy.pruner"], [335, "module-neural_compressor.experimental.pruning"], [336, "module-neural_compressor.experimental.pruning_recipes"], [337, "module-neural_compressor.experimental.pruning_recipes.patterns"], [338, "module-neural_compressor.experimental.pruning_recipes.patterns.pattern"], [339, "module-neural_compressor.experimental.pruning_recipes.patterns.tile_pattern"], [340, "module-neural_compressor.experimental.pruning_v2"], [341, "module-neural_compressor.experimental.pytorch_pruner"], [342, "module-neural_compressor.experimental.pytorch_pruner.logger"], [343, "module-neural_compressor.experimental.pytorch_pruner.patterns"], [344, "module-neural_compressor.experimental.pytorch_pruner.prune_utils"], [345, "module-neural_compressor.experimental.pytorch_pruner.pruner"], [346, "module-neural_compressor.experimental.pytorch_pruner.pruning"], [347, "module-neural_compressor.experimental.pytorch_pruner.scheduler"], [348, "module-neural_compressor.experimental.quantization"], [349, "module-neural_compressor.experimental.scheduler"], [350, "module-neural_compressor.experimental.strategy.auto_mixed_precision"], [351, "module-neural_compressor.experimental.strategy.basic"], [352, "module-neural_compressor.experimental.strategy.bayesian"], [353, "module-neural_compressor.experimental.strategy.exhaustive"], [354, "module-neural_compressor.experimental.strategy"], [355, "module-neural_compressor.experimental.strategy.mse"], [356, "module-neural_compressor.experimental.strategy.mse_v2"], [357, "module-neural_compressor.experimental.strategy.random"], [358, "module-neural_compressor.experimental.strategy.strategy"], [359, "module-neural_compressor.experimental.strategy.utils.constant"], [360, "module-neural_compressor.experimental.strategy.utils"], [361, "module-neural_compressor.experimental.strategy.utils.tuning_sampler"], [362, "module-neural_compressor.experimental.strategy.utils.tuning_space"], [363, "module-neural_compressor.experimental.strategy.utils.tuning_structs"], [364, "module-neural_compressor.experimental.strategy.utils.utility"], [365, "module-neural_compressor"], [366, "module-neural_compressor.metric.bleu"], [367, "module-neural_compressor.metric.bleu_util"], [368, "module-neural_compressor.metric.coco_label_map"], [369, "module-neural_compressor.metric.coco_tools"], [370, "module-neural_compressor.metric.evaluate_squad"], [371, "module-neural_compressor.metric.f1"], [372, "module-neural_compressor.metric"], [373, "module-neural_compressor.metric.metric"], [374, "module-neural_compressor.mix_precision"], [375, "module-neural_compressor.model.base_model"], [376, "module-neural_compressor.model"], [377, "module-neural_compressor.model.keras_model"], [378, "module-neural_compressor.model.model"], [379, "module-neural_compressor.model.mxnet_model"], [380, "module-neural_compressor.model.nets_factory"], [381, "module-neural_compressor.model.onnx_model"], [382, "module-neural_compressor.model.tensorflow_model"], [383, "module-neural_compressor.model.torch_model"], [384, "module-neural_compressor.objective"], [385, "module-neural_compressor.onnxrt.algorithms"], [386, "module-neural_compressor.onnxrt.algorithms.layer_wise.core"], [387, "module-neural_compressor.onnxrt.algorithms.layer_wise"], [388, "module-neural_compressor.onnxrt.algorithms.smoother.calibrator"], [389, "module-neural_compressor.onnxrt.algorithms.smoother.core"], [390, "module-neural_compressor.onnxrt.algorithms.smoother"], [391, "module-neural_compressor.onnxrt.algorithms.weight_only.awq"], [392, "module-neural_compressor.onnxrt.algorithms.weight_only.gptq"], [393, "module-neural_compressor.onnxrt.algorithms.weight_only"], [394, "module-neural_compressor.onnxrt.algorithms.weight_only.rtn"], [395, "module-neural_compressor.onnxrt.algorithms.weight_only.utility"], [396, "module-neural_compressor.onnxrt"], [397, "module-neural_compressor.onnxrt.quantization.algorithm_entry"], [398, "module-neural_compressor.onnxrt.quantization.autotune"], [399, "module-neural_compressor.onnxrt.quantization.calibrate"], [400, "module-neural_compressor.onnxrt.quantization.config"], [401, "module-neural_compressor.onnxrt.quantization"], [402, "module-neural_compressor.onnxrt.quantization.quantize"], [403, "module-neural_compressor.onnxrt.utils"], [404, "module-neural_compressor.onnxrt.utils.onnx_model"], [405, "module-neural_compressor.onnxrt.utils.utility"], [406, "module-neural_compressor.profiling"], [407, "module-neural_compressor.profiling.parser.factory"], [408, "module-neural_compressor.profiling.parser"], [409, "module-neural_compressor.profiling.parser.onnx_parser.factory"], [410, "module-neural_compressor.profiling.parser.onnx_parser"], [411, "module-neural_compressor.profiling.parser.onnx_parser.parser"], [412, "module-neural_compressor.profiling.parser.parser"], [413, "module-neural_compressor.profiling.parser.result"], [414, "module-neural_compressor.profiling.parser.tensorflow_parser.factory"], [415, "module-neural_compressor.profiling.parser.tensorflow_parser"], [416, "module-neural_compressor.profiling.parser.tensorflow_parser.parser"], [417, "module-neural_compressor.profiling.profiler.factory"], [418, "module-neural_compressor.profiling.profiler"], [419, "module-neural_compressor.profiling.profiler.onnxrt_profiler.factory"], [420, "module-neural_compressor.profiling.profiler.onnxrt_profiler"], [421, "module-neural_compressor.profiling.profiler.onnxrt_profiler.profiler"], [422, "module-neural_compressor.profiling.profiler.onnxrt_profiler.utils"], [423, "module-neural_compressor.profiling.profiler.profiler"], [424, "module-neural_compressor.profiling.profiler.tensorflow_profiler.factory"], [425, "module-neural_compressor.profiling.profiler.tensorflow_profiler"], [426, "module-neural_compressor.profiling.profiler.tensorflow_profiler.profiler"], [427, "module-neural_compressor.profiling.profiler.tensorflow_profiler.utils"], [428, "module-neural_compressor.quantization"], [429, "module-neural_compressor.strategy.auto"], [430, "module-neural_compressor.strategy.auto_mixed_precision"], [431, "module-neural_compressor.strategy.basic"], [432, "module-neural_compressor.strategy.bayesian"], [433, "module-neural_compressor.strategy.conservative"], [434, "module-neural_compressor.strategy.exhaustive"], [435, "module-neural_compressor.strategy.hawq_v2"], [436, "module-neural_compressor.strategy"], [437, "module-neural_compressor.strategy.mse"], [438, "module-neural_compressor.strategy.mse_v2"], [439, "module-neural_compressor.strategy.random"], [440, "module-neural_compressor.strategy.strategy"], [441, "module-neural_compressor.strategy.utils.constant"], [442, "module-neural_compressor.strategy.utils"], [443, "module-neural_compressor.strategy.utils.tuning_sampler"], [444, "module-neural_compressor.strategy.utils.tuning_space"], [445, "module-neural_compressor.strategy.utils.tuning_structs"], [446, "module-neural_compressor.strategy.utils.utility"], [447, "module-neural_compressor.template.api_doc_example"], [448, "module-neural_compressor.template"], [449, "module-neural_compressor.tensorflow.algorithms"], [450, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"], [451, "module-neural_compressor.tensorflow.algorithms.smoother.core"], [452, "module-neural_compressor.tensorflow.algorithms.smoother"], [453, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"], [454, "module-neural_compressor.tensorflow.algorithms.static_quant"], [455, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"], [456, "module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow"], [457, "module-neural_compressor.tensorflow"], [458, "module-neural_compressor.tensorflow.keras"], [459, "module-neural_compressor.tensorflow.keras.layers.conv2d"], [460, "module-neural_compressor.tensorflow.keras.layers.dense"], [461, "module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d"], [462, "module-neural_compressor.tensorflow.keras.layers"], [463, "module-neural_compressor.tensorflow.keras.layers.layer_initializer"], [464, "module-neural_compressor.tensorflow.keras.layers.pool2d"], [465, "module-neural_compressor.tensorflow.keras.layers.separable_conv2d"], [466, "module-neural_compressor.tensorflow.keras.quantization.config"], [467, "module-neural_compressor.tensorflow.keras.quantization"], [468, "module-neural_compressor.tensorflow.quantization.algorithm_entry"], [469, "module-neural_compressor.tensorflow.quantization.autotune"], [470, "module-neural_compressor.tensorflow.quantization.config"], [471, "module-neural_compressor.tensorflow.quantization"], [472, "module-neural_compressor.tensorflow.quantization.quantize"], [473, "module-neural_compressor.tensorflow.quantization.utils.graph_converter"], [474, "module-neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib"], [475, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert"], [476, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer"], [477, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16"], [478, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"], [479, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"], [480, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"], [481, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"], [482, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"], [483, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"], [484, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"], [485, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"], [486, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"], [487, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"], [488, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"], [489, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"], [490, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"], [491, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"], [492, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"], [493, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"], [494, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"], [495, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"], [496, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"], [497, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"], [498, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"], [499, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"], [500, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"], [501, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"], [502, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"], [503, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"], [504, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"], [505, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"], [506, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"], [507, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"], [508, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"], [509, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"], [510, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"], [511, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"], [512, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"], [513, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant"], [514, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value"], [515, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib"], [516, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"], [517, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize"], [518, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"], [519, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize"], [520, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8"], [521, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer"], [522, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter"], [523, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse"], [524, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert"], [525, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation"], [526, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq"], [527, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern"], [528, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq"], [529, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern"], [530, "module-neural_compressor.tensorflow.quantization.utils.graph_util"], [531, "module-neural_compressor.tensorflow.quantization.utils"], [532, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph"], [533, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize"], [534, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat"], [535, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config"], [536, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper"], [537, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers"], [538, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer"], [539, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add"], [540, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base"], [541, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"], [542, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper"], [543, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn"], [544, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2"], [545, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv"], [546, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv"], [547, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in"], [548, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul"], [549, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling"], [550, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq"], [551, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq"], [552, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base"], [553, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn"], [554, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2"], [555, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv"], [556, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu"], [557, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul"], [558, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling"], [559, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"], [560, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction"], [561, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base"], [562, "module-neural_compressor.tensorflow.quantization.utils.transform_graph"], [563, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging"], [564, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat"], [565, "module-neural_compressor.tensorflow.quantization.utils.utility"], [566, "module-neural_compressor.tensorflow.utils.constants"], [567, "module-neural_compressor.tensorflow.utils.data"], [568, "module-neural_compressor.tensorflow.utils"], [569, "module-neural_compressor.tensorflow.utils.model"], [570, "module-neural_compressor.tensorflow.utils.model_wrappers"], [571, "module-neural_compressor.tensorflow.utils.nets_factory"], [572, "module-neural_compressor.tensorflow.utils.utility"], [573, "module-neural_compressor.torch.algorithms.base_algorithm"], [574, "module-neural_compressor.torch.algorithms.habana_fp8.fp8_quant"], [575, "module-neural_compressor.torch.algorithms.habana_fp8"], [576, "module-neural_compressor.torch.algorithms.habana_fp8.modules"], [577, "module-neural_compressor.torch.algorithms.habana_fp8.observer"], [578, "module-neural_compressor.torch.algorithms.habana_fp8.save_load"], [579, "module-neural_compressor.torch.algorithms.habana_fp8.scale"], [580, "module-neural_compressor.torch.algorithms.habana_fp8.tensor"], [581, "module-neural_compressor.torch.algorithms"], [582, "module-neural_compressor.torch.algorithms.layer_wise"], [583, "module-neural_compressor.torch.algorithms.layer_wise.load"], [584, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"], [585, "module-neural_compressor.torch.algorithms.layer_wise.utils"], [586, "module-neural_compressor.torch.algorithms.mix_precision.half_precision_convert"], [587, "module-neural_compressor.torch.algorithms.mix_precision"], [588, "module-neural_compressor.torch.algorithms.mix_precision.module_wrappers"], [589, "module-neural_compressor.torch.algorithms.mx_quant"], [590, "module-neural_compressor.torch.algorithms.mx_quant.mx"], [591, "module-neural_compressor.torch.algorithms.mx_quant.utils"], [592, "module-neural_compressor.torch.algorithms.pt2e_quant.core"], [593, "module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter"], [594, "module-neural_compressor.torch.algorithms.pt2e_quant"], [595, "module-neural_compressor.torch.algorithms.smooth_quant"], [596, "module-neural_compressor.torch.algorithms.smooth_quant.save_load"], [597, "module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant"], [598, "module-neural_compressor.torch.algorithms.smooth_quant.utility"], [599, "module-neural_compressor.torch.algorithms.static_quant"], [600, "module-neural_compressor.torch.algorithms.static_quant.save_load"], [601, "module-neural_compressor.torch.algorithms.static_quant.static_quant"], [602, "module-neural_compressor.torch.algorithms.static_quant.utility"], [603, "module-neural_compressor.torch.algorithms.weight_only.autoround"], [604, "module-neural_compressor.torch.algorithms.weight_only.awq"], [605, "module-neural_compressor.torch.algorithms.weight_only.gptq"], [606, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"], [607, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"], [608, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"], [609, "module-neural_compressor.torch.algorithms.weight_only.hqq"], [610, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"], [611, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"], [612, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"], [613, "module-neural_compressor.torch.algorithms.weight_only.hqq.utility"], [614, "module-neural_compressor.torch.algorithms.weight_only"], [615, "module-neural_compressor.torch.algorithms.weight_only.modules"], [616, "module-neural_compressor.torch.algorithms.weight_only.rtn"], [617, "module-neural_compressor.torch.algorithms.weight_only.save_load"], [618, "module-neural_compressor.torch.algorithms.weight_only.teq"], [619, "module-neural_compressor.torch.algorithms.weight_only.utility"], [620, "module-neural_compressor.torch.amp.autocast"], [621, "module-neural_compressor.torch.amp.fp8.functions"], [622, "module-neural_compressor.torch.amp.fp8"], [623, "module-neural_compressor.torch.amp"], [624, "module-neural_compressor.torch.export._export"], [625, "module-neural_compressor.torch.export"], [626, "module-neural_compressor.torch"], [627, "module-neural_compressor.torch.quantization.algorithm_entry"], [628, "module-neural_compressor.torch.quantization.autotune"], [629, "module-neural_compressor.torch.quantization.config"], [630, "module-neural_compressor.torch.quantization"], [631, "module-neural_compressor.torch.quantization.load_entry"], [632, "module-neural_compressor.torch.quantization.quantize"], [633, "module-neural_compressor.torch.utils.auto_accelerator"], [634, "module-neural_compressor.torch.utils.constants"], [635, "module-neural_compressor.torch.utils.environ"], [636, "module-neural_compressor.torch.utils"], [637, "module-neural_compressor.torch.utils.utility"], [638, "module-neural_compressor.training"], [639, "module-neural_compressor.utils.collect_layer_histogram"], [640, "module-neural_compressor.utils.constant"], [641, "module-neural_compressor.utils.create_obj_from_config"], [642, "module-neural_compressor.utils"], [643, "module-neural_compressor.utils.kl_divergence"], [644, "module-neural_compressor.utils.load_huggingface"], [645, "module-neural_compressor.utils.logger"], [646, "module-neural_compressor.utils.neural_insights_utils"], [647, "module-neural_compressor.utils.options"], [648, "module-neural_compressor.utils.pytorch"], [649, "module-neural_compressor.utils.utility"], [650, "module-neural_compressor.utils.weights_details"], [651, "module-neural_compressor.version"]], "adaptor (class in neural_compressor.adaptor.adaptor)": [[1, "neural_compressor.adaptor.adaptor.Adaptor"]], "adaptor_registry() (in module neural_compressor.adaptor.adaptor)": [[1, "neural_compressor.adaptor.adaptor.adaptor_registry"]], "neural_compressor.adaptor.adaptor": [[1, "module-neural_compressor.adaptor.adaptor"]], "neural_compressor.adaptor": [[2, "module-neural_compressor.adaptor"]], "kerasadaptor (class in neural_compressor.adaptor.keras)": [[3, "neural_compressor.adaptor.keras.KerasAdaptor"]], "neural_compressor.adaptor.keras": [[3, "module-neural_compressor.adaptor.keras"]], "neural_compressor.adaptor.keras_utils.conv2d": [[4, "module-neural_compressor.adaptor.keras_utils.conv2d"]], "neural_compressor.adaptor.keras_utils.dense": [[5, "module-neural_compressor.adaptor.keras_utils.dense"]], "neural_compressor.adaptor.keras_utils.depthwise_conv2d": [[6, "module-neural_compressor.adaptor.keras_utils.depthwise_conv2d"]], "neural_compressor.adaptor.keras_utils": [[7, "module-neural_compressor.adaptor.keras_utils"]], "neural_compressor.adaptor.keras_utils.pool2d": [[8, "module-neural_compressor.adaptor.keras_utils.pool2d"]], "neural_compressor.adaptor.keras_utils.quantizer": [[9, "module-neural_compressor.adaptor.keras_utils.quantizer"]], "neural_compressor.adaptor.keras_utils.separable_conv2d": [[10, "module-neural_compressor.adaptor.keras_utils.separable_conv2d"]], "mxnetadaptor (class in neural_compressor.adaptor.mxnet)": [[11, "neural_compressor.adaptor.mxnet.MxNetAdaptor"]], "neural_compressor.adaptor.mxnet": [[11, "module-neural_compressor.adaptor.mxnet"]], "neural_compressor.adaptor.mxnet_utils": [[12, "module-neural_compressor.adaptor.mxnet_utils"]], "calibcollector (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.CalibCollector"]], "calibdata (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.CalibData"]], "collectorbase (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.CollectorBase"]], "dataiterloader (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.DataIterLoader"]], "dataloaderwrap (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.DataLoaderWrap"]], "namecollector (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.NameCollector"]], "optype (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.OpType"]], "tensorcollector (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.TensorCollector"]], "amp_convert() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.amp_convert"]], "calib_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.calib_model"]], "check_mx_version() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.check_mx_version"]], "combine_capabilities() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.combine_capabilities"]], "create_data_example() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.create_data_example"]], "distribute_calib_tensors() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.distribute_calib_tensors"]], "ensure_list() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.ensure_list"]], "fuse() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.fuse"]], "get_framework_name() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.get_framework_name"]], "is_model_quantized() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.is_model_quantized"]], "isiterable() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.isiterable"]], "make_module() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.make_module"]], "make_nc_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.make_nc_model"]], "make_symbol_block() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.make_symbol_block"]], "ndarray_to_device() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.ndarray_to_device"]], "neural_compressor.adaptor.mxnet_utils.util": [[13, "module-neural_compressor.adaptor.mxnet_utils.util"]], "parse_tune_config() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.parse_tune_config"]], "prepare_dataloader() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.prepare_dataloader"]], "prepare_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.prepare_model"]], "prepare_model_data() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.prepare_model_data"]], "quantize_sym_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.quantize_sym_model"]], "query_quantizable_nodes() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.query_quantizable_nodes"]], "run_forward() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.run_forward"]], "onnxrt_integeropsadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor"]], "onnxrt_qdqadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor"]], "onnxrt_qlinearopsadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor"]], "onnxrt_weightonlyadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_WeightOnlyAdaptor"]], "onnxruntimeadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"]], "neural_compressor.adaptor.onnxrt": [[14, "module-neural_compressor.adaptor.onnxrt"]], "onnxrtaugment (class in neural_compressor.adaptor.ox_utils.calibration)": [[15, "neural_compressor.adaptor.ox_utils.calibration.ONNXRTAugment"]], "neural_compressor.adaptor.ox_utils.calibration": [[15, "module-neural_compressor.adaptor.ox_utils.calibration"]], "calibratorbase (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.CalibratorBase"]], "histogramcollector (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.HistogramCollector"]], "klcalibrator (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.KLCalibrator"]], "minmaxcalibrator (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.MinMaxCalibrator"]], "percentilecalibrator (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.PercentileCalibrator"]], "calib_registry() (in module neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.calib_registry"]], "neural_compressor.adaptor.ox_utils.calibrator": [[16, "module-neural_compressor.adaptor.ox_utils.calibrator"]], "smooth_distribution() (in module neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.smooth_distribution"]], "neural_compressor.adaptor.ox_utils": [[17, "module-neural_compressor.adaptor.ox_utils"]], "activationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.ActivationOperator"]], "float16activationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.Float16ActivationOperator"]], "qactivationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.QActivationOperator"]], "removableactivationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.RemovableActivationOperator"]], "neural_compressor.adaptor.ox_utils.operators.activation": [[18, "module-neural_compressor.adaptor.ox_utils.operators.activation"]], "argmaxoperator (class in neural_compressor.adaptor.ox_utils.operators.argmax)": [[19, "neural_compressor.adaptor.ox_utils.operators.argmax.ArgMaxOperator"]], "qargmaxoperator (class in neural_compressor.adaptor.ox_utils.operators.argmax)": [[19, "neural_compressor.adaptor.ox_utils.operators.argmax.QArgMaxOperator"]], "neural_compressor.adaptor.ox_utils.operators.argmax": [[19, "module-neural_compressor.adaptor.ox_utils.operators.argmax"]], "attentionoperator (class in neural_compressor.adaptor.ox_utils.operators.attention)": [[20, "neural_compressor.adaptor.ox_utils.operators.attention.AttentionOperator"]], "qattentionoperator (class in neural_compressor.adaptor.ox_utils.operators.attention)": [[20, "neural_compressor.adaptor.ox_utils.operators.attention.QAttentionOperator"]], "neural_compressor.adaptor.ox_utils.operators.attention": [[20, "module-neural_compressor.adaptor.ox_utils.operators.attention"]], "binarydirect8bitoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.BinaryDirect8BitOperator"]], "binaryoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.BinaryOperator"]], "float16binaryoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.Float16BinaryOperator"]], "qbinaryoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.QBinaryOperator"]], "neural_compressor.adaptor.ox_utils.operators.binary_op": [[21, "module-neural_compressor.adaptor.ox_utils.operators.binary_op"]], "concatoperator (class in neural_compressor.adaptor.ox_utils.operators.concat)": [[22, "neural_compressor.adaptor.ox_utils.operators.concat.ConcatOperator"]], "qconcatoperator (class in neural_compressor.adaptor.ox_utils.operators.concat)": [[22, "neural_compressor.adaptor.ox_utils.operators.concat.QConcatOperator"]], "neural_compressor.adaptor.ox_utils.operators.concat": [[22, "module-neural_compressor.adaptor.ox_utils.operators.concat"]], "convoperator (class in neural_compressor.adaptor.ox_utils.operators.conv)": [[23, "neural_compressor.adaptor.ox_utils.operators.conv.ConvOperator"]], "qconvoperator (class in neural_compressor.adaptor.ox_utils.operators.conv)": [[23, "neural_compressor.adaptor.ox_utils.operators.conv.QConvOperator"]], "neural_compressor.adaptor.ox_utils.operators.conv": [[23, "module-neural_compressor.adaptor.ox_utils.operators.conv"]], "direct8bitoperator (class in neural_compressor.adaptor.ox_utils.operators.direct_q8)": [[24, "neural_compressor.adaptor.ox_utils.operators.direct_q8.Direct8BitOperator"]], "qdirectoperator (class in neural_compressor.adaptor.ox_utils.operators.direct_q8)": [[24, "neural_compressor.adaptor.ox_utils.operators.direct_q8.QDirectOperator"]], "neural_compressor.adaptor.ox_utils.operators.direct_q8": [[24, "module-neural_compressor.adaptor.ox_utils.operators.direct_q8"]], "embedlayernormalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.embed_layernorm)": [[25, "neural_compressor.adaptor.ox_utils.operators.embed_layernorm.EmbedLayerNormalizationOperator"]], "qembedlayernormalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.embed_layernorm)": [[25, "neural_compressor.adaptor.ox_utils.operators.embed_layernorm.QEmbedLayerNormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.embed_layernorm": [[25, "module-neural_compressor.adaptor.ox_utils.operators.embed_layernorm"]], "gatheroperator (class in neural_compressor.adaptor.ox_utils.operators.gather)": [[26, "neural_compressor.adaptor.ox_utils.operators.gather.GatherOperator"]], "qgatheroperator (class in neural_compressor.adaptor.ox_utils.operators.gather)": [[26, "neural_compressor.adaptor.ox_utils.operators.gather.QGatherOperator"]], "neural_compressor.adaptor.ox_utils.operators.gather": [[26, "module-neural_compressor.adaptor.ox_utils.operators.gather"]], "globalaveragepooloperator (class in neural_compressor.adaptor.ox_utils.operators.gavgpool)": [[27, "neural_compressor.adaptor.ox_utils.operators.gavgpool.GlobalAveragePoolOperator"]], "qglobalaveragepooloperator (class in neural_compressor.adaptor.ox_utils.operators.gavgpool)": [[27, "neural_compressor.adaptor.ox_utils.operators.gavgpool.QGlobalAveragePoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.gavgpool": [[27, "module-neural_compressor.adaptor.ox_utils.operators.gavgpool"]], "gemmoperator (class in neural_compressor.adaptor.ox_utils.operators.gemm)": [[28, "neural_compressor.adaptor.ox_utils.operators.gemm.GemmOperator"]], "qgemmoperator (class in neural_compressor.adaptor.ox_utils.operators.gemm)": [[28, "neural_compressor.adaptor.ox_utils.operators.gemm.QGemmOperator"]], "neural_compressor.adaptor.ox_utils.operators.gemm": [[28, "module-neural_compressor.adaptor.ox_utils.operators.gemm"]], "neural_compressor.adaptor.ox_utils.operators": [[29, "module-neural_compressor.adaptor.ox_utils.operators"]], "lstmoperator (class in neural_compressor.adaptor.ox_utils.operators.lstm)": [[30, "neural_compressor.adaptor.ox_utils.operators.lstm.LSTMOperator"]], "neural_compressor.adaptor.ox_utils.operators.lstm": [[30, "module-neural_compressor.adaptor.ox_utils.operators.lstm"]], "fusedmatmuloperator (class in neural_compressor.adaptor.ox_utils.operators.matmul)": [[31, "neural_compressor.adaptor.ox_utils.operators.matmul.FusedMatMulOperator"]], "matmuloperator (class in neural_compressor.adaptor.ox_utils.operators.matmul)": [[31, "neural_compressor.adaptor.ox_utils.operators.matmul.MatMulOperator"]], "qmatmuloperator (class in neural_compressor.adaptor.ox_utils.operators.matmul)": [[31, "neural_compressor.adaptor.ox_utils.operators.matmul.QMatMulOperator"]], "neural_compressor.adaptor.ox_utils.operators.matmul": [[31, "module-neural_compressor.adaptor.ox_utils.operators.matmul"]], "maxpooloperator (class in neural_compressor.adaptor.ox_utils.operators.maxpool)": [[32, "neural_compressor.adaptor.ox_utils.operators.maxpool.MaxPoolOperator"]], "qmaxpooloperator (class in neural_compressor.adaptor.ox_utils.operators.maxpool)": [[32, "neural_compressor.adaptor.ox_utils.operators.maxpool.QMaxPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.maxpool": [[32, "module-neural_compressor.adaptor.ox_utils.operators.maxpool"]], "batchnormalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.norm)": [[33, "neural_compressor.adaptor.ox_utils.operators.norm.BatchNormalizationOperator"]], "normalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.norm)": [[33, "neural_compressor.adaptor.ox_utils.operators.norm.NormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.norm": [[33, "module-neural_compressor.adaptor.ox_utils.operators.norm"]], "operator (class in neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.Operator"]], "qoperator (class in neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.QOperator"]], "neural_compressor.adaptor.ox_utils.operators.ops": [[34, "module-neural_compressor.adaptor.ox_utils.operators.ops"]], "op_registry() (in module neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.op_registry"]], "qop_registry() (in module neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.qop_registry"]], "padoperator (class in neural_compressor.adaptor.ox_utils.operators.pad)": [[35, "neural_compressor.adaptor.ox_utils.operators.pad.PadOperator"]], "qpadoperator (class in neural_compressor.adaptor.ox_utils.operators.pad)": [[35, "neural_compressor.adaptor.ox_utils.operators.pad.QPadOperator"]], "neural_compressor.adaptor.ox_utils.operators.pad": [[35, "module-neural_compressor.adaptor.ox_utils.operators.pad"]], "pooloperator (class in neural_compressor.adaptor.ox_utils.operators.pooling)": [[36, "neural_compressor.adaptor.ox_utils.operators.pooling.PoolOperator"]], "qpooloperator (class in neural_compressor.adaptor.ox_utils.operators.pooling)": [[36, "neural_compressor.adaptor.ox_utils.operators.pooling.QPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.pooling": [[36, "module-neural_compressor.adaptor.ox_utils.operators.pooling"]], "reduceminmaxoperator (class in neural_compressor.adaptor.ox_utils.operators.reduce)": [[37, "neural_compressor.adaptor.ox_utils.operators.reduce.ReduceMinMaxOperator"]], "reduceoperator (class in neural_compressor.adaptor.ox_utils.operators.reduce)": [[37, "neural_compressor.adaptor.ox_utils.operators.reduce.ReduceOperator"]], "neural_compressor.adaptor.ox_utils.operators.reduce": [[37, "module-neural_compressor.adaptor.ox_utils.operators.reduce"]], "qresizeoperator (class in neural_compressor.adaptor.ox_utils.operators.resize)": [[38, "neural_compressor.adaptor.ox_utils.operators.resize.QResizeOperator"]], "resizeoperator (class in neural_compressor.adaptor.ox_utils.operators.resize)": [[38, "neural_compressor.adaptor.ox_utils.operators.resize.ResizeOperator"]], "neural_compressor.adaptor.ox_utils.operators.resize": [[38, "module-neural_compressor.adaptor.ox_utils.operators.resize"]], "qsplitoperator (class in neural_compressor.adaptor.ox_utils.operators.split)": [[39, "neural_compressor.adaptor.ox_utils.operators.split.QSplitOperator"]], "splitoperator (class in neural_compressor.adaptor.ox_utils.operators.split)": [[39, "neural_compressor.adaptor.ox_utils.operators.split.SplitOperator"]], "neural_compressor.adaptor.ox_utils.operators.split": [[39, "module-neural_compressor.adaptor.ox_utils.operators.split"]], "unarydirect8bitoperator (class in neural_compressor.adaptor.ox_utils.operators.unary_op)": [[40, "neural_compressor.adaptor.ox_utils.operators.unary_op.UnaryDirect8BitOperator"]], "unaryoperator (class in neural_compressor.adaptor.ox_utils.operators.unary_op)": [[40, "neural_compressor.adaptor.ox_utils.operators.unary_op.UnaryOperator"]], "neural_compressor.adaptor.ox_utils.operators.unary_op": [[40, "module-neural_compressor.adaptor.ox_utils.operators.unary_op"]], "quantizer (class in neural_compressor.adaptor.ox_utils.quantizer)": [[41, "neural_compressor.adaptor.ox_utils.quantizer.Quantizer"]], "neural_compressor.adaptor.ox_utils.quantizer": [[41, "module-neural_compressor.adaptor.ox_utils.quantizer"]], "ortsmoothquant (class in neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.ORTSmoothQuant"]], "get_quant_dequant_output() (in module neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.get_quant_dequant_output"]], "make_sub_graph() (in module neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.make_sub_graph"]], "neural_compressor.adaptor.ox_utils.smooth_quant": [[42, "module-neural_compressor.adaptor.ox_utils.smooth_quant"]], "quant_dequant_data() (in module neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.quant_dequant_data"]], "quantformat (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantFormat"]], "quanttype (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantType"]], "quantizationmode (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizationMode"]], "quantizedinitializer (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizedInitializer"]], "quantizedvalue (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizedValue"]], "quantizedvaluetype (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizedValueType"]], "valueinfo (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.ValueInfo"]], "attribute_to_kwarg() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.attribute_to_kwarg"]], "calculate_scale_zp() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.calculate_scale_zp"]], "cast_tensor() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.cast_tensor"]], "collate_preds() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.collate_preds"]], "dequantize_data() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.dequantize_data"]], "dequantize_data_with_scale_zero() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.dequantize_data_with_scale_zero"]], "dtype_to_name() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.dtype_to_name"]], "find_by_name() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.find_by_name"]], "float_to_bfloat16() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.float_to_bfloat16"]], "float_to_float16() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.float_to_float16"]], "get_node_original_name() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.get_node_original_name"]], "infer_shapes() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.infer_shapes"]], "is_b_transposed() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.is_B_transposed"]], "make_dquant_node() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.make_dquant_node"]], "make_quant_node() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.make_quant_node"]], "neural_compressor.adaptor.ox_utils.util": [[43, "module-neural_compressor.adaptor.ox_utils.util"]], "quantize_data() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_data"]], "quantize_data_per_channel() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_data_per_channel"]], "quantize_data_with_scale_zero() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_data_with_scale_zero"]], "quantize_nparray() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_nparray"]], "remove_init_from_model_input() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.remove_init_from_model_input"]], "simple_progress_bar() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.simple_progress_bar"]], "split_shared_bias() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.split_shared_bias"]], "to_numpy() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.to_numpy"]], "trt_env_setup() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.trt_env_setup"]], "apply_awq_clip() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.apply_awq_clip"]], "apply_awq_scale() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.apply_awq_scale"]], "awq_quantize() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.awq_quantize"]], "get_blob_size() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.get_blob_size"]], "get_weight_scale() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.get_weight_scale"]], "gptq() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.gptq"]], "gptq_quantize() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.gptq_quantize"]], "make_matmul_weight_only_node() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.make_matmul_weight_only_node"]], "neural_compressor.adaptor.ox_utils.weight_only": [[44, "module-neural_compressor.adaptor.ox_utils.weight_only"]], "pad_tensor() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.pad_tensor"]], "prepare_inputs() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.prepare_inputs"]], "qdq_tensor() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.qdq_tensor"]], "quant_tensor() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.quant_tensor"]], "rtn_quantize() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.rtn_quantize"]], "pytorchadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorchAdaptor"]], "pytorchweightonlyadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorchWeightOnlyAdaptor"]], "pytorch_fxadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor"]], "pytorch_ipexadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor"]], "templateadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.TemplateAdaptor"]], "get_ops_recursively() (in module neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.get_ops_recursively"]], "neural_compressor.adaptor.pytorch": [[45, "module-neural_compressor.adaptor.pytorch"]], "querybackendcapability (class in neural_compressor.adaptor.query)": [[46, "neural_compressor.adaptor.query.QueryBackendCapability"]], "neural_compressor.adaptor.query": [[46, "module-neural_compressor.adaptor.query"]], "tensorflowadaptor (class in neural_compressor.adaptor.tensorflow)": [[47, "neural_compressor.adaptor.tensorflow.TensorFlowAdaptor"]], "tensorflowquery (class in neural_compressor.adaptor.tensorflow)": [[47, "neural_compressor.adaptor.tensorflow.TensorflowQuery"]], "tensorflow_itexadaptor (class in neural_compressor.adaptor.tensorflow)": [[47, "neural_compressor.adaptor.tensorflow.Tensorflow_ITEXAdaptor"]], "neural_compressor.adaptor.tensorflow": [[47, "module-neural_compressor.adaptor.tensorflow"]], "graphconverter (class in neural_compressor.adaptor.tf_utils.graph_converter)": [[48, "neural_compressor.adaptor.tf_utils.graph_converter.GraphConverter"]], "neural_compressor.adaptor.tf_utils.graph_converter": [[48, "module-neural_compressor.adaptor.tf_utils.graph_converter"]], "graphconverterwithoutcalib (class in neural_compressor.adaptor.tf_utils.graph_converter_without_calib)": [[49, "neural_compressor.adaptor.tf_utils.graph_converter_without_calib.GraphConverterWithoutCalib"]], "neural_compressor.adaptor.tf_utils.graph_converter_without_calib": [[49, "module-neural_compressor.adaptor.tf_utils.graph_converter_without_calib"]], "bf16convert (class in neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert)": [[50, "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert.BF16Convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert": [[50, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert"]], "dequantizecastoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer)": [[51, "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer.DequantizeCastOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[51, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16": [[52, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16"]], "convertaddtobiasaddoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd)": [[53, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd.ConvertAddToBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd": [[53, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd"]], "convertlayoutoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout)": [[54, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout.ConvertLayoutOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout": [[54, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout"]], "convertleakyreluoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu)": [[55, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu.ConvertLeakyReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu": [[55, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu"]], "convertnantorandom (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random)": [[56, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random.ConvertNanToRandom"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random": [[56, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random"]], "convertplaceholdertoconst (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const)": [[57, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const.ConvertPlaceholderToConst"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const": [[57, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const"]], "dilatedcontraction (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction)": [[58, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction.DilatedContraction"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction": [[58, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction"]], "injectdummybiasaddoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd)": [[59, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd.InjectDummyBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd": [[59, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd"]], "expanddimsoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer)": [[60, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer.ExpandDimsOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer": [[60, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer"]], "fetchweightfromreshapeoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape)": [[61, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape.FetchWeightFromReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape": [[61, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "foldbatchnormnodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm)": [[62, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm.FoldBatchNormNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm": [[62, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm"]], "graphfoldconstantoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant)": [[63, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant.GraphFoldConstantOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant": [[63, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant"]], "fusebiasaddandaddoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add)": [[64, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add.FuseBiasAddAndAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add": [[64, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add"]], "fusecolumnwisemuloptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul)": [[65, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul.FuseColumnWiseMulOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul": [[65, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul"]], "fuseconvwithmathoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math)": [[66, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math.FuseConvWithMathOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math": [[66, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math"]], "fusedecomposedbnoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.FuseDecomposedBNOptimizer"]], "bypass_reshape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.get_const_dim_count"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn": [[67, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn"]], "node_from_map() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.node_from_map"]], "node_name_from_input() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.values_from_const"]], "fusedecomposedinoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.FuseDecomposedINOptimizer"]], "bypass_reshape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.get_const_dim_count"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in": [[68, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in"]], "node_from_map() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.node_from_map"]], "node_name_from_input() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.values_from_const"]], "fusegeluoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu)": [[69, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu.FuseGeluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu": [[69, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu"]], "fuselayernormoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.FuseLayerNormOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm": [[70, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm"]], "node_from_map() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.node_from_map"]], "node_name_from_input() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.node_name_from_input"]], "values_from_const() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.values_from_const"]], "fusepadwithconv2doptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv)": [[71, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv.FusePadWithConv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv": [[71, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv"]], "fusepadwithfp32conv2doptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv)": [[72, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv.FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[72, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "fusetransposereshapeoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose)": [[73, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose.FuseTransposeReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose": [[73, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose"]], "graphcseoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer)": [[74, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer.GraphCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer": [[74, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer"]], "grappleroptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass)": [[75, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass.GrapplerOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass": [[75, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic": [[76, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic"]], "insertprintminmaxnode (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node)": [[77, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node.InsertPrintMinMaxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node": [[77, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node"]], "movesqueezeafterreluoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu)": [[78, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu.MoveSqueezeAfterReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu": [[78, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu"]], "preoptimization (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize)": [[79, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize.PreOptimization"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize": [[79, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize"]], "removetrainingnodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes)": [[80, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes.RemoveTrainingNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes": [[80, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes"]], "renamebatchnormoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm)": [[81, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm.RenameBatchNormOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm": [[81, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm"]], "splitsharedinputoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input)": [[82, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input.SplitSharedInputOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input": [[82, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input"]], "stripequivalentnodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes)": [[83, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes.StripEquivalentNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes": [[83, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes"]], "stripunusednodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes)": [[84, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes.StripUnusedNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes": [[84, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes"]], "switchoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer)": [[85, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer.SwitchOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer": [[85, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer"]], "graphrewriterbase (class in neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base)": [[86, "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base.GraphRewriterBase"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base": [[86, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base"]], "neural_compressor.adaptor.tf_utils.graph_rewriter": [[87, "module-neural_compressor.adaptor.tf_utils.graph_rewriter"]], "freezefakequantopoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant)": [[88, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant.FreezeFakeQuantOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant": [[88, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant"]], "freezevaluetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value)": [[89, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value.FreezeValueTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value": [[89, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value"]], "freezevaluewithoutcalibtransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib)": [[90, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib.FreezeValueWithoutCalibTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib": [[90, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib"]], "fuseconvredundantdequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize)": [[91, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize.FuseConvRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[91, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "fuseconvrequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize)": [[92, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize.FuseConvRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize": [[92, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize"]], "fusematmulredundantdequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize)": [[93, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize.FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[93, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "fusematmulrequantizedequantizenewapitransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeNewAPITransformer"]], "fusematmulrequantizedequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeTransformer"]], "fusematmulrequantizenewapitransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeNewAPITransformer"]], "fusematmulrequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize": [[94, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8": [[95, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8"]], "metainfochangingmemopoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer)": [[96, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer.MetaInfoChangingMemOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer": [[96, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer"]], "posthostconstconverter (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter)": [[97, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter.PostHostConstConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter": [[97, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter"]], "postcseoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse)": [[98, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse.PostCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse": [[98, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse"]], "quantizedrnnconverter (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert)": [[99, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert.QuantizedRNNConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert": [[99, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert"]], "scalepropagationtransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation)": [[100, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation.ScaleProPagationTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation": [[100, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx": [[101, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx"]], "onnxgraph (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph)": [[102, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph.OnnxGraph"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph": [[102, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph"]], "onnxnode (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node)": [[103, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node.OnnxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node": [[103, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node"]], "onnxopschema (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema)": [[104, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema.OnnxOpSchema"]], "get_max_supported_opset_version() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema)": [[104, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema.get_max_supported_opset_version"]], "get_schema() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema)": [[104, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema.get_schema"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema": [[104, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema"]], "seqtype (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.SeqType"]], "add_port_to_name() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.add_port_to_name"]], "are_shapes_equal() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.are_shapes_equal"]], "assert_error() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.assert_error"]], "compute_const_folding_using_tf() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.compute_const_folding_using_tf"]], "convert_tensorflow_tensor_to_onnx() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.convert_tensorflow_tensor_to_onnx"]], "find_opset() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.find_opset"]], "get_index_from_strided_slice_of_shape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_index_from_strided_slice_of_shape"]], "get_subgraphs_from_onnx() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_subgraphs_from_onnx"]], "get_tensorflow_node_attr() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_node_attr"]], "get_tensorflow_node_shape_attr() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_node_shape_attr"]], "get_tensorflow_tensor_data() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_tensor_data"]], "get_tensorflow_tensor_shape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_tensor_shape"]], "infer_onnx_shape_dtype() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.infer_onnx_shape_dtype"]], "initialize_name_counter() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.initialize_name_counter"]], "is_list_or_tuple() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.is_list_or_tuple"]], "is_onnx_domain() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.is_onnx_domain"]], "make_onnx_inputs_outputs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.make_onnx_inputs_outputs"]], "make_onnx_shape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.make_onnx_shape"]], "map_numpy_to_onnx_dtype() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.map_numpy_to_onnx_dtype"]], "map_onnx_to_numpy_type() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.map_onnx_to_numpy_type"]], "map_tensorflow_dtype() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.map_tensorflow_dtype"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils": [[105, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils"]], "read_tensorflow_node_attrs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.read_tensorflow_node_attrs"]], "save_protobuf() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.save_protobuf"]], "set_name() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.set_name"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq": [[106, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq"]], "generategraphwithqdqpattern (class in neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern)": [[107, "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern.GenerateGraphWithQDQPattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern": [[107, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern"]], "mergeduplicatedqdqoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq)": [[108, "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq.MergeDuplicatedQDQOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq": [[108, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "shareqdqforitexypatternoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern)": [[109, "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern.ShareQDQForItexYPatternOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern": [[109, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "graphanalyzer (class in neural_compressor.adaptor.tf_utils.graph_util)": [[110, "neural_compressor.adaptor.tf_utils.graph_util.GraphAnalyzer"]], "graphrewriterhelper (class in neural_compressor.adaptor.tf_utils.graph_util)": [[110, "neural_compressor.adaptor.tf_utils.graph_util.GraphRewriterHelper"]], "neural_compressor.adaptor.tf_utils.graph_util": [[110, "module-neural_compressor.adaptor.tf_utils.graph_util"]], "neural_compressor.adaptor.tf_utils": [[111, "module-neural_compressor.adaptor.tf_utils"]], "neural_compressor.adaptor.tf_utils.quantize_graph": [[112, "module-neural_compressor.adaptor.tf_utils.quantize_graph"]], "fakequantize (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize)": [[113, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize.FakeQuantize"]], "fakequantizebase (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize)": [[113, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize.FakeQuantizeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize": [[113, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat": [[114, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat"]], "quantizeconfig (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config)": [[115, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config.QuantizeConfig"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config": [[115, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config"]], "init_quantize_config() (in module neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper)": [[116, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper.init_quantize_config"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper": [[116, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper"]], "qat_clone_function() (in module neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper)": [[116, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper.qat_clone_function"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers": [[117, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers"]], "config_quantizable_layers() (in module neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer)": [[118, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer.config_quantizable_layers"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer": [[118, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer"]], "quantizelayeradd (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add)": [[119, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add.QuantizeLayerAdd"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[119, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add"]], "quantizelayerbase (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base)": [[120, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base.QuantizeLayerBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[120, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base"]], "quantizelayerbatchnormalization (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn)": [[121, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn.QuantizeLayerBatchNormalization"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[121, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"]], "quantizewrapper (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper)": [[122, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper.QuantizeWrapper"]], "quantizewrapperbase (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper)": [[122, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper.QuantizeWrapperBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper": [[122, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn)": [[123, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn": [[123, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2)": [[124, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2": [[124, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv)": [[125, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv.FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv": [[125, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv"]], "fusenodestartwithdeconv2d (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv)": [[126, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv.FuseNodeStartWithDeconv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv": [[126, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv"]], "fusenodestartwithfusedinstancenorm (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in)": [[127, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in.FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in": [[127, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in"]], "fusenodestartwithmatmul (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul)": [[128, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul": [[128, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul"]], "fusenodestartwithpooling (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling)": [[129, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling.FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling": [[129, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq": [[130, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq"]], "optimizeqdqgraph (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq)": [[131, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq.OptimizeQDQGraph"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq": [[131, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq"]], "quantizegraphbase (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base)": [[132, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base.QuantizeGraphBase"]], "quantizenodebase (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base)": [[132, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base.QuantizeNodeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base": [[132, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn)": [[133, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn": [[133, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2)": [[134, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2": [[134, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv)": [[135, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv.FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv": [[135, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv"]], "quantizegraphforintel (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu)": [[136, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu.QuantizeGraphForIntel"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu": [[136, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu"]], "fusenodestartwithmatmul (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul)": [[137, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul": [[137, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul"]], "fusenodestartwithpooling (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling)": [[138, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling.FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling": [[138, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling"]], "quantizegraphhelper (class in neural_compressor.adaptor.tf_utils.quantize_graph_common)": [[139, "neural_compressor.adaptor.tf_utils.quantize_graph_common.QuantizeGraphHelper"]], "neural_compressor.adaptor.tf_utils.quantize_graph_common": [[139, "module-neural_compressor.adaptor.tf_utils.quantize_graph_common"]], "smoothquantcalibration (class in neural_compressor.adaptor.tf_utils.smooth_quant_calibration)": [[140, "neural_compressor.adaptor.tf_utils.smooth_quant_calibration.SmoothQuantCalibration"]], "smoothquantcalibrationllm (class in neural_compressor.adaptor.tf_utils.smooth_quant_calibration)": [[140, "neural_compressor.adaptor.tf_utils.smooth_quant_calibration.SmoothQuantCalibrationLLM"]], "neural_compressor.adaptor.tf_utils.smooth_quant_calibration": [[140, "module-neural_compressor.adaptor.tf_utils.smooth_quant_calibration"]], "smoothquantscaler (class in neural_compressor.adaptor.tf_utils.smooth_quant_scaler)": [[141, "neural_compressor.adaptor.tf_utils.smooth_quant_scaler.SmoothQuantScaler"]], "smoothquantscalerllm (class in neural_compressor.adaptor.tf_utils.smooth_quant_scaler)": [[141, "neural_compressor.adaptor.tf_utils.smooth_quant_scaler.SmoothQuantScalerLLM"]], "neural_compressor.adaptor.tf_utils.smooth_quant_scaler": [[141, "module-neural_compressor.adaptor.tf_utils.smooth_quant_scaler"]], "tensorflowqdqtoonnxqdqconverter (class in neural_compressor.adaptor.tf_utils.tf2onnx_converter)": [[142, "neural_compressor.adaptor.tf_utils.tf2onnx_converter.TensorflowQDQToOnnxQDQConverter"]], "neural_compressor.adaptor.tf_utils.tf2onnx_converter": [[142, "module-neural_compressor.adaptor.tf_utils.tf2onnx_converter"]], "biascorrection (class in neural_compressor.adaptor.tf_utils.transform_graph.bias_correction)": [[143, "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction.BiasCorrection"]], "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction": [[143, "module-neural_compressor.adaptor.tf_utils.transform_graph.bias_correction"]], "graphtransformbase (class in neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base)": [[144, "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base.GraphTransformBase"]], "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base": [[144, "module-neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base"]], "neural_compressor.adaptor.tf_utils.transform_graph": [[145, "module-neural_compressor.adaptor.tf_utils.transform_graph"]], "insertlogging (class in neural_compressor.adaptor.tf_utils.transform_graph.insert_logging)": [[146, "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging.InsertLogging"]], "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging": [[146, "module-neural_compressor.adaptor.tf_utils.transform_graph.insert_logging"]], "rerangequantizedconcat (class in neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat)": [[147, "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat.RerangeQuantizedConcat"]], "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat": [[147, "module-neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat"]], "apply_inlining() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.apply_inlining"]], "collate_tf_preds() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.collate_tf_preds"]], "construct_function_from_graph_def() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.construct_function_from_graph_def"]], "disable_random() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.disable_random"]], "fix_ref_type_of_graph_def() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.fix_ref_type_of_graph_def"]], "generate_feed_dict() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.generate_feed_dict"]], "get_estimator_graph() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_estimator_graph"]], "get_graph_def() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_graph_def"]], "get_input_output_node_names() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_input_output_node_names"]], "get_model_input_shape() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_model_input_shape"]], "get_tensor_by_name() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_tensor_by_name"]], "get_tensor_val_from_graph_node() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_tensor_val_from_graph_node"]], "get_weight_from_input_tensor() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_weight_from_input_tensor"]], "int8_node_name_reverse() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.int8_node_name_reverse"]], "is_ckpt_format() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.is_ckpt_format"]], "is_saved_model_format() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.is_saved_model_format"]], "iterator_sess_run() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.iterator_sess_run"]], "neural_compressor.adaptor.tf_utils.util": [[148, "module-neural_compressor.adaptor.tf_utils.util"]], "parse_saved_model() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.parse_saved_model"]], "read_graph() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.read_graph"]], "reconstruct_saved_model() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.reconstruct_saved_model"]], "strip_equivalent_nodes() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.strip_equivalent_nodes"]], "strip_unused_nodes() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.strip_unused_nodes"]], "tf_diagnosis_helper() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.tf_diagnosis_helper"]], "version1_eq_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_lte_version2"]], "write_graph() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.write_graph"]], "neural_compressor.adaptor.torch_utils.auto_round": [[149, "module-neural_compressor.adaptor.torch_utils.auto_round"]], "actawareweightquant (class in neural_compressor.adaptor.torch_utils.awq)": [[150, "neural_compressor.adaptor.torch_utils.awq.ActAwareWeightQuant"]], "neural_compressor.adaptor.torch_utils.awq": [[150, "module-neural_compressor.adaptor.torch_utils.awq"]], "bf16modulewrapper (class in neural_compressor.adaptor.torch_utils.bf16_convert)": [[151, "neural_compressor.adaptor.torch_utils.bf16_convert.BF16ModuleWrapper"]], "convert() (in module neural_compressor.adaptor.torch_utils.bf16_convert)": [[151, "neural_compressor.adaptor.torch_utils.bf16_convert.Convert"]], "bf16_symbolic_trace() (in module neural_compressor.adaptor.torch_utils.bf16_convert)": [[151, "neural_compressor.adaptor.torch_utils.bf16_convert.bf16_symbolic_trace"]], "neural_compressor.adaptor.torch_utils.bf16_convert": [[151, "module-neural_compressor.adaptor.torch_utils.bf16_convert"]], "gptq (class in neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.GPTQ"]], "gptquantizer (class in neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.GPTQuantizer"]], "find_layers() (in module neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.find_layers"]], "find_layers_name() (in module neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.find_layers_name"]], "is_leaf() (in module neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.is_leaf"]], "log_quantizable_layers_per_transformer() (in module neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.log_quantizable_layers_per_transformer"]], "neural_compressor.adaptor.torch_utils.gptq": [[152, "module-neural_compressor.adaptor.torch_utils.gptq"]], "quantize() (in module neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.quantize"]], "trace_gptq_target_blocks() (in module neural_compressor.adaptor.torch_utils.gptq)": [[152, "neural_compressor.adaptor.torch_utils.gptq.trace_gptq_target_blocks"]], "hessiantrace (class in neural_compressor.adaptor.torch_utils.hawq_metric)": [[153, "neural_compressor.adaptor.torch_utils.hawq_metric.HessianTrace"]], "node_collector (class in neural_compressor.adaptor.torch_utils.hawq_metric)": [[153, "neural_compressor.adaptor.torch_utils.hawq_metric.Node_collector"]], "compare_weights() (in module neural_compressor.adaptor.torch_utils.hawq_metric)": [[153, "neural_compressor.adaptor.torch_utils.hawq_metric.compare_weights"]], "hawq_top() (in module neural_compressor.adaptor.torch_utils.hawq_metric)": [[153, "neural_compressor.adaptor.torch_utils.hawq_metric.hawq_top"]], "neural_compressor.adaptor.torch_utils.hawq_metric": [[153, "module-neural_compressor.adaptor.torch_utils.hawq_metric"]], "neural_compressor.adaptor.torch_utils": [[154, "module-neural_compressor.adaptor.torch_utils"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant": [[155, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant"]], "pickleerror": [[156, "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle.PickleError"], [584, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.PickleError"]], "picklingerror": [[156, "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle.PicklingError"], [584, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.PicklingError"]], "unpicklingerror": [[156, "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle.UnpicklingError"], [584, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.UnpicklingError"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle": [[156, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle"]], "layerwisequant (class in neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize)": [[157, "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize.LayerWiseQuant"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize": [[157, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize"]], "load() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load)": [[158, "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load.load"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load": [[158, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load"]], "dowload_hf_model() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.dowload_hf_model"]], "get_children() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_children"]], "get_module() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_module"]], "get_named_children() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_named_children"]], "get_super_module_by_name() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_super_module_by_name"]], "load_empty_model() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_empty_model"]], "load_layer_wise_quantized_model() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_layer_wise_quantized_model"]], "load_tensor() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_tensor"]], "load_tensor_from_shard() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_tensor_from_shard"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils": [[159, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.utils"]], "update_module() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[159, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.update_module"]], "ipex_mixed_precision() (in module neural_compressor.adaptor.torch_utils.mixed_precision)": [[160, "neural_compressor.adaptor.torch_utils.mixed_precision.ipex_mixed_precision"]], "neural_compressor.adaptor.torch_utils.mixed_precision": [[160, "module-neural_compressor.adaptor.torch_utils.mixed_precision"]], "fakeaffinetensorquantfunction (class in neural_compressor.adaptor.torch_utils.model_wrapper)": [[161, "neural_compressor.adaptor.torch_utils.model_wrapper.FakeAffineTensorQuantFunction"]], "mullinear (class in neural_compressor.adaptor.torch_utils.model_wrapper)": [[161, "neural_compressor.adaptor.torch_utils.model_wrapper.MulLinear"]], "teqlinearfakequant (class in neural_compressor.adaptor.torch_utils.model_wrapper)": [[161, "neural_compressor.adaptor.torch_utils.model_wrapper.TEQLinearFakeQuant"]], "neural_compressor.adaptor.torch_utils.model_wrapper": [[161, "module-neural_compressor.adaptor.torch_utils.model_wrapper"]], "transformerbasedmodelblockpatterndetector (class in neural_compressor.adaptor.torch_utils.pattern_detector)": [[162, "neural_compressor.adaptor.torch_utils.pattern_detector.TransformerBasedModelBlockPatternDetector"]], "neural_compressor.adaptor.torch_utils.pattern_detector": [[162, "module-neural_compressor.adaptor.torch_utils.pattern_detector"]], "neural_compressor.adaptor.torch_utils.symbolic_trace": [[163, "module-neural_compressor.adaptor.torch_utils.symbolic_trace"]], "symbolic_trace() (in module neural_compressor.adaptor.torch_utils.symbolic_trace)": [[163, "neural_compressor.adaptor.torch_utils.symbolic_trace.symbolic_trace"]], "trace_and_fuse_sub_graph() (in module neural_compressor.adaptor.torch_utils.symbolic_trace)": [[163, "neural_compressor.adaptor.torch_utils.symbolic_trace.trace_and_fuse_sub_graph"]], "tequantizer (class in neural_compressor.adaptor.torch_utils.teq)": [[164, "neural_compressor.adaptor.torch_utils.teq.TEQuantizer"]], "neural_compressor.adaptor.torch_utils.teq": [[164, "module-neural_compressor.adaptor.torch_utils.teq"]], "append_attr() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.append_attr"]], "auto_copy() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.auto_copy"]], "calculate_quant_min_max() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.calculate_quant_min_max"]], "calibration() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.calibration"]], "check_cfg_and_qconfig() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.check_cfg_and_qconfig"]], "collate_torch_preds() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.collate_torch_preds"]], "collect_weight_info() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.collect_weight_info"]], "fetch_module() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.fetch_module"]], "forward_wrapper() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.forward_wrapper"]], "generate_activation_observer() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.generate_activation_observer"]], "get_absorb_layers() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_absorb_layers"]], "get_block_prefix() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_block_prefix"]], "get_depth() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_depth"]], "get_dict_at_depth() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_dict_at_depth"]], "get_element_under_depth() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_element_under_depth"]], "get_embedding_contiguous() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_embedding_contiguous"]], "get_example_input() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_example_input"]], "get_fallback_order() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_fallback_order"]], "get_hidden_states() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_hidden_states"]], "get_module_input_output() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_module_input_output"]], "get_mse_order_per_fp32() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_mse_order_per_fp32"]], "get_mse_order_per_int8() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_mse_order_per_int8"]], "get_op_type_by_name() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_op_type_by_name"]], "get_quantizable_ops_from_cfgs() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_quantizable_ops_from_cfgs"]], "get_torch_version() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.get_torch_version"]], "input2tuple() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.input2tuple"]], "is_fused_module() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.is_fused_module"]], "match_datatype_pattern() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.match_datatype_pattern"]], "move_input_device() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.move_input_device"]], "neural_compressor.adaptor.torch_utils.util": [[165, "module-neural_compressor.adaptor.torch_utils.util"]], "paser_cfgs() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.paser_cfgs"]], "set_module() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.set_module"]], "simple_inference() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.simple_inference"]], "update_sq_scale() (in module neural_compressor.adaptor.torch_utils.util)": [[165, "neural_compressor.adaptor.torch_utils.util.update_sq_scale"]], "neural_compressor.adaptor.torch_utils.waq.auto_alpha": [[166, "module-neural_compressor.adaptor.torch_utils.waq.auto_alpha"]], "neural_compressor.adaptor.torch_utils.waq.calibration": [[167, "module-neural_compressor.adaptor.torch_utils.waq.calibration"]], "neural_compressor.adaptor.torch_utils.waq.graph_trace": [[168, "module-neural_compressor.adaptor.torch_utils.waq.graph_trace"]], "neural_compressor.adaptor.torch_utils.waq": [[169, "module-neural_compressor.adaptor.torch_utils.waq"]], "torchsmoothquant (class in neural_compressor.adaptor.torch_utils.waq.smooth_quant)": [[170, "neural_compressor.adaptor.torch_utils.waq.smooth_quant.TorchSmoothQuant"]], "neural_compressor.adaptor.torch_utils.waq.smooth_quant": [[170, "module-neural_compressor.adaptor.torch_utils.waq.smooth_quant"]], "get_module() (in module neural_compressor.adaptor.torch_utils.waq.utils)": [[171, "neural_compressor.adaptor.torch_utils.waq.utils.get_module"]], "neural_compressor.adaptor.torch_utils.waq.utils": [[171, "module-neural_compressor.adaptor.torch_utils.waq.utils"]], "register_autotune() (in module neural_compressor.adaptor.torch_utils.waq.utils)": [[171, "neural_compressor.adaptor.torch_utils.waq.utils.register_autotune"]], "reshape_in_channel_to_last() (in module neural_compressor.adaptor.torch_utils.waq.utils)": [[171, "neural_compressor.adaptor.torch_utils.waq.utils.reshape_in_channel_to_last"]], "reshape_scale_as_input() (in module neural_compressor.adaptor.torch_utils.waq.utils)": [[171, "neural_compressor.adaptor.torch_utils.waq.utils.reshape_scale_as_input"]], "reshape_scale_as_weight() (in module neural_compressor.adaptor.torch_utils.waq.utils)": [[171, "neural_compressor.adaptor.torch_utils.waq.utils.reshape_scale_as_weight"]], "set_module() (in module neural_compressor.adaptor.torch_utils.waq.utils)": [[171, "neural_compressor.adaptor.torch_utils.waq.utils.set_module"]], "autoround_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.autoround_quantize"]], "awq_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.awq_quantize"]], "gptq_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.gptq_quantize"]], "neural_compressor.adaptor.torch_utils.weight_only": [[172, "module-neural_compressor.adaptor.torch_utils.weight_only"]], "qdq_weight_actor() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.qdq_weight_actor"]], "qdq_weight_asym() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.qdq_weight_asym"]], "qdq_weight_sym() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.qdq_weight_sym"]], "quant_weight() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.quant_weight"]], "quant_weight_w_scale() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.quant_weight_w_scale"]], "quantize_4bit() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.quantize_4bit"]], "rtn_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.rtn_quantize"]], "search_clip() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.search_clip"]], "teq_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[172, "neural_compressor.adaptor.torch_utils.weight_only.teq_quantize"]], "algorithms (class in neural_compressor.algorithm.algorithm)": [[173, "neural_compressor.algorithm.algorithm.ALGORITHMS"]], "algorithm (class in neural_compressor.algorithm.algorithm)": [[173, "neural_compressor.algorithm.algorithm.Algorithm"]], "algorithmscheduler (class in neural_compressor.algorithm.algorithm)": [[173, "neural_compressor.algorithm.algorithm.AlgorithmScheduler"]], "algorithm_registry() (in module neural_compressor.algorithm.algorithm)": [[173, "neural_compressor.algorithm.algorithm.algorithm_registry"]], "neural_compressor.algorithm.algorithm": [[173, "module-neural_compressor.algorithm.algorithm"]], "fastbiascorrection (class in neural_compressor.algorithm.fast_bias_correction)": [[174, "neural_compressor.algorithm.fast_bias_correction.FastBiasCorrection"]], "neural_compressor.algorithm.fast_bias_correction": [[174, "module-neural_compressor.algorithm.fast_bias_correction"]], "neural_compressor.algorithm": [[175, "module-neural_compressor.algorithm"]], "smoothquant (class in neural_compressor.algorithm.smooth_quant)": [[176, "neural_compressor.algorithm.smooth_quant.SmoothQuant"]], "neural_compressor.algorithm.smooth_quant": [[176, "module-neural_compressor.algorithm.smooth_quant"]], "weightcorrection (class in neural_compressor.algorithm.weight_correction)": [[177, "neural_compressor.algorithm.weight_correction.WeightCorrection"]], "neural_compressor.algorithm.weight_correction": [[177, "module-neural_compressor.algorithm.weight_correction"]], "benchmark_with_raw_cmd() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.benchmark_with_raw_cmd"]], "call_one() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.call_one"]], "config_instance() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.config_instance"]], "fit() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.fit"]], "generate_prefix() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.generate_prefix"]], "get_architecture() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.get_architecture"]], "get_bounded_threads() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.get_bounded_threads"]], "get_core_ids() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.get_core_ids"]], "get_physical_ids() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.get_physical_ids"]], "get_threads() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.get_threads"]], "get_threads_per_core() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.get_threads_per_core"]], "neural_compressor.benchmark": [[178, "module-neural_compressor.benchmark"]], "profile() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.profile"]], "run_instance() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.run_instance"]], "set_all_env_var() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.set_all_env_var"]], "set_env_var() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.set_env_var"]], "summary_benchmark() (in module neural_compressor.benchmark)": [[178, "neural_compressor.benchmark.summary_benchmark"]], "baseconfig (class in neural_compressor.common.base_config)": [[179, "neural_compressor.common.base_config.BaseConfig"]], "composableconfig (class in neural_compressor.common.base_config)": [[179, "neural_compressor.common.base_config.ComposableConfig"]], "neural_compressor.common.base_config": [[179, "module-neural_compressor.common.base_config"]], "register_config() (in module neural_compressor.common.base_config)": [[179, "neural_compressor.common.base_config.register_config"]], "register_supported_configs_for_fwk() (in module neural_compressor.common.base_config)": [[179, "neural_compressor.common.base_config.register_supported_configs_for_fwk"]], "evaluator (class in neural_compressor.common.base_tuning)": [[180, "neural_compressor.common.base_tuning.Evaluator"]], "sequentialsampler (class in neural_compressor.common.base_tuning)": [[180, "neural_compressor.common.base_tuning.SequentialSampler"]], "tuningconfig (class in neural_compressor.common.base_tuning)": [[180, "neural_compressor.common.base_tuning.TuningConfig"]], "neural_compressor.common.base_tuning": [[180, "module-neural_compressor.common.base_tuning"]], "neural_compressor.common": [[181, "module-neural_compressor.common"]], "paramlevel (class in neural_compressor.common.tuning_param)": [[182, "neural_compressor.common.tuning_param.ParamLevel"]], "tuningparam (class in neural_compressor.common.tuning_param)": [[182, "neural_compressor.common.tuning_param.TuningParam"]], "neural_compressor.common.tuning_param": [[182, "module-neural_compressor.common.tuning_param"]], "mode (class in neural_compressor.common.utils.constants)": [[183, "neural_compressor.common.utils.constants.Mode"]], "neural_compressor.common.utils.constants": [[183, "module-neural_compressor.common.utils.constants"]], "neural_compressor.common.utils": [[184, "module-neural_compressor.common.utils"]], "logger (class in neural_compressor.common.utils.logger)": [[185, "neural_compressor.common.utils.logger.Logger"]], "tuninglogger (class in neural_compressor.common.utils.logger)": [[185, "neural_compressor.common.utils.logger.TuningLogger"]], "neural_compressor.common.utils.logger": [[185, "module-neural_compressor.common.utils.logger"]], "load_config_mapping() (in module neural_compressor.common.utils.save_load)": [[186, "neural_compressor.common.utils.save_load.load_config_mapping"]], "neural_compressor.common.utils.save_load": [[186, "module-neural_compressor.common.utils.save_load"]], "save_config_mapping() (in module neural_compressor.common.utils.save_load)": [[186, "neural_compressor.common.utils.save_load.save_config_mapping"]], "cpuinfo (class in neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.CpuInfo"]], "lazyimport (class in neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.LazyImport"]], "dump_elapsed_time() (in module neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.dump_elapsed_time"]], "neural_compressor.common.utils.utility": [[187, "module-neural_compressor.common.utils.utility"]], "set_random_seed() (in module neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.set_random_seed"]], "set_resume_from() (in module neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.set_resume_from"]], "set_tensorboard() (in module neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.set_tensorboard"]], "set_workspace() (in module neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.set_workspace"]], "singleton() (in module neural_compressor.common.utils.utility)": [[187, "neural_compressor.common.utils.utility.singleton"]], "basecallbacks (class in neural_compressor.compression.callbacks)": [[188, "neural_compressor.compression.callbacks.BaseCallbacks"]], "distillationcallbacks (class in neural_compressor.compression.callbacks)": [[188, "neural_compressor.compression.callbacks.DistillationCallbacks"]], "pruningcallbacks (class in neural_compressor.compression.callbacks)": [[188, "neural_compressor.compression.callbacks.PruningCallbacks"]], "quantizationawaretrainingcallbacks (class in neural_compressor.compression.callbacks)": [[188, "neural_compressor.compression.callbacks.QuantizationAwareTrainingCallbacks"]], "_epoch_ran (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[188, "neural_compressor.compression.callbacks.DistillationCallbacks._epoch_ran"]], "best_model (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[188, "neural_compressor.compression.callbacks.DistillationCallbacks.best_model"]], "best_score (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[188, "neural_compressor.compression.callbacks.DistillationCallbacks.best_score"]], "eval_frequency (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[188, "neural_compressor.compression.callbacks.DistillationCallbacks.eval_frequency"]], "neural_compressor.compression.callbacks": [[188, "module-neural_compressor.compression.callbacks"]], "criterions (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.Criterions"]], "intermediatelayersknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.IntermediateLayersKnowledgeDistillationLoss"]], "knowledgedistillationframework (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.KnowledgeDistillationFramework"]], "knowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.KnowledgeDistillationLoss"]], "pytorchcriterions (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchCriterions"]], "pytorchcrossentropyloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchCrossEntropyLoss"]], "pytorchintermediatelayersknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchIntermediateLayersKnowledgeDistillationLoss"]], "pytorchintermediatelayersknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"]], "pytorchknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchKnowledgeDistillationLoss"]], "pytorchknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchKnowledgeDistillationLossWrapper"]], "pytorchselfknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchSelfKnowledgeDistillationLoss"]], "pytorchselfknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.PyTorchSelfKnowledgeDistillationLossWrapper"]], "selfknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.SelfKnowledgeDistillationLoss"]], "tensorflowcrossentropyloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.TensorFlowCrossEntropyLoss"]], "tensorflowsparsecategoricalcrossentropy (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.TensorFlowSparseCategoricalCrossentropy"]], "tensorflowcriterions (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.TensorflowCriterions"]], "tensorflowknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.TensorflowKnowledgeDistillationLoss"]], "tensorflowknowledgedistillationlossexternal (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.TensorflowKnowledgeDistillationLossExternal"]], "tensorflowknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.TensorflowKnowledgeDistillationLossWrapper"]], "criterion_registry() (in module neural_compressor.compression.distillation.criterions)": [[189, "neural_compressor.compression.distillation.criterions.criterion_registry"]], "neural_compressor.compression.distillation.criterions": [[189, "module-neural_compressor.compression.distillation.criterions"]], "neural_compressor.compression.distillation": [[190, "module-neural_compressor.compression.distillation"]], "optimizers (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.Optimizers"]], "pytorchoptimizers (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.PyTorchOptimizers"]], "pytorchsgd (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.PyTorchSGD"]], "tensorflowadam (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.TensorFlowAdam"]], "tensorflowadamw (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.TensorFlowAdamW"]], "tensorflowsgd (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.TensorFlowSGD"]], "tensorflowoptimizers (class in neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.TensorflowOptimizers"]], "neural_compressor.compression.distillation.optimizers": [[191, "module-neural_compressor.compression.distillation.optimizers"]], "optimizer_registry() (in module neural_compressor.compression.distillation.optimizers)": [[191, "neural_compressor.compression.distillation.optimizers.optimizer_registry"]], "get_activation() (in module neural_compressor.compression.distillation.utility)": [[192, "neural_compressor.compression.distillation.utility.get_activation"]], "neural_compressor.compression.distillation.utility": [[192, "module-neural_compressor.compression.distillation.utility"]], "record_output() (in module neural_compressor.compression.distillation.utility)": [[192, "neural_compressor.compression.distillation.utility.record_output"]], "neural_compressor.compression.hpo": [[193, "module-neural_compressor.compression.hpo"]], "neural_compressor.compression.hpo.sa_optimizer": [[194, "module-neural_compressor.compression.hpo.sa_optimizer"]], "bayesianoptimizationsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[195, "neural_compressor.compression.hpo.search_algorithms.BayesianOptimizationSearcher"]], "gridsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[195, "neural_compressor.compression.hpo.search_algorithms.GridSearcher"]], "randomsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[195, "neural_compressor.compression.hpo.search_algorithms.RandomSearcher"]], "searcher (class in neural_compressor.compression.hpo.search_algorithms)": [[195, "neural_compressor.compression.hpo.search_algorithms.Searcher"]], "xgbsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[195, "neural_compressor.compression.hpo.search_algorithms.XgbSearcher"]], "neural_compressor.compression.hpo.search_algorithms": [[195, "module-neural_compressor.compression.hpo.search_algorithms"]], "register_searcher() (in module neural_compressor.compression.hpo.search_algorithms)": [[195, "neural_compressor.compression.hpo.search_algorithms.register_searcher"]], "basesearchspace (class in neural_compressor.compression.hpo.search_space)": [[196, "neural_compressor.compression.hpo.search_space.BaseSearchSpace"]], "continuoussearchspace (class in neural_compressor.compression.hpo.search_space)": [[196, "neural_compressor.compression.hpo.search_space.ContinuousSearchSpace"]], "discretesearchspace (class in neural_compressor.compression.hpo.search_space)": [[196, "neural_compressor.compression.hpo.search_space.DiscreteSearchSpace"]], "searchspace (class in neural_compressor.compression.hpo.search_space)": [[196, "neural_compressor.compression.hpo.search_space.SearchSpace"]], "neural_compressor.compression.hpo.search_space": [[196, "module-neural_compressor.compression.hpo.search_space"]], "register_searchspace() (in module neural_compressor.compression.hpo.search_space)": [[196, "neural_compressor.compression.hpo.search_space.register_searchspace"]], "neural_compressor.compression": [[197, "module-neural_compressor.compression"]], "blockmaskcriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.BlockMaskCriterion"]], "gradientcriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.GradientCriterion"]], "magnitudecriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.MagnitudeCriterion"]], "pruningcriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.PruningCriterion"]], "retrainfreecriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.RetrainFreeCriterion"]], "snipcriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.SnipCriterion"]], "snipmomentumcriterion (class in neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.SnipMomentumCriterion"]], "get_criterion() (in module neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.get_criterion"]], "neural_compressor.compression.pruner.criteria": [[198, "module-neural_compressor.compression.pruner.criteria"]], "register_criterion() (in module neural_compressor.compression.pruner.criteria)": [[198, "neural_compressor.compression.pruner.criteria.register_criterion"]], "scores (neural_compressor.compression.pruner.criteria.blockmaskcriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.BlockMaskCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.gradientcriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.GradientCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.magnitudecriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.MagnitudeCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.pruningcriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.PruningCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.retrainfreecriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.RetrainFreeCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.snipcriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.SnipCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.snipmomentumcriterion attribute)": [[198, "neural_compressor.compression.pruner.criteria.SnipMomentumCriterion.scores"]], "dsnot() (in module neural_compressor.compression.pruner.dsnot)": [[199, "neural_compressor.compression.pruner.dsnot.DSnoT"]], "neural_compressor.compression.pruner.dsnot": [[199, "module-neural_compressor.compression.pruner.dsnot"]], "return_reorder_indice() (in module neural_compressor.compression.pruner.dsnot)": [[199, "neural_compressor.compression.pruner.dsnot.return_reorder_indice"]], "neural_compressor.compression.pruner": [[200, "module-neural_compressor.compression.pruner"]], "prepare_pruning() (in module neural_compressor.compression.pruner)": [[200, "neural_compressor.compression.pruner.prepare_pruning"]], "save() (in module neural_compressor.compression.pruner)": [[200, "neural_compressor.compression.pruner.save"]], "generate_ffn2_pruning_config() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[201, "neural_compressor.compression.pruner.model_slim.auto_slim.generate_ffn2_pruning_config"]], "generate_mha_pruning_config() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[201, "neural_compressor.compression.pruner.model_slim.auto_slim.generate_mha_pruning_config"]], "model_slim() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[201, "neural_compressor.compression.pruner.model_slim.auto_slim.model_slim"]], "model_slim_ffn2() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[201, "neural_compressor.compression.pruner.model_slim.auto_slim.model_slim_ffn2"]], "model_slim_mha() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[201, "neural_compressor.compression.pruner.model_slim.auto_slim.model_slim_mha"]], "neural_compressor.compression.pruner.model_slim.auto_slim": [[201, "module-neural_compressor.compression.pruner.model_slim.auto_slim"]], "parse_auto_slim_config() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[201, "neural_compressor.compression.pruner.model_slim.auto_slim.parse_auto_slim_config"]], "neural_compressor.compression.pruner.model_slim": [[202, "module-neural_compressor.compression.pruner.model_slim"]], "classifierheadsearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher"]], "classifierheadsearchertf (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF"]], "jitbasicsearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher"]], "linear2linearsearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher"]], "recipesearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher"]], "selfmhasearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher"]], "current_pattern (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.current_pattern"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.device"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.flatten_static_graph"]], "get_attributes() (in module neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.get_attributes"]], "get_common_module() (in module neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.get_common_module"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.model"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer": [[203, "module-neural_compressor.compression.pruner.model_slim.pattern_analyzer"]], "print_iterables() (in module neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.print_iterables"]], "recipe (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.recipe"]], "searching_results (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.searching_results"]], "searching_results (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.searching_results"]], "searching_results (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.searching_results"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.static_graph"]], "target_layers (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.target_layers"]], "target_layers (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.target_layers"]], "target_op_lut (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.target_op_lut"]], "targets (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[203, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.targets"]], "linearcompression (class in neural_compressor.compression.pruner.model_slim.weight_slim)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression"]], "linearcompressioniterator (class in neural_compressor.compression.pruner.model_slim.weight_slim)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompressionIterator"]], "postcompressionutils (class in neural_compressor.compression.pruner.model_slim.weight_slim)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.PostCompressionUtils"]], "device (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompression attribute)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression.device"]], "layer_1 (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompression attribute)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression.layer_1"]], "layer_2 (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompression attribute)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression.layer_2"]], "linear_patterns (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompressioniterator attribute)": [[204, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompressionIterator.linear_patterns"]], "neural_compressor.compression.pruner.model_slim.weight_slim": [[204, "module-neural_compressor.compression.pruner.model_slim.weight_slim"]], "basepattern (class in neural_compressor.compression.pruner.patterns.base)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern"]], "kerasbasepattern (class in neural_compressor.compression.pruner.patterns.base)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern"]], "pytorchbasepattern (class in neural_compressor.compression.pruner.patterns.base)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern"]], "config (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.config"]], "config (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.config"]], "config (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.config"]], "invalid_layers (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.invalid_layers"]], "invalid_layers (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.invalid_layers"]], "invalid_layers (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.invalid_layers"]], "is_global (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.is_global"]], "is_global (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.is_global"]], "is_global (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.is_global"]], "keep_mask_layers (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.keep_mask_layers"]], "keep_mask_layers (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.keep_mask_layers"]], "keep_mask_layers (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.keep_mask_layers"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.max_sparsity_ratio_per_op"]], "min_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.min_sparsity_ratio_per_op"]], "min_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.min_sparsity_ratio_per_op"]], "min_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.min_sparsity_ratio_per_op"]], "modules (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.modules"]], "modules (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.modules"]], "modules (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.modules"]], "neural_compressor.compression.pruner.patterns.base": [[205, "module-neural_compressor.compression.pruner.patterns.base"]], "pattern (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.pattern"]], "pattern (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.pattern"]], "pattern (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.pattern"]], "register_pattern() (in module neural_compressor.compression.pruner.patterns.base)": [[205, "neural_compressor.compression.pruner.patterns.base.register_pattern"]], "target_sparsity (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.BasePattern.target_sparsity"]], "target_sparsity (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.target_sparsity"]], "target_sparsity (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[205, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.target_sparsity"]], "get_pattern() (in module neural_compressor.compression.pruner.patterns)": [[206, "neural_compressor.compression.pruner.patterns.get_pattern"]], "neural_compressor.compression.pruner.patterns": [[206, "module-neural_compressor.compression.pruner.patterns"]], "m (neural_compressor.compression.pruner.patterns.mha.patternmha attribute)": [[207, "neural_compressor.compression.pruner.patterns.mha.PatternMHA.M"]], "n (neural_compressor.compression.pruner.patterns.mha.patternmha attribute)": [[207, "neural_compressor.compression.pruner.patterns.mha.PatternMHA.N"]], "patternmha (class in neural_compressor.compression.pruner.patterns.mha)": [[207, "neural_compressor.compression.pruner.patterns.mha.PatternMHA"]], "neural_compressor.compression.pruner.patterns.mha": [[207, "module-neural_compressor.compression.pruner.patterns.mha"]], "m (neural_compressor.compression.pruner.patterns.ninm.pytorchpatternninm attribute)": [[208, "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM.M"]], "n (neural_compressor.compression.pruner.patterns.ninm.pytorchpatternninm attribute)": [[208, "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM.N"]], "pytorchpatternninm (class in neural_compressor.compression.pruner.patterns.ninm)": [[208, "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM"]], "neural_compressor.compression.pruner.patterns.ninm": [[208, "module-neural_compressor.compression.pruner.patterns.ninm"]], "keraspatternnxm (class in neural_compressor.compression.pruner.patterns.nxm)": [[209, "neural_compressor.compression.pruner.patterns.nxm.KerasPatternNxM"]], "pytorchpatternnxm (class in neural_compressor.compression.pruner.patterns.nxm)": [[209, "neural_compressor.compression.pruner.patterns.nxm.PytorchPatternNxM"]], "block_size (neural_compressor.compression.pruner.patterns.nxm.keraspatternnxm attribute)": [[209, "neural_compressor.compression.pruner.patterns.nxm.KerasPatternNxM.block_size"]], "block_size (neural_compressor.compression.pruner.patterns.nxm.pytorchpatternnxm attribute)": [[209, "neural_compressor.compression.pruner.patterns.nxm.PytorchPatternNxM.block_size"]], "neural_compressor.compression.pruner.patterns.nxm": [[209, "module-neural_compressor.compression.pruner.patterns.nxm"]], "basepruner (class in neural_compressor.compression.pruner.pruners.base)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner"]], "kerasbasepruner (class in neural_compressor.compression.pruner.pruners.base)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner"]], "pytorchbasepruner (class in neural_compressor.compression.pruner.pruners.base)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner"]], "config (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.config"]], "config (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.config"]], "config (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.config"]], "current_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.current_sparsity_ratio"]], "current_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.current_sparsity_ratio"]], "current_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.current_sparsity_ratio"]], "end_step (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.end_step"]], "end_step (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.end_step"]], "end_step (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.end_step"]], "global_step (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.global_step"]], "global_step (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.global_step"]], "global_step (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.global_step"]], "masks (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.masks"]], "masks (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.masks"]], "masks (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.masks"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.max_sparsity_ratio_per_op"]], "modules (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.modules"]], "modules (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.modules"]], "modules (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.modules"]], "neural_compressor.compression.pruner.pruners.base": [[210, "module-neural_compressor.compression.pruner.pruners.base"]], "pattern (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.pattern"]], "pattern (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.pattern"]], "pattern (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.pattern"]], "pruning_frequency (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.pruning_frequency"]], "pruning_frequency (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.pruning_frequency"]], "pruning_frequency (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.pruning_frequency"]], "register_pruner() (in module neural_compressor.compression.pruner.pruners.base)": [[210, "neural_compressor.compression.pruner.pruners.base.register_pruner"]], "scheduler (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.scheduler"]], "scheduler (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.scheduler"]], "scheduler (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.scheduler"]], "scores (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.scores"]], "scores (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.scores"]], "scores (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.scores"]], "start_step (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.start_step"]], "start_step (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.start_step"]], "start_step (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.start_step"]], "target_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.BasePruner.target_sparsity_ratio"]], "target_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.target_sparsity_ratio"]], "target_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.target_sparsity_ratio"]], "kerasbasicpruner (class in neural_compressor.compression.pruner.pruners.basic)": [[211, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner"]], "pytorchbasicpruner (class in neural_compressor.compression.pruner.pruners.basic)": [[211, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner"]], "criterion (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.criterion"]], "criterion (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.criterion"]], "neural_compressor.compression.pruner.pruners.basic": [[211, "module-neural_compressor.compression.pruner.pruners.basic"]], "pattern (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.pattern"]], "pattern (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.reg"]], "reg (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.scheduler"]], "scheduler (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[211, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.scheduler"]], "pytorchblockmaskpruner (class in neural_compressor.compression.pruner.pruners.block_mask)": [[212, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner"]], "criterion (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.criterion"]], "neural_compressor.compression.pruner.pruners.block_mask": [[212, "module-neural_compressor.compression.pruner.pruners.block_mask"]], "pattern (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.scheduler"]], "get_pruner() (in module neural_compressor.compression.pruner.pruners)": [[213, "neural_compressor.compression.pruner.pruners.get_pruner"]], "neural_compressor.compression.pruner.pruners": [[213, "module-neural_compressor.compression.pruner.pruners"]], "parse_valid_pruner_types() (in module neural_compressor.compression.pruner.pruners)": [[213, "neural_compressor.compression.pruner.pruners.parse_valid_pruner_types"]], "pythonmultiheadattentionpruner (class in neural_compressor.compression.pruner.pruners.mha)": [[214, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner"]], "head_masks (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[214, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.head_masks"]], "linear_layers (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[214, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.linear_layers"]], "mha_compressions (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[214, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.mha_compressions"]], "mha_scores (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[214, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.mha_scores"]], "neural_compressor.compression.pruner.pruners.mha": [[214, "module-neural_compressor.compression.pruner.pruners.mha"]], "pytorchpatternlockpruner (class in neural_compressor.compression.pruner.pruners.pattern_lock)": [[215, "neural_compressor.compression.pruner.pruners.pattern_lock.PytorchPatternLockPruner"]], "neural_compressor.compression.pruner.pruners.pattern_lock": [[215, "module-neural_compressor.compression.pruner.pruners.pattern_lock"]], "pytorchprogressivepruner (class in neural_compressor.compression.pruner.pruners.progressive)": [[216, "neural_compressor.compression.pruner.pruners.progressive.PytorchProgressivePruner"]], "neural_compressor.compression.pruner.pruners.progressive": [[216, "module-neural_compressor.compression.pruner.pruners.progressive"]], "pytorchretrainfreepruner (class in neural_compressor.compression.pruner.pruners.retrain_free)": [[217, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner"]], "criterion (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[217, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.criterion"]], "neural_compressor.compression.pruner.pruners.retrain_free": [[217, "module-neural_compressor.compression.pruner.pruners.retrain_free"]], "pattern (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[217, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[217, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[217, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.scheduler"]], "sparsegptpruner (class in neural_compressor.compression.pruner.pruners.sparse_gpt)": [[218, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner"]], "criterion (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[218, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.criterion"]], "neural_compressor.compression.pruner.pruners.sparse_gpt": [[218, "module-neural_compressor.compression.pruner.pruners.sparse_gpt"]], "pattern (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[218, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[218, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[218, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.scheduler"]], "basepruning (class in neural_compressor.compression.pruner.pruning)": [[219, "neural_compressor.compression.pruner.pruning.BasePruning"]], "basicpruning (class in neural_compressor.compression.pruner.pruning)": [[219, "neural_compressor.compression.pruner.pruning.BasicPruning"]], "retrainfreepruning (class in neural_compressor.compression.pruner.pruning)": [[219, "neural_compressor.compression.pruner.pruning.RetrainFreePruning"]], "sparsegptpruning (class in neural_compressor.compression.pruner.pruning)": [[219, "neural_compressor.compression.pruner.pruning.SparseGPTPruning"]], "config_file_path (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasePruning.config_file_path"]], "config_file_path (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasicPruning.config_file_path"]], "config_file_path (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.config_file_path"]], "model (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasePruning.model"]], "model (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasicPruning.model"]], "model (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.model"]], "neural_compressor.compression.pruner.pruning": [[219, "module-neural_compressor.compression.pruner.pruning"]], "pruner_info (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasePruning.pruner_info"]], "pruner_info (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasicPruning.pruner_info"]], "pruner_info (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.pruner_info"]], "pruners (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasePruning.pruners"]], "pruners (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.BasicPruning.pruners"]], "pruners (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[219, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.pruners"]], "register_pruning() (in module neural_compressor.compression.pruner.pruning)": [[219, "neural_compressor.compression.pruner.pruning.register_pruning"]], "basereg (class in neural_compressor.compression.pruner.regs)": [[220, "neural_compressor.compression.pruner.regs.BaseReg"]], "grouplasso (class in neural_compressor.compression.pruner.regs)": [[220, "neural_compressor.compression.pruner.regs.GroupLasso"]], "alpha (neural_compressor.compression.pruner.regs.grouplasso attribute)": [[220, "neural_compressor.compression.pruner.regs.GroupLasso.alpha"]], "get_reg() (in module neural_compressor.compression.pruner.regs)": [[220, "neural_compressor.compression.pruner.regs.get_reg"]], "get_reg_type() (in module neural_compressor.compression.pruner.regs)": [[220, "neural_compressor.compression.pruner.regs.get_reg_type"]], "neural_compressor.compression.pruner.regs": [[220, "module-neural_compressor.compression.pruner.regs"]], "reg_terms (neural_compressor.compression.pruner.regs.grouplasso attribute)": [[220, "neural_compressor.compression.pruner.regs.GroupLasso.reg_terms"]], "register_reg() (in module neural_compressor.compression.pruner.regs)": [[220, "neural_compressor.compression.pruner.regs.register_reg"]], "iterativescheduler (class in neural_compressor.compression.pruner.schedulers)": [[221, "neural_compressor.compression.pruner.schedulers.IterativeScheduler"]], "oneshotscheduler (class in neural_compressor.compression.pruner.schedulers)": [[221, "neural_compressor.compression.pruner.schedulers.OneshotScheduler"]], "pruningscheduler (class in neural_compressor.compression.pruner.schedulers)": [[221, "neural_compressor.compression.pruner.schedulers.PruningScheduler"]], "config (neural_compressor.compression.pruner.schedulers.pruningscheduler attribute)": [[221, "neural_compressor.compression.pruner.schedulers.PruningScheduler.config"]], "get_scheduler() (in module neural_compressor.compression.pruner.schedulers)": [[221, "neural_compressor.compression.pruner.schedulers.get_scheduler"]], "neural_compressor.compression.pruner.schedulers": [[221, "module-neural_compressor.compression.pruner.schedulers"]], "register_scheduler() (in module neural_compressor.compression.pruner.schedulers)": [[221, "neural_compressor.compression.pruner.schedulers.register_scheduler"]], "magnitudecriterion (class in neural_compressor.compression.pruner.tf_criteria)": [[222, "neural_compressor.compression.pruner.tf_criteria.MagnitudeCriterion"]], "pruningcriterion (class in neural_compressor.compression.pruner.tf_criteria)": [[222, "neural_compressor.compression.pruner.tf_criteria.PruningCriterion"]], "get_tf_criterion() (in module neural_compressor.compression.pruner.tf_criteria)": [[222, "neural_compressor.compression.pruner.tf_criteria.get_tf_criterion"]], "neural_compressor.compression.pruner.tf_criteria": [[222, "module-neural_compressor.compression.pruner.tf_criteria"]], "register_criterion() (in module neural_compressor.compression.pruner.tf_criteria)": [[222, "neural_compressor.compression.pruner.tf_criteria.register_criterion"]], "scores (neural_compressor.compression.pruner.tf_criteria.magnitudecriterion attribute)": [[222, "neural_compressor.compression.pruner.tf_criteria.MagnitudeCriterion.scores"]], "scores (neural_compressor.compression.pruner.tf_criteria.pruningcriterion attribute)": [[222, "neural_compressor.compression.pruner.tf_criteria.PruningCriterion.scores"]], "check_config() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.check_config"]], "check_key_validity() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.check_key_validity"]], "collect_layer_inputs() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.collect_layer_inputs"]], "generate_pruner_config() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.generate_pruner_config"]], "get_layers() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.get_layers"]], "get_sparsity_ratio() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.get_sparsity_ratio"]], "get_sparsity_ratio_tf() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.get_sparsity_ratio_tf"]], "neural_compressor.compression.pruner.utils": [[223, "module-neural_compressor.compression.pruner.utils"]], "parse_last_linear() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.parse_last_linear"]], "parse_last_linear_tf() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.parse_last_linear_tf"]], "parse_to_prune() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.parse_to_prune"]], "parse_to_prune_tf() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.parse_to_prune_tf"]], "process_and_check_config() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.process_and_check_config"]], "process_config() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.process_config"]], "process_weight_config() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.process_weight_config"]], "process_yaml_config() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.process_yaml_config"]], "reset_none_to_default() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.reset_none_to_default"]], "update_params() (in module neural_compressor.compression.pruner.utils)": [[223, "neural_compressor.compression.pruner.utils.update_params"]], "neural_compressor.compression.pruner.wanda": [[224, "module-neural_compressor.compression.pruner.wanda"]], "neural_compressor.compression.pruner.wanda.prune": [[225, "module-neural_compressor.compression.pruner.wanda.prune"]], "prune_wanda() (in module neural_compressor.compression.pruner.wanda.prune)": [[225, "neural_compressor.compression.pruner.wanda.prune.prune_wanda"]], "find_layers() (in module neural_compressor.compression.pruner.wanda.utils)": [[226, "neural_compressor.compression.pruner.wanda.utils.find_layers"]], "neural_compressor.compression.pruner.wanda.utils": [[226, "module-neural_compressor.compression.pruner.wanda.utils"]], "wrappedgpt (class in neural_compressor.compression.pruner.wanda.wrapper)": [[227, "neural_compressor.compression.pruner.wanda.wrapper.WrappedGPT"]], "neural_compressor.compression.pruner.wanda.wrapper": [[227, "module-neural_compressor.compression.pruner.wanda.wrapper"]], "benchmark_conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.Benchmark_Conf"]], "conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.Conf"]], "distillation_conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.Distillation_Conf"]], "graph_optimization_conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.Graph_Optimization_Conf"]], "mixedprecision_conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.MixedPrecision_Conf"]], "nasconfig (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.NASConfig"]], "prunerv2 (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.PrunerV2"]], "pruning_conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.Pruning_Conf"]], "quantization_conf (class in neural_compressor.conf.config)": [[228, "neural_compressor.conf.config.Quantization_Conf"]], "neural_compressor.conf.config": [[228, "module-neural_compressor.conf.config"]], "dotdict (class in neural_compressor.conf.dotdict)": [[229, "neural_compressor.conf.dotdict.DotDict"]], "deep_get() (in module neural_compressor.conf.dotdict)": [[229, "neural_compressor.conf.dotdict.deep_get"]], "deep_set() (in module neural_compressor.conf.dotdict)": [[229, "neural_compressor.conf.dotdict.deep_set"]], "neural_compressor.conf.dotdict": [[229, "module-neural_compressor.conf.dotdict"]], "neural_compressor.conf": [[230, "module-neural_compressor.conf"]], "accuracycriterion (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.AccuracyCriterion"]], "benchmarkconfig (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.BenchmarkConfig"]], "distillationconfig (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.DistillationConfig"]], "knowledgedistillationlossconfig (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.KnowledgeDistillationLossConfig"]], "options (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.Options"]], "quantizationconfig (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.QuantizationConfig"]], "weightpruningconfig (class in neural_compressor.conf.pythonic_config)": [[231, "neural_compressor.conf.pythonic_config.WeightPruningConfig"]], "neural_compressor.conf.pythonic_config": [[231, "module-neural_compressor.conf.pythonic_config"]], "accuracycriterion (class in neural_compressor.config)": [[232, "neural_compressor.config.AccuracyCriterion"]], "benchmarkconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.BenchmarkConfig"]], "distillationconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.DistillationConfig"]], "dotdict (class in neural_compressor.config)": [[232, "neural_compressor.config.DotDict"]], "exportconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.ExportConfig"]], "hpoconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.HPOConfig"]], "intermediatelayersknowledgedistillationlossconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.IntermediateLayersKnowledgeDistillationLossConfig"]], "keras (class in neural_compressor.config)": [[232, "neural_compressor.config.Keras"]], "knowledgedistillationlossconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.KnowledgeDistillationLossConfig"]], "mxnet (class in neural_compressor.config)": [[232, "neural_compressor.config.MXNet"]], "mixedprecisionconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.MixedPrecisionConfig"]], "nasconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.NASConfig"]], "onnx (class in neural_compressor.config)": [[232, "neural_compressor.config.ONNX"]], "onnxqlinear2qdqconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.ONNXQlinear2QDQConfig"]], "options (class in neural_compressor.config)": [[232, "neural_compressor.config.Options"]], "posttrainingquantconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.PostTrainingQuantConfig"]], "pytorch (class in neural_compressor.config)": [[232, "neural_compressor.config.PyTorch"]], "quantizationawaretrainingconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.QuantizationAwareTrainingConfig"]], "selfknowledgedistillationlossconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.SelfKnowledgeDistillationLossConfig"]], "tf2onnxconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.TF2ONNXConfig"]], "tensorflow (class in neural_compressor.config)": [[232, "neural_compressor.config.TensorFlow"]], "torch2onnxconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.Torch2ONNXConfig"]], "tuningcriterion (class in neural_compressor.config)": [[232, "neural_compressor.config.TuningCriterion"]], "weightpruningconfig (class in neural_compressor.config)": [[232, "neural_compressor.config.WeightPruningConfig"]], "neural_compressor.config": [[232, "module-neural_compressor.config"]], "neural_compressor.contrib": [[233, "module-neural_compressor.contrib"]], "neural_compressor.contrib.strategy": [[234, "module-neural_compressor.contrib.strategy"]], "sigopttunestrategy (class in neural_compressor.contrib.strategy.sigopt)": [[235, "neural_compressor.contrib.strategy.sigopt.SigOptTuneStrategy"]], "neural_compressor.contrib.strategy.sigopt": [[235, "module-neural_compressor.contrib.strategy.sigopt"]], "tpetunestrategy (class in neural_compressor.contrib.strategy.tpe)": [[236, "neural_compressor.contrib.strategy.tpe.TpeTuneStrategy"]], "neural_compressor.contrib.strategy.tpe": [[236, "module-neural_compressor.contrib.strategy.tpe"]], "basedataloader (class in neural_compressor.data.dataloaders.base_dataloader)": [[237, "neural_compressor.data.dataloaders.base_dataloader.BaseDataLoader"]], "neural_compressor.data.dataloaders.base_dataloader": [[237, "module-neural_compressor.data.dataloaders.base_dataloader"]], "dataloader (class in neural_compressor.data.dataloaders.dataloader)": [[238, "neural_compressor.data.dataloaders.dataloader.DataLoader"]], "check_dataloader() (in module neural_compressor.data.dataloaders.dataloader)": [[238, "neural_compressor.data.dataloaders.dataloader.check_dataloader"]], "neural_compressor.data.dataloaders.dataloader": [[238, "module-neural_compressor.data.dataloaders.dataloader"]], "defaultdataloader (class in neural_compressor.data.dataloaders.default_dataloader)": [[239, "neural_compressor.data.dataloaders.default_dataloader.DefaultDataLoader"]], "default_collate() (in module neural_compressor.data.dataloaders.default_dataloader)": [[239, "neural_compressor.data.dataloaders.default_dataloader.default_collate"]], "neural_compressor.data.dataloaders.default_dataloader": [[239, "module-neural_compressor.data.dataloaders.default_dataloader"]], "fetcher (class in neural_compressor.data.dataloaders.fetcher)": [[240, "neural_compressor.data.dataloaders.fetcher.Fetcher"]], "indexfetcher (class in neural_compressor.data.dataloaders.fetcher)": [[240, "neural_compressor.data.dataloaders.fetcher.IndexFetcher"]], "iterablefetcher (class in neural_compressor.data.dataloaders.fetcher)": [[240, "neural_compressor.data.dataloaders.fetcher.IterableFetcher"]], "neural_compressor.data.dataloaders.fetcher": [[240, "module-neural_compressor.data.dataloaders.fetcher"]], "neural_compressor.data.dataloaders": [[241, "module-neural_compressor.data.dataloaders"]], "mxnetdataloader (class in neural_compressor.data.dataloaders.mxnet_dataloader)": [[242, "neural_compressor.data.dataloaders.mxnet_dataloader.MXNetDataLoader"]], "neural_compressor.data.dataloaders.mxnet_dataloader": [[242, "module-neural_compressor.data.dataloaders.mxnet_dataloader"]], "onnxrtbertdataloader (class in neural_compressor.data.dataloaders.onnxrt_dataloader)": [[243, "neural_compressor.data.dataloaders.onnxrt_dataloader.ONNXRTBertDataLoader"]], "onnxrtdataloader (class in neural_compressor.data.dataloaders.onnxrt_dataloader)": [[243, "neural_compressor.data.dataloaders.onnxrt_dataloader.ONNXRTDataLoader"]], "neural_compressor.data.dataloaders.onnxrt_dataloader": [[243, "module-neural_compressor.data.dataloaders.onnxrt_dataloader"]], "pytorchdataloader (class in neural_compressor.data.dataloaders.pytorch_dataloader)": [[244, "neural_compressor.data.dataloaders.pytorch_dataloader.PyTorchDataLoader"]], "neural_compressor.data.dataloaders.pytorch_dataloader": [[244, "module-neural_compressor.data.dataloaders.pytorch_dataloader"]], "batchsampler (class in neural_compressor.data.dataloaders.sampler)": [[245, "neural_compressor.data.dataloaders.sampler.BatchSampler"]], "iterablesampler (class in neural_compressor.data.dataloaders.sampler)": [[245, "neural_compressor.data.dataloaders.sampler.IterableSampler"]], "sampler (class in neural_compressor.data.dataloaders.sampler)": [[245, "neural_compressor.data.dataloaders.sampler.Sampler"]], "sequentialsampler (class in neural_compressor.data.dataloaders.sampler)": [[245, "neural_compressor.data.dataloaders.sampler.SequentialSampler"]], "neural_compressor.data.dataloaders.sampler": [[245, "module-neural_compressor.data.dataloaders.sampler"]], "tfdatadataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[246, "neural_compressor.data.dataloaders.tensorflow_dataloader.TFDataDataLoader"]], "tensorflowbertdataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[246, "neural_compressor.data.dataloaders.tensorflow_dataloader.TensorflowBertDataLoader"]], "tensorflowdataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[246, "neural_compressor.data.dataloaders.tensorflow_dataloader.TensorflowDataLoader"]], "tensorflowmodelzoobertdataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[246, "neural_compressor.data.dataloaders.tensorflow_dataloader.TensorflowModelZooBertDataLoader"]], "neural_compressor.data.dataloaders.tensorflow_dataloader": [[246, "module-neural_compressor.data.dataloaders.tensorflow_dataloader"]], "inputfeatures (class in neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.InputFeatures"]], "onnxrtbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.ONNXRTBertDataset"]], "parsedecodebert (class in neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.ParseDecodeBert"]], "pytorchbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.PytorchBertDataset"]], "tensorflowbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.TensorflowBertDataset"]], "tensorflowmodelzoobertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.TensorflowModelZooBertDataset"]], "convert_examples_to_features() (in module neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.convert_examples_to_features"]], "load_and_cache_examples() (in module neural_compressor.data.datasets.bert_dataset)": [[247, "neural_compressor.data.datasets.bert_dataset.load_and_cache_examples"]], "neural_compressor.data.datasets.bert_dataset": [[247, "module-neural_compressor.data.datasets.bert_dataset"]], "coconpy (class in neural_compressor.data.datasets.coco_dataset)": [[248, "neural_compressor.data.datasets.coco_dataset.COCONpy"]], "cocoraw (class in neural_compressor.data.datasets.coco_dataset)": [[248, "neural_compressor.data.datasets.coco_dataset.COCORaw"]], "cocorecorddataset (class in neural_compressor.data.datasets.coco_dataset)": [[248, "neural_compressor.data.datasets.coco_dataset.COCORecordDataset"]], "parsedecodecoco (class in neural_compressor.data.datasets.coco_dataset)": [[248, "neural_compressor.data.datasets.coco_dataset.ParseDecodeCoco"]], "neural_compressor.data.datasets.coco_dataset": [[248, "module-neural_compressor.data.datasets.coco_dataset"]], "cifar10 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.CIFAR10"]], "cifar100 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.CIFAR100"]], "dataset (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.Dataset"]], "datasets (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.Datasets"]], "fashionmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.FashionMNIST"]], "imagefolder (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.ImageFolder"]], "iterabledataset (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.IterableDataset"]], "mnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MNIST"]], "mxnetcifar10 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MXNetCIFAR10"]], "mxnetcifar100 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MXNetCIFAR100"]], "mxnetdatasets (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MXNetDatasets"]], "mxnetfashionmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MXNetFashionMNIST"]], "mxnetimagefolder (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MXNetImageFolder"]], "mxnetmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.MXNetMNIST"]], "onnxrtitdatasets (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.ONNXRTITDatasets"]], "onnxrtqldatasets (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.ONNXRTQLDatasets"]], "pytorchdatasets (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PyTorchDatasets"]], "pytorchcifar10 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PytorchCIFAR10"]], "pytorchcifar100 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PytorchCIFAR100"]], "pytorchfashionmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PytorchFashionMNIST"]], "pytorchmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PytorchMNIST"]], "pytorchmxnetwrapdataset (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PytorchMxnetWrapDataset"]], "pytorchmxnetwrapfunction (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.PytorchMxnetWrapFunction"]], "tensorflow (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.Tensorflow"]], "tensorflowcifar10 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowCIFAR10"]], "tensorflowcifar100 (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowCIFAR100"]], "tensorflowdatasets (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowDatasets"]], "tensorflowfashionmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowFashionMNIST"]], "tensorflowimagerecord (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowImageRecord"]], "tensorflowmnist (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowMNIST"]], "tensorflowtfrecorddataset (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowTFRecordDataset"]], "tensorflowvocrecord (class in neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.TensorflowVOCRecord"]], "calculate_md5() (in module neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.calculate_md5"]], "check_integrity() (in module neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.check_integrity"]], "dataset_registry() (in module neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.dataset_registry"]], "download_url() (in module neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.download_url"]], "framework_datasets (in module neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.framework_datasets"]], "gen_bar_updater() (in module neural_compressor.data.datasets.dataset)": [[249, "neural_compressor.data.datasets.dataset.gen_bar_updater"]], "neural_compressor.data.datasets.dataset": [[249, "module-neural_compressor.data.datasets.dataset"]], "dummydataset (class in neural_compressor.data.datasets.dummy_dataset)": [[250, "neural_compressor.data.datasets.dummy_dataset.DummyDataset"]], "neural_compressor.data.datasets.dummy_dataset": [[250, "module-neural_compressor.data.datasets.dummy_dataset"]], "dummydataset (class in neural_compressor.data.datasets.dummy_dataset_v2)": [[251, "neural_compressor.data.datasets.dummy_dataset_v2.DummyDataset"]], "sparsedummydataset (class in neural_compressor.data.datasets.dummy_dataset_v2)": [[251, "neural_compressor.data.datasets.dummy_dataset_v2.SparseDummyDataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[251, "module-neural_compressor.data.datasets.dummy_dataset_v2"]], "imagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[252, "neural_compressor.data.datasets.imagenet_dataset.ImagenetRaw"]], "mxnetimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[252, "neural_compressor.data.datasets.imagenet_dataset.MXNetImagenetRaw"]], "onnxrtimagenetdataset (class in neural_compressor.data.datasets.imagenet_dataset)": [[252, "neural_compressor.data.datasets.imagenet_dataset.ONNXRTImagenetDataset"]], "pytorchimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[252, "neural_compressor.data.datasets.imagenet_dataset.PytorchImagenetRaw"]], "tensorflowimagenetdataset (class in neural_compressor.data.datasets.imagenet_dataset)": [[252, "neural_compressor.data.datasets.imagenet_dataset.TensorflowImagenetDataset"]], "tensorflowimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[252, "neural_compressor.data.datasets.imagenet_dataset.TensorflowImagenetRaw"]], "neural_compressor.data.datasets.imagenet_dataset": [[252, "module-neural_compressor.data.datasets.imagenet_dataset"]], "neural_compressor.data.datasets": [[253, "module-neural_compressor.data.datasets"]], "styletransferdataset (class in neural_compressor.data.datasets.style_transfer_dataset)": [[254, "neural_compressor.data.datasets.style_transfer_dataset.StyleTransferDataset"]], "neural_compressor.data.datasets.style_transfer_dataset": [[254, "module-neural_compressor.data.datasets.style_transfer_dataset"]], "labelbalancecocorawfilter (class in neural_compressor.data.filters.coco_filter)": [[255, "neural_compressor.data.filters.coco_filter.LabelBalanceCOCORawFilter"]], "labelbalancecocorecordfilter (class in neural_compressor.data.filters.coco_filter)": [[255, "neural_compressor.data.filters.coco_filter.LabelBalanceCOCORecordFilter"]], "neural_compressor.data.filters.coco_filter": [[255, "module-neural_compressor.data.filters.coco_filter"]], "filters (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.FILTERS"]], "filter (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.Filter"]], "mxnetfilters (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.MXNetFilters"]], "onnxrtitfilters (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.ONNXRTITFilters"]], "onnxrtqlfilters (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.ONNXRTQLFilters"]], "pytorchfilters (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.PyTorchFilters"]], "tensorflowfilters (class in neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.TensorflowFilters"]], "filter_registry() (in module neural_compressor.data.filters.filter)": [[256, "neural_compressor.data.filters.filter.filter_registry"]], "neural_compressor.data.filters.filter": [[256, "module-neural_compressor.data.filters.filter"]], "neural_compressor.data.filters": [[257, "module-neural_compressor.data.filters"]], "neural_compressor.data": [[258, "module-neural_compressor.data"]], "parsedecodecocotransform (class in neural_compressor.data.transforms.coco_transform)": [[259, "neural_compressor.data.transforms.coco_transform.ParseDecodeCocoTransform"]], "neural_compressor.data.transforms.coco_transform": [[259, "module-neural_compressor.data.transforms.coco_transform"]], "bilinearimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.BilinearImagenetTransform"]], "labelshift (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.LabelShift"]], "onnxresizecropimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.ONNXResizeCropImagenetTransform"]], "onnxbilinearimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.OnnxBilinearImagenetTransform"]], "parsedecodeimagenet (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.ParseDecodeImagenet"]], "parsedecodeimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.ParseDecodeImagenetTransform"]], "quantizedinput (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.QuantizedInput"]], "resizewithaspectratio (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.ResizeWithAspectRatio"]], "tensorflowresizecropimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.TensorflowResizeCropImagenetTransform"]], "tensorflowshiftrescale (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.TensorflowShiftRescale"]], "tensorflowtransposelastchannel (class in neural_compressor.data.transforms.imagenet_transform)": [[260, "neural_compressor.data.transforms.imagenet_transform.TensorflowTransposeLastChannel"]], "neural_compressor.data.transforms.imagenet_transform": [[260, "module-neural_compressor.data.transforms.imagenet_transform"]], "neural_compressor.data.transforms": [[261, "module-neural_compressor.data.transforms"]], "postprocess (class in neural_compressor.data.transforms.postprocess)": [[262, "neural_compressor.data.transforms.postprocess.Postprocess"]], "neural_compressor.data.transforms.postprocess": [[262, "module-neural_compressor.data.transforms.postprocess"]], "basictokenizer (class in neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.BasicTokenizer"]], "fulltokenizer (class in neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.FullTokenizer"]], "wordpiecetokenizer (class in neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.WordpieceTokenizer"]], "convert_by_vocab() (in module neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.convert_by_vocab"]], "convert_to_unicode() (in module neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.convert_to_unicode"]], "load_vocab() (in module neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.load_vocab"]], "neural_compressor.data.transforms.tokenization": [[263, "module-neural_compressor.data.transforms.tokenization"]], "whitespace_tokenize() (in module neural_compressor.data.transforms.tokenization)": [[263, "neural_compressor.data.transforms.tokenization.whitespace_tokenize"]], "alignimagechanneltransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.AlignImageChannelTransform"]], "basetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.BaseTransform"]], "castonnxtransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CastONNXTransform"]], "castpytorchtransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CastPyTorchTransform"]], "casttftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CastTFTransform"]], "centercroptftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CenterCropTFTransform"]], "centercroptransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CenterCropTransform"]], "collecttransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CollectTransform"]], "composetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ComposeTransform"]], "cropresizetftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CropResizeTFTransform"]], "cropresizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CropResizeTransform"]], "croptoboundingbox (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.CropToBoundingBox"]], "inputfeatures (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.InputFeatures"]], "mxnetcropresizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.MXNetCropResizeTransform"]], "mxnetcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.MXNetCropToBoundingBox"]], "mxnetnormalizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.MXNetNormalizeTransform"]], "mxnettransforms (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.MXNetTransforms"]], "mxnettranspose (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.MXNetTranspose"]], "normalizetftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.NormalizeTFTransform"]], "normalizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.NormalizeTransform"]], "onnxrtcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ONNXRTCropToBoundingBox"]], "onnxrtittransforms (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ONNXRTITTransforms"]], "onnxrtqltransforms (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ONNXRTQLTransforms"]], "paddedcentercroptransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PaddedCenterCropTransform"]], "parsedecodevoctransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ParseDecodeVocTransform"]], "pytorchalignimagechannel (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PyTorchAlignImageChannel"]], "pytorchcropresizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PyTorchCropResizeTransform"]], "pytorchnormalizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PyTorchNormalizeTransform"]], "pytorchtransforms (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PyTorchTransforms"]], "pytorchtranspose (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PyTorchTranspose"]], "pytorchmxnettransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PytorchMxnetTransform"]], "pytorchmxnetwrapfunction (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.PytorchMxnetWrapFunction"]], "randomcroptftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomCropTFTransform"]], "randomcroptransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomCropTransform"]], "randomhorizontalflip (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomHorizontalFlip"]], "randomresizedcropmxnettransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomResizedCropMXNetTransform"]], "randomresizedcroppytorchtransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomResizedCropPytorchTransform"]], "randomresizedcroptftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomResizedCropTFTransform"]], "randomresizedcroptransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomResizedCropTransform"]], "randomverticalflip (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RandomVerticalFlip"]], "rescalekeraspretraintransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RescaleKerasPretrainTransform"]], "rescaletftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RescaleTFTransform"]], "rescaletransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.RescaleTransform"]], "resizemxnettransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ResizeMXNetTransform"]], "resizepytorchtransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ResizePytorchTransform"]], "resizetftransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ResizeTFTransform"]], "resizetransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ResizeTransform"]], "resizewithratio (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ResizeWithRatio"]], "squadexample (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.SquadExample"]], "tfmodelzoocollecttransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TFModelZooCollectTransform"]], "tfsquadv1modelzooposttransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TFSquadV1ModelZooPostTransform"]], "tfsquadv1posttransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TFSquadV1PostTransform"]], "transforms (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TRANSFORMS"], [264, "neural_compressor.data.transforms.transform.Transforms"]], "tensorflowcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowCropToBoundingBox"]], "tensorflowrandomhorizontalflip (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowRandomHorizontalFlip"]], "tensorflowrandomverticalflip (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowRandomVerticalFlip"]], "tensorflowresizewithratio (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowResizeWithRatio"]], "tensorflowtransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowTransform"]], "tensorflowtransforms (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowTransforms"]], "tensorflowtranspose (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowTranspose"]], "tensorflowwrapfunction (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.TensorflowWrapFunction"]], "toarray (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ToArray"]], "tondarraytransform (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.ToNDArrayTransform"]], "transpose (class in neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.Transpose"]], "convert_examples_to_features() (in module neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.convert_examples_to_features"]], "get_final_text() (in module neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.get_final_text"]], "get_torchvision_map() (in module neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.get_torchvision_map"]], "neural_compressor.data.transforms.transform": [[264, "module-neural_compressor.data.transforms.transform"]], "read_squad_examples() (in module neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.read_squad_examples"]], "transform_registry() (in module neural_compressor.data.transforms.transform)": [[264, "neural_compressor.data.transforms.transform.transform_registry"]], "benchmark (class in neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.Benchmark"]], "get_architecture() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.get_architecture"]], "get_bounded_threads() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.get_bounded_threads"]], "get_core_ids() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.get_core_ids"]], "get_physical_ids() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.get_physical_ids"]], "get_threads() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.get_threads"]], "get_threads_per_core() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.get_threads_per_core"]], "neural_compressor.experimental.benchmark": [[265, "module-neural_compressor.experimental.benchmark"]], "set_all_env_var() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.set_all_env_var"]], "set_env_var() (in module neural_compressor.experimental.benchmark)": [[265, "neural_compressor.experimental.benchmark.set_env_var"]], "criterions (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.Criterions"]], "intermediatelayersknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.IntermediateLayersKnowledgeDistillationLoss"]], "knowledgedistillationframework (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.KnowledgeDistillationFramework"]], "knowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.KnowledgeDistillationLoss"]], "pytorchcriterions (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.PyTorchCriterions"]], "pytorchintermediatelayersknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.PyTorchIntermediateLayersKnowledgeDistillationLoss"]], "pytorchintermediatelayersknowledgedistillationlosswrapper (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"]], "pytorchknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.PyTorchKnowledgeDistillationLoss"]], "pytorchknowledgedistillationlosswrapper (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.PyTorchKnowledgeDistillationLossWrapper"]], "selfknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.SelfKnowledgeDistillationLoss"]], "tensorflowcriterions (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.TensorflowCriterions"]], "tensorflowknowledgedistillationlossexternal (class in neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.TensorflowKnowledgeDistillationLossExternal"]], "criterion_registry() (in module neural_compressor.experimental.common.criterion)": [[266, "neural_compressor.experimental.common.criterion.criterion_registry"]], "neural_compressor.experimental.common.criterion": [[266, "module-neural_compressor.experimental.common.criterion"]], "dataloader (class in neural_compressor.experimental.common.dataloader)": [[267, "neural_compressor.experimental.common.dataloader.DataLoader"]], "neural_compressor.experimental.common.dataloader": [[267, "module-neural_compressor.experimental.common.dataloader"]], "neural_compressor.experimental.common": [[268, "module-neural_compressor.experimental.common"]], "metric (class in neural_compressor.experimental.common.metric)": [[269, "neural_compressor.experimental.common.metric.Metric"]], "neural_compressor.experimental.common.metric": [[269, "module-neural_compressor.experimental.common.metric"]], "model (class in neural_compressor.experimental.common.model)": [[270, "neural_compressor.experimental.common.model.Model"]], "neural_compressor.experimental.common.model": [[270, "module-neural_compressor.experimental.common.model"]], "set_backend() (in module neural_compressor.experimental.common.model)": [[270, "neural_compressor.experimental.common.model.set_backend"]], "optimizers (class in neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.Optimizers"]], "pytorchoptimizers (class in neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.PyTorchOptimizers"]], "pytorchsgd (class in neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.PyTorchSGD"]], "tensorflowadamw (class in neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.TensorFlowAdamW"]], "tensorflowsgd (class in neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.TensorFlowSGD"]], "tensorflowoptimizers (class in neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.TensorflowOptimizers"]], "neural_compressor.experimental.common.optimizer": [[271, "module-neural_compressor.experimental.common.optimizer"]], "optimizer_registry() (in module neural_compressor.experimental.common.optimizer)": [[271, "neural_compressor.experimental.common.optimizer.optimizer_registry"]], "postprocess (class in neural_compressor.experimental.common.postprocess)": [[272, "neural_compressor.experimental.common.postprocess.Postprocess"]], "neural_compressor.experimental.common.postprocess": [[272, "module-neural_compressor.experimental.common.postprocess"]], "get_activation() (in module neural_compressor.experimental.common.torch_utils)": [[273, "neural_compressor.experimental.common.torch_utils.get_activation"]], "neural_compressor.experimental.common.torch_utils": [[273, "module-neural_compressor.experimental.common.torch_utils"]], "record_output() (in module neural_compressor.experimental.common.torch_utils)": [[273, "neural_compressor.experimental.common.torch_utils.record_output"]], "component (class in neural_compressor.experimental.component)": [[274, "neural_compressor.experimental.component.Component"]], "neural_compressor.experimental.component": [[274, "module-neural_compressor.experimental.component"]], "neural_compressor.experimental.compression": [[275, "module-neural_compressor.experimental.compression"]], "neural_compressor.experimental.contrib": [[276, "module-neural_compressor.experimental.contrib"]], "neural_compressor.experimental.contrib.strategy": [[277, "module-neural_compressor.experimental.contrib.strategy"]], "sigopttunestrategy (class in neural_compressor.experimental.contrib.strategy.sigopt)": [[278, "neural_compressor.experimental.contrib.strategy.sigopt.SigOptTuneStrategy"]], "neural_compressor.experimental.contrib.strategy.sigopt": [[278, "module-neural_compressor.experimental.contrib.strategy.sigopt"]], "tpetunestrategy (class in neural_compressor.experimental.contrib.strategy.tpe)": [[279, "neural_compressor.experimental.contrib.strategy.tpe.TpeTuneStrategy"]], "neural_compressor.experimental.contrib.strategy.tpe": [[279, "module-neural_compressor.experimental.contrib.strategy.tpe"]], "basedataloader (class in neural_compressor.experimental.data.dataloaders.base_dataloader)": [[280, "neural_compressor.experimental.data.dataloaders.base_dataloader.BaseDataLoader"]], "neural_compressor.experimental.data.dataloaders.base_dataloader": [[280, "module-neural_compressor.experimental.data.dataloaders.base_dataloader"]], "neural_compressor.experimental.data.dataloaders.dataloader": [[281, "module-neural_compressor.experimental.data.dataloaders.dataloader"]], "defaultdataloader (class in neural_compressor.experimental.data.dataloaders.default_dataloader)": [[282, "neural_compressor.experimental.data.dataloaders.default_dataloader.DefaultDataLoader"]], "default_collate() (in module neural_compressor.experimental.data.dataloaders.default_dataloader)": [[282, "neural_compressor.experimental.data.dataloaders.default_dataloader.default_collate"]], "neural_compressor.experimental.data.dataloaders.default_dataloader": [[282, "module-neural_compressor.experimental.data.dataloaders.default_dataloader"]], "fetcher (class in neural_compressor.experimental.data.dataloaders.fetcher)": [[283, "neural_compressor.experimental.data.dataloaders.fetcher.Fetcher"]], "indexfetcher (class in neural_compressor.experimental.data.dataloaders.fetcher)": [[283, "neural_compressor.experimental.data.dataloaders.fetcher.IndexFetcher"]], "iterablefetcher (class in neural_compressor.experimental.data.dataloaders.fetcher)": [[283, "neural_compressor.experimental.data.dataloaders.fetcher.IterableFetcher"]], "neural_compressor.experimental.data.dataloaders.fetcher": [[283, "module-neural_compressor.experimental.data.dataloaders.fetcher"]], "neural_compressor.experimental.data.dataloaders": [[284, "module-neural_compressor.experimental.data.dataloaders"]], "mxnetdataloader (class in neural_compressor.experimental.data.dataloaders.mxnet_dataloader)": [[285, "neural_compressor.experimental.data.dataloaders.mxnet_dataloader.MXNetDataLoader"]], "neural_compressor.experimental.data.dataloaders.mxnet_dataloader": [[285, "module-neural_compressor.experimental.data.dataloaders.mxnet_dataloader"]], "onnxrtbertdataloader (class in neural_compressor.experimental.data.dataloaders.onnxrt_dataloader)": [[286, "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader.ONNXRTBertDataLoader"]], "onnxrtdataloader (class in neural_compressor.experimental.data.dataloaders.onnxrt_dataloader)": [[286, "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader.ONNXRTDataLoader"]], "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader": [[286, "module-neural_compressor.experimental.data.dataloaders.onnxrt_dataloader"]], "pytorchdataloader (class in neural_compressor.experimental.data.dataloaders.pytorch_dataloader)": [[287, "neural_compressor.experimental.data.dataloaders.pytorch_dataloader.PyTorchDataLoader"]], "neural_compressor.experimental.data.dataloaders.pytorch_dataloader": [[287, "module-neural_compressor.experimental.data.dataloaders.pytorch_dataloader"]], "batchsampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[288, "neural_compressor.experimental.data.dataloaders.sampler.BatchSampler"]], "iterablesampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[288, "neural_compressor.experimental.data.dataloaders.sampler.IterableSampler"]], "sampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[288, "neural_compressor.experimental.data.dataloaders.sampler.Sampler"]], "sequentialsampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[288, "neural_compressor.experimental.data.dataloaders.sampler.SequentialSampler"]], "neural_compressor.experimental.data.dataloaders.sampler": [[288, "module-neural_compressor.experimental.data.dataloaders.sampler"]], "tfdatadataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[289, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TFDataDataLoader"]], "tensorflowbertdataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[289, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TensorflowBertDataLoader"]], "tensorflowdataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[289, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TensorflowDataLoader"]], "tensorflowmodelzoobertdataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[289, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TensorflowModelZooBertDataLoader"]], "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader": [[289, "module-neural_compressor.experimental.data.dataloaders.tensorflow_dataloader"]], "inputfeatures (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.InputFeatures"]], "onnxrtbertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.ONNXRTBertDataset"]], "parsedecodebert (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.ParseDecodeBert"]], "pytorchbertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.PytorchBertDataset"]], "tensorflowbertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.TensorflowBertDataset"]], "tensorflowmodelzoobertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.TensorflowModelZooBertDataset"]], "convert_examples_to_features() (in module neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.convert_examples_to_features"]], "load_and_cache_examples() (in module neural_compressor.experimental.data.datasets.bert_dataset)": [[290, "neural_compressor.experimental.data.datasets.bert_dataset.load_and_cache_examples"]], "neural_compressor.experimental.data.datasets.bert_dataset": [[290, "module-neural_compressor.experimental.data.datasets.bert_dataset"]], "coconpy (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[291, "neural_compressor.experimental.data.datasets.coco_dataset.COCONpy"]], "cocoraw (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[291, "neural_compressor.experimental.data.datasets.coco_dataset.COCORaw"]], "cocorecorddataset (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[291, "neural_compressor.experimental.data.datasets.coco_dataset.COCORecordDataset"]], "parsedecodecoco (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[291, "neural_compressor.experimental.data.datasets.coco_dataset.ParseDecodeCoco"]], "neural_compressor.experimental.data.datasets.coco_dataset": [[291, "module-neural_compressor.experimental.data.datasets.coco_dataset"]], "cifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.CIFAR10"]], "cifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.CIFAR100"]], "dataset (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.Dataset"]], "datasets (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.Datasets"]], "fashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.FashionMNIST"]], "imagefolder (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.ImageFolder"]], "iterabledataset (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.IterableDataset"]], "mnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MNIST"]], "mxnetcifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MXNetCIFAR10"]], "mxnetcifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MXNetCIFAR100"]], "mxnetdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MXNetDatasets"]], "mxnetfashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MXNetFashionMNIST"]], "mxnetimagefolder (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MXNetImageFolder"]], "mxnetmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.MXNetMNIST"]], "onnxrtitdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.ONNXRTITDatasets"]], "onnxrtqldatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.ONNXRTQLDatasets"]], "pytorchdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PyTorchDatasets"]], "pytorchcifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PytorchCIFAR10"]], "pytorchcifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PytorchCIFAR100"]], "pytorchfashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PytorchFashionMNIST"]], "pytorchmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PytorchMNIST"]], "pytorchmxnetwrapdataset (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PytorchMxnetWrapDataset"]], "pytorchmxnetwrapfunction (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.PytorchMxnetWrapFunction"]], "tensorflowcifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowCIFAR10"]], "tensorflowcifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowCIFAR100"]], "tensorflowdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowDatasets"]], "tensorflowfashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowFashionMNIST"]], "tensorflowimagefolder (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowImageFolder"]], "tensorflowimagerecord (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowImageRecord"]], "tensorflowmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowMNIST"]], "tensorflowtfrecorddataset (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowTFRecordDataset"]], "tensorflowvocrecord (class in neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.TensorflowVOCRecord"]], "calculate_md5() (in module neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.calculate_md5"]], "check_integrity() (in module neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.check_integrity"]], "dataset_registry() (in module neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.dataset_registry"]], "download_url() (in module neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.download_url"]], "framework_datasets (in module neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.framework_datasets"]], "gen_bar_updater() (in module neural_compressor.experimental.data.datasets.dataset)": [[292, "neural_compressor.experimental.data.datasets.dataset.gen_bar_updater"]], "neural_compressor.experimental.data.datasets.dataset": [[292, "module-neural_compressor.experimental.data.datasets.dataset"]], "dummydataset (class in neural_compressor.experimental.data.datasets.dummy_dataset)": [[293, "neural_compressor.experimental.data.datasets.dummy_dataset.DummyDataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset": [[293, "module-neural_compressor.experimental.data.datasets.dummy_dataset"]], "dummydataset (class in neural_compressor.experimental.data.datasets.dummy_dataset_v2)": [[294, "neural_compressor.experimental.data.datasets.dummy_dataset_v2.DummyDataset"]], "sparsedummydataset (class in neural_compressor.experimental.data.datasets.dummy_dataset_v2)": [[294, "neural_compressor.experimental.data.datasets.dummy_dataset_v2.SparseDummyDataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset_v2": [[294, "module-neural_compressor.experimental.data.datasets.dummy_dataset_v2"]], "imagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[295, "neural_compressor.experimental.data.datasets.imagenet_dataset.ImagenetRaw"]], "mxnetimagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[295, "neural_compressor.experimental.data.datasets.imagenet_dataset.MXNetImagenetRaw"]], "onnxrtimagenetdataset (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[295, "neural_compressor.experimental.data.datasets.imagenet_dataset.ONNXRTImagenetDataset"]], "pytorchimagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[295, "neural_compressor.experimental.data.datasets.imagenet_dataset.PytorchImagenetRaw"]], "tensorflowimagenetdataset (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[295, "neural_compressor.experimental.data.datasets.imagenet_dataset.TensorflowImagenetDataset"]], "tensorflowimagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[295, "neural_compressor.experimental.data.datasets.imagenet_dataset.TensorflowImagenetRaw"]], "neural_compressor.experimental.data.datasets.imagenet_dataset": [[295, "module-neural_compressor.experimental.data.datasets.imagenet_dataset"]], "neural_compressor.experimental.data.datasets": [[296, "module-neural_compressor.experimental.data.datasets"]], "styletransferdataset (class in neural_compressor.experimental.data.datasets.style_transfer_dataset)": [[297, "neural_compressor.experimental.data.datasets.style_transfer_dataset.StyleTransferDataset"]], "neural_compressor.experimental.data.datasets.style_transfer_dataset": [[297, "module-neural_compressor.experimental.data.datasets.style_transfer_dataset"]], "labelbalancecocorawfilter (class in neural_compressor.experimental.data.filters.coco_filter)": [[298, "neural_compressor.experimental.data.filters.coco_filter.LabelBalanceCOCORawFilter"]], "labelbalancecocorecordfilter (class in neural_compressor.experimental.data.filters.coco_filter)": [[298, "neural_compressor.experimental.data.filters.coco_filter.LabelBalanceCOCORecordFilter"]], "neural_compressor.experimental.data.filters.coco_filter": [[298, "module-neural_compressor.experimental.data.filters.coco_filter"]], "filters (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.FILTERS"]], "filter (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.Filter"]], "mxnetfilters (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.MXNetFilters"]], "onnxrtitfilters (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.ONNXRTITFilters"]], "onnxrtqlfilters (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.ONNXRTQLFilters"]], "pytorchfilters (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.PyTorchFilters"]], "tensorflowfilters (class in neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.TensorflowFilters"]], "filter_registry() (in module neural_compressor.experimental.data.filters.filter)": [[299, "neural_compressor.experimental.data.filters.filter.filter_registry"]], "neural_compressor.experimental.data.filters.filter": [[299, "module-neural_compressor.experimental.data.filters.filter"]], "neural_compressor.experimental.data.filters": [[300, "module-neural_compressor.experimental.data.filters"]], "neural_compressor.experimental.data": [[301, "module-neural_compressor.experimental.data"]], "bilinearimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.BilinearImagenetTransform"]], "labelshift (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.LabelShift"]], "onnxresizecropimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.ONNXResizeCropImagenetTransform"]], "onnxbilinearimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.OnnxBilinearImagenetTransform"]], "parsedecodeimagenet (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.ParseDecodeImagenet"]], "parsedecodeimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.ParseDecodeImagenetTransform"]], "quantizedinput (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.QuantizedInput"]], "resizewithaspectratio (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.ResizeWithAspectRatio"]], "tensorflowresizecropimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[302, "neural_compressor.experimental.data.transforms.imagenet_transform.TensorflowResizeCropImagenetTransform"]], "neural_compressor.experimental.data.transforms.imagenet_transform": [[302, "module-neural_compressor.experimental.data.transforms.imagenet_transform"]], "neural_compressor.experimental.data.transforms": [[303, "module-neural_compressor.experimental.data.transforms"]], "basictokenizer (class in neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.BasicTokenizer"]], "fulltokenizer (class in neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.FullTokenizer"]], "wordpiecetokenizer (class in neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.WordpieceTokenizer"]], "convert_by_vocab() (in module neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.convert_by_vocab"]], "convert_to_unicode() (in module neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.convert_to_unicode"]], "load_vocab() (in module neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.load_vocab"]], "neural_compressor.experimental.data.transforms.tokenization": [[304, "module-neural_compressor.experimental.data.transforms.tokenization"]], "whitespace_tokenize() (in module neural_compressor.experimental.data.transforms.tokenization)": [[304, "neural_compressor.experimental.data.transforms.tokenization.whitespace_tokenize"]], "alignimagechanneltransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.AlignImageChannelTransform"]], "basetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.BaseTransform"]], "castonnxtransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CastONNXTransform"]], "castpytorchtransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CastPyTorchTransform"]], "casttftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CastTFTransform"]], "centercroptftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CenterCropTFTransform"]], "centercroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CenterCropTransform"]], "collecttransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CollectTransform"]], "composetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ComposeTransform"]], "cropresizetftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CropResizeTFTransform"]], "cropresizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CropResizeTransform"]], "croptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.CropToBoundingBox"]], "inputfeatures (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.InputFeatures"]], "mxnetcropresizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.MXNetCropResizeTransform"]], "mxnetcroptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.MXNetCropToBoundingBox"]], "mxnetnormalizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.MXNetNormalizeTransform"]], "mxnettransforms (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.MXNetTransforms"]], "mxnettranspose (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.MXNetTranspose"]], "normalizetftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.NormalizeTFTransform"]], "normalizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.NormalizeTransform"]], "onnxrtcroptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ONNXRTCropToBoundingBox"]], "onnxrtittransforms (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ONNXRTITTransforms"]], "onnxrtqltransforms (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ONNXRTQLTransforms"]], "paddedcentercroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PaddedCenterCropTransform"]], "parsedecodevoctransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ParseDecodeVocTransform"]], "pytorchalignimagechannel (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PyTorchAlignImageChannel"]], "pytorchcropresizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PyTorchCropResizeTransform"]], "pytorchnormalizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PyTorchNormalizeTransform"]], "pytorchtransforms (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PyTorchTransforms"]], "pytorchtranspose (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PyTorchTranspose"]], "pytorchmxnettransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PytorchMxnetTransform"]], "pytorchmxnetwrapfunction (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.PytorchMxnetWrapFunction"]], "randomcroptftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomCropTFTransform"]], "randomcroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomCropTransform"]], "randomhorizontalflip (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomHorizontalFlip"]], "randomresizedcropmxnettransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropMXNetTransform"]], "randomresizedcroppytorchtransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropPytorchTransform"]], "randomresizedcroptftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropTFTransform"]], "randomresizedcroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropTransform"]], "randomverticalflip (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RandomVerticalFlip"]], "rescalekeraspretraintransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RescaleKerasPretrainTransform"]], "rescaletftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RescaleTFTransform"]], "rescaletransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.RescaleTransform"]], "resizemxnettransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ResizeMXNetTransform"]], "resizepytorchtransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ResizePytorchTransform"]], "resizetftransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ResizeTFTransform"]], "resizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ResizeTransform"]], "resizewithratio (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ResizeWithRatio"]], "squadexample (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.SquadExample"]], "tfmodelzoocollecttransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TFModelZooCollectTransform"]], "tfsquadv1modelzooposttransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TFSquadV1ModelZooPostTransform"]], "tfsquadv1posttransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TFSquadV1PostTransform"]], "transforms (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TRANSFORMS"], [305, "neural_compressor.experimental.data.transforms.transform.Transforms"]], "tensorflowcroptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowCropToBoundingBox"]], "tensorflowrandomhorizontalflip (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowRandomHorizontalFlip"]], "tensorflowrandomverticalflip (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowRandomVerticalFlip"]], "tensorflowresizewithratio (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowResizeWithRatio"]], "tensorflowtransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowTransform"]], "tensorflowtransforms (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowTransforms"]], "tensorflowtranspose (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowTranspose"]], "tensorflowwrapfunction (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.TensorflowWrapFunction"]], "toarray (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ToArray"]], "tondarraytransform (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.ToNDArrayTransform"]], "transpose (class in neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.Transpose"]], "convert_examples_to_features() (in module neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.convert_examples_to_features"]], "get_final_text() (in module neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.get_final_text"]], "get_torchvision_map() (in module neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.get_torchvision_map"]], "neural_compressor.experimental.data.transforms.transform": [[305, "module-neural_compressor.experimental.data.transforms.transform"]], "read_squad_examples() (in module neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.read_squad_examples"]], "transform_registry() (in module neural_compressor.experimental.data.transforms.transform)": [[305, "neural_compressor.experimental.data.transforms.transform.transform_registry"]], "distillation (class in neural_compressor.experimental.distillation)": [[306, "neural_compressor.experimental.distillation.Distillation"]], "_epoch_ran (neural_compressor.experimental.distillation.distillation attribute)": [[306, "neural_compressor.experimental.distillation.Distillation._epoch_ran"]], "best_model (neural_compressor.experimental.distillation.distillation attribute)": [[306, "neural_compressor.experimental.distillation.Distillation.best_model"]], "best_score (neural_compressor.experimental.distillation.distillation attribute)": [[306, "neural_compressor.experimental.distillation.Distillation.best_score"]], "eval_frequency (neural_compressor.experimental.distillation.distillation attribute)": [[306, "neural_compressor.experimental.distillation.Distillation.eval_frequency"]], "neural_compressor.experimental.distillation": [[306, "module-neural_compressor.experimental.distillation"]], "neural_compressor.experimental.export": [[307, "module-neural_compressor.experimental.export"]], "check_model() (in module neural_compressor.experimental.export.qlinear2qdq)": [[308, "neural_compressor.experimental.export.qlinear2qdq.check_model"]], "neural_compressor.experimental.export.qlinear2qdq": [[308, "module-neural_compressor.experimental.export.qlinear2qdq"]], "onnx_qlinear_to_qdq() (in module neural_compressor.experimental.export.qlinear2qdq)": [[308, "neural_compressor.experimental.export.qlinear2qdq.onnx_qlinear_to_qdq"]], "neural_compressor.experimental.export.tf2onnx": [[309, "module-neural_compressor.experimental.export.tf2onnx"]], "tf_to_fp32_onnx() (in module neural_compressor.experimental.export.tf2onnx)": [[309, "neural_compressor.experimental.export.tf2onnx.tf_to_fp32_onnx"]], "tf_to_int8_onnx() (in module neural_compressor.experimental.export.tf2onnx)": [[309, "neural_compressor.experimental.export.tf2onnx.tf_to_int8_onnx"]], "dynamic_quant_export() (in module neural_compressor.experimental.export.torch2onnx)": [[310, "neural_compressor.experimental.export.torch2onnx.dynamic_quant_export"]], "get_node_mapping() (in module neural_compressor.experimental.export.torch2onnx)": [[310, "neural_compressor.experimental.export.torch2onnx.get_node_mapping"]], "get_quantizable_onnx_ops() (in module neural_compressor.experimental.export.torch2onnx)": [[310, "neural_compressor.experimental.export.torch2onnx.get_quantizable_onnx_ops"]], "neural_compressor.experimental.export.torch2onnx": [[310, "module-neural_compressor.experimental.export.torch2onnx"]], "static_quant_export() (in module neural_compressor.experimental.export.torch2onnx)": [[310, "neural_compressor.experimental.export.torch2onnx.static_quant_export"]], "torch_to_fp32_onnx() (in module neural_compressor.experimental.export.torch2onnx)": [[310, "neural_compressor.experimental.export.torch2onnx.torch_to_fp32_onnx"]], "torch_to_int8_onnx() (in module neural_compressor.experimental.export.torch2onnx)": [[310, "neural_compressor.experimental.export.torch2onnx.torch_to_int8_onnx"]], "graph_optimization (class in neural_compressor.experimental.graph_optimization)": [[311, "neural_compressor.experimental.graph_optimization.Graph_Optimization"]], "neural_compressor.experimental.graph_optimization": [[311, "module-neural_compressor.experimental.graph_optimization"]], "neural_compressor.experimental": [[312, "module-neural_compressor.experimental"]], "bleu (class in neural_compressor.experimental.metric.bleu)": [[313, "neural_compressor.experimental.metric.bleu.BLEU"]], "unicoderegex (class in neural_compressor.experimental.metric.bleu)": [[313, "neural_compressor.experimental.metric.bleu.UnicodeRegex"]], "bleu_tokenize() (in module neural_compressor.experimental.metric.bleu)": [[313, "neural_compressor.experimental.metric.bleu.bleu_tokenize"]], "labels (neural_compressor.experimental.metric.bleu.bleu attribute)": [[313, "neural_compressor.experimental.metric.bleu.BLEU.labels"]], "neural_compressor.experimental.metric.bleu": [[313, "module-neural_compressor.experimental.metric.bleu"]], "nondigit_punct_re (neural_compressor.experimental.metric.bleu.unicoderegex attribute)": [[313, "neural_compressor.experimental.metric.bleu.UnicodeRegex.nondigit_punct_re"]], "predictions (neural_compressor.experimental.metric.bleu.bleu attribute)": [[313, "neural_compressor.experimental.metric.bleu.BLEU.predictions"]], "punct_nondigit_re (neural_compressor.experimental.metric.bleu.unicoderegex attribute)": [[313, "neural_compressor.experimental.metric.bleu.UnicodeRegex.punct_nondigit_re"]], "symbol_re (neural_compressor.experimental.metric.bleu.unicoderegex attribute)": [[313, "neural_compressor.experimental.metric.bleu.UnicodeRegex.symbol_re"]], "compute_bleu() (in module neural_compressor.experimental.metric.bleu_util)": [[314, "neural_compressor.experimental.metric.bleu_util.compute_bleu"]], "neural_compressor.experimental.metric.bleu_util": [[314, "module-neural_compressor.experimental.metric.bleu_util"]], "neural_compressor.experimental.metric.coco_label_map": [[315, "module-neural_compressor.experimental.metric.coco_label_map"]], "cocoevalwrapper (class in neural_compressor.experimental.metric.coco_tools)": [[316, "neural_compressor.experimental.metric.coco_tools.COCOEvalWrapper"]], "cocowrapper (class in neural_compressor.experimental.metric.coco_tools)": [[316, "neural_compressor.experimental.metric.coco_tools.COCOWrapper"]], "exportsingleimagedetectionboxestococo() (in module neural_compressor.experimental.metric.coco_tools)": [[316, "neural_compressor.experimental.metric.coco_tools.ExportSingleImageDetectionBoxesToCoco"]], "exportsingleimagedetectionmaskstococo() (in module neural_compressor.experimental.metric.coco_tools)": [[316, "neural_compressor.experimental.metric.coco_tools.ExportSingleImageDetectionMasksToCoco"]], "exportsingleimagegroundtruthtococo() (in module neural_compressor.experimental.metric.coco_tools)": [[316, "neural_compressor.experimental.metric.coco_tools.ExportSingleImageGroundtruthToCoco"]], "dataset (neural_compressor.experimental.metric.coco_tools.cocowrapper attribute)": [[316, "neural_compressor.experimental.metric.coco_tools.COCOWrapper.dataset"]], "detection_type (neural_compressor.experimental.metric.coco_tools.cocowrapper attribute)": [[316, "neural_compressor.experimental.metric.coco_tools.COCOWrapper.detection_type"]], "neural_compressor.experimental.metric.coco_tools": [[316, "module-neural_compressor.experimental.metric.coco_tools"]], "evaluate() (in module neural_compressor.experimental.metric.evaluate_squad)": [[317, "neural_compressor.experimental.metric.evaluate_squad.evaluate"]], "exact_match_score() (in module neural_compressor.experimental.metric.evaluate_squad)": [[317, "neural_compressor.experimental.metric.evaluate_squad.exact_match_score"]], "f1_score() (in module neural_compressor.experimental.metric.evaluate_squad)": [[317, "neural_compressor.experimental.metric.evaluate_squad.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.experimental.metric.evaluate_squad)": [[317, "neural_compressor.experimental.metric.evaluate_squad.metric_max_over_ground_truths"]], "neural_compressor.experimental.metric.evaluate_squad": [[317, "module-neural_compressor.experimental.metric.evaluate_squad"]], "evaluate() (in module neural_compressor.experimental.metric.f1)": [[318, "neural_compressor.experimental.metric.f1.evaluate"]], "f1_score() (in module neural_compressor.experimental.metric.f1)": [[318, "neural_compressor.experimental.metric.f1.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.experimental.metric.f1)": [[318, "neural_compressor.experimental.metric.f1.metric_max_over_ground_truths"]], "neural_compressor.experimental.metric.f1": [[318, "module-neural_compressor.experimental.metric.f1"]], "normalize_answer() (in module neural_compressor.experimental.metric.f1)": [[318, "neural_compressor.experimental.metric.f1.normalize_answer"]], "neural_compressor.experimental.metric": [[319, "module-neural_compressor.experimental.metric"]], "accuracy (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.Accuracy"]], "basemetric (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.BaseMetric"]], "cocomapv2 (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.COCOmAPv2"]], "f1 (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.F1"]], "generaltopk (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.GeneralTopK"]], "loss (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.Loss"]], "mae (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.MAE"]], "metrics (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.METRICS"]], "mse (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.MSE"]], "mxnetmetrics (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.MXNetMetrics"]], "onnxrtglue (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.ONNXRTGLUE"]], "onnxrtitmetrics (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.ONNXRTITMetrics"]], "onnxrtqlmetrics (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.ONNXRTQLMetrics"]], "pytorchloss (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.PyTorchLoss"]], "pytorchmetrics (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.PyTorchMetrics"]], "rmse (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.RMSE"]], "roc (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.ROC"]], "squadf1 (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.SquadF1"]], "tensorflowcocomap (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.TensorflowCOCOMAP"]], "tensorflowmap (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.TensorflowMAP"]], "tensorflowmetrics (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.TensorflowMetrics"]], "tensorflowtopk (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.TensorflowTopK"]], "tensorflowvocmap (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.TensorflowVOCMAP"]], "wrapmxnetmetric (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.WrapMXNetMetric"]], "wraponnxrtmetric (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.WrapONNXRTMetric"]], "wrappytorchmetric (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.WrapPyTorchMetric"]], "compare_label (neural_compressor.experimental.metric.metric.mae attribute)": [[320, "neural_compressor.experimental.metric.metric.MAE.compare_label"]], "compare_label (neural_compressor.experimental.metric.metric.mse attribute)": [[320, "neural_compressor.experimental.metric.metric.MSE.compare_label"]], "k (neural_compressor.experimental.metric.metric.generaltopk attribute)": [[320, "neural_compressor.experimental.metric.metric.GeneralTopK.k"]], "k (neural_compressor.experimental.metric.metric.tensorflowtopk attribute)": [[320, "neural_compressor.experimental.metric.metric.TensorflowTopK.k"]], "label_list (neural_compressor.experimental.metric.metric.accuracy attribute)": [[320, "neural_compressor.experimental.metric.metric.Accuracy.label_list"]], "label_list (neural_compressor.experimental.metric.metric.mae attribute)": [[320, "neural_compressor.experimental.metric.metric.MAE.label_list"]], "label_list (neural_compressor.experimental.metric.metric.mse attribute)": [[320, "neural_compressor.experimental.metric.metric.MSE.label_list"]], "miou (class in neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.mIOU"]], "metric_registry() (in module neural_compressor.experimental.metric.metric)": [[320, "neural_compressor.experimental.metric.metric.metric_registry"]], "metrics (neural_compressor.experimental.metric.metric.metrics attribute)": [[320, "neural_compressor.experimental.metric.metric.METRICS.metrics"]], "metrics (neural_compressor.experimental.metric.metric.mxnetmetrics attribute)": [[320, "neural_compressor.experimental.metric.metric.MXNetMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.onnxrtitmetrics attribute)": [[320, "neural_compressor.experimental.metric.metric.ONNXRTITMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.onnxrtqlmetrics attribute)": [[320, "neural_compressor.experimental.metric.metric.ONNXRTQLMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.pytorchmetrics attribute)": [[320, "neural_compressor.experimental.metric.metric.PyTorchMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.tensorflowmetrics attribute)": [[320, "neural_compressor.experimental.metric.metric.TensorflowMetrics.metrics"]], "mse (neural_compressor.experimental.metric.metric.rmse attribute)": [[320, "neural_compressor.experimental.metric.metric.RMSE.mse"]], "neural_compressor.experimental.metric.metric": [[320, "module-neural_compressor.experimental.metric.metric"]], "num_correct (neural_compressor.experimental.metric.metric.generaltopk attribute)": [[320, "neural_compressor.experimental.metric.metric.GeneralTopK.num_correct"]], "num_correct (neural_compressor.experimental.metric.metric.tensorflowtopk attribute)": [[320, "neural_compressor.experimental.metric.metric.TensorflowTopK.num_correct"]], "num_sample (neural_compressor.experimental.metric.metric.generaltopk attribute)": [[320, "neural_compressor.experimental.metric.metric.GeneralTopK.num_sample"]], "num_sample (neural_compressor.experimental.metric.metric.tensorflowtopk attribute)": [[320, "neural_compressor.experimental.metric.metric.TensorflowTopK.num_sample"]], "pred_list (neural_compressor.experimental.metric.metric.accuracy attribute)": [[320, "neural_compressor.experimental.metric.metric.Accuracy.pred_list"]], "pred_list (neural_compressor.experimental.metric.metric.mae attribute)": [[320, "neural_compressor.experimental.metric.metric.MAE.pred_list"]], "pred_list (neural_compressor.experimental.metric.metric.mse attribute)": [[320, "neural_compressor.experimental.metric.metric.MSE.pred_list"]], "sample (neural_compressor.experimental.metric.metric.accuracy attribute)": [[320, "neural_compressor.experimental.metric.metric.Accuracy.sample"]], "sample (neural_compressor.experimental.metric.metric.loss attribute)": [[320, "neural_compressor.experimental.metric.metric.Loss.sample"]], "sum (neural_compressor.experimental.metric.metric.loss attribute)": [[320, "neural_compressor.experimental.metric.metric.Loss.sum"]], "mixedprecision (class in neural_compressor.experimental.mixed_precision)": [[321, "neural_compressor.experimental.mixed_precision.MixedPrecision"]], "neural_compressor.experimental.mixed_precision": [[321, "module-neural_compressor.experimental.mixed_precision"]], "modelconversion (class in neural_compressor.experimental.model_conversion)": [[322, "neural_compressor.experimental.model_conversion.ModelConversion"]], "neural_compressor.experimental.model_conversion": [[322, "module-neural_compressor.experimental.model_conversion"]], "basicnas (class in neural_compressor.experimental.nas.basic_nas)": [[323, "neural_compressor.experimental.nas.basic_nas.BasicNAS"]], "neural_compressor.experimental.nas.basic_nas": [[323, "module-neural_compressor.experimental.nas.basic_nas"]], "dynas (class in neural_compressor.experimental.nas.dynas)": [[324, "neural_compressor.experimental.nas.dynas.DyNAS"]], "neural_compressor.experimental.nas.dynas": [[324, "module-neural_compressor.experimental.nas.dynas"]], "neural_compressor.experimental.nas": [[325, "module-neural_compressor.experimental.nas"]], "nas (class in neural_compressor.experimental.nas.nas)": [[326, "neural_compressor.experimental.nas.nas.NAS"]], "nasbase (class in neural_compressor.experimental.nas.nas)": [[326, "neural_compressor.experimental.nas.nas.NASBase"]], "neural_compressor.experimental.nas.nas": [[326, "module-neural_compressor.experimental.nas.nas"]], "create_search_space_pool() (in module neural_compressor.experimental.nas.nas_utils)": [[327, "neural_compressor.experimental.nas.nas_utils.create_search_space_pool"]], "find_pareto_front() (in module neural_compressor.experimental.nas.nas_utils)": [[327, "neural_compressor.experimental.nas.nas_utils.find_pareto_front"]], "nas_registry() (in module neural_compressor.experimental.nas.nas_utils)": [[327, "neural_compressor.experimental.nas.nas_utils.nas_registry"]], "neural_compressor.experimental.nas.nas_utils": [[327, "module-neural_compressor.experimental.nas.nas_utils"]], "bayesianoptimizationsearcher (class in neural_compressor.experimental.nas.search_algorithms)": [[328, "neural_compressor.experimental.nas.search_algorithms.BayesianOptimizationSearcher"]], "gridsearcher (class in neural_compressor.experimental.nas.search_algorithms)": [[328, "neural_compressor.experimental.nas.search_algorithms.GridSearcher"]], "randomsearcher (class in neural_compressor.experimental.nas.search_algorithms)": [[328, "neural_compressor.experimental.nas.search_algorithms.RandomSearcher"]], "searcher (class in neural_compressor.experimental.nas.search_algorithms)": [[328, "neural_compressor.experimental.nas.search_algorithms.Searcher"]], "neural_compressor.experimental.nas.search_algorithms": [[328, "module-neural_compressor.experimental.nas.search_algorithms"]], "gradientsensitivitypruner (class in neural_compressor.experimental.pruner_legacy.gradient_sensitivity)": [[329, "neural_compressor.experimental.pruner_legacy.gradient_sensitivity.GradientSensitivityPruner"]], "neural_compressor.experimental.pruner_legacy.gradient_sensitivity": [[329, "module-neural_compressor.experimental.pruner_legacy.gradient_sensitivity"]], "grouplassopruner (class in neural_compressor.experimental.pruner_legacy.group_lasso)": [[330, "neural_compressor.experimental.pruner_legacy.group_lasso.GroupLassoPruner"]], "neural_compressor.experimental.pruner_legacy.group_lasso": [[330, "module-neural_compressor.experimental.pruner_legacy.group_lasso"]], "neural_compressor.experimental.pruner_legacy": [[331, "module-neural_compressor.experimental.pruner_legacy"]], "basicmagnitudepruner (class in neural_compressor.experimental.pruner_legacy.magnitude)": [[332, "neural_compressor.experimental.pruner_legacy.magnitude.BasicMagnitudePruner"]], "neural_compressor.experimental.pruner_legacy.magnitude": [[332, "module-neural_compressor.experimental.pruner_legacy.magnitude"]], "patternlockpruner (class in neural_compressor.experimental.pruner_legacy.pattern_lock)": [[333, "neural_compressor.experimental.pruner_legacy.pattern_lock.PatternLockPruner"]], "neural_compressor.experimental.pruner_legacy.pattern_lock": [[333, "module-neural_compressor.experimental.pruner_legacy.pattern_lock"]], "pruner (class in neural_compressor.experimental.pruner_legacy.pruner)": [[334, "neural_compressor.experimental.pruner_legacy.pruner.Pruner"]], "neural_compressor.experimental.pruner_legacy.pruner": [[334, "module-neural_compressor.experimental.pruner_legacy.pruner"]], "pruner_registry() (in module neural_compressor.experimental.pruner_legacy.pruner)": [[334, "neural_compressor.experimental.pruner_legacy.pruner.pruner_registry"]], "pruning (class in neural_compressor.experimental.pruning)": [[335, "neural_compressor.experimental.pruning.Pruning"]], "tfpruningcallback (class in neural_compressor.experimental.pruning)": [[335, "neural_compressor.experimental.pruning.TfPruningCallback"]], "conf (neural_compressor.experimental.pruning.pruning attribute)": [[335, "neural_compressor.experimental.pruning.Pruning.conf"]], "neural_compressor.experimental.pruning": [[335, "module-neural_compressor.experimental.pruning"]], "pruners (neural_compressor.experimental.pruning.pruning attribute)": [[335, "neural_compressor.experimental.pruning.Pruning.pruners"]], "neural_compressor.experimental.pruning_recipes": [[336, "module-neural_compressor.experimental.pruning_recipes"]], "neural_compressor.experimental.pruning_recipes.patterns": [[337, "module-neural_compressor.experimental.pruning_recipes.patterns"]], "patterns (class in neural_compressor.experimental.pruning_recipes.patterns.pattern)": [[338, "neural_compressor.experimental.pruning_recipes.patterns.pattern.PATTERNS"]], "patternbase (class in neural_compressor.experimental.pruning_recipes.patterns.pattern)": [[338, "neural_compressor.experimental.pruning_recipes.patterns.pattern.PatternBase"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern": [[338, "module-neural_compressor.experimental.pruning_recipes.patterns.pattern"]], "pattern_registry() (in module neural_compressor.experimental.pruning_recipes.patterns.pattern)": [[338, "neural_compressor.experimental.pruning_recipes.patterns.pattern.pattern_registry"]], "patterns (neural_compressor.experimental.pruning_recipes.patterns.pattern.patterns attribute)": [[338, "neural_compressor.experimental.pruning_recipes.patterns.pattern.PATTERNS.patterns"]], "tilepatternbase (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[339, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePatternBase"]], "tilepattern_1x1 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[339, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_1x1"]], "tilepattern_1x16 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[339, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_1x16"]], "tilepattern_1x2 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[339, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_1x2"]], "tilepattern_2x2 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[339, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_2x2"]], "tilepattern_4x1 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[339, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_4x1"]], "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern": [[339, "module-neural_compressor.experimental.pruning_recipes.patterns.tile_pattern"]], "pruning (class in neural_compressor.experimental.pruning_v2)": [[340, "neural_compressor.experimental.pruning_v2.Pruning"]], "tfpruningcallback (class in neural_compressor.experimental.pruning_v2)": [[340, "neural_compressor.experimental.pruning_v2.TfPruningCallback"]], "conf (neural_compressor.experimental.pruning_v2.pruning attribute)": [[340, "neural_compressor.experimental.pruning_v2.Pruning.conf"]], "neural_compressor.experimental.pruning_v2": [[340, "module-neural_compressor.experimental.pruning_v2"]], "pruners (neural_compressor.experimental.pruning_v2.pruning attribute)": [[340, "neural_compressor.experimental.pruning_v2.Pruning.pruners"]], "neural_compressor.experimental.pytorch_pruner": [[341, "module-neural_compressor.experimental.pytorch_pruner"]], "neural_compressor.experimental.pytorch_pruner.logger": [[342, "module-neural_compressor.experimental.pytorch_pruner.logger"]], "m (neural_compressor.experimental.pytorch_pruner.patterns.patternninm attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM.M"]], "n (neural_compressor.experimental.pytorch_pruner.patterns.patternninm attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM.N"]], "pattern (class in neural_compressor.experimental.pytorch_pruner.patterns)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.Pattern"]], "patternninm (class in neural_compressor.experimental.pytorch_pruner.patterns)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM"]], "patternnxm (class in neural_compressor.experimental.pytorch_pruner.patterns)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNxM"]], "block_size (neural_compressor.experimental.pytorch_pruner.patterns.patternnxm attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNxM.block_size"]], "get_pattern() (in module neural_compressor.experimental.pytorch_pruner.patterns)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.get_pattern"]], "is_global (neural_compressor.experimental.pytorch_pruner.patterns.pattern attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.Pattern.is_global"]], "neural_compressor.experimental.pytorch_pruner.patterns": [[343, "module-neural_compressor.experimental.pytorch_pruner.patterns"]], "pattern (neural_compressor.experimental.pytorch_pruner.patterns.pattern attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.Pattern.pattern"]], "register_pattern() (in module neural_compressor.experimental.pytorch_pruner.patterns)": [[343, "neural_compressor.experimental.pytorch_pruner.patterns.register_pattern"]], "check_config() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[344, "neural_compressor.experimental.pytorch_pruner.prune_utils.check_config"]], "neural_compressor.experimental.pytorch_pruner.prune_utils": [[344, "module-neural_compressor.experimental.pytorch_pruner.prune_utils"]], "parse_not_to_prune() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[344, "neural_compressor.experimental.pytorch_pruner.prune_utils.parse_not_to_prune"]], "parse_to_prune() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[344, "neural_compressor.experimental.pytorch_pruner.prune_utils.parse_to_prune"]], "process_and_check_config() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[344, "neural_compressor.experimental.pytorch_pruner.prune_utils.process_and_check_config"]], "process_config() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[344, "neural_compressor.experimental.pytorch_pruner.prune_utils.process_config"]], "reset_non_value_to_default() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[344, "neural_compressor.experimental.pytorch_pruner.prune_utils.reset_non_value_to_default"]], "magnitudepruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.MagnitudePruner"]], "patternlockpruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.PatternLockPruner"]], "pruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner"]], "snipmomentumpruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.SnipMomentumPruner"]], "snippruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.SnipPruner"]], "config (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.config"]], "current_sparsity_ratio (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.current_sparsity_ratio"]], "end_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.end_step"]], "get_pruner() (in module neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.get_pruner"]], "global_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.global_step"]], "masks (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.masks"]], "max_sparsity_ratio_per_layer (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.max_sparsity_ratio_per_layer"]], "modules (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.modules"]], "neural_compressor.experimental.pytorch_pruner.pruner": [[345, "module-neural_compressor.experimental.pytorch_pruner.pruner"]], "pattern (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.pattern"]], "register_pruners() (in module neural_compressor.experimental.pytorch_pruner.pruner)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.register_pruners"]], "scheduler (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.scheduler"]], "scores (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.scores"]], "start_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.start_step"]], "target_sparsity_ratio (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.target_sparsity_ratio"]], "update_frequency_on_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.update_frequency_on_step"]], "pruning (class in neural_compressor.experimental.pytorch_pruner.pruning)": [[346, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning"]], "config_file_path (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[346, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.config_file_path"]], "model (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[346, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.model"]], "neural_compressor.experimental.pytorch_pruner.pruning": [[346, "module-neural_compressor.experimental.pytorch_pruner.pruning"]], "pruner_info (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[346, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.pruner_info"]], "pruners (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[346, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.pruners"]], "iterativescheduler (class in neural_compressor.experimental.pytorch_pruner.scheduler)": [[347, "neural_compressor.experimental.pytorch_pruner.scheduler.IterativeScheduler"]], "oneshotscheduler (class in neural_compressor.experimental.pytorch_pruner.scheduler)": [[347, "neural_compressor.experimental.pytorch_pruner.scheduler.OneshotScheduler"]], "scheduler (class in neural_compressor.experimental.pytorch_pruner.scheduler)": [[347, "neural_compressor.experimental.pytorch_pruner.scheduler.Scheduler"]], "config (neural_compressor.experimental.pytorch_pruner.scheduler.scheduler attribute)": [[347, "neural_compressor.experimental.pytorch_pruner.scheduler.Scheduler.config"]], "get_scheduler() (in module neural_compressor.experimental.pytorch_pruner.scheduler)": [[347, "neural_compressor.experimental.pytorch_pruner.scheduler.get_scheduler"]], "neural_compressor.experimental.pytorch_pruner.scheduler": [[347, "module-neural_compressor.experimental.pytorch_pruner.scheduler"]], "register_scheduler() (in module neural_compressor.experimental.pytorch_pruner.scheduler)": [[347, "neural_compressor.experimental.pytorch_pruner.scheduler.register_scheduler"]], "quantization (class in neural_compressor.experimental.quantization)": [[348, "neural_compressor.experimental.quantization.Quantization"]], "neural_compressor.experimental.quantization": [[348, "module-neural_compressor.experimental.quantization"]], "scheduler (class in neural_compressor.experimental.scheduler)": [[349, "neural_compressor.experimental.scheduler.Scheduler"]], "neural_compressor.experimental.scheduler": [[349, "module-neural_compressor.experimental.scheduler"]], "automixedprecisiontunestrategy (class in neural_compressor.experimental.strategy.auto_mixed_precision)": [[350, "neural_compressor.experimental.strategy.auto_mixed_precision.AutoMixedPrecisionTuneStrategy"]], "neural_compressor.experimental.strategy.auto_mixed_precision": [[350, "module-neural_compressor.experimental.strategy.auto_mixed_precision"]], "basictunestrategy (class in neural_compressor.experimental.strategy.basic)": [[351, "neural_compressor.experimental.strategy.basic.BasicTuneStrategy"]], "neural_compressor.experimental.strategy.basic": [[351, "module-neural_compressor.experimental.strategy.basic"]], "bayesianoptimization (class in neural_compressor.experimental.strategy.bayesian)": [[352, "neural_compressor.experimental.strategy.bayesian.BayesianOptimization"]], "bayesiantunestrategy (class in neural_compressor.experimental.strategy.bayesian)": [[352, "neural_compressor.experimental.strategy.bayesian.BayesianTuneStrategy"]], "targetspace (class in neural_compressor.experimental.strategy.bayesian)": [[352, "neural_compressor.experimental.strategy.bayesian.TargetSpace"]], "acq_max() (in module neural_compressor.experimental.strategy.bayesian)": [[352, "neural_compressor.experimental.strategy.bayesian.acq_max"]], "neural_compressor.experimental.strategy.bayesian": [[352, "module-neural_compressor.experimental.strategy.bayesian"]], "exhaustivetunestrategy (class in neural_compressor.experimental.strategy.exhaustive)": [[353, "neural_compressor.experimental.strategy.exhaustive.ExhaustiveTuneStrategy"]], "neural_compressor.experimental.strategy.exhaustive": [[353, "module-neural_compressor.experimental.strategy.exhaustive"]], "neural_compressor.experimental.strategy": [[354, "module-neural_compressor.experimental.strategy"]], "msetunestrategy (class in neural_compressor.experimental.strategy.mse)": [[355, "neural_compressor.experimental.strategy.mse.MSETuneStrategy"]], "neural_compressor.experimental.strategy.mse": [[355, "module-neural_compressor.experimental.strategy.mse"]], "mse_v2tunestrategy (class in neural_compressor.experimental.strategy.mse_v2)": [[356, "neural_compressor.experimental.strategy.mse_v2.MSE_V2TuneStrategy"]], "neural_compressor.experimental.strategy.mse_v2": [[356, "module-neural_compressor.experimental.strategy.mse_v2"]], "randomtunestrategy (class in neural_compressor.experimental.strategy.random)": [[357, "neural_compressor.experimental.strategy.random.RandomTuneStrategy"]], "neural_compressor.experimental.strategy.random": [[357, "module-neural_compressor.experimental.strategy.random"]], "tunestrategy (class in neural_compressor.experimental.strategy.strategy)": [[358, "neural_compressor.experimental.strategy.strategy.TuneStrategy"]], "neural_compressor.experimental.strategy.strategy": [[358, "module-neural_compressor.experimental.strategy.strategy"]], "strategy_registry() (in module neural_compressor.experimental.strategy.strategy)": [[358, "neural_compressor.experimental.strategy.strategy.strategy_registry"]], "neural_compressor.experimental.strategy.utils.constant": [[359, "module-neural_compressor.experimental.strategy.utils.constant"]], "neural_compressor.experimental.strategy.utils": [[360, "module-neural_compressor.experimental.strategy.utils"]], "fallbacktuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.FallbackTuningSampler"]], "modelwisetuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.ModelWiseTuningSampler"]], "optypewisetuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.OpTypeWiseTuningSampler"]], "opwisetuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.OpWiseTuningSampler"]], "smoothquantsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.SmoothQuantSampler"]], "tuningorder (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.TuningOrder"]], "tuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.TuningSampler"]], "tuningsamplerregistry (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[361, "neural_compressor.experimental.strategy.utils.tuning_sampler.TuningSamplerRegistry"]], "neural_compressor.experimental.strategy.utils.tuning_sampler": [[361, "module-neural_compressor.experimental.strategy.utils.tuning_sampler"]], "tuningitem (class in neural_compressor.experimental.strategy.utils.tuning_space)": [[362, "neural_compressor.experimental.strategy.utils.tuning_space.TuningItem"]], "tuningspace (class in neural_compressor.experimental.strategy.utils.tuning_space)": [[362, "neural_compressor.experimental.strategy.utils.tuning_space.TuningSpace"]], "initial_tuning_cfg_with_quant_mode() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[362, "neural_compressor.experimental.strategy.utils.tuning_space.initial_tuning_cfg_with_quant_mode"]], "neural_compressor.experimental.strategy.utils.tuning_space": [[362, "module-neural_compressor.experimental.strategy.utils.tuning_space"]], "pattern_to_internal() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[362, "neural_compressor.experimental.strategy.utils.tuning_space.pattern_to_internal"]], "pattern_to_path() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[362, "neural_compressor.experimental.strategy.utils.tuning_space.pattern_to_path"]], "quant_mode_from_pattern() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[362, "neural_compressor.experimental.strategy.utils.tuning_space.quant_mode_from_pattern"]], "optuningconfig (class in neural_compressor.experimental.strategy.utils.tuning_structs)": [[363, "neural_compressor.experimental.strategy.utils.tuning_structs.OpTuningConfig"]], "neural_compressor.experimental.strategy.utils.tuning_structs": [[363, "module-neural_compressor.experimental.strategy.utils.tuning_structs"]], "ordereddefaultdict (class in neural_compressor.experimental.strategy.utils.utility)": [[364, "neural_compressor.experimental.strategy.utils.utility.OrderedDefaultDict"]], "extract_data_type() (in module neural_compressor.experimental.strategy.utils.utility)": [[364, "neural_compressor.experimental.strategy.utils.utility.extract_data_type"]], "get_adaptor_name() (in module neural_compressor.experimental.strategy.utils.utility)": [[364, "neural_compressor.experimental.strategy.utils.utility.get_adaptor_name"]], "neural_compressor.experimental.strategy.utils.utility": [[364, "module-neural_compressor.experimental.strategy.utils.utility"]], "reverted_data_type() (in module neural_compressor.experimental.strategy.utils.utility)": [[364, "neural_compressor.experimental.strategy.utils.utility.reverted_data_type"]], "neural_compressor": [[365, "module-neural_compressor"]], "bleu (class in neural_compressor.metric.bleu)": [[366, "neural_compressor.metric.bleu.BLEU"]], "unicoderegex (class in neural_compressor.metric.bleu)": [[366, "neural_compressor.metric.bleu.UnicodeRegex"]], "bleu_tokenize() (in module neural_compressor.metric.bleu)": [[366, "neural_compressor.metric.bleu.bleu_tokenize"]], "labels (neural_compressor.metric.bleu.bleu attribute)": [[366, "neural_compressor.metric.bleu.BLEU.labels"]], "neural_compressor.metric.bleu": [[366, "module-neural_compressor.metric.bleu"]], "nondigit_punct_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[366, "neural_compressor.metric.bleu.UnicodeRegex.nondigit_punct_re"]], "predictions (neural_compressor.metric.bleu.bleu attribute)": [[366, "neural_compressor.metric.bleu.BLEU.predictions"]], "punct_nondigit_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[366, "neural_compressor.metric.bleu.UnicodeRegex.punct_nondigit_re"]], "symbol_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[366, "neural_compressor.metric.bleu.UnicodeRegex.symbol_re"]], "compute_bleu() (in module neural_compressor.metric.bleu_util)": [[367, "neural_compressor.metric.bleu_util.compute_bleu"]], "neural_compressor.metric.bleu_util": [[367, "module-neural_compressor.metric.bleu_util"]], "neural_compressor.metric.coco_label_map": [[368, "module-neural_compressor.metric.coco_label_map"]], "cocoevalwrapper (class in neural_compressor.metric.coco_tools)": [[369, "neural_compressor.metric.coco_tools.COCOEvalWrapper"]], "cocowrapper (class in neural_compressor.metric.coco_tools)": [[369, "neural_compressor.metric.coco_tools.COCOWrapper"]], "exportsingleimagedetectionboxestococo() (in module neural_compressor.metric.coco_tools)": [[369, "neural_compressor.metric.coco_tools.ExportSingleImageDetectionBoxesToCoco"]], "exportsingleimagedetectionmaskstococo() (in module neural_compressor.metric.coco_tools)": [[369, "neural_compressor.metric.coco_tools.ExportSingleImageDetectionMasksToCoco"]], "exportsingleimagegroundtruthtococo() (in module neural_compressor.metric.coco_tools)": [[369, "neural_compressor.metric.coco_tools.ExportSingleImageGroundtruthToCoco"]], "dataset (neural_compressor.metric.coco_tools.cocowrapper attribute)": [[369, "neural_compressor.metric.coco_tools.COCOWrapper.dataset"]], "detection_type (neural_compressor.metric.coco_tools.cocowrapper attribute)": [[369, "neural_compressor.metric.coco_tools.COCOWrapper.detection_type"]], "neural_compressor.metric.coco_tools": [[369, "module-neural_compressor.metric.coco_tools"]], "evaluate() (in module neural_compressor.metric.evaluate_squad)": [[370, "neural_compressor.metric.evaluate_squad.evaluate"]], "exact_match_score() (in module neural_compressor.metric.evaluate_squad)": [[370, "neural_compressor.metric.evaluate_squad.exact_match_score"]], "f1_score() (in module neural_compressor.metric.evaluate_squad)": [[370, "neural_compressor.metric.evaluate_squad.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.metric.evaluate_squad)": [[370, "neural_compressor.metric.evaluate_squad.metric_max_over_ground_truths"]], "neural_compressor.metric.evaluate_squad": [[370, "module-neural_compressor.metric.evaluate_squad"]], "evaluate() (in module neural_compressor.metric.f1)": [[371, "neural_compressor.metric.f1.evaluate"]], "f1_score() (in module neural_compressor.metric.f1)": [[371, "neural_compressor.metric.f1.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.metric.f1)": [[371, "neural_compressor.metric.f1.metric_max_over_ground_truths"]], "neural_compressor.metric.f1": [[371, "module-neural_compressor.metric.f1"]], "normalize_answer() (in module neural_compressor.metric.f1)": [[371, "neural_compressor.metric.f1.normalize_answer"]], "neural_compressor.metric": [[372, "module-neural_compressor.metric"]], "accuracy (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.Accuracy"]], "basemetric (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.BaseMetric"]], "cocomapv2 (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.COCOmAPv2"]], "f1 (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.F1"]], "generaltopk (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.GeneralTopK"]], "loss (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.Loss"]], "mae (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.MAE"]], "metrics (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.METRICS"]], "mse (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.MSE"]], "mxnetmetrics (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.MXNetMetrics"]], "metric (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.Metric"]], "onnxrtglue (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.ONNXRTGLUE"]], "onnxrtitmetrics (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.ONNXRTITMetrics"]], "onnxrtqlmetrics (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.ONNXRTQLMetrics"]], "pytorchloss (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.PyTorchLoss"]], "pytorchmetrics (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.PyTorchMetrics"]], "rmse (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.RMSE"]], "roc (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.ROC"]], "squadf1 (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.SquadF1"]], "tensorflowcocomap (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.TensorflowCOCOMAP"]], "tensorflowmap (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.TensorflowMAP"]], "tensorflowmetrics (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.TensorflowMetrics"]], "tensorflowtopk (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.TensorflowTopK"]], "tensorflowvocmap (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.TensorflowVOCMAP"]], "wrapmxnetmetric (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.WrapMXNetMetric"]], "wraponnxrtmetric (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.WrapONNXRTMetric"]], "wrappytorchmetric (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.WrapPyTorchMetric"]], "compare_label (neural_compressor.metric.metric.mae attribute)": [[373, "neural_compressor.metric.metric.MAE.compare_label"]], "compare_label (neural_compressor.metric.metric.mse attribute)": [[373, "neural_compressor.metric.metric.MSE.compare_label"]], "k (neural_compressor.metric.metric.generaltopk attribute)": [[373, "neural_compressor.metric.metric.GeneralTopK.k"]], "k (neural_compressor.metric.metric.tensorflowtopk attribute)": [[373, "neural_compressor.metric.metric.TensorflowTopK.k"]], "label_list (neural_compressor.metric.metric.accuracy attribute)": [[373, "neural_compressor.metric.metric.Accuracy.label_list"]], "label_list (neural_compressor.metric.metric.mae attribute)": [[373, "neural_compressor.metric.metric.MAE.label_list"]], "label_list (neural_compressor.metric.metric.mse attribute)": [[373, "neural_compressor.metric.metric.MSE.label_list"]], "miou (class in neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.mIOU"]], "metric_registry() (in module neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.metric_registry"]], "metrics (neural_compressor.metric.metric.metrics attribute)": [[373, "neural_compressor.metric.metric.METRICS.metrics"]], "metrics (neural_compressor.metric.metric.mxnetmetrics attribute)": [[373, "neural_compressor.metric.metric.MXNetMetrics.metrics"]], "metrics (neural_compressor.metric.metric.onnxrtitmetrics attribute)": [[373, "neural_compressor.metric.metric.ONNXRTITMetrics.metrics"]], "metrics (neural_compressor.metric.metric.onnxrtqlmetrics attribute)": [[373, "neural_compressor.metric.metric.ONNXRTQLMetrics.metrics"]], "metrics (neural_compressor.metric.metric.pytorchmetrics attribute)": [[373, "neural_compressor.metric.metric.PyTorchMetrics.metrics"]], "metrics (neural_compressor.metric.metric.tensorflowmetrics attribute)": [[373, "neural_compressor.metric.metric.TensorflowMetrics.metrics"]], "mse (neural_compressor.metric.metric.rmse attribute)": [[373, "neural_compressor.metric.metric.RMSE.mse"]], "neural_compressor.metric.metric": [[373, "module-neural_compressor.metric.metric"]], "num_correct (neural_compressor.metric.metric.generaltopk attribute)": [[373, "neural_compressor.metric.metric.GeneralTopK.num_correct"]], "num_correct (neural_compressor.metric.metric.tensorflowtopk attribute)": [[373, "neural_compressor.metric.metric.TensorflowTopK.num_correct"]], "num_sample (neural_compressor.metric.metric.generaltopk attribute)": [[373, "neural_compressor.metric.metric.GeneralTopK.num_sample"]], "num_sample (neural_compressor.metric.metric.tensorflowtopk attribute)": [[373, "neural_compressor.metric.metric.TensorflowTopK.num_sample"]], "pred_list (neural_compressor.metric.metric.accuracy attribute)": [[373, "neural_compressor.metric.metric.Accuracy.pred_list"]], "pred_list (neural_compressor.metric.metric.mae attribute)": [[373, "neural_compressor.metric.metric.MAE.pred_list"]], "pred_list (neural_compressor.metric.metric.mse attribute)": [[373, "neural_compressor.metric.metric.MSE.pred_list"]], "register_customer_metric() (in module neural_compressor.metric.metric)": [[373, "neural_compressor.metric.metric.register_customer_metric"]], "sample (neural_compressor.metric.metric.accuracy attribute)": [[373, "neural_compressor.metric.metric.Accuracy.sample"]], "sample (neural_compressor.metric.metric.loss attribute)": [[373, "neural_compressor.metric.metric.Loss.sample"]], "sum (neural_compressor.metric.metric.loss attribute)": [[373, "neural_compressor.metric.metric.Loss.sum"]], "fit() (in module neural_compressor.mix_precision)": [[374, "neural_compressor.mix_precision.fit"]], "neural_compressor.mix_precision": [[374, "module-neural_compressor.mix_precision"]], "basemodel (class in neural_compressor.model.base_model)": [[375, "neural_compressor.model.base_model.BaseModel"]], "neural_compressor.model.base_model": [[375, "module-neural_compressor.model.base_model"]], "neural_compressor.model": [[376, "module-neural_compressor.model"]], "kerasmodel (class in neural_compressor.model.keras_model)": [[377, "neural_compressor.model.keras_model.KerasModel"]], "neural_compressor.model.keras_model": [[377, "module-neural_compressor.model.keras_model"]], "model (class in neural_compressor.model.model)": [[378, "neural_compressor.model.model.Model"]], "get_model_fwk_name() (in module neural_compressor.model.model)": [[378, "neural_compressor.model.model.get_model_fwk_name"]], "neural_compressor.model.model": [[378, "module-neural_compressor.model.model"]], "mxnetmodel (class in neural_compressor.model.mxnet_model)": [[379, "neural_compressor.model.mxnet_model.MXNetModel"]], "neural_compressor.model.mxnet_model": [[379, "module-neural_compressor.model.mxnet_model"]], "tfslimnetsfactory (class in neural_compressor.model.nets_factory)": [[380, "neural_compressor.model.nets_factory.TFSlimNetsFactory"]], "neural_compressor.model.nets_factory": [[380, "module-neural_compressor.model.nets_factory"]], "onnxmodel (class in neural_compressor.model.onnx_model)": [[381, "neural_compressor.model.onnx_model.ONNXModel"]], "neural_compressor.model.onnx_model": [[381, "module-neural_compressor.model.onnx_model"]], "tensorflowbasemodel (class in neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.TensorflowBaseModel"]], "tensorflowcheckpointmodel (class in neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.TensorflowCheckpointModel"]], "tensorflowllmmodel (class in neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.TensorflowLLMModel"]], "tensorflowmodel (class in neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.TensorflowModel"]], "tensorflowqatmodel (class in neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.TensorflowQATModel"]], "tensorflowsavedmodelmodel (class in neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.TensorflowSavedModelModel"]], "checkpoint_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.checkpoint_session"]], "estimator_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.estimator_session"]], "frozen_pb_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.frozen_pb_session"]], "get_model_type() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.get_model_type"]], "graph_def_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.graph_def_session"]], "graph_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.graph_session"]], "keras_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.keras_session"]], "load_saved_model() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.load_saved_model"]], "neural_compressor.model.tensorflow_model": [[382, "module-neural_compressor.model.tensorflow_model"]], "saved_model_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.saved_model_session"]], "slim_session() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.slim_session"]], "try_loading_keras() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.try_loading_keras"]], "validate_and_inference_input_output() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.validate_and_inference_input_output"]], "validate_graph_node() (in module neural_compressor.model.tensorflow_model)": [[382, "neural_compressor.model.tensorflow_model.validate_graph_node"]], "ipexmodel (class in neural_compressor.model.torch_model)": [[383, "neural_compressor.model.torch_model.IPEXModel"]], "pytorchbasemodel (class in neural_compressor.model.torch_model)": [[383, "neural_compressor.model.torch_model.PyTorchBaseModel"]], "pytorchfxmodel (class in neural_compressor.model.torch_model)": [[383, "neural_compressor.model.torch_model.PyTorchFXModel"]], "pytorchmodel (class in neural_compressor.model.torch_model)": [[383, "neural_compressor.model.torch_model.PyTorchModel"]], "neural_compressor.model.torch_model": [[383, "module-neural_compressor.model.torch_model"]], "accuracy (class in neural_compressor.objective)": [[384, "neural_compressor.objective.Accuracy"]], "footprint (class in neural_compressor.objective)": [[384, "neural_compressor.objective.Footprint"]], "modelsize (class in neural_compressor.objective)": [[384, "neural_compressor.objective.ModelSize"]], "multiobjective (class in neural_compressor.objective)": [[384, "neural_compressor.objective.MultiObjective"]], "objective (class in neural_compressor.objective)": [[384, "neural_compressor.objective.Objective"]], "performance (class in neural_compressor.objective)": [[384, "neural_compressor.objective.Performance"]], "neural_compressor.objective": [[384, "module-neural_compressor.objective"]], "objective_custom_registry() (in module neural_compressor.objective)": [[384, "neural_compressor.objective.objective_custom_registry"]], "objective_registry() (in module neural_compressor.objective)": [[384, "neural_compressor.objective.objective_registry"]], "neural_compressor.onnxrt.algorithms": [[385, "module-neural_compressor.onnxrt.algorithms"]], "layer_wise_quant() (in module neural_compressor.onnxrt.algorithms.layer_wise.core)": [[386, "neural_compressor.onnxrt.algorithms.layer_wise.core.layer_wise_quant"]], "neural_compressor.onnxrt.algorithms.layer_wise.core": [[386, "module-neural_compressor.onnxrt.algorithms.layer_wise.core"]], "neural_compressor.onnxrt.algorithms.layer_wise": [[387, "module-neural_compressor.onnxrt.algorithms.layer_wise"]], "calibrator (class in neural_compressor.onnxrt.algorithms.smoother.calibrator)": [[388, "neural_compressor.onnxrt.algorithms.smoother.calibrator.Calibrator"]], "neural_compressor.onnxrt.algorithms.smoother.calibrator": [[388, "module-neural_compressor.onnxrt.algorithms.smoother.calibrator"]], "smoother (class in neural_compressor.onnxrt.algorithms.smoother.core)": [[389, "neural_compressor.onnxrt.algorithms.smoother.core.Smoother"]], "neural_compressor.onnxrt.algorithms.smoother.core": [[389, "module-neural_compressor.onnxrt.algorithms.smoother.core"]], "neural_compressor.onnxrt.algorithms.smoother": [[390, "module-neural_compressor.onnxrt.algorithms.smoother"]], "apply_awq_on_model() (in module neural_compressor.onnxrt.algorithms.weight_only.awq)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.awq.apply_awq_on_model"]], "awq_quantize() (in module neural_compressor.onnxrt.algorithms.weight_only.awq)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.awq.awq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.awq": [[391, "module-neural_compressor.onnxrt.algorithms.weight_only.awq"]], "apply_gptq_on_model() (in module neural_compressor.onnxrt.algorithms.weight_only.gptq)": [[392, "neural_compressor.onnxrt.algorithms.weight_only.gptq.apply_gptq_on_model"]], "gptq_quantize() (in module neural_compressor.onnxrt.algorithms.weight_only.gptq)": [[392, "neural_compressor.onnxrt.algorithms.weight_only.gptq.gptq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.gptq": [[392, "module-neural_compressor.onnxrt.algorithms.weight_only.gptq"]], "neural_compressor.onnxrt.algorithms.weight_only": [[393, "module-neural_compressor.onnxrt.algorithms.weight_only"]], "apply_rtn_on_model() (in module neural_compressor.onnxrt.algorithms.weight_only.rtn)": [[394, "neural_compressor.onnxrt.algorithms.weight_only.rtn.apply_rtn_on_model"]], "neural_compressor.onnxrt.algorithms.weight_only.rtn": [[394, "module-neural_compressor.onnxrt.algorithms.weight_only.rtn"]], "rtn_quantize() (in module neural_compressor.onnxrt.algorithms.weight_only.rtn)": [[394, "neural_compressor.onnxrt.algorithms.weight_only.rtn.rtn_quantize"]], "make_matmul_weight_only_node() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[395, "neural_compressor.onnxrt.algorithms.weight_only.utility.make_matmul_weight_only_node"]], "neural_compressor.onnxrt.algorithms.weight_only.utility": [[395, "module-neural_compressor.onnxrt.algorithms.weight_only.utility"]], "pad_tensor() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[395, "neural_compressor.onnxrt.algorithms.weight_only.utility.pad_tensor"]], "prepare_inputs() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[395, "neural_compressor.onnxrt.algorithms.weight_only.utility.prepare_inputs"]], "qdq_tensor() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[395, "neural_compressor.onnxrt.algorithms.weight_only.utility.qdq_tensor"]], "quant_tensor() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[395, "neural_compressor.onnxrt.algorithms.weight_only.utility.quant_tensor"]], "neural_compressor.onnxrt": [[396, "module-neural_compressor.onnxrt"]], "awq_quantize_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[397, "neural_compressor.onnxrt.quantization.algorithm_entry.awq_quantize_entry"]], "gptq_quantize_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[397, "neural_compressor.onnxrt.quantization.algorithm_entry.gptq_quantize_entry"]], "neural_compressor.onnxrt.quantization.algorithm_entry": [[397, "module-neural_compressor.onnxrt.quantization.algorithm_entry"]], "rtn_quantize_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[397, "neural_compressor.onnxrt.quantization.algorithm_entry.rtn_quantize_entry"]], "smooth_quant_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[397, "neural_compressor.onnxrt.quantization.algorithm_entry.smooth_quant_entry"]], "autotune() (in module neural_compressor.onnxrt.quantization.autotune)": [[398, "neural_compressor.onnxrt.quantization.autotune.autotune"]], "neural_compressor.onnxrt.quantization.autotune": [[398, "module-neural_compressor.onnxrt.quantization.autotune"]], "calibrationdatareader (class in neural_compressor.onnxrt.quantization.calibrate)": [[399, "neural_compressor.onnxrt.quantization.calibrate.CalibrationDataReader"]], "neural_compressor.onnxrt.quantization.calibrate": [[399, "module-neural_compressor.onnxrt.quantization.calibrate"]], "awqconfig (class in neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.AWQConfig"]], "gptqconfig (class in neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.GPTQConfig"]], "rtnconfig (class in neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.RTNConfig"]], "smoohquantconfig (class in neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.SmoohQuantConfig"]], "get_default_awq_config() (in module neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.get_default_awq_config"]], "get_default_gptq_config() (in module neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.get_default_gptq_config"]], "get_default_rtn_config() (in module neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.get_default_rtn_config"]], "get_default_sq_config() (in module neural_compressor.onnxrt.quantization.config)": [[400, "neural_compressor.onnxrt.quantization.config.get_default_sq_config"]], "neural_compressor.onnxrt.quantization.config": [[400, "module-neural_compressor.onnxrt.quantization.config"]], "neural_compressor.onnxrt.quantization": [[401, "module-neural_compressor.onnxrt.quantization"]], "neural_compressor.onnxrt.quantization.quantize": [[402, "module-neural_compressor.onnxrt.quantization.quantize"]], "neural_compressor.onnxrt.utils": [[403, "module-neural_compressor.onnxrt.utils"]], "onnxmodel (class in neural_compressor.onnxrt.utils.onnx_model)": [[404, "neural_compressor.onnxrt.utils.onnx_model.ONNXModel"]], "neural_compressor.onnxrt.utils.onnx_model": [[404, "module-neural_compressor.onnxrt.utils.onnx_model"]], "check_model_with_infer_shapes() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.check_model_with_infer_shapes"]], "find_by_name() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.find_by_name"]], "get_qrange_for_qtype() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.get_qrange_for_qType"]], "is_b_transposed() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.is_B_transposed"]], "neural_compressor.onnxrt.utils.utility": [[405, "module-neural_compressor.onnxrt.utils.utility"]], "quantize_data() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.quantize_data"]], "register_algo() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.register_algo"]], "simple_progress_bar() (in module neural_compressor.onnxrt.utils.utility)": [[405, "neural_compressor.onnxrt.utils.utility.simple_progress_bar"]], "neural_compressor.profiling": [[406, "module-neural_compressor.profiling"]], "parserfactory (class in neural_compressor.profiling.parser.factory)": [[407, "neural_compressor.profiling.parser.factory.ParserFactory"]], "neural_compressor.profiling.parser.factory": [[407, "module-neural_compressor.profiling.parser.factory"]], "neural_compressor.profiling.parser": [[408, "module-neural_compressor.profiling.parser"]], "onnxrtparserfactory (class in neural_compressor.profiling.parser.onnx_parser.factory)": [[409, "neural_compressor.profiling.parser.onnx_parser.factory.OnnxrtParserFactory"]], "neural_compressor.profiling.parser.onnx_parser.factory": [[409, "module-neural_compressor.profiling.parser.onnx_parser.factory"]], "neural_compressor.profiling.parser.onnx_parser": [[410, "module-neural_compressor.profiling.parser.onnx_parser"]], "onnxprofilingparser (class in neural_compressor.profiling.parser.onnx_parser.parser)": [[411, "neural_compressor.profiling.parser.onnx_parser.parser.OnnxProfilingParser"]], "neural_compressor.profiling.parser.onnx_parser.parser": [[411, "module-neural_compressor.profiling.parser.onnx_parser.parser"]], "profilingparser (class in neural_compressor.profiling.parser.parser)": [[412, "neural_compressor.profiling.parser.parser.ProfilingParser"]], "neural_compressor.profiling.parser.parser": [[412, "module-neural_compressor.profiling.parser.parser"]], "profilingresult (class in neural_compressor.profiling.parser.result)": [[413, "neural_compressor.profiling.parser.result.ProfilingResult"]], "neural_compressor.profiling.parser.result": [[413, "module-neural_compressor.profiling.parser.result"]], "tensorflowparserfactory (class in neural_compressor.profiling.parser.tensorflow_parser.factory)": [[414, "neural_compressor.profiling.parser.tensorflow_parser.factory.TensorFlowParserFactory"]], "neural_compressor.profiling.parser.tensorflow_parser.factory": [[414, "module-neural_compressor.profiling.parser.tensorflow_parser.factory"]], "neural_compressor.profiling.parser.tensorflow_parser": [[415, "module-neural_compressor.profiling.parser.tensorflow_parser"]], "tensorflowprofilingparser (class in neural_compressor.profiling.parser.tensorflow_parser.parser)": [[416, "neural_compressor.profiling.parser.tensorflow_parser.parser.TensorFlowProfilingParser"]], "neural_compressor.profiling.parser.tensorflow_parser.parser": [[416, "module-neural_compressor.profiling.parser.tensorflow_parser.parser"]], "profilerfactory (class in neural_compressor.profiling.profiler.factory)": [[417, "neural_compressor.profiling.profiler.factory.ProfilerFactory"]], "neural_compressor.profiling.profiler.factory": [[417, "module-neural_compressor.profiling.profiler.factory"]], "neural_compressor.profiling.profiler": [[418, "module-neural_compressor.profiling.profiler"]], "profilerfactory (class in neural_compressor.profiling.profiler.onnxrt_profiler.factory)": [[419, "neural_compressor.profiling.profiler.onnxrt_profiler.factory.ProfilerFactory"]], "neural_compressor.profiling.profiler.onnxrt_profiler.factory": [[419, "module-neural_compressor.profiling.profiler.onnxrt_profiler.factory"]], "neural_compressor.profiling.profiler.onnxrt_profiler": [[420, "module-neural_compressor.profiling.profiler.onnxrt_profiler"]], "profiler (class in neural_compressor.profiling.profiler.onnxrt_profiler.profiler)": [[421, "neural_compressor.profiling.profiler.onnxrt_profiler.profiler.Profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.profiler": [[421, "module-neural_compressor.profiling.profiler.onnxrt_profiler.profiler"]], "create_onnx_config() (in module neural_compressor.profiling.profiler.onnxrt_profiler.utils)": [[422, "neural_compressor.profiling.profiler.onnxrt_profiler.utils.create_onnx_config"]], "neural_compressor.profiling.profiler.onnxrt_profiler.utils": [[422, "module-neural_compressor.profiling.profiler.onnxrt_profiler.utils"]], "profiler (class in neural_compressor.profiling.profiler.profiler)": [[423, "neural_compressor.profiling.profiler.profiler.Profiler"]], "neural_compressor.profiling.profiler.profiler": [[423, "module-neural_compressor.profiling.profiler.profiler"]], "profilerfactory (class in neural_compressor.profiling.profiler.tensorflow_profiler.factory)": [[424, "neural_compressor.profiling.profiler.tensorflow_profiler.factory.ProfilerFactory"]], "neural_compressor.profiling.profiler.tensorflow_profiler.factory": [[424, "module-neural_compressor.profiling.profiler.tensorflow_profiler.factory"]], "neural_compressor.profiling.profiler.tensorflow_profiler": [[425, "module-neural_compressor.profiling.profiler.tensorflow_profiler"]], "profiler (class in neural_compressor.profiling.profiler.tensorflow_profiler.profiler)": [[426, "neural_compressor.profiling.profiler.tensorflow_profiler.profiler.Profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.profiler": [[426, "module-neural_compressor.profiling.profiler.tensorflow_profiler.profiler"]], "create_tf_config() (in module neural_compressor.profiling.profiler.tensorflow_profiler.utils)": [[427, "neural_compressor.profiling.profiler.tensorflow_profiler.utils.create_tf_config"]], "delete_assign() (in module neural_compressor.profiling.profiler.tensorflow_profiler.utils)": [[427, "neural_compressor.profiling.profiler.tensorflow_profiler.utils.delete_assign"]], "neural_compressor.profiling.profiler.tensorflow_profiler.utils": [[427, "module-neural_compressor.profiling.profiler.tensorflow_profiler.utils"]], "set_eager_execution() (in module neural_compressor.profiling.profiler.tensorflow_profiler.utils)": [[427, "neural_compressor.profiling.profiler.tensorflow_profiler.utils.set_eager_execution"]], "fit() (in module neural_compressor.quantization)": [[428, "neural_compressor.quantization.fit"]], "neural_compressor.quantization": [[428, "module-neural_compressor.quantization"]], "autotunestrategy (class in neural_compressor.strategy.auto)": [[429, "neural_compressor.strategy.auto.AutoTuneStrategy"]], "neural_compressor.strategy.auto": [[429, "module-neural_compressor.strategy.auto"]], "automixedprecisiontunestrategy (class in neural_compressor.strategy.auto_mixed_precision)": [[430, "neural_compressor.strategy.auto_mixed_precision.AutoMixedPrecisionTuneStrategy"]], "neural_compressor.strategy.auto_mixed_precision": [[430, "module-neural_compressor.strategy.auto_mixed_precision"]], "basictunestrategy (class in neural_compressor.strategy.basic)": [[431, "neural_compressor.strategy.basic.BasicTuneStrategy"]], "neural_compressor.strategy.basic": [[431, "module-neural_compressor.strategy.basic"]], "bayesianoptimization (class in neural_compressor.strategy.bayesian)": [[432, "neural_compressor.strategy.bayesian.BayesianOptimization"]], "bayesiantunestrategy (class in neural_compressor.strategy.bayesian)": [[432, "neural_compressor.strategy.bayesian.BayesianTuneStrategy"]], "targetspace (class in neural_compressor.strategy.bayesian)": [[432, "neural_compressor.strategy.bayesian.TargetSpace"]], "acq_max() (in module neural_compressor.strategy.bayesian)": [[432, "neural_compressor.strategy.bayesian.acq_max"]], "neural_compressor.strategy.bayesian": [[432, "module-neural_compressor.strategy.bayesian"]], "conservativetunestrategy (class in neural_compressor.strategy.conservative)": [[433, "neural_compressor.strategy.conservative.ConservativeTuneStrategy"]], "neural_compressor.strategy.conservative": [[433, "module-neural_compressor.strategy.conservative"]], "exhaustivetunestrategy (class in neural_compressor.strategy.exhaustive)": [[434, "neural_compressor.strategy.exhaustive.ExhaustiveTuneStrategy"]], "neural_compressor.strategy.exhaustive": [[434, "module-neural_compressor.strategy.exhaustive"]], "hawq_v2tunestrategy (class in neural_compressor.strategy.hawq_v2)": [[435, "neural_compressor.strategy.hawq_v2.HAWQ_V2TuneStrategy"]], "neural_compressor.strategy.hawq_v2": [[435, "module-neural_compressor.strategy.hawq_v2"]], "neural_compressor.strategy": [[436, "module-neural_compressor.strategy"]], "msetunestrategy (class in neural_compressor.strategy.mse)": [[437, "neural_compressor.strategy.mse.MSETuneStrategy"]], "neural_compressor.strategy.mse": [[437, "module-neural_compressor.strategy.mse"]], "mse_v2tunestrategy (class in neural_compressor.strategy.mse_v2)": [[438, "neural_compressor.strategy.mse_v2.MSE_V2TuneStrategy"]], "neural_compressor.strategy.mse_v2": [[438, "module-neural_compressor.strategy.mse_v2"]], "randomtunestrategy (class in neural_compressor.strategy.random)": [[439, "neural_compressor.strategy.random.RandomTuneStrategy"]], "neural_compressor.strategy.random": [[439, "module-neural_compressor.strategy.random"]], "tunestrategy (class in neural_compressor.strategy.strategy)": [[440, "neural_compressor.strategy.strategy.TuneStrategy"]], "tunestrategymeta (class in neural_compressor.strategy.strategy)": [[440, "neural_compressor.strategy.strategy.TuneStrategyMeta"]], "neural_compressor.strategy.strategy": [[440, "module-neural_compressor.strategy.strategy"]], "strategy_registry() (in module neural_compressor.strategy.strategy)": [[440, "neural_compressor.strategy.strategy.strategy_registry"]], "neural_compressor.strategy.utils.constant": [[441, "module-neural_compressor.strategy.utils.constant"]], "neural_compressor.strategy.utils": [[442, "module-neural_compressor.strategy.utils"]], "blockfallbacktuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.BlockFallbackTuningSampler"]], "fallbacktuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.FallbackTuningSampler"]], "lowerbitssampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.LowerBitsSampler"]], "modelwisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.ModelWiseTuningSampler"]], "optypewisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.OpTypeWiseTuningSampler"]], "opwisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.OpWiseTuningSampler"]], "smoothquantsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.SmoothQuantSampler"]], "tuningorder (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.TuningOrder"]], "tuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.TuningSampler"]], "weightonlyquantsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[443, "neural_compressor.strategy.utils.tuning_sampler.WeightOnlyQuantSampler"]], "neural_compressor.strategy.utils.tuning_sampler": [[443, "module-neural_compressor.strategy.utils.tuning_sampler"]], "tuningitem (class in neural_compressor.strategy.utils.tuning_space)": [[444, "neural_compressor.strategy.utils.tuning_space.TuningItem"]], "tuningspace (class in neural_compressor.strategy.utils.tuning_space)": [[444, "neural_compressor.strategy.utils.tuning_space.TuningSpace"]], "initial_tuning_cfg_with_quant_mode() (in module neural_compressor.strategy.utils.tuning_space)": [[444, "neural_compressor.strategy.utils.tuning_space.initial_tuning_cfg_with_quant_mode"]], "neural_compressor.strategy.utils.tuning_space": [[444, "module-neural_compressor.strategy.utils.tuning_space"]], "pattern_to_internal() (in module neural_compressor.strategy.utils.tuning_space)": [[444, "neural_compressor.strategy.utils.tuning_space.pattern_to_internal"]], "pattern_to_path() (in module neural_compressor.strategy.utils.tuning_space)": [[444, "neural_compressor.strategy.utils.tuning_space.pattern_to_path"]], "quant_mode_from_pattern() (in module neural_compressor.strategy.utils.tuning_space)": [[444, "neural_compressor.strategy.utils.tuning_space.quant_mode_from_pattern"]], "optuningconfig (class in neural_compressor.strategy.utils.tuning_structs)": [[445, "neural_compressor.strategy.utils.tuning_structs.OpTuningConfig"]], "neural_compressor.strategy.utils.tuning_structs": [[445, "module-neural_compressor.strategy.utils.tuning_structs"]], "classregister (class in neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.ClassRegister"]], "ordereddefaultdict (class in neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.OrderedDefaultDict"]], "quantoptions (class in neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.QuantOptions"]], "quanttype (class in neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.QuantType"]], "build_slave_faker_model() (in module neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.build_slave_faker_model"]], "extract_data_type() (in module neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.extract_data_type"]], "get_adaptor_name() (in module neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.get_adaptor_name"]], "neural_compressor.strategy.utils.utility": [[446, "module-neural_compressor.strategy.utils.utility"]], "preprocess_user_cfg() (in module neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.preprocess_user_cfg"]], "reverted_data_type() (in module neural_compressor.strategy.utils.utility)": [[446, "neural_compressor.strategy.utils.utility.reverted_data_type"]], "exampleclass (class in neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.ExampleClass"]], "attr1 (neural_compressor.template.api_doc_example.exampleclass attribute)": [[447, "neural_compressor.template.api_doc_example.ExampleClass.attr1"]], "attr2 (neural_compressor.template.api_doc_example.exampleclass attribute)": [[447, "neural_compressor.template.api_doc_example.ExampleClass.attr2"]], "attr5 (neural_compressor.template.api_doc_example.exampleclass attribute)": [[447, "neural_compressor.template.api_doc_example.ExampleClass.attr5"]], "attribute1 (in module neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.attribute1"]], "function1() (in module neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.function1"]], "function2() (in module neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.function2"]], "function3() (in module neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.function3"]], "generator1() (in module neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.generator1"]], "module_debug_level1 (in module neural_compressor.template.api_doc_example)": [[447, "neural_compressor.template.api_doc_example.module_debug_level1"]], "neural_compressor.template.api_doc_example": [[447, "module-neural_compressor.template.api_doc_example"]], "neural_compressor.template": [[448, "module-neural_compressor.template"]], "neural_compressor.tensorflow.algorithms": [[449, "module-neural_compressor.tensorflow.algorithms"]], "smoothquantcalibration (class in neural_compressor.tensorflow.algorithms.smoother.calibration)": [[450, "neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibration"]], "smoothquantcalibrationllm (class in neural_compressor.tensorflow.algorithms.smoother.calibration)": [[450, "neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibrationLLM"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[450, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"]], "smoothquant (class in neural_compressor.tensorflow.algorithms.smoother.core)": [[451, "neural_compressor.tensorflow.algorithms.smoother.core.SmoothQuant"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[451, "module-neural_compressor.tensorflow.algorithms.smoother.core"]], "neural_compressor.tensorflow.algorithms.smoother": [[452, "module-neural_compressor.tensorflow.algorithms.smoother"]], "smoothquantscaler (class in neural_compressor.tensorflow.algorithms.smoother.scaler)": [[453, "neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScaler"]], "smoothquantscalerllm (class in neural_compressor.tensorflow.algorithms.smoother.scaler)": [[453, "neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScalerLLM"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[453, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"]], "neural_compressor.tensorflow.algorithms.static_quant": [[454, "module-neural_compressor.tensorflow.algorithms.static_quant"]], "kerasadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[455, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasAdaptor"]], "kerasconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[455, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasConfigConverter"]], "kerasquery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[455, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasQuery"]], "kerassurgery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[455, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasSurgery"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[455, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"]], "tensorflowadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[456, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorFlowAdaptor"]], "tensorflowconfig (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[456, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorFlowConfig"]], "tensorflowconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[456, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorflowConfigConverter"]], "tensorflowquery (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[456, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.TensorflowQuery"]], "tensorflow_itexadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.tensorflow)": [[456, "neural_compressor.tensorflow.algorithms.static_quant.tensorflow.Tensorflow_ITEXAdaptor"]], "neural_compressor.tensorflow.algorithms.static_quant.tensorflow": [[456, "module-neural_compressor.tensorflow.algorithms.static_quant.tensorflow"]], "neural_compressor.tensorflow": [[457, "module-neural_compressor.tensorflow"]], "neural_compressor.tensorflow.keras": [[458, "module-neural_compressor.tensorflow.keras"]], "neural_compressor.tensorflow.keras.layers.conv2d": [[459, "module-neural_compressor.tensorflow.keras.layers.conv2d"]], "neural_compressor.tensorflow.keras.layers.dense": [[460, "module-neural_compressor.tensorflow.keras.layers.dense"]], "neural_compressor.tensorflow.keras.layers.depthwise_conv2d": [[461, "module-neural_compressor.tensorflow.keras.layers.depthwise_conv2d"]], "neural_compressor.tensorflow.keras.layers": [[462, "module-neural_compressor.tensorflow.keras.layers"]], "neural_compressor.tensorflow.keras.layers.layer_initializer": [[463, "module-neural_compressor.tensorflow.keras.layers.layer_initializer"]], "neural_compressor.tensorflow.keras.layers.pool2d": [[464, "module-neural_compressor.tensorflow.keras.layers.pool2d"]], "neural_compressor.tensorflow.keras.layers.separable_conv2d": [[465, "module-neural_compressor.tensorflow.keras.layers.separable_conv2d"]], "staticquantconfig (class in neural_compressor.tensorflow.keras.quantization.config)": [[466, "neural_compressor.tensorflow.keras.quantization.config.StaticQuantConfig"]], "get_all_registered_configs() (in module neural_compressor.tensorflow.keras.quantization.config)": [[466, "neural_compressor.tensorflow.keras.quantization.config.get_all_registered_configs"]], "get_default_static_quant_config() (in module neural_compressor.tensorflow.keras.quantization.config)": [[466, "neural_compressor.tensorflow.keras.quantization.config.get_default_static_quant_config"]], "neural_compressor.tensorflow.keras.quantization.config": [[466, "module-neural_compressor.tensorflow.keras.quantization.config"]], "neural_compressor.tensorflow.keras.quantization": [[467, "module-neural_compressor.tensorflow.keras.quantization"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[468, "module-neural_compressor.tensorflow.quantization.algorithm_entry"]], "static_quant_entry() (in module neural_compressor.tensorflow.quantization.algorithm_entry)": [[468, "neural_compressor.tensorflow.quantization.algorithm_entry.static_quant_entry"]], "autotune() (in module neural_compressor.tensorflow.quantization.autotune)": [[469, "neural_compressor.tensorflow.quantization.autotune.autotune"]], "neural_compressor.tensorflow.quantization.autotune": [[469, "module-neural_compressor.tensorflow.quantization.autotune"]], "smoothquantconfig (class in neural_compressor.tensorflow.quantization.config)": [[470, "neural_compressor.tensorflow.quantization.config.SmoothQuantConfig"]], "staticquantconfig (class in neural_compressor.tensorflow.quantization.config)": [[470, "neural_compressor.tensorflow.quantization.config.StaticQuantConfig"]], "get_default_sq_config() (in module neural_compressor.tensorflow.quantization.config)": [[470, "neural_compressor.tensorflow.quantization.config.get_default_sq_config"]], "get_default_static_quant_config() (in module neural_compressor.tensorflow.quantization.config)": [[470, "neural_compressor.tensorflow.quantization.config.get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization.config": [[470, "module-neural_compressor.tensorflow.quantization.config"]], "neural_compressor.tensorflow.quantization": [[471, "module-neural_compressor.tensorflow.quantization"]], "neural_compressor.tensorflow.quantization.quantize": [[472, "module-neural_compressor.tensorflow.quantization.quantize"]], "quantize_model() (in module neural_compressor.tensorflow.quantization.quantize)": [[472, "neural_compressor.tensorflow.quantization.quantize.quantize_model"]], "quantize_model_with_single_config() (in module neural_compressor.tensorflow.quantization.quantize)": [[472, "neural_compressor.tensorflow.quantization.quantize.quantize_model_with_single_config"]], "graphconverter (class in neural_compressor.tensorflow.quantization.utils.graph_converter)": [[473, "neural_compressor.tensorflow.quantization.utils.graph_converter.GraphConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_converter": [[473, "module-neural_compressor.tensorflow.quantization.utils.graph_converter"]], "graphconverterwithoutcalib (class in neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib)": [[474, "neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib.GraphConverterWithoutCalib"]], "neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib": [[474, "module-neural_compressor.tensorflow.quantization.utils.graph_converter_without_calib"]], "bf16convert (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert)": [[475, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert.BF16Convert"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert": [[475, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.bf16_convert"]], "dequantizecastoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer)": [[476, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer.DequantizeCastOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[476, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16": [[477, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.bf16"]], "convertaddtobiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd.ConvertAddToBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[478, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"]], "convertlayoutoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout.ConvertLayoutOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[479, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"]], "convertleakyreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu)": [[480, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu.ConvertLeakyReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[480, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"]], "convertnantorandom (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random)": [[481, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random.ConvertNanToRandom"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[481, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"]], "convertplaceholdertoconst (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const)": [[482, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const.ConvertPlaceholderToConst"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[482, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"]], "dilatedcontraction (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction)": [[483, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction.DilatedContraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[483, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"]], "injectdummybiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd)": [[484, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd.InjectDummyBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[484, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"]], "expanddimsoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer)": [[485, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer.ExpandDimsOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[485, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"]], "fetchweightfromreshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape)": [[486, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape.FetchWeightFromReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[486, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "foldbatchnormnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm)": [[487, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm.FoldBatchNormNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[487, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"]], "graphfoldconstantoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant)": [[488, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant.GraphFoldConstantOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[488, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"]], "fusebiasaddandaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add)": [[489, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add.FuseBiasAddAndAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[489, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"]], "fusecolumnwisemuloptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul)": [[490, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul.FuseColumnWiseMulOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[490, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"]], "fuseconvwithmathoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math)": [[491, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math.FuseConvWithMathOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[491, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"]], "fusedecomposedbnoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.FuseDecomposedBNOptimizer"]], "bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.get_const_dim_count"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[492, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.values_from_const"]], "fusedecomposedinoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.FuseDecomposedINOptimizer"]], "bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.get_const_dim_count"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[493, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.values_from_const"]], "fusegeluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu)": [[494, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu.FuseGeluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[494, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"]], "fuselayernormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[495, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.FuseLayerNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[495, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[495, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[495, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_name_from_input"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[495, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.values_from_const"]], "fusepadwithconv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv)": [[496, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv.FusePadWithConv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[496, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"]], "fusepadwithfp32conv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv)": [[497, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv.FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[497, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "fusetransposereshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose)": [[498, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose.FuseTransposeReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[498, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"]], "graphcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer)": [[499, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer.GraphCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[499, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"]], "grappleroptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass)": [[500, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass.GrapplerOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[500, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[501, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"]], "insertprintminmaxnode (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node)": [[502, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node.InsertPrintMinMaxNode"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[502, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"]], "movesqueezeafterreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu)": [[503, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu.MoveSqueezeAfterReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[503, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"]], "preoptimization (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize)": [[504, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize.PreOptimization"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[504, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"]], "removetrainingnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes)": [[505, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes.RemoveTrainingNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[505, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"]], "renamebatchnormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm)": [[506, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm.RenameBatchNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[506, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"]], "splitsharedinputoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input)": [[507, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input.SplitSharedInputOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[507, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"]], "stripequivalentnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes)": [[508, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes.StripEquivalentNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[508, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"]], "stripunusednodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes)": [[509, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes.StripUnusedNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[509, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"]], "switchoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer)": [[510, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer.SwitchOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[510, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"]], "graphrewriterbase (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base)": [[511, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base.GraphRewriterBase"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[511, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[512, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"]], "freezefakequantopoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant)": [[513, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant.FreezeFakeQuantOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant": [[513, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_fake_quant"]], "freezevaluetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value)": [[514, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value.FreezeValueTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value": [[514, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value"]], "freezevaluewithoutcalibtransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib)": [[515, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib.FreezeValueWithoutCalibTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib": [[515, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.freeze_value_without_calib"]], "fuseconvredundantdequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize)": [[516, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize.FuseConvRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[516, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "fuseconvrequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize)": [[517, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize.FuseConvRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize": [[517, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_conv_requantize"]], "fusematmulredundantdequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize)": [[518, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize.FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[518, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "fusematmulrequantizedequantizenewapitransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[519, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeNewAPITransformer"]], "fusematmulrequantizedequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[519, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeTransformer"]], "fusematmulrequantizenewapitransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[519, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeNewAPITransformer"]], "fusematmulrequantizetransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize)": [[519, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize": [[519, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8": [[520, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8"]], "metainfochangingmemopoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer)": [[521, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer.MetaInfoChangingMemOpOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer": [[521, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.meta_op_optimizer"]], "posthostconstconverter (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter)": [[522, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter.PostHostConstConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter": [[522, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_hostconst_converter"]], "postcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse)": [[523, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse.PostCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse": [[523, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.post_quantized_op_cse"]], "quantizedrnnconverter (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert)": [[524, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert.QuantizedRNNConverter"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert": [[524, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.rnn_convert"]], "scalepropagationtransformer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation)": [[525, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation.ScaleProPagationTransformer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation": [[525, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq": [[526, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq"]], "generategraphwithqdqpattern (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern)": [[527, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern.GenerateGraphWithQDQPattern"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern": [[527, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.insert_qdq_pattern"]], "mergeduplicatedqdqoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq)": [[528, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq.MergeDuplicatedQDQOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq": [[528, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "shareqdqforitexypatternoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern)": [[529, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern.ShareQDQForItexYPatternOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern": [[529, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "graphanalyzer (class in neural_compressor.tensorflow.quantization.utils.graph_util)": [[530, "neural_compressor.tensorflow.quantization.utils.graph_util.GraphAnalyzer"]], "graphrewriterhelper (class in neural_compressor.tensorflow.quantization.utils.graph_util)": [[530, "neural_compressor.tensorflow.quantization.utils.graph_util.GraphRewriterHelper"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[530, "module-neural_compressor.tensorflow.quantization.utils.graph_util"]], "neural_compressor.tensorflow.quantization.utils": [[531, "module-neural_compressor.tensorflow.quantization.utils"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph": [[532, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph"]], "fakequantize (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize)": [[533, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize.FakeQuantize"]], "fakequantizebase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize)": [[533, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize.FakeQuantizeBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize": [[533, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.fake_quantize"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat": [[534, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat"]], "quantizeconfig (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config)": [[535, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config.QuantizeConfig"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config": [[535, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_config"]], "init_quantize_config() (in module neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper)": [[536, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper.init_quantize_config"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper": [[536, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper"]], "qat_clone_function() (in module neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper)": [[536, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_helper.qat_clone_function"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers": [[537, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers"]], "config_quantizable_layers() (in module neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer)": [[538, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer.config_quantizable_layers"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer": [[538, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.optimize_layer"]], "quantizelayeradd (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add)": [[539, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add.QuantizeLayerAdd"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[539, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_add"]], "quantizelayerbase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base)": [[540, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base.QuantizeLayerBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[540, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_base"]], "quantizelayerbatchnormalization (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn)": [[541, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn.QuantizeLayerBatchNormalization"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[541, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"]], "quantizewrapper (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper)": [[542, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper.QuantizeWrapper"]], "quantizewrapperbase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper)": [[542, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper.QuantizeWrapperBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper": [[542, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qat.quantize_wrapper"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn)": [[543, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn": [[543, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2)": [[544, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2": [[544, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv)": [[545, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv.FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv": [[545, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_conv"]], "fusenodestartwithdeconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv)": [[546, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv.FuseNodeStartWithDeconv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv": [[546, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_deconv"]], "fusenodestartwithfusedinstancenorm (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in)": [[547, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in.FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in": [[547, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_in"]], "fusenodestartwithmatmul (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul)": [[548, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul": [[548, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_matmul"]], "fusenodestartwithpooling (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling)": [[549, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling.FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling": [[549, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq": [[550, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq"]], "optimizeqdqgraph (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq)": [[551, "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq.OptimizeQDQGraph"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq": [[551, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.qdq.optimize_qdq"]], "quantizegraphbase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base)": [[552, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base.QuantizeGraphBase"]], "quantizenodebase (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base)": [[552, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base.QuantizeNodeBase"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base": [[552, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_base"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn)": [[553, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn": [[553, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2)": [[554, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2": [[554, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv)": [[555, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv.FuseNodeStartWithConv2d"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv": [[555, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_conv"]], "quantizegraphforintel (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu)": [[556, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu.QuantizeGraphForIntel"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu": [[556, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_for_intel_cpu"]], "fusenodestartwithmatmul (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul)": [[557, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul": [[557, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_matmul"]], "fusenodestartwithpooling (class in neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling)": [[558, "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling.FuseNodeStartWithPooling"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling": [[558, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph.quantize_graph_pooling"]], "quantizegraphhelper (class in neural_compressor.tensorflow.quantization.utils.quantize_graph_common)": [[559, "neural_compressor.tensorflow.quantization.utils.quantize_graph_common.QuantizeGraphHelper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[559, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"]], "biascorrection (class in neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction)": [[560, "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction.BiasCorrection"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction": [[560, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.bias_correction"]], "graphtransformbase (class in neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base)": [[561, "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base.GraphTransformBase"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base": [[561, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.graph_transform_base"]], "neural_compressor.tensorflow.quantization.utils.transform_graph": [[562, "module-neural_compressor.tensorflow.quantization.utils.transform_graph"]], "insertlogging (class in neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging)": [[563, "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging.InsertLogging"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging": [[563, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.insert_logging"]], "rerangequantizedconcat (class in neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat)": [[564, "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat.RerangeQuantizedConcat"]], "neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat": [[564, "module-neural_compressor.tensorflow.quantization.utils.transform_graph.rerange_quantized_concat"]], "apply_inlining() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.apply_inlining"]], "collate_tf_preds() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.collate_tf_preds"]], "construct_function_from_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.construct_function_from_graph_def"]], "fix_ref_type_of_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.fix_ref_type_of_graph_def"]], "generate_feed_dict() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.generate_feed_dict"]], "get_estimator_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_estimator_graph"]], "get_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_graph_def"]], "get_input_output_node_names() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_input_output_node_names"]], "get_model_input_shape() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_model_input_shape"]], "get_tensor_by_name() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_tensor_by_name"]], "get_tensor_val_from_graph_node() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_tensor_val_from_graph_node"]], "get_weight_from_input_tensor() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.get_weight_from_input_tensor"]], "int8_node_name_reverse() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.int8_node_name_reverse"]], "is_ckpt_format() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.is_ckpt_format"]], "is_saved_model_format() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.is_saved_model_format"]], "iterator_sess_run() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.iterator_sess_run"]], "neural_compressor.tensorflow.quantization.utils.utility": [[565, "module-neural_compressor.tensorflow.quantization.utils.utility"]], "parse_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.parse_saved_model"]], "read_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.read_graph"]], "reconstruct_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.reconstruct_saved_model"]], "strip_equivalent_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.strip_equivalent_nodes"]], "strip_unused_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.strip_unused_nodes"]], "write_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[565, "neural_compressor.tensorflow.quantization.utils.utility.write_graph"]], "neural_compressor.tensorflow.utils.constants": [[566, "module-neural_compressor.tensorflow.utils.constants"]], "basedataloader (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.BaseDataLoader"]], "batchsampler (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.BatchSampler"]], "dummydataset (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.DummyDataset"]], "dummydatasetv2 (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.DummyDatasetV2"]], "indexfetcher (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.IndexFetcher"]], "iterablefetcher (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.IterableFetcher"]], "iterablesampler (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.IterableSampler"]], "sequentialsampler (class in neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.SequentialSampler"]], "default_collate() (in module neural_compressor.tensorflow.utils.data)": [[567, "neural_compressor.tensorflow.utils.data.default_collate"]], "neural_compressor.tensorflow.utils.data": [[567, "module-neural_compressor.tensorflow.utils.data"]], "neural_compressor.tensorflow.utils": [[568, "module-neural_compressor.tensorflow.utils"]], "model (class in neural_compressor.tensorflow.utils.model)": [[569, "neural_compressor.tensorflow.utils.model.Model"]], "neural_compressor.tensorflow.utils.model": [[569, "module-neural_compressor.tensorflow.utils.model"]], "basemodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.BaseModel"]], "kerasmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.KerasModel"]], "tensorflowbasemodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowBaseModel"]], "tensorflowcheckpointmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowCheckpointModel"]], "tensorflowllmmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowLLMModel"]], "tensorflowmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowModel"]], "tensorflowqatmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowQATModel"]], "tensorflowsavedmodelmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowSavedModelModel"]], "checkpoint_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.checkpoint_session"]], "estimator_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.estimator_session"]], "frozen_pb_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.frozen_pb_session"]], "get_model_type() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.get_model_type"]], "graph_def_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.graph_def_session"]], "graph_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.graph_session"]], "keras_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.keras_session"]], "load_saved_model() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.load_saved_model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[570, "module-neural_compressor.tensorflow.utils.model_wrappers"]], "saved_model_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.saved_model_session"]], "slim_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.slim_session"]], "try_loading_keras() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.try_loading_keras"]], "validate_and_inference_input_output() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.validate_and_inference_input_output"]], "validate_graph_node() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[570, "neural_compressor.tensorflow.utils.model_wrappers.validate_graph_node"]], "tfslimnetsfactory (class in neural_compressor.tensorflow.utils.nets_factory)": [[571, "neural_compressor.tensorflow.utils.nets_factory.TFSlimNetsFactory"]], "neural_compressor.tensorflow.utils.nets_factory": [[571, "module-neural_compressor.tensorflow.utils.nets_factory"]], "captureoutputtofile (class in neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.CaptureOutputToFile"]], "cpuinfo (class in neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.CpuInfo"]], "dequantize() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.Dequantize"]], "lazyimport (class in neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.LazyImport"]], "statistics (class in neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.Statistics"]], "combine_histogram() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.combine_histogram"]], "deep_get() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.deep_get"]], "dequantize_weight() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.dequantize_weight"]], "disable_random() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.disable_random"]], "dump_data_to_local() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.dump_data_to_local"]], "dump_elapsed_time() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.dump_elapsed_time"]], "get_all_fp32_data() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.get_all_fp32_data"]], "get_tensor_histogram() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.get_tensor_histogram"]], "itex_installed() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.itex_installed"]], "load_data_from_pkl() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.load_data_from_pkl"]], "neural_compressor.tensorflow.utils.utility": [[572, "module-neural_compressor.tensorflow.utils.utility"]], "register_algo() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.register_algo"]], "singleton() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.singleton"]], "valid_keras_format() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.valid_keras_format"]], "version1_eq_version2() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.tensorflow.utils.utility)": [[572, "neural_compressor.tensorflow.utils.utility.version1_lte_version2"]], "quantizer (class in neural_compressor.torch.algorithms.base_algorithm)": [[573, "neural_compressor.torch.algorithms.base_algorithm.Quantizer"]], "neural_compressor.torch.algorithms.base_algorithm": [[573, "module-neural_compressor.torch.algorithms.base_algorithm"]], "neural_compressor.torch.algorithms.habana_fp8.fp8_quant": [[574, "module-neural_compressor.torch.algorithms.habana_fp8.fp8_quant"]], "neural_compressor.torch.algorithms.habana_fp8": [[575, "module-neural_compressor.torch.algorithms.habana_fp8"]], "neural_compressor.torch.algorithms.habana_fp8.modules": [[576, "module-neural_compressor.torch.algorithms.habana_fp8.modules"]], "neural_compressor.torch.algorithms.habana_fp8.observer": [[577, "module-neural_compressor.torch.algorithms.habana_fp8.observer"]], "neural_compressor.torch.algorithms.habana_fp8.save_load": [[578, "module-neural_compressor.torch.algorithms.habana_fp8.save_load"]], "neural_compressor.torch.algorithms.habana_fp8.scale": [[579, "module-neural_compressor.torch.algorithms.habana_fp8.scale"]], "neural_compressor.torch.algorithms.habana_fp8.tensor": [[580, "module-neural_compressor.torch.algorithms.habana_fp8.tensor"]], "neural_compressor.torch.algorithms": [[581, "module-neural_compressor.torch.algorithms"]], "neural_compressor.torch.algorithms.layer_wise": [[582, "module-neural_compressor.torch.algorithms.layer_wise"]], "load() (in module neural_compressor.torch.algorithms.layer_wise.load)": [[583, "neural_compressor.torch.algorithms.layer_wise.load.load"]], "neural_compressor.torch.algorithms.layer_wise.load": [[583, "module-neural_compressor.torch.algorithms.layer_wise.load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[584, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"]], "dowload_hf_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.dowload_hf_model"]], "get_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.get_children"]], "get_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.get_module"]], "get_named_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.get_named_children"]], "get_super_module_by_name() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.get_super_module_by_name"]], "load_empty_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.load_empty_model"]], "load_layer_wise_quantized_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.load_layer_wise_quantized_model"]], "load_tensor() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.load_tensor"]], "load_tensor_from_shard() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_shard"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[585, "module-neural_compressor.torch.algorithms.layer_wise.utils"]], "update_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[585, "neural_compressor.torch.algorithms.layer_wise.utils.update_module"]], "halfprecisionconverter (class in neural_compressor.torch.algorithms.mix_precision.half_precision_convert)": [[586, "neural_compressor.torch.algorithms.mix_precision.half_precision_convert.HalfPrecisionConverter"]], "neural_compressor.torch.algorithms.mix_precision.half_precision_convert": [[586, "module-neural_compressor.torch.algorithms.mix_precision.half_precision_convert"]], "neural_compressor.torch.algorithms.mix_precision": [[587, "module-neural_compressor.torch.algorithms.mix_precision"]], "halfprecisionmodulewrapper (class in neural_compressor.torch.algorithms.mix_precision.module_wrappers)": [[588, "neural_compressor.torch.algorithms.mix_precision.module_wrappers.HalfPrecisionModuleWrapper"]], "neural_compressor.torch.algorithms.mix_precision.module_wrappers": [[588, "module-neural_compressor.torch.algorithms.mix_precision.module_wrappers"]], "neural_compressor.torch.algorithms.mx_quant": [[589, "module-neural_compressor.torch.algorithms.mx_quant"]], "mxquantizer (class in neural_compressor.torch.algorithms.mx_quant.mx)": [[590, "neural_compressor.torch.algorithms.mx_quant.mx.MXQuantizer"]], "neural_compressor.torch.algorithms.mx_quant.mx": [[590, "module-neural_compressor.torch.algorithms.mx_quant.mx"]], "elemformat (class in neural_compressor.torch.algorithms.mx_quant.utils)": [[591, "neural_compressor.torch.algorithms.mx_quant.utils.ElemFormat"]], "roundingmode (class in neural_compressor.torch.algorithms.mx_quant.utils)": [[591, "neural_compressor.torch.algorithms.mx_quant.utils.RoundingMode"]], "neural_compressor.torch.algorithms.mx_quant.utils": [[591, "module-neural_compressor.torch.algorithms.mx_quant.utils"]], "quantize_elemwise_op() (in module neural_compressor.torch.algorithms.mx_quant.utils)": [[591, "neural_compressor.torch.algorithms.mx_quant.utils.quantize_elemwise_op"]], "w8a8pt2equantizer (class in neural_compressor.torch.algorithms.pt2e_quant.core)": [[592, "neural_compressor.torch.algorithms.pt2e_quant.core.W8A8PT2EQuantizer"]], "neural_compressor.torch.algorithms.pt2e_quant.core": [[592, "module-neural_compressor.torch.algorithms.pt2e_quant.core"]], "get_half_precision_node_set() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[593, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.get_half_precision_node_set"]], "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter": [[593, "module-neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter"]], "pattern_factory() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[593, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.pattern_factory"]], "transformation() (in module neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter)": [[593, "neural_compressor.torch.algorithms.pt2e_quant.half_precision_rewriter.transformation"]], "neural_compressor.torch.algorithms.pt2e_quant": [[594, "module-neural_compressor.torch.algorithms.pt2e_quant"]], "neural_compressor.torch.algorithms.smooth_quant": [[595, "module-neural_compressor.torch.algorithms.smooth_quant"]], "neural_compressor.torch.algorithms.smooth_quant.save_load": [[596, "module-neural_compressor.torch.algorithms.smooth_quant.save_load"]], "recover_model_from_json() (in module neural_compressor.torch.algorithms.smooth_quant.save_load)": [[596, "neural_compressor.torch.algorithms.smooth_quant.save_load.recover_model_from_json"]], "smoothquantquantizer (class in neural_compressor.torch.algorithms.smooth_quant.smooth_quant)": [[597, "neural_compressor.torch.algorithms.smooth_quant.smooth_quant.SmoothQuantQuantizer"]], "neural_compressor.torch.algorithms.smooth_quant.smooth_quant": [[597, "module-neural_compressor.torch.algorithms.smooth_quant.smooth_quant"]], "torchsmoothquant (class in neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.TorchSmoothQuant"]], "check_cfg_and_qconfig() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.check_cfg_and_qconfig"]], "get_module() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.get_module"]], "get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.get_quantizable_ops_recursively"]], "neural_compressor.torch.algorithms.smooth_quant.utility": [[598, "module-neural_compressor.torch.algorithms.smooth_quant.utility"]], "register_autotune() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.register_autotune"]], "reshape_in_channel_to_last() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.reshape_in_channel_to_last"]], "reshape_scale_as_input() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.reshape_scale_as_input"]], "reshape_scale_as_weight() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.reshape_scale_as_weight"]], "set_module() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.set_module"]], "update_sq_scale() (in module neural_compressor.torch.algorithms.smooth_quant.utility)": [[598, "neural_compressor.torch.algorithms.smooth_quant.utility.update_sq_scale"]], "neural_compressor.torch.algorithms.static_quant": [[599, "module-neural_compressor.torch.algorithms.static_quant"]], "neural_compressor.torch.algorithms.static_quant.save_load": [[600, "module-neural_compressor.torch.algorithms.static_quant.save_load"]], "staticquantquantizer (class in neural_compressor.torch.algorithms.static_quant.static_quant)": [[601, "neural_compressor.torch.algorithms.static_quant.static_quant.StaticQuantQuantizer"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[601, "module-neural_compressor.torch.algorithms.static_quant.static_quant"]], "statistics (class in neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.Statistics"]], "transformerbasedmodelblockpatterndetector (class in neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.TransformerBasedModelBlockPatternDetector"]], "check_cfg_and_qconfig() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.check_cfg_and_qconfig"]], "dump_model_op_stats() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.dump_model_op_stats"]], "generate_activation_observer() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.generate_activation_observer"]], "get_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.get_depth"]], "get_dict_at_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.get_dict_at_depth"]], "get_element_under_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.get_element_under_depth"]], "get_quantizable_ops_from_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_from_cfgs"]], "get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_recursively"]], "neural_compressor.torch.algorithms.static_quant.utility": [[602, "module-neural_compressor.torch.algorithms.static_quant.utility"]], "parse_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.parse_cfgs"]], "simple_inference() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[602, "neural_compressor.torch.algorithms.static_quant.utility.simple_inference"]], "autoroundquantizer (class in neural_compressor.torch.algorithms.weight_only.autoround)": [[603, "neural_compressor.torch.algorithms.weight_only.autoround.AutoRoundQuantizer"]], "get_autoround_default_run_fn() (in module neural_compressor.torch.algorithms.weight_only.autoround)": [[603, "neural_compressor.torch.algorithms.weight_only.autoround.get_autoround_default_run_fn"]], "neural_compressor.torch.algorithms.weight_only.autoround": [[603, "module-neural_compressor.torch.algorithms.weight_only.autoround"]], "awqquantizer (class in neural_compressor.torch.algorithms.weight_only.awq)": [[604, "neural_compressor.torch.algorithms.weight_only.awq.AWQQuantizer"]], "neural_compressor.torch.algorithms.weight_only.awq": [[604, "module-neural_compressor.torch.algorithms.weight_only.awq"]], "gptq (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.GPTQ"]], "gptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.GPTQuantizer"]], "rawgptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.RAWGPTQuantizer"]], "find_layers() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.find_layers"]], "find_layers_name() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.find_layers_name"]], "is_leaf() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.is_leaf"]], "log_quantizable_layers_per_transformer() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.log_quantizable_layers_per_transformer"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[605, "module-neural_compressor.torch.algorithms.weight_only.gptq"]], "quantize() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.quantize"]], "trace_gptq_target_blocks() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[605, "neural_compressor.torch.algorithms.weight_only.gptq.trace_gptq_target_blocks"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[606, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"]], "hqqmoduleconfig (class in neural_compressor.torch.algorithms.weight_only.hqq.config)": [[607, "neural_compressor.torch.algorithms.weight_only.hqq.config.HQQModuleConfig"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[607, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[608, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[609, "module-neural_compressor.torch.algorithms.weight_only.hqq"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[610, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[611, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"]], "hqquantizer (class in neural_compressor.torch.algorithms.weight_only.hqq.quantizer)": [[612, "neural_compressor.torch.algorithms.weight_only.hqq.quantizer.HQQuantizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[612, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"]], "dump_elapsed_time() (in module neural_compressor.torch.algorithms.weight_only.hqq.utility)": [[613, "neural_compressor.torch.algorithms.weight_only.hqq.utility.dump_elapsed_time"]], "neural_compressor.torch.algorithms.weight_only.hqq.utility": [[613, "module-neural_compressor.torch.algorithms.weight_only.hqq.utility"]], "neural_compressor.torch.algorithms.weight_only": [[614, "module-neural_compressor.torch.algorithms.weight_only"]], "fakeaffinetensorquantfunction (class in neural_compressor.torch.algorithms.weight_only.modules)": [[615, "neural_compressor.torch.algorithms.weight_only.modules.FakeAffineTensorQuantFunction"]], "mullinear (class in neural_compressor.torch.algorithms.weight_only.modules)": [[615, "neural_compressor.torch.algorithms.weight_only.modules.MulLinear"]], "teqlinearfakequant (class in neural_compressor.torch.algorithms.weight_only.modules)": [[615, "neural_compressor.torch.algorithms.weight_only.modules.TEQLinearFakeQuant"]], "neural_compressor.torch.algorithms.weight_only.modules": [[615, "module-neural_compressor.torch.algorithms.weight_only.modules"]], "rtnquantizer (class in neural_compressor.torch.algorithms.weight_only.rtn)": [[616, "neural_compressor.torch.algorithms.weight_only.rtn.RTNQuantizer"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[616, "module-neural_compressor.torch.algorithms.weight_only.rtn"]], "neural_compressor.torch.algorithms.weight_only.save_load": [[617, "module-neural_compressor.torch.algorithms.weight_only.save_load"]], "tequantizer (class in neural_compressor.torch.algorithms.weight_only.teq)": [[618, "neural_compressor.torch.algorithms.weight_only.teq.TEQuantizer"]], "trainableequivalenttransformation (class in neural_compressor.torch.algorithms.weight_only.teq)": [[618, "neural_compressor.torch.algorithms.weight_only.teq.TrainableEquivalentTransformation"]], "neural_compressor.torch.algorithms.weight_only.teq": [[618, "module-neural_compressor.torch.algorithms.weight_only.teq"]], "fetch_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.fetch_module"]], "get_absorb_layers() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.get_absorb_layers"]], "get_block_prefix() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.get_block_prefix"]], "get_example_input() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.get_example_input"]], "get_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.get_module"]], "get_module_input_output() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.get_module_input_output"]], "neural_compressor.torch.algorithms.weight_only.utility": [[619, "module-neural_compressor.torch.algorithms.weight_only.utility"]], "qdq_weight_actor() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_actor"]], "qdq_weight_asym() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_asym"]], "qdq_weight_sym() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_sym"]], "quant_tensor() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.quant_tensor"]], "quant_weight_w_scale() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.quant_weight_w_scale"]], "quantize_4bit() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.quantize_4bit"]], "recover_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.recover_forward"]], "replace_forward() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.replace_forward"]], "search_clip() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.search_clip"]], "set_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[619, "neural_compressor.torch.algorithms.weight_only.utility.set_module"]], "autocast (class in neural_compressor.torch.amp.autocast)": [[620, "neural_compressor.torch.amp.autocast.autocast"]], "neural_compressor.torch.amp.autocast": [[620, "module-neural_compressor.torch.amp.autocast"]], "neural_compressor.torch.amp.fp8.functions": [[621, "module-neural_compressor.torch.amp.fp8.functions"]], "neural_compressor.torch.amp.fp8": [[622, "module-neural_compressor.torch.amp.fp8"]], "neural_compressor.torch.amp": [[623, "module-neural_compressor.torch.amp"]], "export_model_for_pt2e_quant() (in module neural_compressor.torch.export._export)": [[624, "neural_compressor.torch.export._export.export_model_for_pt2e_quant"]], "neural_compressor.torch.export._export": [[624, "module-neural_compressor.torch.export._export"]], "neural_compressor.torch.export": [[625, "module-neural_compressor.torch.export"]], "neural_compressor.torch": [[626, "module-neural_compressor.torch"]], "neural_compressor.torch.quantization.algorithm_entry": [[627, "module-neural_compressor.torch.quantization.algorithm_entry"]], "rtn_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[627, "neural_compressor.torch.quantization.algorithm_entry.rtn_entry"]], "autotune() (in module neural_compressor.torch.quantization.autotune)": [[628, "neural_compressor.torch.quantization.autotune.autotune"]], "neural_compressor.torch.quantization.autotune": [[628, "module-neural_compressor.torch.quantization.autotune"]], "gptqconfig (class in neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.GPTQConfig"]], "hqqconfig (class in neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.HQQConfig"]], "rtnconfig (class in neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.RTNConfig"]], "get_default_gptq_config() (in module neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.get_default_gptq_config"]], "get_default_hqq_config() (in module neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.get_default_hqq_config"]], "get_default_rtn_config() (in module neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.get_default_rtn_config"]], "get_woq_tuning_config() (in module neural_compressor.torch.quantization.config)": [[629, "neural_compressor.torch.quantization.config.get_woq_tuning_config"]], "neural_compressor.torch.quantization.config": [[629, "module-neural_compressor.torch.quantization.config"]], "neural_compressor.torch.quantization": [[630, "module-neural_compressor.torch.quantization"]], "neural_compressor.torch.quantization.load_entry": [[631, "module-neural_compressor.torch.quantization.load_entry"]], "convert() (in module neural_compressor.torch.quantization.quantize)": [[632, "neural_compressor.torch.quantization.quantize.convert"]], "neural_compressor.torch.quantization.quantize": [[632, "module-neural_compressor.torch.quantization.quantize"]], "prepare() (in module neural_compressor.torch.quantization.quantize)": [[632, "neural_compressor.torch.quantization.quantize.prepare"]], "quantize() (in module neural_compressor.torch.quantization.quantize)": [[632, "neural_compressor.torch.quantization.quantize.quantize"]], "auto_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[633, "neural_compressor.torch.utils.auto_accelerator.Auto_Accelerator"]], "cpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[633, "neural_compressor.torch.utils.auto_accelerator.CPU_Accelerator"]], "cuda_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[633, "neural_compressor.torch.utils.auto_accelerator.CUDA_Accelerator"]], "hpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[633, "neural_compressor.torch.utils.auto_accelerator.HPU_Accelerator"]], "xpu_accelerator (class in neural_compressor.torch.utils.auto_accelerator)": [[633, "neural_compressor.torch.utils.auto_accelerator.XPU_Accelerator"]], "neural_compressor.torch.utils.auto_accelerator": [[633, "module-neural_compressor.torch.utils.auto_accelerator"]], "register_accelerator() (in module neural_compressor.torch.utils.auto_accelerator)": [[633, "neural_compressor.torch.utils.auto_accelerator.register_accelerator"]], "neural_compressor.torch.utils.constants": [[634, "module-neural_compressor.torch.utils.constants"]], "neural_compressor.torch.utils.environ": [[635, "module-neural_compressor.torch.utils.environ"]], "neural_compressor.torch.utils": [[636, "module-neural_compressor.torch.utils"]], "fetch_module() (in module neural_compressor.torch.utils.utility)": [[637, "neural_compressor.torch.utils.utility.fetch_module"]], "get_quantizer() (in module neural_compressor.torch.utils.utility)": [[637, "neural_compressor.torch.utils.utility.get_quantizer"]], "neural_compressor.torch.utils.utility": [[637, "module-neural_compressor.torch.utils.utility"]], "postprocess_model() (in module neural_compressor.torch.utils.utility)": [[637, "neural_compressor.torch.utils.utility.postprocess_model"]], "register_algo() (in module neural_compressor.torch.utils.utility)": [[637, "neural_compressor.torch.utils.utility.register_algo"]], "set_module() (in module neural_compressor.torch.utils.utility)": [[637, "neural_compressor.torch.utils.utility.set_module"]], "callbacks (class in neural_compressor.training)": [[638, "neural_compressor.training.CallBacks"]], "compressionmanager (class in neural_compressor.training)": [[638, "neural_compressor.training.CompressionManager"]], "fit() (in module neural_compressor.training)": [[638, "neural_compressor.training.fit"]], "neural_compressor.training": [[638, "module-neural_compressor.training"]], "prepare_compression() (in module neural_compressor.training)": [[638, "neural_compressor.training.prepare_compression"]], "layerhistogramcollector (class in neural_compressor.utils.collect_layer_histogram)": [[639, "neural_compressor.utils.collect_layer_histogram.LayerHistogramCollector"]], "neural_compressor.utils.collect_layer_histogram": [[639, "module-neural_compressor.utils.collect_layer_histogram"]], "neural_compressor.utils.constant": [[640, "module-neural_compressor.utils.constant"]], "create_dataloader() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.create_dataloader"]], "create_dataset() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.create_dataset"]], "create_eval_func() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.create_eval_func"]], "create_train_func() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.create_train_func"]], "get_algorithm() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.get_algorithm"]], "get_func_from_config() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.get_func_from_config"]], "get_metrics() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.get_metrics"]], "get_postprocess() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.get_postprocess"]], "get_preprocess() (in module neural_compressor.utils.create_obj_from_config)": [[641, "neural_compressor.utils.create_obj_from_config.get_preprocess"]], "neural_compressor.utils.create_obj_from_config": [[641, "module-neural_compressor.utils.create_obj_from_config"]], "neural_compressor.utils": [[642, "module-neural_compressor.utils"]], "kl_divergence (class in neural_compressor.utils.kl_divergence)": [[643, "neural_compressor.utils.kl_divergence.KL_Divergence"]], "neural_compressor.utils.kl_divergence": [[643, "module-neural_compressor.utils.kl_divergence"]], "optimizedmodel (class in neural_compressor.utils.load_huggingface)": [[644, "neural_compressor.utils.load_huggingface.OptimizedModel"]], "export_compressed_model() (in module neural_compressor.utils.load_huggingface)": [[644, "neural_compressor.utils.load_huggingface.export_compressed_model"]], "neural_compressor.utils.load_huggingface": [[644, "module-neural_compressor.utils.load_huggingface"]], "save_for_huggingface_upstream() (in module neural_compressor.utils.load_huggingface)": [[644, "neural_compressor.utils.load_huggingface.save_for_huggingface_upstream"]], "logger (class in neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.Logger"]], "debug() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.debug"]], "error() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.error"]], "fatal() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.fatal"]], "info() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.info"]], "log() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.log"]], "neural_compressor.utils.logger": [[645, "module-neural_compressor.utils.logger"]], "warn() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.warn"]], "warning() (in module neural_compressor.utils.logger)": [[645, "neural_compressor.utils.logger.warning"]], "get_model_path() (in module neural_compressor.utils.neural_insights_utils)": [[646, "neural_compressor.utils.neural_insights_utils.get_model_path"]], "neural_compressor.utils.neural_insights_utils": [[646, "module-neural_compressor.utils.neural_insights_utils"]], "register_neural_insights_workload() (in module neural_compressor.utils.neural_insights_utils)": [[646, "neural_compressor.utils.neural_insights_utils.register_neural_insights_workload"]], "update_neural_insights_workload() (in module neural_compressor.utils.neural_insights_utils)": [[646, "neural_compressor.utils.neural_insights_utils.update_neural_insights_workload"]], "update_neural_insights_workload_accuracy_data() (in module neural_compressor.utils.neural_insights_utils)": [[646, "neural_compressor.utils.neural_insights_utils.update_neural_insights_workload_accuracy_data"]], "neural_compressor.utils.options": [[647, "module-neural_compressor.utils.options"]], "onnxrt (class in neural_compressor.utils.options)": [[647, "neural_compressor.utils.options.onnxrt"]], "is_int8_model() (in module neural_compressor.utils.pytorch)": [[648, "neural_compressor.utils.pytorch.is_int8_model"]], "load() (in module neural_compressor.utils.pytorch)": [[648, "neural_compressor.utils.pytorch.load"]], "load_weight_only() (in module neural_compressor.utils.pytorch)": [[648, "neural_compressor.utils.pytorch.load_weight_only"]], "neural_compressor.utils.pytorch": [[648, "module-neural_compressor.utils.pytorch"]], "recover_model_from_json() (in module neural_compressor.utils.pytorch)": [[648, "neural_compressor.utils.pytorch.recover_model_from_json"]], "captureoutputtofile (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.CaptureOutputToFile"]], "cpuinfo (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.CpuInfo"]], "dequantize() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.Dequantize"]], "dotdict (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.DotDict"]], "global_state (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.GLOBAL_STATE"]], "lazyimport (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.LazyImport"]], "mode (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.MODE"]], "opentry (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.OpEntry"]], "statistics (class in neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.Statistics"]], "alias_param() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.alias_param"]], "calculate_mse() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.calculate_mse"]], "check_key_exist() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.check_key_exist"]], "combine_histogram() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.combine_histogram"]], "compare_objects() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.compare_objects"]], "compute_sparsity() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.compute_sparsity"]], "dequantize_weight() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.dequantize_weight"]], "dump_class_attrs() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.dump_class_attrs"]], "dump_data_to_local() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.dump_data_to_local"]], "dump_elapsed_time() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.dump_elapsed_time"]], "dump_table() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.dump_table"]], "dump_table_to_csv() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.dump_table_to_csv"]], "equal_dicts() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.equal_dicts"]], "fault_tolerant_file() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.fault_tolerant_file"]], "get_all_fp32_data() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_all_fp32_data"]], "get_number_of_sockets() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_number_of_sockets"]], "get_op_list() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_op_list"]], "get_size() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_size"]], "get_tensor_histogram() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_tensor_histogram"]], "get_tensors_info() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_tensors_info"]], "get_tuning_history() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_tuning_history"]], "get_weights_details() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.get_weights_details"]], "load_data_from_pkl() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.load_data_from_pkl"]], "mse_metric_gap() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.mse_metric_gap"]], "neural_compressor.utils.utility": [[649, "module-neural_compressor.utils.utility"]], "print_op_list() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.print_op_list"]], "print_table() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.print_table"]], "recover() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.recover"]], "set_random_seed() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.set_random_seed"]], "set_resume_from() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.set_resume_from"]], "set_tensorboard() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.set_tensorboard"]], "set_workspace() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.set_workspace"]], "show_memory_info() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.show_memory_info"]], "singleton() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.singleton"]], "str2array() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.str2array"]], "time_limit() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.time_limit"]], "version1_eq_version2() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.utils.utility)": [[649, "neural_compressor.utils.utility.version1_lte_version2"]], "weightsdetails (class in neural_compressor.utils.weights_details)": [[650, "neural_compressor.utils.weights_details.WeightsDetails"]], "weightsstatistics (class in neural_compressor.utils.weights_details)": [[650, "neural_compressor.utils.weights_details.WeightsStatistics"]], "neural_compressor.utils.weights_details": [[650, "module-neural_compressor.utils.weights_details"]], "neural_compressor.version": [[651, "module-neural_compressor.version"]]}})